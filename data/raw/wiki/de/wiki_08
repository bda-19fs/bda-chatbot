{"id": "1472630", "url": "https://de.wikipedia.org/wiki?curid=1472630", "title": "MacBook", "text": "MacBook\n\nDas MacBook ist ein Notebook der Firma Apple. Das erste Modell wurde am 16. Mai 2006 vorgestellt und war das Nachfolgemodell der beiden PowerPC-basierten iBooks und des 12″-PowerBooks. Das ursprüngliche MacBook war mit einem Intel-Core-Duo- und später einem Intel-Core-2-Duo-Prozessor ausgestattet und hatte ein 13 Zoll großes Display. Am 20. Juli 2011 wurde der Verkauf des MacBooks weitgehend eingestellt (gilt nicht für das MacBook Pro), bis Februar 2012 war es noch für Bildungseinrichtungen erhältlich. Das MacBook Air ersetzte das MacBook fortan als das günstigste Einstiegsmodell. Im März 2015 wurde der Name \"MacBook\" von Apple wiederbelebt, wobei das neue Gerät bis auf den Namen kaum Gemeinsamkeiten mit dem von 2006 bis 2011 produzierten Gerät hat.\n\nDie Standardausführung des MacBooks umfasste zuletzt eine 2,4-GHz-CPU mit 2 GB RAM (2 × 1 GB) in Weiß mit \"SuperDrive\" und 250-GB-Festplatte.\n\nMacBooks der ersten Revision enthielten einen Intel Core Duo, solche der zweiten und dritten Revision (seit 8. November 2006 und 15. Mai 2007) einen Core-2-Duo-Prozessor. Bei der vierten Revision vom 1. November 2007 wurden CPUs mit bis zu 2,2 GHz und der Grafikchip Intel GMA X3100 mit 144 MB Shared Memory verbaut. Die letzte Änderung an der Ausstattung (Revision 5) erfolgte am 26. Februar 2008. Dabei wurden die Taktraten erhöht und die Ausstattung an RAM und Festplattenspeicher verbessert.\n\nAlle MacBooks verfügten über die integrierte iSight-Kamera, eine Stromversorgung mit MagSafe-Anschluss – ein magnetisches Verschlusssystem – AirPort Extreme und Bluetooth. Der separate Grafikprozessor (GPU) im iBook/PowerBook 12″ wurde zunächst durch die integrierte Grafik des Chipsatzes Intel GMA 950 mit 64 MB DDR2 SDRAM (Shared Memory) ersetzt, später wurde der wesentlich leistungsstärkere Intel GMA X 3100 verbaut (144 MB RAM). Das MacBook wurde mit der Software iLife, Front Row, Photo Booth, diversen anderen Programmen und dem Betriebssystem Mac OS X Snow Leopard ausgeliefert. Der integrierte TFT-Bildschirm hatte eine Diagonale von 13,3″ und war hochglänzend, 79 % heller und verfügte über eine 30 % höhere Auflösung als der des alten iBooks.\n\nUm die volle Leistung von CPU und GPU nutzen zu können, empfiehlt Apple die Bestückung der RAM-Steckplätze mit Paaren gleicher Module (2 × 1 GB werksseitig). Unabhängige Tests ergaben für die Core-2-Duo-Modelle, dass die Verwendung ungleicher RAM-Bausteine kaum mit wesentlichen Einschränkungen verbunden ist.\n\nDie schwarze Variante des MacBooks war serienmäßig mit einer größeren Festplatte ausgestattet (in der dritten Revision 160 GB statt 120 GB). Der ausstattungsbereinigte Kaufpreis liegt ca. 120 € bzw. 200 CHF über dem eines technisch identischen MacBooks in Weiß. Seit dem 1. November 2007 konnte zudem als größte Kapazität eine 250-GB-Festplatte (5400/min) ausgewählt werden.\n\nEinige frühe MacBook-Modelle mit Polycarbonat-Gehäuse wiesen das sogenannte „Random Shutdown Syndrome“ auf – die betroffenen Modelle gingen eigenständig und ohne Vorwarnung einfach aus. Das Problem wurde durch einen Austausch der Kühlkörper im Gehäuseinneren sowie Firmware-Updates behoben.\nWeiter traten selbst bei normaler Benutzung des Geräts häufig Haarrisse im Gehäuse auf, das schließlich sogar brechen konnte. Daher initiierte Apple für die betroffenen Geräte eine Garantie-Erweiterung. Auch bei der neueren Polycarbonat-Unibody-Variante gibt es mittlerweile Beschwerden von Nutzern im Internet, die von Haarrissen in den MacBook-Gehäusen berichten. Häufig treten diese Haarrisse im Bereich der Displayscharniere auf.\nIm Februar 2010 kündigte Apple ein weiteres Austauschprogramm für zahlreiche von Festplattendefekten betroffene MacBooks an; diese Defekte wurden unter anderem durch eine zu hohe Hitzeentwicklung der Geräte verursacht.\n\nDas MacBook ersetzte neben dem 12″-PowerBook in erster Linie die beiden iBook-Modelle, wobei abgesehen von der weißen Farbgebung und den verwendeten Materialien auch das Design des 13″-MacBooks weitgehend neu war. Es erscheint insgesamt schlichter, da einige Elemente aus dem Blickfeld des Benutzers entfernt wurden. So wurden beispielsweise die Lautsprecheröffnungen an die Gehäuserückseite verlegt, und der neue magnetische Verschlussmechanismus ist nun im Inneren des Gehäuses verborgen.\n\nGegenüber seinen Vorgängern ist das MacBook mit einer Höhe von 2,75 cm nochmals dünner geworden und hat mit dem breitformatigen 13″-Bildschirm ein neues Format erhalten. Auch die Tastatur wurde umfassend überarbeitet und ist nun vollkommen in das Gehäuse integriert.\n\nDer zwangsweise hochglänzende Bildschirm sorgt teilweise für negative Resonanz. Einerseits bietet er eine höhere Helligkeit, brillantere Farben und eine schärfere Darstellung, führt andererseits aber bei Gebrauch unter freiem Himmel oder in Büroumgebungen mit flächigen Deckenbeleuchtungen zu unerwünschten Reflexionen.\n\nDie integrierte GPU Intel GMA X3100 senkt die Herstellungskosten für das MacBook. Auch verbraucht der Grafikchip weniger Strom als die meisten ATI- und Nvidia-Chipsätze, wodurch die Akkulaufzeit höher ist. Dadurch bedingt, erzeugt er weniger Abwärme, so dass die Grafikeinheit ohne Lüfter auskommt.\n\nAllerdings verwendet er einen Teil (bis zu 144 MB) des RAM des MacBooks (Shared Memory). Dadurch und wegen der allgemeinen Leistungsschwäche des GMA X3100 im Vergleich mit anderen mobilen Grafiklösungen kommt es zu Leistungseinbußen bei grafikintensiven Programmen (3D-Imaging und modernen 3D-Computerspielen).\n\nBeim Grafikausgang handelt es sich um einen Mini-DVI-Anschluss, der über verschiedene, optional erhältliche Adapter einen VGA-Ausgang, einen DVI-Ausgang sowie TV-Out und S-Video-Ausgang bereitstellt.\n\nSeit Oktober 2008 ist statt des Intel GMA X3100 mit Mini-DVI-Anschluss ein Nvidia Geforce 9400 M mit Mini-Displayport-Anschluss verbaut. Der Grafikchip nutzt 256 MB des Hauptspeichers und soll laut Apple die fünffache Leistung gegenüber dem Intel-Chip bieten.\n\nIm Gegensatz zu früheren Apple-Notebooks war das MacBook teilweise leichter zu erweitern und eigenen Bedürfnissen anzupassen – so konnte die Festplatte unkompliziert ausgetauscht werden. Andererseits aber waren die Speicher-Steckplätze bei den neueren MacBooks nur nach Aufschrauben der unteren Abdeckung erreichbar.\n\nErweiterbarkeit via Steckkarten blieb dem MacBook Pro vorbehalten, dieses hat einen ExpressCard/34-Slot. Das MacBook war laut Hersteller auf maximal 4 GB Hauptspeicher erweiterbar, die Version mit Intel 965-Chipsatz bot jedoch theoretisch die Möglichkeit, auf bis 8 GB erweitert zu werden. Speicher über 3,3 GB ist allerdings nur mit einer 64-bit-Firmware und ab Mac OS X Leopard nutzbar.\n\nlinke Gehäuseseite:\n\nLegende: \n\n\n\n\"→ Hauptartikel: \"\n\nAm 20. Oktober 2009 stellte Apple eine neue Version des weißen MacBooks vor. Es bekam ein neu entwickeltes „Unibody“-Gehäuse aus weißem Polycarbonat. Die Spezifikationen sind weitestgehend identisch mit denen des Aluminium Unibody MacBooks.\n\n\nDie erste Version des weißen Unibody MacBooks wurde seit dem 21. Januar 2009 auch zunächst mit der Nvidia-GeForce-9400M-Grafik ausgeliefert. Im April 2010 wurde in dem zweiten Modell dieser Generation die leistungsstärkere Nvidia-GeForce-320M eingesetzt.\n\nLegende: \n\nApple überarbeitet das Polycarbonat-Unibody nochmals. Details:\n\nDas weiße MacBook war seit der Vorstellung der neuen MacBook-Air-Modelle im Juli 2011 für Endkunden nicht mehr erhältlich. Zu einem ähnlichen Preis wie zuvor beim MacBook wurde das Einstiegsmodell des MacBook Air mit 11″-Display, 1,6 GHz-Intel Core i5, 64 GB-SSD und 2 GB Arbeitsspeicher angeboten. Für Bildungseinrichtungen war das Gerät jedoch zunächst weiterhin erhältlich, bis es im Februar 2012 endgültig eingestellt wurde.\n\n"}
{"id": "1473512", "url": "https://de.wikipedia.org/wiki?curid=1473512", "title": "Internet World Business", "text": "Internet World Business\n\nInternet World Business ist eine 14-täglich erscheinende Fachzeitung des Verlags „Neue Mediengesellschaft Ulm mbH“ (mit Sitz in München), die erstmals im Oktober 2005 erschien. Sie ist aus der monatlich erscheinenden Fachzeitschrift „Internet World“ hervorgegangen.\n\nInternet World Business ist eine Business-to-Business-Zeitung, die sich an Leser wendet, welche im Internet etwas vermarkten oder verkaufen wollen. Themenschwerpunkte sind unter anderem Online-Marketing, Webshop-Systeme, Online-Zahlungsabwicklung, E-Commerce, Studien und Trends rund um das Internet, Internetrecht und Berichte aus der Internet-Wirtschaft.\n\nDie Zeitschrift hat eine verbreitete Auflage von 16.857 Exemplaren (Stand: IVW II/2010) und ist ausschließlich im Abonnement erhältlich. Chefredakteur der Publikation ist derzeit Günter Götz, nachdem Dominik Grollmann im April 2013 abberufen wurde.\n\nUnter dem Titel der Internet World wird seit 1997 jährlich auch eine Fachmesse mit Kongress ausgerichtet. Der thematische Schwerpunkt ist an die Inhalte der Fachzeitung angelehnt.\n\n"}
{"id": "1475748", "url": "https://de.wikipedia.org/wiki?curid=1475748", "title": "Cars (Film)", "text": "Cars (Film)\n\nCars ist ein Animationsfilm von Pixar aus dem Jahre 2006. Es ist der erste Film, an dem Regisseur John Lasseter seit \"Toy Story 2\" (1999) wieder als Regisseur und nicht nur als Produzent mitgearbeitet hat. Offizieller Kinostart in Deutschland war der 7. September 2006.\n\nIn „Cars“ sind alle Charaktere Autos, die sich wie Menschen bzw. Tiere benehmen. Menschen kommen im Film nicht vor. Am 28. Juli 2011 erschien in Deutschland die Fortsetzung des Filmes, \"Cars 2\". Darüber hinaus entstanden zwischen 2008 und 2011 unter dem Titel \"Cars Toon – Hooks unglaubliche Geschichten\" eine Reihe von computeranimierten Kurzgeschichten, die im Stil des Films gehalten sind und zum Teil als Vorfilm zu anderen Pixarproduktionen im Kino und im Fernsehen zu sehen waren bzw. sind. Der dritte Teil der Filmreihe kam 2017 unter dem Titel \"\" in die Kinos.\n\nNachdem es beim letzten Rennen um den „Piston Cup“ ein dreifaches Unentschieden gab, muss „Lightning McQueen“, ein sprechendes NASCAR-Auto (ist laut Mister „John Gunnell“ ein Trans Am), zu einem Entscheidungsrennen nach Los Angeles. Auf dem Weg wird er aber nachts von seinem Transport-Truck getrennt. Er muss somit allein nach Kalifornien finden. Orientierungslos (wie alle realen NASCAR-Autos hat er keine Scheinwerfer) landet er auf der Route 66 in „Radiator Springs“, wo er versehentlich die einzige Dorfstraße zerstört. Er wird dazu verurteilt, sie zu reparieren.\n\nWährend er damit beschäftigt ist, freundet er sich mit Hook (im Original: Mater), dem Abschleppwagen, an. Außerdem verliebt er sich in Sally, einen Porsche. Sie erklärt ihm, wie lebendig Radiator Springs früher war, durch eine neue Interstate aber alle Kundschaft verloren hat und von der Landkarte verschwunden ist. Sally war eine erfolgreiche Anwältin in L.A. Sie ist vor dem Großstadtleben geflüchtet und lebt hier wegen der beeindruckenden Landschaft. Es kommt auch zum Konflikt mit Doc Hudson, der früher selbst ein berühmter Rennwagen war. Nach einem schweren Unfall wurde er von seinem Rennstall nicht mehr akzeptiert, weshalb er Rennwagen wie Lightning zuerst mit Verachtung betrachtet. Als die Straße fertig ist, hat sich Lightning mit allen Bewohnern des Dorfes angefreundet und möchte eigentlich nicht mehr weg. Die Medien und sein Rennteam finden ihn aber wieder, da Doc Hudson sie angerufen hat, und holen ihn zu dem großen Rennen ab.\n\nWährend des Rennens ist Lightning zuerst unkonzentriert und liegt weit hinten, da er immer wieder an Radiator Springs zurückdenkt. Plötzlich stellt er aber fest, dass seine Freunde mit an der Box und ihm zur Seite stehen. Mit dieser Unterstützung geht er in Führung und ist nah dran zu gewinnen, als sein Konkurrent „King“, für den dies das letzte Rennen vor dem Ruhestand ist, aus dem Rennen geworfen wird. Statt den schon sicheren Sieg für sich in Anspruch zu nehmen, hält Lightning an und schiebt den stark beschädigten King über die Ziellinie, damit er sein letztes Rennen beenden kann. So verliert er zwar den Piston Cup, gewinnt jedoch den Respekt aller anderen Autos und verhindert, dass den King dasselbe Schicksal ereilt wie dereinst Doc Hudson.\n\nNachdem Lightning sein neues Rennhauptquartier in Radiator Springs eröffnet hat, wird auch der Ort wieder bekannt und beliebt. Zudem eröffnet er zusammen mit Sally das früher sehr beliebte Auto-Hotel „Wheel Well“ wieder.\n\nDie Synchronisation entstand im Auftrag der Film- & Fernseh-Synchron in München. Das Dialogbuch stammt von Benedikt Rabanus, welcher zusammen mit Kai Taschner Dialogregie führte.\n\nIn der österreichischen Kinofassung ist als Rennkommentator auch Heinz Prüller, der ehemalige Formel-1-Sportkommentator des ORF, zu hören.\n\nDie Filmmusik (engl. \"Score\") schrieb der Komponist Randy Newman. Folgende Stücke bilden den Soundtrack zu \"Cars\". Die Titel des deutschen Soundtracks stehen in Klammern.\n\n\n\n\nEs erschienen zwei Fortsetzungen des Films: \"Cars 2\" (2011) und \"\" (2017).\n\n"}
{"id": "1476402", "url": "https://de.wikipedia.org/wiki?curid=1476402", "title": "3D-Maus", "text": "3D-Maus\n\nEine 3D-Maus ist ein Eingabegerät (Befehlsgeber) für Computer. In den häufigsten Anwendungsfällen dient sie dazu, in einer virtuellen 3D-Umgebung Objekte zu bewegen oder sich selbst durch eine virtuelle 3D-Landschaft zu manövrieren. Interaktive Applikationen werden durch die Eingabe eines Benutzers gesteuert. Dafür stehen ihm folgende Medien zur Verfügung: Tastatur, (2D-)Maus, Joystick, Spaceball, Datenhandschuh, Spracheingabe, Bilderkennung und 3D-Maus.\n\nAuf einem stationären Untersatz ist flexibel ein Steuerkörper in Form einer Kugel oder eines Pucks angebracht. Schub- und Drehkräfte, die der Benutzer auf den Steuerkörper ausübt werden in Eingabebefehle umgesetzt. Ein solches System verfügt über drei translatorische und drei rotatorische Freiheitsgrade. „3D-Mäuse oder Steuerkugeln messen über den Federdruck eine statische Auslenkung für Position und Winkel einer Kugel, die von der Hand des Benutzers umschlossen wird. Die Auslenkungswege und -winkel sind sehr klein, so daß die Auflösung dieser Geräte begrenzt ist. Deshalb werden Steuerkugeln vorwiegend für Geschwindigkeitssteuerungen verwendet.“\n\nEine 3D-Maus – auch Spacemouse genannt – eignet sich als Zusatzgerät zur normalen Maus für die beidhändige Bedienung. Diese Form der Interaktion wird als besonders natürlich empfunden, wenn die dominante Hand relativ zur weniger dominanten Hand agiert. Die beidhändige Interaktionstechnik vermindert die kognitive Belastung des Anwenders. Bei immersiven Visualisierungssystemen dürfen die Eingabemedien den Anwender nicht von der virtuellen 3D-Umgebung ablenken. Auch die Bewegung des Nutzers sollte es nicht einschränken. Eingabegeräte sollen den Nutzerfokus nicht auf sich ziehen. Diese Kriterien werden von einer 3D-Maus erfüllt.\n\nDer Benutzer hält das Eingabegerät in seiner Hand und kann es frei im Raum bewegen. Über im Gerät integrierte oder externe Sensoren werden Position und Bewegung im Raum bestimmt. Kommen externe Sensoren zum Einsatz, spricht man von Tracking.\n\nDie Technologie wurde ab den 1970ern am Deutschen Zentrum für Luft- und Raumfahrt (DLR) vom Institut für Robotik und Mechatronik entwickelt, da man für die Steuerung von Robotern Eingabegeräte benötigte, die alle sechs Freiheitsgrade (DoF, engl. Degrees of Freedom) erfassen. In den 1980er Jahren gab es zeitgleich in Europa (1982) wie in den USA (1983) Patente, die ein Steuerungssystem beschrieben, bei dem die Kräfte und Momente durch eine Hohlkugel von der menschlichen Hand abgenommen wurden. Zeitgleich wurde in diesen Jahren im DLR am Institut für Robotik und Mechatronik an ähnlichen Konzepten zur Roboterbedienung unter der Bezeichnung \"Spacemouse\" gearbeitet.\n\nIm Laufe der 1980er Jahre etablierte sich dieses universelle 6D-Eingabegerät allerdings eher als Navigations- und Positionierungshilfe in virtuellen Szenarien, im Anwendungsbereich von 3D-Grafik und CAD-Anwendungen. Die Entwicklergruppe des DLR-Institutes erlangte dafür 1985 das internationale Patent.\n\n\n\n\n\n\nDer auf einem Untersatz befestigte Steuerkörper lässt sich in alle Richtungen um einige Millimeter ziehen, drücken, kippen und drehen. Er springt nach dem loslassen wie ein Joystick zurück in seine Ausgangsposition. Die Messung der sechs Komponenten (Translation und Rotation) erfolgt über reibungs- und verschleißfreie opto-elektronische Sensoren. Mehrere am Untersatz angebrachte Tasten können von Anwendungsprogrammen individuell belegt werden.\n\nDas Arbeiten im dreidimensionalen Raum ist mit einer gewöhnlichen Maus stark erschwert. Deshalb haben die Entwickler der freien 3D-Grafiksoftware Blender zusammen mit dem Unternehmen 3Dconnexion ein Plugin entworfen, das die kommerziell erhältliche 3D-Maus Spacenavigator in Blender einbindet.\n\n"}
{"id": "1481504", "url": "https://de.wikipedia.org/wiki?curid=1481504", "title": "Tandy TRS-80 Color Computer", "text": "Tandy TRS-80 Color Computer\n\nTandy TRS-80 Color Computer, auch CoCo genannt, ist eine Serie von Homecomputern, aus der TRS-80-Serie von Tandy RadioShack. Als Prozessor wurde ein Motorola 6809-E verwendet. Anders als sein Vorgänger konnte er Farbgrafik darstellen.\n\nDer Prozessor 6809 wurde mit 0,895 MHz getaktet und der Rechner hatte 4 KByte Hauptspeicher. Er war mit der Dragon 32-Serie teilkompatibel.\n\nDer Homecomputer wird an einen Fernseher oder Monitor angeschlossen und kann neun verschiedene Farben bei 64×32 Pixel darstellen. Die höchste Auflösung beträgt 256×192, die Darstellung reduziert sich dann auf monochrom. Er kostete anfangs 400 US-Dollar. Als Programmiersprache wurde Color BASIC eingesetzt. Zur Datenspeicherung diente eine Datasette oder ein 5¼-Zoll-Disketten-Laufwerk. Anders als beim TRS-80 Modell 1 gab es auch einen Erweiterungsschacht für Spielmodule.\n\nTechnisch ist er baugleich mit dem Modell 1. Das Gehäuse ist aber kleiner, das Betriebssystem modifiziert und es gab mehr Erweiterungsmöglichkeiten, sowie 16–64 KByte RAM.\n\nDer Preis betrug 240 US-Dollar und das Modell 2 wurde mit dem Multitasking-Betriebssystem OS-9 geliefert.\n\nDieser ist mit 128 KByte RAM ausgestattet (erweiterbar auf 512 KByte). Die Auflösung beträgt 640×225 Pixel bei 64 Farben.\n\nMit dem TRS-80 Color Computer konkurrierte Tandy zunächst gegen Commodores VC 20 und später den Commodore 64 und Atari 400. Der Erfolg war mäßig, vor allem das Modell 3 konnte sich nicht gegen andere 16-Bit-Computer wie den Amiga durchsetzen.\n\nTrotz des Misserfolgs gab es ca. über 1.000 Programme (sowohl Anwendungen als auch Spiele) für diesen Rechner.\n\nSiehe auch .\n\n"}
{"id": "1482166", "url": "https://de.wikipedia.org/wiki?curid=1482166", "title": "XULRunner", "text": "XULRunner\n\nXULRunner ist eine Laufzeitumgebung für Anwendungen, die auf der „XML User Interface Language“ (abgekürzt: XUL) aufsetzen. Sie wird von der Mozilla Foundation entwickelt. Das Programm nutzt dafür die Bibliothek \"libxul\" der Gecko-Engine. Alle XUL-basierten Anwendungen wie Mozilla Firefox, Mozilla Thunderbird oder der Medienspieler Songbird lassen sich auf XULRunner portieren. XULRunner stellt auch eine Umgebung für das Installieren, das Deployment (d. h. Verteilung und Installation, einschließlich Konfiguration), die Aktualisierung und das Deinstallieren dieser Anwendungen zur Verfügung.\n\nAnwendungen, welche die Gecko-Engine ohne die XULRunner-Laufzeitumgebung benötigen, verwenden die Bibliothek libxul, so zum Beispiel Galeon oder Liferea.\n\nDie erste „Developer-Preview“ von XULRunner wurde im Februar 2006 freigegeben. Die Mozilla Foundation plante, ihre XUL-Anwendungen wie Mozilla Firefox auf XULRunner zu portieren. Ein Vorteil, der sich daraus ergäbe, wäre, dass man nur einmal mit XULRunner eine XUL/Gecko-Laufzeitumgebung installieren müsste, die dann alle weiteren XUL-Anwendungen benutzen könnten. Bislang wurde für jedes einzelne Programm eine separate XUL/Gecko-Laufzeitumgebung installiert. Mozillas erste offiziell herausgegebene XULRunner-Anwendung war die Linux-Variante von Mozilla Firefox 3.0.\n\n"}
{"id": "1482658", "url": "https://de.wikipedia.org/wiki?curid=1482658", "title": "Foxit Reader", "text": "Foxit Reader\n\nFoxit Reader ist eine kostenlose Software für Windows, macOS und Linux zum Anzeigen von PDF-Dateien und somit eine Alternative zum weitverbreiteten Adobe Reader. Für alle Geräte mit Windows 10 und Smartphones und Tabletcomputer mit den Betriebssystemen Android oder iOS gibt es eigene Versionen unter dem Namen \"Foxit MobilePDF\".\n\nEntwickelt wird das Programm von der im US-Bundesstaat Kalifornien ansässigen Firma \"Foxit Corporation\". Eine größere Bekanntheit erreichte es vor allem nach dem Erscheinen der Version 6 des Adobe Reader, die von vielen Anwendern wegen der langen Ladezeiten kaum benötigter Plug-ins kritisiert wurde. Anders als z. B. Sumatra PDF ist Foxit Reader jedoch nicht quelloffen.\n\nFoxit Reader läuft unter Windows ab Vista, bis Version 4.x auch ab Windows 2000. Darüber hinaus gibt es Varianten für OS X und Linux. Im Gegensatz zum Adobe Reader muss Foxit Reader nicht installiert werden, weshalb er sich zum Ausführen auf Wechseldatenträgern eignet.\n\nWährend frühe Versionen relativ handlich waren (z. B. 3,6 MB in Version 3.0), ist die Datenmenge des Downloads, abhängig von der Variante, auf 29 bis 56 MB angewachsen und liegt damit deutlich über früher vergleichbaren Produkten wie z. B. Sumatra PDF mit knapp 5 MB. Im Vergleich zum Adobe Acrobat Reader DC, mit bis zu 142,9 MB für die OS-X-Variante, ist er aber immer noch erheblich kleiner und bietet inzwischen deutlich mehr Funktionen.\n\nZur Darstellung eingebetteter Bilder, die im JPEG-2000-Format komprimiert sind, ist ein kostenloses Plug-in erforderlich. Der Foxit Reader selbst ist erst ab Version 4 ausschließlich kostenlos.\n\nEin als \"FreeType\" bezeichnetes Feature ermöglicht es, Text an jeder beliebigen Stelle in ein PDF-Dokument einzufügen, auch dann, wenn vom Ersteller die Funktion „Formular ausfüllen“ nicht vorgesehen wurde. Weiterhin werden verschiedene Werkzeuge zum Kommentieren und Verarbeiten von Text geboten. So können Textpassagen markiert, unterstrichen, durchgestrichen oder ausgeblendet werden. Auch das Einfügen von Kommentarfeldern, Figuren, Mess- oder Freihandlinien ist möglich. Eine weitere Besonderheit ist die Fähigkeit, PDF-Dateien in Reintext umzuwandeln und abzuspeichern. Ab Version 2.1 kann Foxit Reader auch Formularfunktionen (Eingabe- und Auswahlfelder) in bestehende PDF-Dokumente integrieren.\n\nÄnderungen können entweder direkt im PDF abgespeichert werden, oder in einer separaten Änderungsdatei, was die Bearbeitung eines Dokuments durch verschiedene Personen erleichtert. Ein anderer Bearbeiter benötigt die Originaldatei und kann die Änderungsdatei dann importieren, weitere Änderungen machen, diese exportieren und weiterschicken. Auf diese Weise ist die gemeinsame Arbeit auch an sehr großen Dokumenten möglich, ohne diese jedes Mal vollständig versenden zu müssen.\n\nWerbung, die nach Anwendungsstart angezeigt wird, lässt sich dauerhaft unter \"Einstellungen→Allgemein\" abschalten.\n\nEbenso wie der Adobe Reader bietet Foxit Reader ein Browser-Plug-in, mit dem auf Wunsch PDF-Dokumente aus dem Web sofort im Browserfenster betrachtet werden können. Das Programm integriert sich in den Browser, sofern Foxit Reader als Standardprogramm für PDF-Dateien ausgewählt wurde.\n\nDer Foxit Reader ist auch als portable App verfügbar, mit der sich PDF-Dateien\nohne weitere Anpassungen oder Einrichtung (\"Installationen\") auf verschiedenen Rechnern, auch von einem Wechseldatenträger aus, ansehen und annotieren lassen.\n\nIn seiner wechselhaften Geschichte wurden Sicherheitsprobleme des Foxit-Readers namhaft. So sei mit Version 6.1.4 das Foxit-Installationsprogramm mit potenziell unerwünschten Programmen wie OpenCandy gebündelt gewesen, die die Browser-Hijacking--Malware Conduit installierten. Diese bösartigen Programme wurden nach Nutzer-Beschwerden erst mit Version 6.2.1 entfernt.\n\nIm Juli 2014 berichtete das mit Computersicherheit befasste Internet Storm Center, dass die mobile Version für das iPhone unverschlüsselte Telemetriedaten und andere Daten an entfernte Server in China weiterleitet, obschon Anwender versucht haben sollen, diese Datenerfassung zu unterbinden.\n\n\n"}
{"id": "1486504", "url": "https://de.wikipedia.org/wiki?curid=1486504", "title": "Ghemical", "text": "Ghemical\n\nGhemical ist eine Computerchemie-Software, die unter der GPL steht.\n\nGhemical wurde in der Programmiersprache C++ geschrieben. Die grafische Benutzeroberfläche nutzt das GUI-Toolkit GTK+ und die Grafikschnittstelle OpenGL.\nDas Programm unterstützt verschiedene Quantenchemische und statistisch-mechanische Methoden direkt, fungiert aber auch als Frontend für GAMESS. Moleküle lassen sich als 3D-Modell visualisieren.\n\n"}
{"id": "1486896", "url": "https://de.wikipedia.org/wiki?curid=1486896", "title": "Monitor (IT-Magazin)", "text": "Monitor (IT-Magazin)\n\nMonitor (Eigenbezeichnung: \"monitor\") ist ein österreichisches IKT-Monatsmagazin für Entscheider im Unternehmen, IT-Consulter, Selbständige und professionelle Anwender. Bei dieser Leserzielgruppe ist Monitor die meistgenutzte Informationsquelle für Neuheiten und Berichte aus den Bereichen Informationstechnologie und Telekommunikation sowie IT-Aus- und -Weiterbildung in Österreich. Neben den Monatsausgaben bieten Sonderausgaben Analysen und Marktüberblicke für den EDV-Einkauf und zeigen Trends auf.\n\nGegründet wurde das Magazin im Herbst 1983, Herausgeber ist Verlag Holzhausen GmbH. Chefredakteur ist Rudolf Felser.\n\nDie monatliche Druckauflage laut ÖAK im 1. Halbjahr 2017 betrug 12.000 Stück. \n\n"}
{"id": "1486935", "url": "https://de.wikipedia.org/wiki?curid=1486935", "title": "Kosmos CP1", "text": "Kosmos CP1\n\nDer Kosmos CP1 („Computer-Praxis“) war ein Lerncomputer, der ab 1983 von dem für seine Experimentierkästen bekannten Kosmos-Verlag hergestellt wurde. Er sollte die Reihe der Kosmos-Elektronikbaukästen auf den Bereich der Computertechnik erweitern.\n\nAls Prozessor ist ein mit 6 MHz getakteter Intel 8049 sowie ein 8155 im Einsatz, als Arbeitsspeicher stehen 128 Befehlsplätze (mit je 6 bit für den Befehl und 8  bit für den Operanden) zur Verfügung. Die Eingabe erfolgt über eine Folientastatur mit 30 Tasten (10 Ziffern, 10 Ziffern im Ziffernblock, 10 Funktionstasten). Für die Ausgabe ist lediglich eine sechsstellige 7-Segment-Anzeige eingebaut.\n\nDas Gehäuse ist so konzipiert, dass es direkt mit den damals üblichen Basisplatten der Kosmos-Elektronikbaukästen verbunden werden kann.\n\nDer Computer wird in einer vereinfachten Pseudo-Maschinensprache programmiert, die mittels des Interpreters im ROM des verbauten Microcontrollers ausgeführt wird. Eine direkte Programmierung der CPU in ihrer natürlichen Maschinensprache ist nicht möglich. Die Programmierung erfolgt durch die Eingabe der numerischen, zweistelligen Befehle, gefolgt von dreistelligen Operanden. Insgesamt stehen 21 Befehle zur Verfügung, plus 3 weitere bei Verwendung der Speichererweiterung CP3. Alle Zahlen (Befehle, Operanden, Daten, Adressen) werden im Dezimalsystem dargestellt.\n\nAn das Kassetten-Modul kann über einen DIN-Anschluss ein handelsüblicher MC-Rekorder angeschlossen werden, um Programme zu laden bzw. zu speichern. Die Steuerung erfolgt über bereits auf dem Hauptrechner vorgesehene Funktionstasten.\n\nSpeichererweiterung um 128 Speicherplätze auf insgesamt 256, sowie zusätzliche IO-Leitungen.\n\nÜber das Relais-Modul können 8 elektronische Relais gesteuert werden.\n\nDas Interface enthält 8 Transistor-Verstärkerstufen mit 8 Leuchtdioden, die die Wirkung der Ausgabe-Befehle sofort sichtbar machen, sowie 8 Schalter, die weitere Experimente zur Dateneingabe erlauben. Die Ausgänge der Transistor-Verstärkerstufen sind für weitere Anwendungen herausgeführt.\n\n"}
{"id": "1488804", "url": "https://de.wikipedia.org/wiki?curid=1488804", "title": "TED Notepad", "text": "TED Notepad\n\nTED Notepad ist ein Freeware-Texteditor für Windows zur Erstellung von einfachen Textdateien, aber auch zum Schreiben von Programm- und anderem Code geeignet. Auch extrem große Dateien werden ohne Geschwindigkeitsverlust verarbeitet.\n\nTED Notepad wurde ab 2001 von Juraj Simlovic an der Fakultät für Mathematik und Physik der Prager Karls-Universität entworfen. Das Hauptaugenmerk lag dabei von Beginn an auf Geschwindigkeit und Effizienz. Das Programm ist portabel, lässt sich also direkt von einem USB-Speicherstick an jedem Windows-PC ohne Installation benutzen.\n\n\n"}
{"id": "1490193", "url": "https://de.wikipedia.org/wiki?curid=1490193", "title": "S-System", "text": "S-System\n\nS-Systeme (S für Sättigung (von Saturation) oder Synergismus) dienen zur Beschreibung und Simulation biologischer und biochemischer Systeme die einem Grenz- oder Sättigungszustand zustreben.\n\nSie können fast alle kinetischen Phänomene natürlicher Reaktionen zuverlässig beschreiben. Die Wechselwirkungen werden durch einen Satz nichtlinearer Differentialgleichungen erster Ordnung beschrieben, die aus einem Produktions- und einem Abbauterm bestehen:\n\nformula_1 ; für i = 1 .. N \n\nN bezeichnet die Anzahl der wechselwirkenden Substanzen. Mit \"x\" sind die Konzentrationsvariablen bezeichnet, mit \"α\" die Produktionsrate und mit \"β\" die Abbaurate. Die Exponenten \"g\" und \"h\" entsprechen Reaktionsordnungen der Produktions- und Abbaufunktionen der Substanz \"i\" als Funktion der Substanz \"j\".\n\nFür ein System mit 2 Substanzen ergibt sich folgendes Differentialgleichungssystem:\n\nformula_2\n\nformula_3\n\n"}
{"id": "1494533", "url": "https://de.wikipedia.org/wiki?curid=1494533", "title": "Omikron BASIC", "text": "Omikron BASIC\n\nOmikron BASIC ist ein Dialekt der Programmiersprache BASIC, der Mitte der 1980er Jahre von der Omikron.Soft + Hardware GmbH für den ATARI ST, STE und TT entwickelt wurde. Ab 1988 gehörte der Omikron-Basic-Interpreter einschließlich Handbuch zur Grundausstattung aller in Deutschland ausgelieferten ST-Computer.\nOmikron BASIC zeichnete sich vor allem durch mathematische Fähigkeiten inklusive 19-stelliger Rechengenauigkeit aus sowie durch ein neuartiges Interpreter-Konzept, das eine für damalige Verhältnisse hohe Rechengeschwindigkeit ermöglichte: -zigmal schneller als Atari BASIC, oft etwa doppelt so schnell wie GFA-BASIC.\n\nDer Editor und Interpreter (Version 3.0) wurde bald nach Erscheinen der MEGA-ST-Serie von Atari lizenziert und standardmäßig anstatt des instabilen und unfertigen \"Atari ST BASIC\" mit ausgeliefert. Den Compiler konnte man nachkaufen. Damit konnte man optional kompilierte Programme weitergeben, ohne dass der Anwender den Quellcode einsehen konnte.\n\nKompilierte Programme konnten die Koprozessoren nutzen und die Abbruch-Tastenkombination \"CTRL-C\" sperren.\n\nMit der Weiterentwicklung der ATARI-Serien nach STE, TT und Falcon wurden wegen Inkompatibilitäten zwischen den Rechnermodellen und Unsauberkeiten in Omikron BASIC immer wieder Anpassungen der Software erforderlich, wodurch der Anwender gezwungen war, die mehr oder weniger teuren neuen Versionen des Compilers (3.5, 4.0, 5.0) zu erwerben, um kompatibel zu bleiben. Die letzte Version 5.0 lief dann endlich auch auf Atari-Emulatoren „sauber“, z. B. MagicPC von ASH, so dass man auch auf dem PC oder Mac seine Atari-Programme in Omikron BASIC weiter laufen lassen kann.\n\nNahezu alle Funktionalitäten des Betriebssystems waren von Omikron BASIC aus erreichbar und nutzbar, wie zum Beispiel Zugriffe auf BIOS und die Grafische Benutzeroberfläche GEM.\n\nDie Ausrichtung des Omikron BASIC auf eine eher wissenschaftlich-technisch interessierte Zielgruppe zeigt sich u. a. an den Erweiterungs-Bibliotheken, die zusätzlich erworben werden konnten:\n\n\nFür Anwendungen außerhalb der Ingenieurwissenschaften gab es aber ebenfalls Bibliotheken:\n\nMit der Konzentration ATARIs von Homecomputern zu Spielekonsolen verlor auch Omikron BASIC in den 1990er Jahren rasch an Bedeutung.\n\nOmikron BASIC wurde bis 2013 von Berkhan-Software (Versionen 5, 6, 7 und 8) weiterentwickelt und vertrieben, vor allem für Apple-Macintosh-Systeme. Eine Version für Intel-Macs (bis Mac OS 10.6) ist 2008 erschienen (8.5). Sowohl der Editor als auch die kompilierten Programme arbeiten unter Rosetta, da ausschließlich PowerPC-Code verwendet bzw. erstellt wird. Mit Mac OS 10.7 wurde Rosetta von Apple entfernt.\n\n\n"}
{"id": "1495741", "url": "https://de.wikipedia.org/wiki?curid=1495741", "title": "SAP GUI", "text": "SAP GUI\n\nSAP GUI (\"SAP Graphical User Interface\") bezeichnet einerseits die grafische Benutzeroberfläche eines SAP-Systems, anderseits auch jenes Programm, das diese Oberfläche bereitstellt und betreibt.\n\nIn dem mehrstufigen Client-Server-Modell der verschiedenen SAP-Systeme, die in der Regel als Drei-Schichten-Architektur realisiert sind, stellt das SAP GUI die Programmkomponente der Präsentationsschicht dar. Es wickelt also die Bildschirmdarstellung und Benutzerinteraktion ab, aber es ist (im Regelfall) nicht für Anwendungslogik oder Datenhaltung zuständig.\n\n\"SAP GUI\" (als Programm) ermöglicht den Zugriff auf einen oder verschiedene Applikationsserver eines oder mehrerer SAP-Systeme (genauer: ABAP-Systeme wie SAP ERP, SAP Web AS ABAP), wozu das DIAG-Protokoll verwendet wird. Es gibt von SAP mehrere \"SAP-GUI\"-Implementierungen, um verschiedene Betriebssysteme abzudecken. Den Zugriff auf den vollen Funktionsumfang der SAP-Software ermöglicht nur das \"SAP GUI für Windows\", das für einige Funktionen einen Webbrowser hinzuzieht und auch mit weiteren \"Windows\"-Anwendungen Daten austauschen kann.\n\nDas \"SAP GUI\" bereitet aus relativ wenigen Daten eine ggfs. komplexe Bildschirmdarstellung auf. Dieses Verfahren dient dem Zweck, die Kommunikations- und Datenlast für die Applikationsserver kleinzuhalten, indem ein großer Teil der Rechenlast zur grafischen Aufbereitung auf den lokalen PC eines Nutzers gelegt ist und somit nicht vom Zentralrechner kommen muss. Lediglich die „nackten“ Daten kommen vom Server; alles Tabellarisch-Grafische, Farben usw. baut das \"SAP-GUI\"-Programm lokal (auf dem Arbeitsplatzrechner) auf, unter Nutzung der einzelnen PC-Rechenleistung.\n\n\"SAP GUI für Windows\" ist ein Windows-Programm, das direkt auf dem Personal Computer eines Benutzers ausgeführt wird. Dies ist die am häufigsten benutzte \"SAP GUI\"-Implementierung und auch die „älteste“ in dem Sinne, dass es eine kontinuierliche Entwicklung und Versionsabfolge seit Anfang der 1990er Jahre gibt.\n\nDer Nutzer startet eine Programmkopie des SAPGUI, die entweder\nEinstiegspunkt ist häufig \"SAP-Logon\", das eine Liste der verwendbaren Systeme anzeigen kann, aus der der Benutzer nur auszuwählen braucht.\nEine weitere Möglichkeit der Verwendung ist die Ausführung des \"SAP GUI\" auf einem Terminalserver, so dass der \"SAPGUI für Windows\" auch mit anderen Betriebssystemen verwendet werden kann, sofern es eine entsprechende Terminalserver-Zugangssoftware für diese gibt.\n\nVon SAP erscheinen relativ oft neue \"Patches\" für die Komponenten des GUI. Beim Installieren des GUI können (neben dem Kernprogramm, dem eigentlichen SAP GUI) einige Zusatzkomponenten mitinstalliert werden. Zu diesen zählen Anwendungen für den Zugriff auf diese Systeme oder auf deren Inhalte:\n\nEine bestimmte Version des SAP GUI kann meistens mit älteren und teilweise auch mit neueren Releases der Server-Systeme benutzt werden. Am 20. Januar 2009 war die Version 7.10 der aktuelle Release-Stand für das SAP GUI, während gleichzeitig auch die Version 6.20 noch gewartet wurde.\n\nEine alternative Zugriffsmöglichkeit auf ein SAP-System besteht in der Verwendung dieses plattformunabhängigen, weitgehend in Java geschriebenen GUI. Dies ist auch der Ersatz für die \"SAP GUI\"-Portierungen für alle nicht-\"Windows\"-Betriebssysteme.\n\nDie Verwendung ist möglich auf AIX, HP-UX, diversen Linux-Distributionen, Apple Mac OS X, Sun Solaris und Microsoft Windows.\n\nEine Nachbildung der \"SAP GUI\"-Oberfläche mittels HTML und JavaScript, so dass für die Verwendung ein Web-Browser genügt. Siehe auch ITS.\n\nEine weitere Zugriffsmöglichkeit eröffnet die Software Duet, die in einer Kooperation zwischen SAP und Microsoft entwickelt wurde und die eine Integration der Softwareprodukte beider Konzerne zum Ziel hat. Duet ermöglicht für ausgewählte Szenarien den Zugriff auf SAP-Funktionen aus Microsoft-Office-Anwendungen.\n\nBis 2012 waren für die Anpassung von SAP-GUI-Screens (sogenannten „DynPros“) ABAP-Kenntnisse erforderlich. Inzwischen ist dies mit „SAP Screen Personas“ ohne Programmierung möglich, allerdings zurzeit nicht im \"SAP GUI for Java\". Personas wird auf einem Server mit SAP NetWeaver 7.0x oder 7.3x (nicht jedoch 7.1x) installiert und steht dann auch auf allen anderen Servern (einschließlich NW 7.1x, also insbesondere Banking Services) in der System-Landschaft zur Verfügung, vorausgesetzt sie verfügen über ein ABAP-Kernel-Release von 7.21 oder höher.\n\nIn \"SAP GUI für Windows\" bietet SAP seit 1998 kostenlos das Tool \"GuiXT\" zur Anpassung der Screens an.\n\n"}
{"id": "1496361", "url": "https://de.wikipedia.org/wiki?curid=1496361", "title": "Project Builder", "text": "Project Builder\n\nProject Builder war eine integrierte Entwicklungsumgebung (IDE) von Apple zur Entwicklung von nativen Programmen für Mac OS X und von Java-Programmen. Project Builder diente später als Basis für Xcode, das auch der offizielle Nachfolger wurde.\n\nDas GNUstep-Projekt hat einen Klon des ursprünglichen NeXTStep Project Builder namens ProjectCenter geschrieben.\n\nProject Builder war nur die Entwicklungsumgebung; das gesamte Entwicklungspaket wurde „Developer Tools“ genannt.\n\nNeben der IDE gab es in den Developer Tools folgende Tools und Programme:\n\nZusammen mit der ersten öffentlichen Version von Mac OS X, Version 10.0 („Cheetah,“ 2001), erschienen auch die Developer Tools 1.0. In jeder 10.0-Box lag auch eine CD mit den Entwicklertools, sodass jeder diese installieren und damit Programme schreiben konnte. (Die Entwicklertools lagen bis einschließlich Mac OS X Snow Leopard, Version 10.6 von 2009, immer der Installations-Disc bei.)\n\nAls Kern-Features von Version 1.0 wurden unter anderem Quelltext-Indizierung, Lesezeichen, Darwin-Support, und Durchsuchen von Frameworks genannt.\n\nIn den FAQ zu Project Builder 1.0 schrieb Apple, dass Project Builder komplett neu entwickelt sei. ProjectBuilder aus NeXTStep wurde in ProjectBuilderWO umbenannt und sei nur noch zum Programmieren von WebObjects-Software gedacht.\n\nAuf der WWDC 2001 wurde Project Builder 1.0.1 freigegeben. Es brachte Unterstützung für das neue WebObjects 5.0, womit auch ProjectBuilderWO nicht mehr unterstützt wurde.\n\nWeitere Änderungen in Version 1.0.1 sind Syntax-Prüfung ohne Kompilieren, Prefix-Header (werden implizit in jeder Quelltext-Datei eingebunden), konfigurierbare Build-Phasen, und Fortsetzen nach Build-Fehlern.\n\nIm September 2001 wurde Mac OS X 10.1 („Puma“) freigegeben. Gleichzeitig wurde eine neue Version der Developer Tools veröffentlicht, die Project Builder 1.1 beinhaltete.\n\nDie wichtigsten Änderungen sind laut Apple u. a. Unterstützung für Objective-C++, Klassenbrowser, verbesserte Quelltext-Indizierung und neue Vorlagen.\n\nDrei Monate später, im Dezember 2001, gab Apple mit aktualisierten Developer Tools auch Project Builder 1.1.1 frei.\nAls wichtigste Änderungen gibt Apple hier AppleScript Studio (heute AppleScript-Editor), syntaxabhängiges Einrücken, Kontextmenüs, Navigation in Listen über Pfeiltasten und Bugfixes an.\n\nIm Juli 2002 gab Apple eine neue Version der Developer Tools frei, die auch (zusammen mit einem wichtigen Update vom August des Jahres) in der Box von Mac OS X 10.2 („Jaguar“) zu finden waren.\n\nProject Builder wurde auf Version 2.0.1 gebracht, die wichtigsten Änderungen laut Apple sind gcc 3.1 (2.95 wird zur Wahrung der Kompatibilität mit älteren Systemen noch mitgeliefert, ist aber nicht mehr der Standard), Interface Builder 2.1 (unterstützt das Metal-Fenster-Design von Jaguar), ein neues BSD-SDK und aktualisierte Dokumentation.\n\nVon AppleScript Studio wurde Version 1.2 freigegeben.\n\nEnde 2002 veröffentlichte Apple ein Update für die Developer Tools für Mac OS X 10.2. ProjectBuilder wurde damit auf Version 2.1 aktualisiert, die wichtigsten neuen Features sind dabei Unterstützung für externe Code-Editoren und simultane Kompilierung auf mehreren CPUs.\n\nInterface Builder und AppleScript Studio erfuhren lediglich Bugfixes. Neu auf der CD waren CHUD 2.5.1 zum hardwarenahen System-Debugging, sowie eine erste Beta-Version von AppleScript Editor 2.0.\n\nObwohl mit der WWDC 2003 Xcode 1.0 vorgestellt wurde und damit die Unterstützung für Project Builder beendet wurde, stellte Apple im Sommer 2003 ein Update für Project Builder 2.1 bereit, mit dem unter anderem gcc auf Version 3.3 aktualisiert wurde. Damit konnten auch Entwickler, die Mac OS X 10.2 und Project Builder nutzten, die neuen Tools nutzen (Xcode läuft nur auf Mac OS X Panther und darüber.)\n\nMit Mac OS X Panther (10.3, 2003) wurde Project Builder durch Xcode ersetzt. Neuerungen sind u. a. eine neue Oberfläche, verteiltes Kompilieren (via distcc), Code-Vervollständigung und neue Compiler. Überreste von Project Builder sind jedoch sogar in Xcode 4.0 noch zu finden, so besitzt jedes Xcode-Projekt-Bundle eine Datei namens codice_1 (PBX, Project Builder X Project).\n\n\nRelease Notes\n"}
{"id": "1501546", "url": "https://de.wikipedia.org/wiki?curid=1501546", "title": "Magnetblasenspeicher", "text": "Magnetblasenspeicher\n\nMagnetblasenspeicher ist eine Art von Computer-Datenspeicher, bei dem ein dünner Film eines magnetisierbaren Materials zum Einsatz kommt, in dem sich kleine magnetische Bereiche, die sogenannten Blasen () befinden. Jede dieser Blasen speichert ein Bit Daten. Der Magnetblasenspeicher galt in den 1970er Jahren als vielversprechende Technologie, geriet aber in den 1980er Jahren bald gegenüber den Festplatten kommerziell ins Hintertreffen.\n\nDer Magnetblasenspeicher ist im Wesentlichen das geistige Kind einer einzigen Person, Andrew Bobeck. Bobeck hatte in den 1960er Jahren an verschiedenen Projekten in Zusammenhang mit Magnetismus gearbeitet, von denen zwei ihn für die Entwicklung des Magnetblasenspeichers prädestinierten. Dabei handelte es sich um das Magnetkernspeicher-System, welches über einen Transistor-basierten Controller gesteuert wurde, und den Twistor-Speicher.\n\nTwistorspeicher basiert auf Magnetostriktion, einem Effekt, durch den Magnetisierungsmuster bewegt werden können. Wenn ein solches Muster beispielsweise auf Magnetband gespeichert ist, durch das anschließend elektrischer Strom geleitet wird, so bewegt sich das Muster als Ganzes in Stromflussrichtung. Durch Platzieren eines Detektors an einer Stelle über dem Band kann die gespeicherte Information sukzessive ausgelesen werden, ohne dass das Band sich physikalisch bewegt. Es handelt sich beim Twistorspeicher also um ein unbewegliches Analogon des Trommelspeichers. In den 1960er Jahren wurde der Twistorspeicher vom amerikanischen Konzern AT&T in einer Reihe von Geräten eingesetzt.\n\nIm Jahre 1967 stieß Bobeck zu einem Entwicklungsteam der Bell Laboratories und begann mit Verbesserungsarbeiten am Twistorspeicher. Sein Ziel dabei war, mithilfe eines Materials, in dem sich Magnetisierungsmuster nur in eine Richtung bewegen können, eine 2D-Version des Twistorspeichers zu konstruieren. Die Muster sollten an einer Seite des Materials eingeschrieben und anschließend wie im Twistorspeicher elektrisch bewegt werden. Wegen der richtungsgebundenen Beweglichkeit wäre dabei die Bildung von Spuren \"(Tracks)\" zu erwarten.\n\nBobeck begann seine Materialsuche mit Orthoferrit. Dabei bemerkte er einen interessanten Effekt: Legt man ein externes Magnetfeld an ein Magnetisierungsmuster in diesem Medium an, so kontrahiert der Bereich zu einem kleinen Kreis, den Bobeck als \"Blase (englisch: bubble)\" bezeichnete. Diese Blasen waren viel kleiner als die Magnetisierungsdomänen normaler Speichermedien wie Magnetband, sodass viel höhere Speicherdichten möglich erschienen.\n\nNach längerer Experimentierzeit erwies sich Granat als mit den besten Eigenschaften ausgestattet. Die Blasen bildeten sich leicht und waren gut beweglich. Es blieb jedoch schwierig, sie zum Auslesen der Daten gezielt an die Stelle des Detektors zu bewegen. Anders als im eindimensionalen Twistorspeicher standen nunmehr zwei Dimensionen zur Verfügung, und die laterale Bewegung der Bläschen war das Problem. Die Lösung war das Aufbringen eines Musters kleiner magnetisierbarer Felder auf die Granatoberfläche. Bei Anlegen eines schwachen Magnetfeldes wurden sie magnetisch, und die Blasen bleiben an ihrem einen Ende „kleben“. Durch Feldumkehr werden die Blasen zum anderen Ende, durch erneute Umkehr zum nächsten Feld in Linie transportiert. \n\nEine Speichereinheit besteht aus aufgereihten kleinen Elektromagneten als Schreibköpfe an einem Ende der Speicherschicht und Detektoren am anderen Ende. Eingeschriebene Blasen wandern langsam von einem Ende zum anderen, wobei sich benachbarte Lagen aus Twistorelementen bilden. Wird die Ausgabe der Detektoren wieder an die Schreibköpfe zurückgeleitet, so resultiert ein Zyklus, in dem die Informationen beliebig lange gespeichert werden können.\n\nDer Magnetblasenspeicher ist ein nichtflüchtiger Speicher. Selbst wenn der Strom abgeschaltet wird, bleiben die Bläschen erhalten, so wie auch die Magnetisierungsmuster auf einer Festplatte. Ein weiterer Vorteil ist das Fehlen mechanisch beweglicher Teile. Durch die geringe Größe der Bläschen lässt sich eine hohe Informationsdichte erzielen. Ein Nachteil hingegen ist die geringe Auslesegeschwindigkeit (Zugriffszeit ca. 500 Mikrosekunden). Bevor die Blasen bis zum Detektor gewandert sind, kann die Information nicht gelesen werden.\n\nBobecks Team war bald in der Lage, 4.096 Bits pro Quadratzentimeter zu speichern, was der Speicherdichte der zu dieser Zeit üblichen Kernspeicher entsprach. Dadurch wurde das Interesse der Industrie in bedeutendem Umfang geweckt. Der Magnetbläschenspeicher schien sich als Alternative zu core-, Magnetband- und Diskettenspeicher anzubieten. Bis auf den Markt für Hochgeschwindigkeitsspeicher versprach der Magnetblasenspeicher, alle anderen Speicherarten zu ersetzen.\n\nMitte der 1970er Jahre arbeitete praktisch jede größere Elektronikfirma am Magnetblasenspeicher. Gegen Ende des Jahrzehnts waren mehrere Versionen auf dem Markt, und Intel lancierte seine eigene 1-Mebibit-Version, den \"7110\". Anfang der 1980er Jahre jedoch erwies sich Magnetblasenspeicher mit der Einführung der Festplatte mit höherer Informationsdichte und kürzerer Zugriffszeit als Sackgasse. Die Entwicklungsarbeiten wurden somit beinahe vollständig eingestellt. Lediglich Nischenprodukte, bei denen es auf Zuverlässigkeit unter hoher mechanischer Belastung (z. B. in Gegenwart starker Vibration) ankam, konnten sich noch halten.\n\nEine solche Anwendung war das \"Bubble System\"-Videospielsystem der Firma Konami, das 1984 eingeführt wurde. Es basierte auf austauschbaren Magnetblasenspeicherkassetten und einem Derivat der Z80-Konsole. Zu den erhältlichen Spielen zählten \"Gradius\", \"Attack Rush/Hyper Crash/Hyper Crush\" und \"TwinBee\". Das Magnetblasenspeichersystem benötigte eine etwa 20 Sekunden lange Aufwärmzeit, die auf dem Bildschirm vor dem Laden des Spiels heruntergezählt wurde, da der Speicher erst bei 30 bis 40 °C optimal betrieben werden kann. Das Magnetblasenspeichersystem erwies sich als wenig populär, und viele dafür produzierte Spiele wurden in der Folge für andere Videokonsolen mit konventionellem ROM-Speicher hergestellt.\n\n"}
{"id": "1501930", "url": "https://de.wikipedia.org/wiki?curid=1501930", "title": "Macintosh LC", "text": "Macintosh LC\n\nDer Macintosh LC (LC - \"low-cost color\" – preisgünstig, farbfähig) stand am Anfang der in den 1990er Jahren von Apple auf den Markt gebrachten Produktfamilie für Heimanwender. Er wurde zwischen dem 15. Oktober 1990 bis zum 23. März 1992 gebaut und verkauft. Der Preis war bewusst niedrig angesetzt, um Kunden zu erreichen, die bis dahin keinen Apple Macintosh nutzten, und das Gerät für z. B. Privatnutzer, Schüler und Studenten interessant zu machen. Tatsächlich konnte der Umsatz schon 1990 gewaltig angekurbelt werden.\n\nZusammen mit dem Macintosh IIsi war der Macintosh LC der erste Macintosh mit integriertem Audio-Eingang. Der Name „LC“ steht in den folgenden Jahren für eine ganze Produktlinie von Rechnern für den Privatanwender.\n\nFür den Macintosh LC verwendete Apple ein sehr flaches Gehäuse, das ihm den Spitznamen „Pizzaschachtel“ einbrachte, das exakt unter Apples 12″- und 13″-Monitore passte. Der Innenraum bot gerade genug Platz für ein 3,5″-Diskettenlaufwerk und eine Festplatte in halber Bauhöhe. Frühe Modelle wurden alternativ auch mit zwei Diskettenlaufwerken und ohne Festplatte ausgeliefert. Über der Hauptplatine mit dem seit 1984 gebauten Motorola 68020-Prozessor, der mit 16 MHz getaktet war, fand nur eine Erweiterungsplatine Platz – die Erweiterbarkeit des Rechners war also stark beschränkt. Der Macintosh LC verfügte nicht über einen mathematischen Coprozessor. Der 16 Bit breite Datenbus und der maximale Speicherausbau von 10 MByte RAM (werksseitig mit 2 MByte RAM auf der Hauptplatine ausgeliefert) begrenzten die Leistungsfähigkeit des Rechners.\n\nAnsonsten waren die im Mac-Umfeld etablierten Schnittstellen integriert, also die üblichen zwei seriellen Schnittstellen für Modem und Druckeranschluss (auch als Netzwerkport für LocalTalk), Tonein- und Ausgang, eine SCSI-Schnittstelle für externe Peripheriegeräte wie z. B. Wechselplattenlaufwerke, eine integrierte Grafikkarte mit eigenem Speicher, Apple Desktop Bus für Tastatur und Maus.\n\nBekannt war die Wartungsfreundlichkeit des Rechners, dessen Gehäuse ohne das Lösen von Schrauben geöffnet werden konnte. Alle Bauteile, einschließlich Netzteil und Hauptplatine, werden schraubenlos von Klips gehalten.\n\nDer Macintosh LC wurde mit dem Betriebssystem MacOS 6.0.7 und 256 kByte Video-RAM ausgeliefert. Bei einer Bildschirmauflösung von 512×384 Pixeln konnten damit 256 Farben, bei 640×480 Pixel lediglich 16 Farben dargestellt werden. Bei Aufrüstung des Video-RAM auf 512 kByte erweiterte sich die Palette auf 32.768 Farben (512×384 Pixel). Apple bot speziell für den Macintosh LC einen 12″-Festfrequenzbildschirm an, der nur eine Auflösung von 512×384 Pixeln darstellen konnte.\n\nAuch ohne NuBus-Slots gab es eine Reihe von Erweiterungskarten für den Processor Direct Slot (PDS) des Macintosh LC. Ursprünglich war er dazu gedacht, eine Apple IIe Emulationskarte aufzunehmen, und sollte den im Umfeld von Schulen und Hochschulen weit verbreiteten Apple IIe ablösen. Für den PDS des Macintosh LC wurde von Drittanbietern eine Reihe von Beschleunigerkarten, Netzwerkkarten und Grafikkarten entwickelt. Ethernet-Karten für den PDS waren mit einem eigenen ROM ausgestattet, so dass diese Karten ohne eigene Treiber im MacOS eingebunden werden. Sehr beliebt war auch die Aufrüstung mit einem mathematischen Koprozessor des Typs Motorola 68882 als PDS-Erweiterungskarte.\n\nDer Macintosh LC verkaufte sich gut und wurde 1992 vom Macintosh LC II mit Motorola 68030 Prozessor abgelöst. Der Name „LC“ wurde von Apple später auch für PowerPC-Modelle verwendet und verschwand erst mit Einführung des iMac aus dem Programm.\n\n\"Macintosh LC\" („Pizzaschachtel“, erstes Modell einer neuen Serie günstiger Rechner)\n\n"}
{"id": "1502164", "url": "https://de.wikipedia.org/wiki?curid=1502164", "title": "GINA", "text": "GINA\n\nGINA (engl. \"\", „grafische Identifikation und Authentifikation“) ist eine Softwarekomponente einiger älterer Microsoft-Windows-Betriebssysteme, die sichere Authentifizierungs- und interaktive Anmeldedienste zur Verfügung stellt.\n\nGINA ist eine Dynamic Link Library, die zusammen mit dem Winlogon-Prozess beim Systemstart geladen wird. Sie ist dafür verantwortlich, eine Tastenkombination zur sicheren Anmeldung (üblicherweise ++) zu verarbeiten, den Benutzernamen und das Kennwort entgegenzunehmen, zu prüfen und die ersten Prozesse für den Benutzer (z. B. die Taskleiste) zu starten.\n\nSeit Windows Vista ersetzt Microsoft die GINA durch eine neue Komponente, genannt Credential Provider.\n\nMicrosoft stellt als Teil des Betriebssystems eine Standard-GINA-Bibliothek (MSGINA.DLL) zur Verfügung, welche folgende Funktionen bietet:\n\nWinlogon kann für die Verwendung einer anderen GINA-Bibliothek konfiguriert werden, die andere Authentifizierungsmethoden wie z. B. Smartcards oder Fingerabdruckscanner unterstützt oder eine andere Anmeldeoberfläche bereitstellt.\n"}
{"id": "1502815", "url": "https://de.wikipedia.org/wiki?curid=1502815", "title": "ChEBI", "text": "ChEBI\n\nChEBI (\"Chemical Entities of Biological Interest\") ist ein freies Lexikon über molekulare Entitäten mit Hauptaugenmerk auf chemische Verbindungen, die im Stoffwechsel von Lebewesen vorkommen. Die Bezeichnung 'molekulare Entitäten' bezieht sich auf jegliche Arten von Atomen, Molekülen, Ionen, Ionenpaaren, Radikalen, Komplexen, Konformationen usw.\n\nChEBI bietet zusätzlich eine Ontologie, mit der sich die komplexe Klassifizierung chemischer Verbindungen anhand einer Baumstruktur veranschaulichen lässt.\n\nDie in ChEBI verwendete Nomenklatur, Terminologie und Symbolik entsprechen internationalem Standard und werden von folgenden Gremien empfohlen:\n\n\nMoleküle, welche direkt durch das Genom kodiert werden (z. B. Nukleinsäuren, Proteine und aus Abspaltung entstandene Peptide), finden in der Regel keinen Eingang in die ChEBI Datenbank.\n\nAlle bei ChEBI gespeicherten Daten sind weder proprietär, noch wurden sie von einer proprietären Quelle bezogen. Der freie Zugriff auf die Daten ist somit gewährleistet. Zusätzlich lässt sich jedes Datenelement auf seine ursprüngliche Quelle zurückverfolgen.\n\n"}
{"id": "1503195", "url": "https://de.wikipedia.org/wiki?curid=1503195", "title": "CPanel", "text": "CPanel\n\ncPanel ist ein web-basiertes Konfigurationstool für Webserver- und Webhosting-Unternehmen, das vom Hersteller cPanel Inc. für die Unix-/Linux-Betriebssysteme CentOS, FreeBSD, Red Hat Enterprise Linux und CloudLinux entwickelt wurde.\n\ncPanel gilt neben Plesk als führender Anbieter auf dem US-amerikanischen Markt und bietet eine webbasierte Administrationsoberfläche für fast alle gängigen administrativen Aufgaben. Es ermöglicht unter GNU/Linux-Webservern zahlreiche Funktionen, die ansonsten nur mit einem hohen Konfigurationsaufwand oder Wissensstand verfügbar sind. Dazu zählt beispielsweise die Unterstützung von Microsoft FrontPage Server Extensions oder Java mittels Apache Tomcat. cPanel ist auch multilingual, mehr als 20 der wichtigsten Sprachen stehen zur Verfügung.\n\n"}
{"id": "1503245", "url": "https://de.wikipedia.org/wiki?curid=1503245", "title": "X1 Search", "text": "X1 Search\n\nX1 Search (früher \"Yahoo! Desktop Search\") ist ein Desktop-Suchprogramm, das die Suche nach Dateien auf dem eigenen Computer ermöglicht. Für die Suche bietet es eine der Yahoo-Suchmaschine ähnliche Oberfläche und einige Erweiterungen für die Windows-Taskleiste und den Desktop. X1 gestattet ein schnelles und einfaches Durchsuchen der persönlichen Dateien.\n\nDerzeit steht eine kostenfreie Version der Software nicht mehr zum Download zur Verfügung. Der Preis für die „Professional Client“ genannte Version beträgt 50 $.\n\nX1 Search unterstützt u. a. das Durchsuchen folgender Dateien:\n\nYahoo Desktop Search kann durch Plugins erweitert werden.\n"}
{"id": "1505178", "url": "https://de.wikipedia.org/wiki?curid=1505178", "title": "NT-Loader", "text": "NT-Loader\n\nNT-Loader, kurz NTLDR, ist der Bootmanager von Microsoft für alle Windows-NT-Systeme bis einschließlich Windows Server 2003. Seine Konfiguration liest er aus der Textdatei „boot.ini“. Sie ist nötig, da die Windows-Registrierungsdatenbank erst nach dem Start des Betriebssystems zur Verfügung steht. Sie ermöglicht zudem das Editieren auch außerhalb von Windows. NTLDR wurde ab Windows Vista vom \"Bootmgr\" abgelöst.\n\nDie Konfigurationsdatei liegt neben den Dateien „ntldr“ und „ntdetect.com“ sowie ggf. „ntbootdd.sys“ und „bootsect.dos“ im Stammverzeichnis der aktiven Primärpartition (normalerweise „C:\\“) und unterscheidet sich in den möglichen Parametern je nach Windowsversion. Dieser Bootmanager ist notwendig geworden, da Windows NT keinen DOS-Kern mehr besitzt und vor dem Start von Windows eine Möglichkeit geschaffen werden muss, das Startverhalten über Parameter zu beeinflussen. Da die DOS-basierenden und die NT-Windowssysteme funktional höchst unterschiedlich sind, sollte zudem auf diesem Weg die Möglichkeit geschaffen werden, verschiedene Windowsversionen parallel zu betreiben.\n\nEin früher sehr häufiges Dualbootszenario ist der klassische Parallelbetrieb von Windows 95 oder Windows 98 und Windows NT 4.0. Da dieses Betriebssystem wenig Multimediaunterstützung aufwies und kein Plug and Play unterstützt und deshalb auch USB und FireWire nie implementiert wurden, war es sinnvoll, für die tägliche Arbeit der Stabilität wegen Windows NT zu verwenden, zum Scannen oder für Multimediaanwendungen Windows 95 oder 98 zu starten.\n\nDer NTLDR wird nur auf x86-basierten Computern verwendet. RISC-basierte Computer verfügen über eine Firmware, die ein Bootmenü implementiert und so das Starten mehrerer Betriebssysteme ermöglicht. Die Datei „osloader.exe“, die nur auf RISC-basierten Computern existiert, startet das Betriebssystem direkt mittels Parametern, die ihr von der Firmware übergeben werden.\n\nDie „boot.ini“ ist die Konfigurationsdatei des Bootmanagers „ntldr“. Diese Datei ist nötig, da die Windows-Registrierungsdatenbank erst nach dem Start des Betriebssystems zur Verfügung steht. Die Pfadangaben in der boot.ini entsprechen den Konventionen von RISC-Computern, die im ARC-Standard festgelegt sind.\n\n\nErläuterung zum Beispiel: Den Start von Windows NT (Startverzeichnis hinter den Partitionsangaben) übernimmt der Bootloader bis zum Laden der Startdateien und Treiber direkt, für ein DOS oder DOS-basierendes Windows übergibt der Bootloader diese Arbeit an die DOS-Startdateien, auf die der folgende Eintrag verweist. Je Partition lassen sich aber jeweils nur ein DOS- und ein NT-System starten, fremde Betriebssysteme wie Linux oder Netware werden offiziell nicht unterstützt. Ebenso erfordert das Installieren mehrerer NT-Systeme oder mehrerer Windows 3.x/9x-Versionen auf demselben Rechner ein tieferes Fachwissen über das Verhalten und die technischen Anforderungen der verschiedenen Windowsversionen und ist nicht ohne manuelle Eingriffe möglich.\n\nNTLDR startet von Festplatte oder Diskette ohne den Master Boot Record zu ändern, im Gegensatz zu einigen anderen Bootloadern z. B. unter Linux. Anspruchsvollere Konfigurationen lassen sich besser und bequemer (oder überhaupt erst) mit Bootmanagern anderer Hersteller und Partitionierungsprogrammen erledigen. Ein völliger Ersatz für NTLDR sind sie aber nicht, da er zum Laden der Startdateien fest ins NT-System eingebunden ist. Es ist mit den meisten Bootmanagern (z. B. GRUB und LILO für Linux) meist problemlos ein Parallelbetrieb möglich.\n\n\"multi(0)disk(0)rdisk(d)partition(p)\\Windows-Verzeichnis=\"Text im Bootmenü\" [Optionen…]\"\n\n\"d\" ist logische Nummer der Disk aus BIOS-Sicht. 0 für die erste Platte (0x80), 1 für die zweite Platte (0x81) etc. Das hat nichts mit Master, Slave oder SCSI-ID zu tun. Bei 3 ist üblicherweise Schluss.\n\n\"p\" ist die Nummer der Partition auf der Platte. Die erste primäre Partition ist 1. Danach folgen alle weiteren primären Partitionen gefolgt von den erweiterten. Die Erweiterungspartitionen selbst (Typ 0x05 und 0x0F) zählen nicht mit.\n\n\"Windows-Verzeichnis\" ist das %SystemRoot% der betreffenden Installation ohne Laufwerksbuchstabe.\n\n\"Optionen\" siehe unten.\n\n\"scsi(c)disk(d)rdisk(l)partition(p)\\Windows-Verzeichnis=\"Text im Bootmenü\" [Optionen…]\"\n\nFür diese Variante muss sich die Datei „ntbootdd.sys“ im Hauptverzeichnis der Startpartition befinden – also da, wo auch die „boot.ini“ ist. Diese Datei muss eine (umbenannte) Kopie des zum Ansprechen der gewünschten Festplatte erforderlichen Treibers aus %SystemRoot%\\System32\\Drivers\\ sein. Bei IDE-Platten ist das üblicherweise „atapi.sys“, es sei denn, der verwendete Controller bedarf eines herstellerspezifischen Treibers (bei SCSI immer).\n\n\n"}
{"id": "1507211", "url": "https://de.wikipedia.org/wiki?curid=1507211", "title": "Grapher", "text": "Grapher\n\nGrapher ist ein Computerprogramm, das als Bestandteil des Betriebssystems OS X von Apple mitgeliefert wird. Es ermöglicht sowohl einfache sowie komplexe Graphen zwei- und dreidimensional graphisch darzustellen. Den Leistungsumfang von Grapher skizzieren die dem Programm beigefügten Beispiele, die von Differenzial- und Integralgleichungen über Toroiden bis zu Lorenz-Attraktoren reichen. Die Fähigkeiten umfassen auch die Darstellung von Funktionen und Kombinationen derselbigen. Die Darstellung eines Graphen lässt sich anpassen, indem die Farbe der Linien variiert wird, einer Oberfläche eines von vielen Muster zugewiesen wird oder Kommentare hinzugefügt werden, die zudem noch formatiert werden können. Mit Grapher können auch Animationen erstellt werden, indem entweder Konstanten des Graphen verändert werden oder die Ansicht auf den Graphen geschwenkt wird.\n\nBevor es OS X gab, wurde Graphing Calculator, das dem heutigen Grapher ähnelt, als Bestandteil von früheren Apple-Betriebssystemen ab 1994 mehr als 20 Millionen Mal vertrieben. Mit der Einführung von OS X fehlte ein Graphenprogramm im Funktionsumfang des Betriebssystems. Am 22. Juli 2004 kaufte Apple das Programm \"Curvus Pro X\" Arizona Software ab und nannte es in \"Graphing Calculator\" um, bevor entschieden wurde es \"Grapher\" zu nennen. Die Neuigkeit wurde am 15. September 2004 auf AppleInsider veröffentlicht.\n\nGrapher ist ein umfassendes Programm für graphische Berechnungen, fähig sowohl 2D- als auch 3D-Graphen zu erstellen, sei es mittels euklidischen, logarithmischen, doppellogarithmischen oder Polarkoordinaten, selbst Vektorfelder sind möglich.\nGrapher ist eine Cocoa-Anwendung. Die gleichzeitige Darstellung mehrerer Graphen innerhalb eines Koordinatensystems ist ebenso möglich wie der Export von Gleichungen in das Format LaTeX. Es ist eines der wenigen gehobenen Grafikprogramme, die standardkonforme Vektorgrafiken exportieren können. Außerdem sind in der Menüleiste Beispiele angeführt, die den Einstieg in das neue Programm erleichtern.\n"}
{"id": "1507351", "url": "https://de.wikipedia.org/wiki?curid=1507351", "title": "Origin (Software)", "text": "Origin (Software)\n\nOrigin ist ein Analyse- und Darstellungsprogramm für Daten. Neben der Darstellung von Rohdaten in publikationsfähigen Grafiken in 2D und 3D beherrscht Origin viele gängige Analyseverfahren wie Fits, Fourier-Transformationen usw. Erstellte Grafiken können in viele Dateiformate exportiert werden, wie EPS, JPEG, GIF, TIFF, PDF und WMF.\n\nOrigin beinhaltet eine Reihe von Funktionen, die auf die Ansprüche von Wissenschaftlern und Ingenieuren ausgerichtet sind. Arbeitsmappen mit mehreren Datenblättern, publikationsreife Grafiken und standardisierte Analysehilfsmittel bieten einen nahtlos integrierten Workspace zum Importieren von Daten, Erstellen und Anpassen von Diagrammen, Untersuchen und Analysieren von Daten. Origin bietet Hilfsmittel zur Datenanalyse, wie komplexe Statistiken, Regression, nicht-lineare Kurvenanpassung, Bild- und Signalverarbeitung sowie Peakanalyse.\n\nOriginPro ist die erweiterte Version für Wissenschaftler und Ingenieure, die erweiterte numerische Berechnungen und Analysen, Statistik, 3D- und Pulsfit durchführen wollen. Diese finden in OriginPro eine Vielzahl komplexer Hilfsmittel in die Benutzeroberfläche integriert.\n\nOrigin wurde von der Firma \"MicroCal Inc.\", einem Hersteller von Microkalorimetern, zur Auswertung der gemessenen Daten entwickelt und erstmals im März 1991 der Öffentlichkeit vorgestellt. Aufgrund des Erfolges der Software wurde die unabhängige Firma \"Microcal Software, Inc.\" im Oktober 1992 gegründet. Diese verlegte ihren Hauptsitz im Mai 1993 nach Northampton, Massachusetts, und wurde im August 2000 in \"OriginLab Corporation\" umbenannt. Später machte die Firma \"Additive\" Origin und OriginPro komplett auf Deutsch mit Handbüchern verfügbar. Neben der englischen sind auch Versionen in japanischer und deutscher Sprache verfügbar.\n\nEs existieren vergleichbare Open-Source-Programme wie LabPlot oder SciDAVis, welche frei verfügbar sind.\n\n"}
{"id": "1510396", "url": "https://de.wikipedia.org/wiki?curid=1510396", "title": "Framework (Software)", "text": "Framework (Software)\n\nFramework ist ein 1984 von Robert Carr für den IBM-PC entwickeltes Office-Paket. Framework wurde später von der Firma Ashton-Tate gekauft (bekannt als Hersteller von dBASE) und weiterentwickelt. Framework enthält u. a. eine Textverarbeitung, eine Tabellenkalkulation, ein Geschäftsgrafik-Modul, eine Desktop-Datenbank und ein Kommunikationsmodul. Es zeichnet sich besonders durch eine graphische Oberfläche und eine in allen Bereichen vereinheitlichte Bedienung aus. Außerdem verfügt es über eine integrierte Makrosprache namens FRED. Framework wurde als Konkurrenzprodukt zu Lotus Symphony und SPI Open Access auf den Markt gebracht. Die letzte von Ashton-Tate entwickelte Version wurde 1989 als Framework IV herausgebracht. Mit dem Aufkommen von Microsoft Windows wurde Framework zunehmend unbedeutend und konnte sich nicht gegen Programme wie Microsoft Office durchsetzen.\n\nFramework wird heute vom Unternehmen \"Selections & Functions Inc.\" weiterentwickelt. Seit Ende 2008 ist Version IX auf dem Markt und Version X in Arbeit.\n\n"}
{"id": "1511822", "url": "https://de.wikipedia.org/wiki?curid=1511822", "title": "BT2450", "text": "BT2450\n\nAls BT2450 wird ein Test bezeichnet, mit dem im Computerschach-Bereich die Spielstärke von Schachcomputern und Schachprogrammen ermittelt werden kann. Der Test wurde zu Beginn der 1990er Jahre von den Ingenieuren Hubert Bednorz und Freddy Tönissen entwickelt, aus deren Namen sich das Kürzel \"BT\" ableitet. Der Test besteht aus 30 Schachpositionen aus den verschiedenen Phasen einer Schachpartie. Als ein Vorläufer aus den 1980er-Jahren kann der Bratko-Kopec-Test aufgefasst werden.\n\nFür die Durchführung des BT2450-Tests wird die Zeit gemessen, die ein Schachcomputer oder ein Schachprogramm benötigt, um in jeder der 30 Positionen den Lösungszug zu finden. Wird die Lösung nicht innerhalb von 15 Minuten (900 Sekunden) pro Stellung gefunden, geht für die entsprechende Stellung eine Zeit von 900 Sekunden in das Testergebnis ein. Dies gilt ebenfalls, wenn ein Programm zwar den Lösungszug innerhalb von 15 Minuten findet, diesen jedoch im weiteren Verlauf der Stellungsbewertung zugunsten eines anderen vermeintlich besseren Zuges verwirft. Ermittelt ein Programm zunächst den Lösungszug, dann einen anderen und später erneut die richtige Lösung, gilt die Zeit bis zum endgültigen Auffinden der Lösung. \n\nDas Testergebnis errechnet sich aus der Gesamtzeit zur Lösung aller 30 Positionen nach der Formel BT = 2.450 - 2 x Gesamtzeit (Zeit in Minuten) oder BT = 2.450 - Gesamtzeit / 30 (Zeit in Sekunden). Der ermittelte Wert ist begrenzt mit den international gültigen Elo-Werten vergleichbar. Dabei ist aber zu beachten, dass mit dem BT2450-Test nur die taktischen Fähigkeiten eines Programms bewertet werden. Der mit dem BT2450 erreichbare Wert liegt zwischen 1.550 und 2.450. Für Werte unter 1.650 oder über 2.300 gilt der Test jedoch als zu ungenau. \n\nEine überarbeitete Version des Tests wird als BT2630 bezeichnet. Dieser unterscheidet sich vom BT2450-Test durch den höheren Basiswert von 2.630 in der Formel sowie durch sieben andere Stellungen. Er wurde etwa zwei Jahre später entwickelt, um eine bessere Bewertung der gestiegenen Spielstärke von guten Schachprogrammen zu ermöglichen. Der ursprüngliche BT2450 wird mittlerweile nur noch für Schachprogramme auf Kleinstrechnern wie beispielsweise PDAs verwendet.\n\nEine erneute Weiterentwicklung ist der von Hubert Bednorz und Heinz-Josef Schumacher entwickelte BS2830-Test, der aus 27 Positionen besteht und nach der Formel BS = 2.830 - Gesamtzeit / 1,5 - (Gesamtzeit x Gesamtzeit) / (22 * 22) (Zeit in Minuten) berechnet wird. Diese Formel ersetzte 1998 die ursprünglich von den beiden Entwicklern des Tests vorgesehene Formel BS = 2.830 - (Gesamtzeit x Gesamtzeit) / (17 * 17).\n\n"}
{"id": "1511860", "url": "https://de.wikipedia.org/wiki?curid=1511860", "title": "Score Perfect", "text": "Score Perfect\n\nScore Perfect („SPP“, nicht zu verwechseln mit SCORE) ist ein Notensatzprogramm für Microsoft Windows. Programmautor war Klaus Kleinbrahm. \"Score Perfect\" wird von der Firma \"Scoretec\" weiterentwickelt und vertrieben. Es existiert in den Versionen \"Professional\", \"Professional Lite\", \"Standard\" und \"Education\". Nach dem Tod des Programmierers Klaus Kleinbrahm im Jahre 2012 erschienen keine neuen Versionen mehr.\n\nIn \"Score Perfect\" lassen sich Notensatzelemente ohne vorherige Auswahl eines Werkzeugs mit der Maus setzen oder verändern. Die meisten gängigen Aufgaben des klassischen Notensatzes werden unterstützt. Bei einigen Funktionen in \"Score Perfect\" ist es nicht möglich, Werte manuell einzugeben.\n\n\"Score Perfect\" ist in den Sprachen Dänisch, Deutsch, Englisch, Französisch, Niederländisch, Schwedisch und Spanisch verfügbar.\n\nDie Entwicklung von \"Score Perfect\" begann 1989. Für EDV-unterstützten Notensatz gab es seit 1985 verschiedene Lösungsansätze (siehe Finale und Score). Notensatzprogramme waren zu Beginn jedoch recht technisch im Umgang. Der Musiklehrer Klaus Kleinbrahm erstellte ein Software-Konzept mit dem Ziel, eine intuitivere Arbeitsweise zu ermöglichen.\n\n1990 entstand der Score Audio Mode (\"SAM\"), der ein lebensechtes Playback der Partitur ermöglicht, indem gesetzte Zeichen wie Fortissimo, Arpeggio oder Triller beim Abspielen beachtet werden.\n\n1992 folgte die Konzeption von Mehrfach-Bereichen, die eine gleichzeitige Bearbeitung mehrerer Tongruppen ermöglicht.\n\nMitte der 1990er Jahre wurde \"Score Perfect\" zeitweilig von Columbus Soft weiterentwickelt und vermarktet, bevor 2001 Vertrieb und Entwicklung von Scoretec übernommen wurden.\n\nAm 7. Juli 2012 verstarb Klaus Kleinbrahm.\n\nAufgrund seiner Konzeption und der funktionalen Beschränkung findet \"Score Perfect\" vor allem Anwendung im semiprofessionellen Bereich. Das Programm wird von Musikern, Musiklehrern, Chorleitern, Arrangeuren, Komponisten und von Schülern genutzt.\nDie Software ist vor allem in Deutschland verbreitet.\n\n\n\n"}
{"id": "1515378", "url": "https://de.wikipedia.org/wiki?curid=1515378", "title": "Tierisch wild", "text": "Tierisch wild\n\nTierisch wild (Originaltitel The Wild) ist ein CGI-Animationsfilm der Walt Disney Company, bei dem Steve „Spaz“ Williams Regie führte.\n\nJunglöwe Ryan ist deprimiert, dass sein Gebrüll noch immer nicht so imposant klingt wie die Stimme seines Vaters. Mittlerweile ist er das Gespött des ganzen New Yorker Zoos. Obwohl sein Vater Samson versucht, ihn mit seinen Abenteuern aus der Wildnis zu animieren, schafft Ryan nichts als ein leises Krächzen hervorzubringen. Da Ryan glaubt, sein Vater habe das Brüllen in der Wildnis gelernt, beschließt er nach einem Streit mit seinem Vater wegzulaufen und sich in einem grünen Frachtcontainer zu verstecken. Noch bevor Ryan es sich anders überlegt hat, wird der Container verschlossen und abtransportiert.\n\nAls Samson Ryans Hilferufe bemerkt, ist es zu spät. Sogleich bricht er zusammen mit dem Eichhörnchen Benny, dem Koala Nigel, der Giraffe Bridget sowie der Anakonda Larry aus dem Zoo aus, um Ryan zu retten. Sie begeben sich zum New Yorker Hafen und müssen zusehen, dass Ryan unfreiwillig auf ein riesiges Containerschiff verladen wird. Kurzerhand übernehmen Samson und seine Freunde die Kontrolle über ein im Hafen liegendes kleineres Schiff und verfolgen mit Hilfe von Fluggänsen Ryans Spur.\n\nSie stranden am Ufer des afrikanischen Kontinents und machen bei der Suche nach Ryan die Entdeckung, das die Container einer großen Rettungsaktion dienen, um die Tiere der Wildnis vor einem kurz bevorstehenden Vulkanausbruch zu beschützen. Samson folgt seinem verängstigten Sohn in das Dickicht des Dschungels, verliert jedoch seine Spur. Als er gegenüber seinen Freunden zugibt, dass er nicht in der Wildnis aufwuchs, sondern bei einem Zirkus, trennen sich die Wege der Freunde. Wenig später wird der Rest der Gruppe von wilden Gnus unter der Führung des bösen Kazar gefangen genommen. Die Gnus halten Nigel für ihren Gott, da vor langer Zeit ein Stoffkoala – aus einem Flugzeug – vom Himmel fiel und Kazar aus einer gefährlichen Situation bei der Konfrontation mit mehreren Junglöwen rettete. Seitdem predigt Kazar den Glauben, dass durch das Verspeisen eines Löwen die Nahrungskette umgekehrt werden kann, wobei das Gnu zum Jäger aufsteigen sowie der Löwe zur Beute degradiert wird.\n\nSamson hat mittlerweile Ryan gefunden, gesteht ihm seine wahre Herkunft und muss hilflos miterleben, wie auch sein Sohn von den Gnus gefangen genommen und zum Vulkan gebracht wird, wo er von den Gnus gefressen werden soll. Mit der Hilfe einiger Chamäleons, die die Gabe haben, ihn bis zur Unsichtbarkeit zu tarnen, gelingt es Samson, sich in die Höhle der Gnus zu schleichen und seine Freunde zu befreien. Doch Samson selbst gerät in einen Kampf mit Kazar, den er zu verlieren scheint. Das beherzte Eingreifen Ryans bringt seinen Sohn in Lebensgefahr und setzt bei Samson letzte Kräfte frei, mit denen er Kazar zunächst zurückschlagen kann. Doch die Herde der Gnus scheint übermächtig. Zur Überraschung aller schlägt sie sich auf die Seite Samsons, denn die Rettung seines Sohnes hat sie tief beeindruckt. Auch sind sie die Diktatur Kazars überdrüssig und wollen nicht mehr länger so tun, als wären sie nicht das, was sie der Natur nach nunmal sind – Beutetiere. Kazar will in einem finalen Kampf die Löwen töten und wird durch das die Höhle zum Bersten bringende Gebrüll Samsons endgültig besiegt. Kurz bevor der Vulkan ausbricht können die New Yorker Zoobewohner mit der Gnu-Herde gemeinsam auf dem kleinen Schiff von der Insel fliehen.\n\nLaut Urteil des Lexikon des Internationalen Films handelt es sich bei \"Tierisch wild\" um ein „mittels Computertechnik ausgeklügelt gestaltetes Trickfilmabenteuer, dessen Effekte aber nicht über die Ideenarmut der Geschichte hinwegtäuschen können. Bestenfalls einige hübsche Randepisoden werten die rührselige Handlung auf.“\n\nDie FFS Film- & Fernseh-Synchron GmbH war für die Synchronisation verantwortlich. Axel Malzacher schrieb das Dialogbuch und führte die Dialogregie.\n\nDer Film feierte seine Premiere am 6. April 2006 in Israel. Am 14. April 2006 hatte der Film in den Vereinigten Staaten Premiere und spielte in der ersten Woche 22,2 Millionen US-Dollar ein, davon bereits am Eröffnungswochenende gut 9,6 Millionen US-Dollar. In Deutschland und Österreich lief der Film am 1. Juni 2006 an, ihn sahen knapp eine halbe Million Zuschauer in den deutschen Kinos.\n\nBei dem Film handelt es sich um die umfangreichste Animationsproduktion Kanadas, bei der mehr als 400 Animatoren beteiligt waren. Die Ideen zu dem Film entstanden im Zeitraum von 1991 bis zur Umsetzung 2006.\n\n"}
{"id": "1517105", "url": "https://de.wikipedia.org/wiki?curid=1517105", "title": "Hydrogen (Software)", "text": "Hydrogen (Software)\n\nHydrogen ist ein virtueller Drumcomputer und -sequenzer für GNU/Linux. Es existieren inzwischen auch Versionen für Windows und macOS (nur Intel). Hydrogen bietet neben für Schlagzeugsoftware üblichen Standardfunktionen einige professionelle Funktionen wie vollständige Ansteuerung über MIDI und frei definierbare Samples. Samples können zu Bibliotheken zusammengefasst werden, die sich als Datei weitergeben lassen. Unter Linux ist Hydrogen kompatibel zum Soundserver JACK. Damit lässt sich Hydrogen auch mit anderen mit JACK verbundenen Anwendungen synchronisieren.\n\nEntwickelt wird Hydrogen von Alessandro Cominu. Der Quellcode ist unter der GNU General Public License verfügbar. Die grafische Benutzerschnittstelle verwendet die Qt-Bibliothek.\n\nIn Hydrogen lassen sich in einem Matrix-Editor Schlagzeugnoten zu rhythmischen Figuren, so genannten Patterns, zusammensetzen. Die Länge dieser mit Takten vergleichbaren Figuren ist einstellbar, so lassen sich neben dem in der Popmusik üblichen 4-Viertel-Takt auch 3-Viertel- oder 5-Viertel-Taktfiguren komponieren. Die Patterns lassen sich in Endlosschleifen (Loops) abspielen oder in einem Songeditor zu festgelegten Abläufen zusammensetzen. Dabei lassen sich auch mehrere Patterns gleichzeitig abspielen. Die verwendeten Klänge lassen sich in einem Instrumenteditor definieren und ab Version 0.9.5 auch mit einem einfachen Werkzeug schneiden. Außerdem verfügt das Programm über einen Mixer, in dem sich auch Effekt-Plugins im LADSPA-Format einbinden lassen. Unter Linux lassen sich alle Mixerkanäle auch einzeln über den Audioserver JACK ausgeben.\n\nFertige Songs oder auch einzelne Patterns lassen sich direkt aus Hydrogen als Datei im Format .WAV exportieren.\n\nAb Version 0.9.5 bietet Hydrogen in seinem Matrix-Editor auch einen Piano-Roll Modus, in dem sich für die einzelnen Klangsamples auch Noten in verschiedenen Tonhöhen anlegen lassen. Damit lassen sich auch melodische Muster in Hydrogen komponieren, die Percussions-Samples oder auch Melodieinstrumente wie Bass- oder Orgelsounds ansteuern können.\n\n"}
{"id": "1517283", "url": "https://de.wikipedia.org/wiki?curid=1517283", "title": "Blue Brain", "text": "Blue Brain\n\nDas Blue Brain-Projekt versteht sich als Pionierprojekt zum Verständnis der Funktionsweise des Gehirns durch die Bildung groß angelegter Computermodelle. Es wurde von Henry Markrams \"Brain and Mind Institute\" der École Polytechnique in Lausanne (Schweiz) und IBM (USA) im Mai 2005 ins Leben gerufen. Es hatte zum Ziel, bis 2015 ein biologisch korrektes, virtuelles Gehirnmodell zu schaffen. Seit einer EU-Förderung von 1 Milliarde Euro nennt sich dieses Vorhaben Human Brain Project.\n\nEin wichtiges Zwischenziel des Projekts wurde Ende 2007 abgeschlossen: Blue Column hat das Ziel der vollständigen Simulation einer neokortikalen Säule auf zellulärer Ebene erreicht. Neokortikale Säulen besitzen eine Höhe von 2 mm und einen Durchmesser von 0,5 mm. Beim Menschen enthalten sie circa 60.000 Neuronen. Blue Column bezieht sich auf Ratten, deren kortikale Säulen circa 10.000 Nervenzellen und ungefähr 10 Synapsen beinhalten. \n\nDie Simulation geht über das Konzept des künstlichen neuronalen Netzes hinaus: Sie beruht auf biologisch plausiblen und komplexen Modellen verschiedener Nervenzelltypen. Eingesetzt werden der von Phil Goodman entwickelte Neocortical Simulator (NCS) in Kombination mit Michael Hines' Software NEURON. Die Simulation soll auf einem BlueGene Supercomputer berechnet werden. Blue Column soll innerhalb von 2–3 Jahren realisiert und anschließend mit einer Reihe von empirischen Daten getestet werden. \n\nIm weiteren Verlauf soll die Entwicklung in zwei Richtungen fortgeführt werden:\n\nIn einer 10-Jahres-Perspektive sollen verschiedene Forscher weltweit eigene Modelle verschiedener Gehirnregionen erstellen und in eine Internet-Datenbank hochladen können. Die Blue-Brain-Software soll diese Module miteinander vernetzen und daraus die erste Simulation eines vollständigen Gehirns aufbauen. Um das zu erreichen, müssen mehrere noch ungelöste Probleme bewältigt werden.\n\nIm Oktober 2015 wurde als erstes größeres Ergebnis die Simulation der Aktivität von etwa 31.000 Neuronen aus dem somatosensorischen Cortex eines Rattengehirns präsentiert.\n\nAls Nachfolgeprojekt auf EU-Ebene ist das Human Brain Project zu verstehen, das ebenfalls von Markram lanciert wurde.\n\nAm 11. Januar 2018 veröffentlichte die EPFL die Datenplattform \"Blue Brain Nexus\" des Blue Brain Project.\n\nManche Kritiker sehen Markrams Projekt als teuren Irrweg an und meinen, das Geld solle besser für Forschung an echten Hirnen verwendet werden.\n\n\n\n"}
{"id": "1518852", "url": "https://de.wikipedia.org/wiki?curid=1518852", "title": "Apple iPod Hi-Fi", "text": "Apple iPod Hi-Fi\n\nDer iPod Hi-Fi war ein portables Lautsprechersystem von Apple, gedacht als Zubehör zum Anschluss an einen iPod. Es wurde am 28. Februar 2006 vorgestellt und kostete 349 €. Anfang September 2007, nach eineinhalb Jahren wurde der iPod Hi-Fi eingestellt und blieb ohne Nachfolger.\n\niPod Hi-Fi ähnelt einem typischen Mittellautsprecher eines 5.1-Systems. Das Lautsprechersystem besteht aus zwei 80-mm-Lautsprechern und einem 130-mm-Woofer. Äußerlich besteht der iPod Hi-Fi aus weißem Plastik, passend zur weißen iPod-Serie, und einer schwarzen Frontabdeckung, welche auch abnehmbar ist. Die Stromversorgung erfolgt entweder durch das interne Netzteil oder durch sechs Mono-Batterien.\n\nAn das eingebaute Dock kann jeder iPod mit 30-pin-Adapter angeschlossen werden (Universal Dock).\nAuf der Rückseite des Gerätes befindet sich neben dem Stromanschluss (genormter Anschluss – jedes Kabel eines Radiorecorders passte) auch ein 3,5-mm-Anschluss, an welchem Audiogeräte (z. B. iPods ohne 30-pin-Adapter wie der iPod shuffle, Computer oder CD-Player) entweder mit einem analogen oder einem optisch-digitalen Kabel (Mini-Toslink) angeschlossen werden können.\n\nDas Gerät weist als einzige Bedienungselemente zwei Sensortasten auf der Oberseite zur Veränderung der Lautstärke auf. Rückmeldung erfolgt über eine zweifarbige LED (grün/orange). Durch die mitgelieferte Fernbedienung Apple Remote (damalige erste Generation) kann zwischen externem Eingang und iPod gewechselt, die Lautstärke angepasst, die Wiedergabe am iPod gestoppt oder gestartet und das Lied innerhalb einer Playlist ausgewählt werden. Außerdem hatten die iPods der 5. Generation (der iPod classic hingegen nicht mehr) im Dock einen neuen Menüpunkt „Lautsprecher“, mit dem die Beleuchtung des Displays, die Vollbildanzeige des Covers und der Klang des iPod Hi-Fi in drei Stufen geregelt werden kann.\n\n\nGenereller Hinweis: Neuere iPod-Modelle, iPhone 3G, 3GS, 4 und 4S sowie iPod touch der 3. und 4. Generation können mit dem iPod Hi-Fi nicht mehr geladen werden, weil diese eine andere Ladespannung verwenden. Die Wiedergabe von Musiktiteln ist aber weiterhin möglich.\n\n"}
{"id": "1528237", "url": "https://de.wikipedia.org/wiki?curid=1528237", "title": "Optischer Computer", "text": "Optischer Computer\n\nOptische Computer sind Computer oder Rechenwerke, die vollständig oder teilweise mit optischen Elementen anstatt der heute gängigen elektronischen Komponenten arbeiten.\nHierbei kommen optoelektronische Elemente oder passive optische nicht-lineare Elemente zum Einsatz.\n\nDer Einsatz optischer Systeme in der Rechentechnik bietet einige Vorteile gegenüber der konventionellen Elektronik:\n\nDagegen ergibt der erhöhte Aufwand bei der Herstellung und Integration optischer Elemente in vorhandene Systeme höhere Produktionskosten.\n\n\nWährend die Verbindung von Baugruppen und Leiterplatten heute bereits Verwendung findet, sind Verbindungen von und in Integrierten Schaltkreisen noch in der Entwicklung.\n\nEs werden optische Verbindungselemente und/oder Verarbeitungseinheiten in elektronische Systeme integriert.\nLicht dient als Informationsträger, die logischen Schaltvorgänge werden elektronisch gesteuert.\n\nDiese Methode eignet sich besonders gut zur Verteilung des Taktes in einem System, was auch zu einer Minimierung des Taktversatzes führt.\n\nHier kommen vor allem passive optische Elemente zum Einsatz. \nLicht dient auch hier als Informationsträger, jedoch erfolgen die Schaltvorgänge durch Steuer-Lichtstrahlen, die den Brechungsindex von nichtlinearen optischen Stoffen ändern.\nSolche Bauteile weisen ähnliche Eigenschaften wie elektronische Transistoren auf.\n\n"}
{"id": "1528344", "url": "https://de.wikipedia.org/wiki?curid=1528344", "title": "SCons", "text": "SCons\n\nSCons ist ein freies Werkzeug für die Entwicklung und Erstellung von Software.\nEs ist ein Ersatz für das klassische make-Programm und integriert dabei die Funktionalität von Werkzeugen wie Autoconf, Automake und Compiler-Caches wie ccache. SCons basiert auf der Programmiersprache Python, Konfigurationsdateien können als normale Python-Skripte den vollen Umfang der Sprache nutzen.\n\nStandardmäßig wird C, C++, D, Java, Fortran, Objective-C, Yacc, Lex, Qt, SWIG und das Bauen von TeX- und LaTeX-Dokumenten unterstützt. Andere Sprachen oder Dateiformate können durch den Benutzer mittels sogenannter „Builder“ hinzugefügt werden.\n\nDie folgende sehr einfache SConstruct-Datei kompiliert die c-Datei \"hello-world.c\" mit dem plattformspezifischen Compiler.\n\nProgram('hello-world.c')\nDas folgende etwas kompliziertere Beispiel erzeugt eine Umgebung, die für das Bauen des Programms \"hello\" genutzt wird.\n\nenv = Environment()\nenv.Append(CPPFLAGS=Split('-Wall -g'))\nenv.Program('hello',\nWird in SCons ein Build angestoßen, so werden zunächst die Abhängigkeiten ermittelt. Dabei werden noch keine Build-Artefakte (z. B. Objekt-Dateien, Bibliotheken oder Executables) erzeugt oder verändert. Im zweiten Schritt werden diese Abhängigkeiten genutzt, um gemäß der Abhängigkeiten die Buildartefakte zu erzeugen, wenn sich dessen abhängige Dateien seit der letzten SCons Ausführung verändert haben.\n\nSCons’ Softwarearchitektur basiert auf dem 1999 in Perl geschriebenen \"Cons\" von Bob Sidebotham. SCons wurde ursprünglich von Steven Knight und Chad Austin, Charles Crain, Steve Leblanc, Anthony Roach geschrieben.\n\nSCons inspirierte wiederum Waf.\n\n\n"}
{"id": "1532789", "url": "https://de.wikipedia.org/wiki?curid=1532789", "title": "Informationslinguistik", "text": "Informationslinguistik\n\nInformationslinguistik untersucht sprachliche Probleme der Textanalyse. Diese treten z. B. im Kontext des Information Retrieval auf. Informationslinguistik befasst sich mit der Verarbeitung natürlicher Sprache in und für Informationssysteme. Informationslinguistik ist eine wissenschaftliche Disziplin zwischen Informationswissenschaft und Computerlinguistik.\n\n\n"}
{"id": "1536497", "url": "https://de.wikipedia.org/wiki?curid=1536497", "title": "BAM Ge 4/4", "text": "BAM Ge 4/4\n\nDie BAM Ge 4/4 sind vierachsige Meterspur-Elektrolokomotiven, mit der Bauartbezeichnung Ge 4/4, der Schweizer Bahnstrecken Bière–Apples–Morges und Apples–L'Isle. Die Bière-Apples-Morges-Bahn (BAM) wurde im Juli 2003 in Transports de la région Morges–Bière–Cossonay (MBC) umbenannt. \n\nParallel zur zweiten Serie der Ge 4/4 III der Rhätischen Bahn (RhB) beschaffte auch die damalige Bière-Apples-Morges-Bahn bei der Schweizerischen Lokomotiv- und Maschinenfabrik (SLM) und Asea Brown Boveri (ABB) zwei vergleichbare Lokomotiven mit den Betriebsnummern 21 und 22, die jedoch für eine Wechselspannung von 15 kV ausgelegt sind und zusätzliche Puffer für die Beförderung von Regelspurwagen auf Rollböcken besitzen. Die 1994 in Betrieb genommenen Fahrzeuge werden seitdem ausschliesslich für den Transport von Normalspurwagen auf Rollböcken verwendet. Häufigstes Transportgut sind Zuckerrüben. Ausserdem gibt es gelegentlich schwere Militärzüge zum Waffenplatz Bière der Schweizer Armee. Namensgeber der beiden grün-weissen Lokomotiven sind die Flüsse Morges und Venoge, die in den Genfersee fliessen. Der Name und die Nummer stehen jeweils seitlich der Tür.\n"}
{"id": "1540219", "url": "https://de.wikipedia.org/wiki?curid=1540219", "title": "Final Draft", "text": "Final Draft\n\nFinal Draft (engl. etwa \"Endfassung\" oder \"Drehfassung\") ist ein Textverarbeitungsprogramm, um Drehbücher zu schreiben. Es ist für OS X und Windows erhältlich (außerdem spezielle Versionen für iOS). Final Draft stellt den angloamerikanischen Industriestandard für Drehbuchautoren und Produktionsstudios dar.\n\nDas Programm wird mit einer großen Zahl an Vorlagen (\"Templates\") ausgeliefert, welche sich an bekannten US-amerikanischen Fernsehserien orientieren. Allerdings sind die Unterschiede zwischen den Vorlagen relativ gering, da Abweichungen vom Industriestandard nicht gern gesehen sind.\n\nFinal Draft hat mehrere Funktionen, um das Schreiben von Drehbüchern zu beschleunigen und zu erleichtern. So merkt sich das Programm Orte für Szenenüberschriften, Tageszeiten und die Namen der Figuren. Mittels Tabulatortaste und Tastaturkürzel kann man schnell zwischen einzelnen Formatierungen, etwa für Handlungsbeschreibungen, Figurennamen, Dialogen oder Dialoganweisungen wechseln.\n\nEbenso bietet das Programm einige Analysetools, sog. \"Reports\", mit deren Hilfe man u. a. Dialogauszüge einzelner Charaktere erstellen kann.\n\nIm Internet findet man einige Vorlagen für Textverarbeitungsprogramme aus Office-Paketen. Viele davon verwenden Makros, um die Formatierung zu beschleunigen. Kostenlose Alternativen stellen beispielsweise die Programme Celtx, Trelby oder die deutsche Anwendung DramaQueen FREE dar.\n\n"}
{"id": "1541714", "url": "https://de.wikipedia.org/wiki?curid=1541714", "title": "Tokenisierung", "text": "Tokenisierung\n\nTokenisierung bezeichnet in der Computerlinguistik die Segmentierung eines Textes in Einheiten der Wortebene (manchmal auch Sätze, Absätze o. Ä.). Die Tokenisierung des Textes ist Voraussetzung für dessen Weiterverarbeitung, beispielsweise zur syntaktischen Analyse durch Parser, im Textmining oder Information Retrieval.\n\nIn der Informatik bezeichnet der Begriff analog die Zerlegung eines in einer Programmiersprache verfassten Computerprogrammes in kleinste Einheiten, siehe Token (Übersetzerbau) und Tokenbasierte Kompression.\n\nÜblicherweise wird ein Text bei der Tokenisierung in seine Wörter zerlegt. Die White-Space-Tokenisierung ist die einfachste Form einer solchen Zerlegung. Der Text wird bei diesem Verfahren an den Leer- und Interpunktionszeichen aufgetrennt. Bei nicht-segmentisierenden Schriften wie der chinesischen oder japanischen kann es nicht angewandt werden, da in diesen keine Leerzeichen vorhanden sind.\n\nBei einem alternativen Tokenisierungsverfahren bilden Folgen von Buchstaben ein Token, ebenso alle Folgen von Ziffern. Alle anderen Zeichen bilden für sich genommen ein Token.\n\nBeide Verfahren sind jedoch problematisch im Fall von Mehrwortlexemen, speziell Eigennamen, Währungsangaben usw.\nFür den Satz \"Klaus-Rüdiger kauft in New York für $2.50 Fish'n'Chips.\" wäre aus linguistischer Sicht eine Segmentierung in folgende Tokenfolge adäquater:\n\n"}
{"id": "1543884", "url": "https://de.wikipedia.org/wiki?curid=1543884", "title": "TrueDownloader", "text": "TrueDownloader\n\nTrueDownloader (manchmal auch \"True Downloader\") ist ein freier (GNU General Public License) Download-Manager/-Beschleuniger.\nEr bietet Merkmale wie Pausieren/Fortsetzen, gleichzeitiges Herunterladen und Segmentieren des Downloads zum Zweck der Beschleunigung. Sowohl HTTP als auch FTP werden unterstützt. Darüber hinaus gibt es Spezialmerkmale wie Proxy-Unterstützung und ZIP-Vorschau. Das Programm wurde in Visual Basic erstellt.\n\nEr ist für Windows 9x/ME/2000/XP verfügbar und integriert sich über Erweiterungen in den Internet Explorer und in die Varianten des Mozilla-Webbrowsers (Firefox, Mozilla Suite, SeaMonkey). Die Weiterentwicklung des Programmes ist eingestellt worden; Versionen für Windows Vista und neuer sind nicht erhältlich.\n\nDas Programm trug ursprünglich den Namen \"DownloadPlus\", wurde jedoch umbenannt, da ein bekannter Trojaner gleichen Namens auftauchte.\n\n\n"}
{"id": "1544750", "url": "https://de.wikipedia.org/wiki?curid=1544750", "title": "Aria (Software)", "text": "Aria (Software)\n\nAria ist ein freier (GNU General Public License) Download-Manager/-Beschleuniger für unixoide Betriebssysteme wie Linux oder BSD.\n\nDas Programm ist mehrsprachig und verwendet GTK+ zur Darstellung der grafischen Benutzeroberfläche. Es unterstützt die Protokolle HTTP, HTTPS, FTP und SFTP. Die aktuelle Weiterentwicklung Aria2 unterstützt auch BitTorrent und Metalinks.\n\nWeitere Funktionen sind Pausieren und Fortsetzen sowie gleichzeitiges Herunterladen und Segmentieren des Transfervorgangs zum Zweck der Beschleunigung.\n\nAria lässt sich über die Erweiterung FlashGot in die Mozilla-Webbrowser (Firefox, Mozilla Application Suite, SeaMonkey) integrieren.\n\nDie Entwicklung des ursprünglichen Aria wurde im Dezember 2002 eingestellt. Seit dem 17. Februar 2006 wird die Anwendung unter der Bezeichnung aria2 als textbasierte Konsolenanwendung weiterentwickelt.\n\n"}
{"id": "1545021", "url": "https://de.wikipedia.org/wiki?curid=1545021", "title": "HNSKY", "text": "HNSKY\n\nHNSKY oder Hallo Northern Sky ist ein frei verfügbares 2D-Astronomieprogramm für Windows und Linux zur Simulation des Nachthimmels, welches seit Anfang 1998 vom Niederländer Han Kleijn entwickelt wird.\n\nHNSKY umfasst in der aktuellen Grundversion eine Sternendatenbank von 4,5 Millionen Sternen (TYCHO2++) und 30.000 Deep-Sky-Objekten bis zur Magnitude 12,5. Es simuliert den Sternenhimmel der Jahre 1750 bis 2250. Darüber hinaus kann es durch ein Plug-in auf der Herstellerwebsite bis zur Magnitude 15 (GSC) oder 16 (USNO UCAC-Katalog) im online-Zugriff, oder mit weiteren Datenbanken und eigenen Objektdaten erweitert werden. Planetenpositionen können mit einem Zusatzprogramm für den Zeitraum von 13.000 v. Chr. bis 16.999 n. Chr. dargestellt werden.\n\nDas Programm unterstützt die Teleskopsteuerungen ASCOM und Goto.\n\n"}
{"id": "1546657", "url": "https://de.wikipedia.org/wiki?curid=1546657", "title": "Virtual CD", "text": "Virtual CD\n\nDas kommerzielle Programm Virtual CD ist ein CD/DVD-Emulator, also eine Software zur Emulation der optischen Laufwerke CD-ROM und DVD-ROM.\n\nDie sogenannten virtuellen Laufwerke verhalten sich genau wie physische Laufwerke.\nSowohl für den Benutzer als auch für Programme gibt es keinen Unterschied zu tatsächlich vorhandenen Laufwerken. Auch Bedienung und Integration ins Betriebssystem unterscheiden sich nicht von \"echten\" Laufwerken. Trotzdem können virtuelle Datenträger auch in reale Laufwerke eingelegt werden.\nAußerdem können virtuelle Brenner angelegt werden, welche sich wie normale Brenner verhalten, außer dass sie Images erzeugen.\n\nVirtual CD erstellt Abbilder (Images) von CDs und DVDs. Diese lassen sich wie normale Discs in bis zu 23 virtuelle Laufwerke einlegen und benutzen. Das gilt auch für die meisten CDs, die sich aufgrund eines Kopierschutzes nicht kopieren lassen. Außerdem können dabei die Abbilder komprimiert und mit einem Passwort verschlüsselt werden.\n\nVirtual CD kann als Wegbereiter der CD-Emulatoren betrachtet werden. Das Produkt wird seit Mitte der 1990er Jahre verkauft und liegt aktuell in der Version 10 vor.\n\nVirtual CD gibt es sowohl als Einzelplatzversion als auch in netzwerkfähigen Varianten für Client/Server-Netzwerke und Terminalserver-Umgebungen. Für das vereinfachte Management steht zusätzlich der Network Management Server zur Verfügung. Diese Versionen kommen unter anderem in Schulen, Universitäten und Unternehmen zum Einsatz.\n\nEin CD/DVD-Emulator ist auch für Notebook-Besitzer sinnvoll. Um unterwegs CDs und DVDs zu nutzen, können virtuelle Laufwerke zur Arbeitserleichterung und zum Stromsparen beitragen. Die Scheiben müssen nicht transportiert und bei Bedarf eingelegt werden, und das stromverbrauchende optische Laufwerk wird nicht benötigt.\n\nZusätzlich zu den oben beschriebenen Funktionen bietet Virtual CD auch einen virtuellen Brenner. Dieser bietet die Möglichkeit, auch ohne physisch vorhandenen CD-Brenner virtuelle CDs zu erstellen, um etwa die Brennfunktion eines Programmes zu testen. Diese Funktion eignet sich auch zum Überprüfen einer CD- oder DVD-Zusammenstellung, bevor sie auf echte Medien gebrannt wird. So spart man sich eventuell zahlreiche verbrannte Rohlinge. Zusätzlich zum virtuellen Brenner kann man mit Virtual CD auch physische CDs brennen, wenn ein CD-Brenner vorhanden ist. Auf diesem Weg lassen sich CDs kopieren, Images brennen oder sogenannte Smart Virtual CDs erstellen, die wiederum lauffähige Images enthalten.\n\nVirtual CD ist zu zahlreichen ISO-konformen Image-Formaten kompatibel. Das trifft für eine Vielzahl bekannter Image-Formate zu.\nIm Einzelnen sind das:\n\n\nDer Treiber von Virtual CD verfügt als einziger CD-Emulator über eine Hardware-Zertifizierung von Microsoft. Die Software trägt daher das Logo »Designed for Windows 7, Windows x64 Edition« bzw. »Designed for Windows Server 2008«.\n\n"}
{"id": "1552411", "url": "https://de.wikipedia.org/wiki?curid=1552411", "title": "FAR Manager", "text": "FAR Manager\n\nDer FAR Manager (für englisch \"File and Archive Manager\", „Datei- und Archiv-Manager“) ist ein Klon des MS-DOS-Programms Norton Commander für Windows. Als Dateimanager im klassischen Zwei-Fenster-Modus erlaubt er das komfortable Kopieren, Löschen, Umbenennen, Bearbeiten oder Suchen von Dateien und Verzeichnissen im Win32-Konsolenfenster.\n\nGeschrieben wurde das Programm ab 1996 in C++ von Jewgeni Roschal, der zuvor schon das Dateiformat RAR und die zugehörigen Packprogramme RAR und WinRAR schuf. Ab dem Jahr 2000 wurde die Weiterentwicklung von der FAR Group übernommen. Die Versionen vor 1.80 sind Shareware sowie für Bürger der ehemaligen Sowjetunion für nicht-kommerzielle Zwecke kostenlos verwendbar. Seit dem 26. Oktober 2007 sind die Quelltexte der nachfolgenden Version 1.80, die später in 2.0 umbenannt wurde, als Open Source unter der BSD-Lizenz verfügbar.\n\nBis 2011 wurden die Versionen 1.75 und 2.0 gepflegt. Seitdem ist Version 3.0 aktuell, die keine Version-2-Plugins unterstützt. Hier wurde der Unicode-Support des Grundprogramms vervollständigt, es gibt eine zusätzliche 64-Bit-Version und es kann auch mit der seit Vista eingeführten Benutzerkontensteuerung umgehen. Nach Build 2798 (September 2012) wurden wesentliche Teile der API für die Plugins umgestellt, so dass viele FAR-3-Plugins ohne Anpassung nicht weiter funktionieren. Mit dem kurz darauf erschienen Build 2851 wurde die Makrosprache auf die Skriptsprache Lua umgestellt.\n\nDer integrierte Betrachter und Editor unterstützt UTF-8 und andere Unicode-Kodierungen sowie zahlreiche weitere Codepages inklusive IBM EBCDIC- und Macintosh-Zeichenkodierungen. Es können je nach Sperrzustand viele von anderen Programmen zum Schreiben geöffnete Dateien im Betrachter und Editor von FAR geöffnet werden. Wird beispielsweise eine Logdatei im Betrachter geöffnet und navigiert man an deren Ende, dann wird bei der nächsten Erweiterung automatisch weitergescrollt. Mit dem Betrachter können Dateien fast jeder Größe angesehen werden, da immer nur Abschnitte der Datei in den Speicher geladen werden. So sind auch Dateien über 4 GiB kein Problem und die Ansicht ist sofort verfügbar. Als Zugeständnis an diese Geschwindigkeit ist keine Navigation nach Zeilennummern möglich (die erst vom Programm durchgezählt werden müssten), jedoch über die Suche nach Zeichenketten sowie Regulären Ausdrücken und absoluter sowie relativer (+/-) Angabe der Dateiposition in Prozent oder Offset. In älteren Versionen konnte bei gemischter ein bis zwei Zeichen-Kodierung (UTF-8) und entsprechend eingestellter Ansicht nicht die ganze Datei durchsucht werden, beim Betrachten im OEM- oder ANSI-Modus (wo Umlaute als zwei Sonderzeichen auftreten) jedoch schon. Im Betrachter kann bei ausgeschaltetem Zeilenumbruch die Zeilenlänge je nach Einstellung zwischen 100 und 100.000 Zeichen betragen, bis ein Zwangsumbruch durchgeführt wird (bis Version 2.0 waren es unveränderbar 2048 Zeichen).\n\nDie eingebaute Bildschirmumschaltung ermöglicht es, beliebig viele Instanzen des Betrachters und Editors gleichzeitig platzsparend zu öffnen und schnell zwischen diesen und dem Dateimanager hin und her zu wechseln. Ein integrierter Makrorekorder erlaubt das Aufzeichnen und Wiedergeben von Tastatursequenzen. Mittels konfigurierbarer Verknüpfungen zu Dateierweiterungen lassen sich externe Programme wie Betrachter, Packprogramme und andere leicht in die Oberfläche einbinden. Bemerkenswert ist auch die Möglichkeit, symbolische NTFS-Verknüpfungen zu erzeugen.\n\nDie Funktionalität des Programms ist durch zahlreiche Plug-ins erweiterbar. Zum Lieferumfang gehören unter anderem ein vollwertiger FTP-Client, ein Netzwerk-Browser, eine Druckverwaltung sowie eine Prozessliste (als Alternative zum Windows-Taskmanager). Zusätzlich installierbare Plug-ins ermöglichen unter anderem extrem mächtige Syntaxhervorhebung im eingebauten Editor, Mailclients, Bearbeitung der Registrierungsdatenbank, Bearbeitung von ID3-Tags usw.\n\nIm Lieferumfang der Versionen vor 1.80 waren zwei Übersetzungen für die Benutzerschnittstelle und Hilfetexte auf Englisch und Russisch enthalten. Im sogenannten \"Far PlugRinG\", einer von unabhängigen Entwicklern gepflegten Sammlung von FAR-Plug-ins, konnten weitere Sprachdateien heruntergeladen werden. Ab Version 2.0 werden Übersetzungen für Deutsch, Englisch, Polnisch, Russisch, Tschechisch sowie Ungarisch mitgeliefert.\nEs existiert sowohl eine 32-Bit- als auch eine 64-Bit-Version.\n\nIn der 32- und 64-Bit-Version von FAR 3 funktionieren jeweils nur die dazupassenden Plugins. Es funktionieren Plugins für FAR 3 – wobei es mit Build 2798 (September 2012) eine große API-Umstellung gab und so einige vorher produzierte Plugins nicht mehr funktionieren – und so einige Plugins für FAR 1, diese nur mit ANSI-Unterstützung. Deshalb gibt es für so einige FAR-1-Plugins Weiterentwicklungen und 64-Bit-Versionen.\n\nSo auch beispielsweise für das vielseitige MultiArc-Plugin, welches zusätzliche Formate integrieren kann, und sei es durch parsen der Textausgaben von im Hintergrund aufgerufenen Kommandozeilen-Programmen, deren Parameter in einer INI-Datei angegeben wurden. In der Grundversion von FAR wurde es durch ArcLite ersetzt, welches beim Entpacken nicht so viele Formate unterstützt und sich beim Packen auf das 7z- und ZIP-Dateiformat beschränkt. Dazu gibt es den Observer, der einige Containerformate wie MSI, ISO, UDF oder Vdisk unterstützt und auch mit WCX-Modulen des Total Commanders erweitert werden kann. Ein MultiArc-ersetzendes Projekt NewArc wird seit langem nicht mehr weiterentwickelt.\n\nDie Einstellungen von FAR 3 und dazupassenden Plugins werden standardmäßig in den von Windows vorgesehenen APPDATA-Verzeichnissen in SQLite-Datenbanken gespeichert. Alternative Speicherorte für eine portable Installation können angegeben werden. Alte Plugins speichern ihre Einstellung wie gehabt in der Windows-Registrierungsdatenbank.\n\nDer FAR Manager arbeitet (von einigen Bildbetrachter-Plug-ins abgesehen) als interaktive Konsolenanwendung mit einer zeichenorientierten Benutzerschnittstelle im Textmodus und wirkt daher wie ein PC-kompatibles DOS-Programm, ist jedoch nicht unter MS-DOS lauffähig. Er arbeitet im von Anwendungssoftware nur sehr selten genutzten Konsolenfenster, in dem beispielsweise auch die 32-Bit-Programme cmd.exe oder Midnight Commander laufen. Als 32-Bit-Programm hat der FAR Manager Zugriff auf lange Dateinamen, den Windows-Papierkorb, die Zwischenablage und weiteres mehr.\n\n"}
{"id": "1558670", "url": "https://de.wikipedia.org/wiki?curid=1558670", "title": "BlindWrite", "text": "BlindWrite\n\nBlindWrite ist ein Computerprogramm der französischen Firma VSO-Software zum Kopieren von CDs, DVDs und Blu-ray Disc Discs. Das Programm bietet dem Anwender die Möglichkeit, eventuell vorhandene Kopierschutzmaßnahmen zu umgehen und verstößt somit gegen geltendes Recht in Deutschland und vielen weiteren EU-Staaten. Aus diesem Grund ist der Vertrieb und die gewerbliche Nutzung in Deutschland verboten. In der Schweiz sind derartige Programme nicht verboten.\n\nHauptmerkmale der Software sind zwei Funktionen, die vom Vorgänger BlindRead geerbt wurden. Dies sind zum einen Subcodes zur Beschreibung des eingelesenen Mediums und zum anderen die Fähigkeit, Fehlern auf dem Datenträger gegenüber „blind“ zu reagieren, also nicht wie bei anderer Software mit einer Fehlermeldung abzubrechen, sondern den Lesevorgang einfach fortzusetzen.\n\nNeben der Kopierfunktion bietet BlindWrite auch die Möglichkeit, Speicherabbilder von Datenträgern zu erstellen, die dann auch von anderen Programmen genutzt werden können.\n\n"}
{"id": "1558981", "url": "https://de.wikipedia.org/wiki?curid=1558981", "title": "Macintosh LC II", "text": "Macintosh LC II\n\nDer Macintosh LC II (LC steht für „low-cost color“ – preisgünstig, farbfähig) ist ein Macintosh-Rechner der Firma Apple. Er war 1992 die zweite Generation der Macintosh LC-Reihe.\n\nEr unterscheidet sich von seinem Vorgänger durch eine leicht andere Gehäusekonstruktion (ein zweites Diskettenlaufwerk statt einer Festplatte ist nicht mehr vorgesehen) sowie durch den Einsatz eines Motorola-68030-Prozessor mit 16 MHz. Dieser bot durch getrennte Caches für Daten und Instruktionen nur minimal mehr Leistung. Allerdings besitzt der 68030 eine integrierte MMU. Dies ermöglichte dem im Hauptspeicherausbau auf 10 MB limitierten Gerät das ab System 7 im Betriebssystem verankerte Swapping, von Apple \"Virtueller Speicher\" benannt. Der LC II erhielt 4 MB aufgelöteten Speicher auf der Hauptplatine (Vorgänger: 2).\n\nAnsonsten erbte der LC II alle Vor- und Nachteile seines Vorgängers.\n\nAuch der LC II sollte mit einem günstigen Preis (ab 3.100 DM, später sogar 1.400 DM mit Bildschirm) private Nutzer und Studenten anziehen. Vor dem Mac Mini gehörten LC bzw. LC II zu den platzsparenden Tischrechnern, waren trotz ihrer mäßigen Leistung beliebt und fanden guten Absatz.\n\nDer Macintosh LC II wurde in Deutschland mit dem Betriebssystem MacOS 7.0.1 (USA anfangs noch 6.0.7) ausgeliefert und konnte bis System 7.5.5 aufgestockt werden.\n\nUm den Verkauf gegen Ende seiner Laufzeit nochmals anzuwerfen, wurde der LC II u. a. auch als Macintosh Performa 400, 405, 410, 430 abverkauft.\n\n\"Macintosh LC II\" („Pizzaschachtel“, Nachfolger des Macintosh LC)\n\n\n"}
{"id": "1559275", "url": "https://de.wikipedia.org/wiki?curid=1559275", "title": "SpeedFan", "text": "SpeedFan\n\nSpeedFan (aus dem Englischen \"Speed\" für Geschwindigkeit und \"Fan\" für Lüfter) ist ein kostenfreies Mess-, Monitor-, Regel- und Steuerungsprogramm für (interne) PC-Temperatursensoren und -Lüfter, für alle gängigen Windows-Betriebssysteme (ab Windows 95). Des Weiteren können auch diverse Spannungen (wie vCore und andere Netzteil-Ausgangsspannungen) ausgelesen und grafisch, auch über einen längeren Verlauf, dargestellt werden.\n\nMit SpeedFan können u. a. relativ leicht Überhitzungsprobleme von Rechnern diagnostiziert werden, welche sich beispielsweise durch sonst unerklärliche Systemabschaltungen äußern können. Es kann aber auch vorkommen, dass die von SpeedFan ausgelesenen Temperaturen fern jeglicher Realität sind.\n\nEs ist auch möglich die Drehzahl einiger Lüfter (softwaretechnisch) herunterzuregeln, um den Geräuschpegel zu dämpfen. Diese Funktionen sind jedoch davon abhängig, ob die verwendeten Geräte – wie etwa der Hauptprozessor (CPU), der Hauptplatinen-Chipsatz, die Festplatten, das Netzteil – diese Möglichkeit überhaupt haben und ob das Programm auch darauf zugreifen kann.\n\nEine weitere Tuning-Möglichkeit ist das dynamische Verändern des CPU- und/oder FSB-Taktes, was die Wärmeentwicklung der Rechnerkomponenten senken kann, während der Rechner im Leerlauf ist. Das verbessert die Geräuschminderung, da bei weniger Wärmeentwicklung die Lüfter noch weiter heruntergeregelt werden können. Ebenso verbessert es die Akkulaufzeit von batteriebetriebenen Geräten.\n\nDerzeit werden u. a. über 200 verschiedene Hauptplatinen-Chipsätze unterstützt. Als Basis der beschriebenen Funktionalitäten dient unter anderem die in aktuellen Festplatten integrierte, „S.M.A.R.T.“ genannte Technik. Damit ist es in gewissen Grenzen möglich, den physikalischen Zustand von Festplatten auszulesen und zu interpretieren.\n\nDie Größe des Downloads beträgt circa 2,9 MB. Das Programm muss installiert werden, eine portable Version ist nicht erhältlich.\n\n"}
{"id": "1560608", "url": "https://de.wikipedia.org/wiki?curid=1560608", "title": "Cadwork", "text": "Cadwork\n\ncadwork ist ein kommerzielles CAD/CAM-Programm, welches in vielen Bereichen der Planung verwendet werden kann. Dieses Programm eignet sich für Holzbauer, Konstrukteure und Hochbauzeichner sowie Tiefbauzeichner. \n\nIn dem 2-D-Modul cadwork 2D arbeitet man mit normalen, zweidimensionalen Linien und Flächen mit verschiedenen Schraffuren usw. Im 3-D-Modul cadwork 3D arbeitet man hingegen mit Volumen, um Wände darzustellen, Holz- und Stahlstabwerke zu generieren und dreidimensionale Knotenpunkte zu planen. Hier wird alles in einem dreidimensionalen Raum aufgebaut und kann dann dadurch beliebig gedreht und angeschaut werden.\n\nDie zweidimensionale Variante eignet sich im Massivbau besonders für Werkpläne, während das 3-D-Modul für Ausschreibungen und für Wettbewerbe um ein Bauprojekt besser ist. Alternativen zu letzterem sind z. B. Revit oder ArchiCAD.\n\nFür die vielfältigen Anwendungen im Holzbau stellt cadwork mehrere Module zur Verfügung.\n\ncadwork 2D ist das Einstiegsmodul in das Programmpaket von \"cadwork\".\n\nEs ist ein 2.5D-CAD-System, das neben der zweidimensionalen Bearbeitung auch das Mitführen von Höheninformationen erlaubt. So ist ein problemloser Übergang in cadwork 3D möglich.\n\nDie Denkweise des Zeichners und Konstrukteurs spiegelt sich hier wider und sichert das logische Arbeiten, da alle Linien selbst vom Benutzer definiert werden. Der Zeichner kann also beliebige Formen ohne großen Aufwand erstellen. Die Linien lassen sich anschließend in Flächen umwandeln, und können danach mit einer Schraffur gefüllt werden.\n\ncadwork 3D ist ein 3D-CAD/CAM-System. Die Anwendungsbereiche sind hauptsächlich im Holzbau und Stahlbau zu sehen. cadwork 3D bietet die Möglichkeit mit freien Volumenmodellen zu arbeiten. Diese haben eine interne Achse (Länge, Breite und Höhe) die es ermöglichen die einzelnen Bauteile in einfacher Weise zu komplexen, dreidimensionalen Strukturen zusammenzustellen.\nEs gibt verschiedene Zusatzmodule, wie z. B. einen Assistenten für die Eingabe eines Daches, einen Assistenten für die Elementierung von Wänden oder auch der Ausgabe der einzelnen Bauteile als bemaßte 2D Einzelteilzeichnung oder an CNC-Abbund Maschinen.\n\n"}
{"id": "1561910", "url": "https://de.wikipedia.org/wiki?curid=1561910", "title": "Shadow-Passwort", "text": "Shadow-Passwort\n\nUnter dem Begriff Shadow-Password wird eine Methode zum Schutz von Passwörtern verstanden, welche in vielen Unix-Systemen noch heute verwendet wird. Das Passwort wird dabei vor dem Zugriff durch unbefugte Benutzer geschützt, um somit das Brechen von zu schwachen Passwörtern durch Brute-Force- oder Wörterbuchangriffe zu verhindern.\n\nVor der Einführung von Shadow-Passwörtern wurden alle relevanten Benutzerdaten, somit auch der Hashwert des Passworts, in einer Datei gespeichert. Diese Datei (/etc/passwd) musste für alle Benutzer zugänglich (lesbar) sein, um auch Anwendungsprogrammen (beispielsweise zur Anzeige von Dateirechten) das Auflösen von Benutzerkennungen zu Benutzernamen zu ermöglichen, und konnte dadurch leicht für Angriffe auf das System genutzt werden.\n\nDie auf den ersten Blick einfach erscheinende Lösung, Passwort-Hash und Nutzerdaten durch zwei separate Dateien voneinander zu trennen, erfordert jedoch innerhalb des Betriebssystems eine wirksame Trennung von Nutzerrechten und Systemrechten, da ein Zugriff auf die Passwort-Hashes durch unprivilegierte Nutzer, zum Beispiel bei der Anmeldung am System, natürlich möglich bleiben muss.\n\nErstmals wurde ein solches System von den Unix-Derivaten System V 3.2 und BSD 4.3 Reno verwendet. Nutzer anderer Systeme blieben vorerst ausgeschlossen.\n\n1987 entwickelte Julianne Frances Haugh die \"Shadow Password Suite\", die ursprünglich die Befehle login, su und codice_1 enthielt. Entwickelt wurde die \"Shadow Password Suite\" für SCO Xenix, aber bald auf andere Plattformen portiert, z. B. 1992 auf Linux.\n\nInzwischen sind Shadow-Passwörter zum Standardverfahren im Unix- und Linuxbereich geworden. Damit konnte die im ursprünglichen Konzept von Unix enthaltene Sicherheitslücke erfolgreich geschlossen und der unbefugte Zugriff auf die Password-Hashes der Benutzer wirksam verhindert werden. Damit ist die Möglichkeit für einen normalen Nutzer, diese mit Hilfe von Brute-Force und Wörterbuchangriffen zu missbrauchen, eingeschränkt, wenn auch nicht unmöglich. Verschiedene netzwerkbasierende Authentifizierungsysteme wie zum Beispiel Yellow Pages (YP) bzw. Network Information Service (NIS) übertragen die Passwort-Hashes über das Netzwerk und ermöglichen somit dem Angreifer einen unerlaubten Zugriff. Unter anderem aus diesem Grund geht der Trend auch mehr in die Richtung, stärkere Verschlüsselungsverfahren, wie auch immer geartet, für die Passwörter zu verwenden.\n\n"}
{"id": "1562032", "url": "https://de.wikipedia.org/wiki?curid=1562032", "title": "HACMP", "text": "HACMP\n\nDer Cluster Manager für AIX wird HACMP () genannt. Er wird bei Applikationen eingesetzt, die eine hohe Verfügbarkeit aufweisen müssen. Dies sind in der Regel unternehmenskritische Applikationen (z. B. das Abrechnungssystem für Wertpapiergeschäfte bei einer Bank).\n\nMit Version 6.1 wurde HACMP in PowerHA umbenannt. Auch wenn die Software mittlerweile nicht mehr so heißt, ist die Bezeichnung \"HACMP\" – auch für neue Versionen – in Fachkreisen immer noch üblich.\n\nMit Version 7.1 wurden sogenannte SmartAssists eingeführt, die eine automatische Erkennung und Konfiguration von verschiedenen Applikationen als HA-Lösung ermöglichen sollen.\n\nTeilnehmende Maschinen an einem HACMP-Cluster werden \"Knoten\" genannt. Auf diesen Knoten laufen sogenannte \"Resource Group\"s (RG), die den zentralen Begriff in HACMP darstellen: eine RG ist die logische Zusammenfassung\n\n\nBeim Aktivieren einer solchen Resource Group auf einem Clusterknoten werden zunächst die zugehörigen Filesysteme gemountet, anschließend mit Hilfe von in der RG-Definition hinterlegten Start-/Stop-Skripten die Prozesse der RG gestartet. Danach wird die IP-Adresse (die sogenannte \"Service IP\") als IP-Alias auf ein dafür bestimmtes Interface aufgebracht.\n\nWird die Resource Group auf einen anderen Clusterknoten verschoben (\"Takeover\"), so wird erst mit Hilfe des Stop-Scripts die Anwendung beendet, die Filesysteme unmountet und der IP-Alias mit der Service-IP gelöscht, anschließend auf dem in der Reihenfolge nächsten Knoten das Start-Script (siehe oben) abgearbeitet. Für den Client entsteht lediglich eine kurze Unterbrechung (die notwendige Zeit für den Wechsel) bis der Service wieder unter derselben IP-Adresse zur Verfügung steht. Dass diese IP-Adresse nun eine andere Maschine repräsentiert, merkt der Client nicht.\n\nDer größte Teil der Funktionen in HACMP bzw. PowerHA wird durch Scripte (in der Kornshell) erledigt, lediglich ein kleiner Kernel-Patch (der sogenannte \"Dead-Man-Switch\") greift direkt verändernd in das darunterliegende Betriebssystem ein. Diese offene Architektur macht HACMP sehr flexibel.\n\nDas größte Problem das Clustersoftware lösen muss, ist die sogenannte \"Split Brain Condition\": beide Knoten glauben, der aktive zu sein bzw. werden zu müssen. In HACMP/PowerHA werden bei der Konfiguration des Clusters verschiedene Kommunikationsstrecken definiert, über die sich die Clusterknoten wechselseitig Nachrichten über ihre Funktionsfähigkeit zukommen lassen. Dies wird \"Heartbeat\" genannt und kann über\n\n\nbewerkstelligt werden. Kommt ein Knoten aufgrund nicht mehr empfangener Heartbeats zu dem Schluss, nicht mehr mit dem Partner bzw. der Außenwelt kommunizieren zu können, wird der Dead-Man-Switch ausgelöst und der Knoten schaltet sich je nach Konfiguration entweder ab oder startet neu. Der jeweils aktive Knoten prüft darüber hinaus, ob die Kommunikation mit den Clients noch möglich ist, bevor er sich abschaltet, damit der Standby-Knoten übernehmen kann.\n\nMit HACMP/PowerHA ist eine Vielzahl von Clusterkonfigurationen möglich, die bei weitem häufigsten sind aktiv/passiv-Cluster (im HACMP-Jargon \"rotating Cluster\" genannt) und aktiv/aktiv-Cluster (\"cascading Cluster\").\n\nDie Resource Group läuft auf einem von üblicherweise zwei (bei Bedarf aber auch mehr) Knoten, auf dem anderen Knoten läuft lediglich das Betriebssystem und der \"Cluster Manager\". Fällt der aktive Knoten aus, so führt der andere einen Takeover durch. Der Modus wird \"rotating\" genannt, weil die Resource Group zwischen den Knoten hin- und herverschoben wird, also quasi \"rotiert\".\n\nDiese Betriebsart wird bevorzugt für unabdingbar notwendige Systeme eingesetzt und hat den Vorteil, gut planbar bei relativ geringer Komplexität zu sein. Der Nachteil ist, dass ein erheblicher Teil der Kapazität (der/die Standby-Knoten) die meiste Zeit über nicht genutzt wird.\n\nDie Resource Group mit der Hauptanwendung läuft auf einem Knoten, auf einem weiteren Knoten laufen Resource Groups, die bei Bedarf abgeschaltet werden können. Im Fehlerfall führt der Standby-Knoten zunächst die Stop-Skripte seiner eigenen Resource Groups aus, danach wird ein Takeover auf die RG der Hauptanwendung durchgeführt.\n\nDiese Betriebsart ist typisch für Systeme, bei denen eine Produktivinstanz einer oder mehreren Test- bzw. Entwicklungsinstanzen gegenübersteht, etwa bei SAP ERP oder größeren Datenbanken. Die Testinstanzen werden dann, solange kein Fehler auftritt, auf dem Standby-Knoten betrieben, im Fehlerfall stehen sie für einige Zeit nicht zur Verfügung.\n\n"}
{"id": "1563522", "url": "https://de.wikipedia.org/wiki?curid=1563522", "title": "Farbkorrektur", "text": "Farbkorrektur\n\nUnter Farbkorrektur versteht man die Korrektur oder Änderung von Farbstichen fotografischer Aufnahmen.\n\nBei Bildaufnahmen, seien es Fotografien, Film- oder Fernsehaufnahmen, entspricht die Farbwiedergabe des Produkts häufig nicht den Vorstellungen des Fotografen oder Kameramanns. Die Ursachen liegen häufig an unzureichend angepassten Filmmaterial oder besonderen Lichtverhältnissen vor Ort.\n\nObwohl man diesen Gegebenheiten bereits bei der Aufnahme Rechnung trägt, sei es bei der Auswahl des Aufnahmematerials, durch einen manuellen Weißabgleich oder Verwendung von geeigneten Farbfiltern, kann es trotzdem zu Unstimmigkeiten beim Ergebnis kommen. In diesem Falle muss eine Farbkorrektur durchgeführt werden. Diese richtet sich nach künstlerischen Gesichtspunkten und Aspekten der menschlichen Wahrnehmung. Ein Ziel der Farbkorrektur ist ein ausgewogenes Verhältnis der zu erreichenden Farbstimmung. Die Farbkorrektur sollte nicht als Notlösung oder Fehlerkorrektur begriffen werden, sondern stellt einen normalen Arbeitsgang im Bereich der Fotografie und Filmproduktion dar. Dies gilt vor allem dann, wenn für bestimmte Bildelemente strenge Vorgaben des Auftraggebers gelten, weil abgebildete Fahrzeuge oder Gebäude in einem klar definierten Corporate Design erscheinen sollen und daher normale Abweichungen in der Farbdarstellung korrigiert und idealisiert werden müssen.\n\nBei der farblichen Korrektur von Filmaufnahmen, die häufig mit unterschiedlichem Filmmaterial unter wechselnden Lichtverhältnissen gedreht wurden, ist es nötig, alle Aufnahmen der Angleichung zu unterziehen, damit die Wahrnehmung des Zuschauers nicht durch wechselnde Farbstiche von Szene zu Szene gestört wird. Obwohl die Szenen durch Adaptationseffekte des Auges für sich genommen stimmig erscheinen, muss bei der Farbkorrektur die Gesamtheit des geschnittenen Materials berücksichtigt werden.\n\nAuch können Fehler des Aufnahmematerials und geringfügige Unterschiede im Entwicklungsprozess zu unterschiedlichem Farbgleichgewicht führen. Diese Arbeit wird auch als Farb- oder Lichtbestimmung bezeichnet. Die analoge Farbkorrektur wird bereits beim Kopiervorgang im Kopierwerk durchgeführt, bei dem ein Film mit einer Lichtquelle auf einen unbelichteten Film kopiert wird. Das Farbspektrum dieser Lichtquelle ist ausschlaggebend für das Farbgleichgewicht der Kopie. Aus diesem Grund wird das Kopierlicht gesteuert. Die Beeinflussung des Lichtes geschieht entweder subtraktiv oder additiv, man unterscheidet deshalb beim Kopiervorgang entsprechend zwischen \"subtraktivem\" und \"additivem\" Kopieren.\n\nHier wird das Licht mittels Korrekturfiltern angepasst. Dieses Verfahren schließt die Unzulänglichkeiten von Farbfiltern ein. Das bedeutet gebundenes Kapital in langsam verderbenden Filtern, umständlich zu bedienende Steuerstreifen aus so genanntem Leatheroid, einer lederähnlichen Papiersorte, und relativ geringe Kopiergeschwindigkeit. Ein Vorteil ist es, dass das Zusammenstellen der Filtersätze der Lichtbestimmer geschult wird.\n\nDrei farbige Lichtquellen – bevorzugt Rot, Grün und Blau – dienen der Korrektur der Vorlage, deren Intensitäten, besser gesagt die Lichtmengen werden unabhängig voneinander geregelt. Alle Parameter und Änderungen über die Länge des Filmes sind hierbei zu speichern. Dies geschah früher mittels Lochstreifen, die für die gesamte Dauer des Filmes mitliefen. Mittlerweile gibt es jedoch auch Lichtsteuerungen für Kopiermaschinen, bei denen man die Werte auf elektronischen Datenträgern speichert und von da ausliest. Vorteil ist hier die Reinheit der Lichtfarben und die schnelle Änderung im Betrieb zusammen mit der elektronischen Datenverwaltung.\n\nDer Beruf des Farbkorrekteurs in der Filmbranche wird als Lichtbestimmer, im digitalen Bereich als Colorist bezeichnet. Es sind geschulte Fachkräfte, die in speziell eingerichteten Räumen Filme korrigieren. Dabei stehen Farbanalyzer oder Spezialcomputer und spezielle Eingabegeräte zur Verfügung, mit denen die Korrekturparameter sehr genau auch in Echtzeit justiert und gespeichert werden können.\n\nNeben der technisch motivierten Farbkorrektur ist es auch möglich, nachträglich unterschiedliche Stimmungen zu erzeugen. In Zusammenarbeit mit dem Kameramann wird häufig ein besonderer „Look“ des Filmes angestrebt. Beispiele finden sich in Steven Soderberghs Filmen \"Traffic – Macht des Kartells\" und \"Out of Sight\", Stanley Kubricks\" \", Peter Jacksons , Zhang Yimous \"Hero\" und Michelangelo Antonionis \"Die rote Wüste\".\n\nBei der optischen Farbkorrektur von Filmen wurde für jede Einstellung die Lichtstimmung festgelegt und auf Lochstreifen gespeichert. Beim Kopieren des Filmmaterials wurden – durch den Lochstreifen gesteuert – die jeweiligen Lichtquellen oder Filter aktiviert.\n\nBeim analogen Betacam-Standard von Sony konnte eine grobe Farbkorrektur durch Einstellen der Band-Vormagnetisierung vorgenommen werden (möglich durch das separat aufgezeichnete Farbsignal). Grobe Korrekturen konnten so ohne die vergleichsweise teuren Zusatzgeräte erfolgen.\n\nSeit der Jahrtausendwende werden praktisch alle Farbkorrekturen elektronisch durchgeführt. Optisches Filmmaterial wird dazu per Abtaster digitalisiert und (für spätere Verbreitung als Film) per Laser belichtet.\n\nHeutzutage verwendet man für den Vorgang der Farbkorrektur meist den englischen Begriff \"Color Grading\" oder kurz Grading. Daraus leiten sich die alternativen Berufsbezeichnungen Colour Grader und Color-Timer ab. Da das Wort „Farbkorrektur“ mit der Assoziation der Behebung von Fehlern verbunden wird, eignet sich der Begriff Grading besser um auszudrücken, dass der Colorist (also der Grader) maßgeblich an der Erschaffung der Farbstimmungen (Looks) beteiligt ist.\n\nDie Farbkorrektur wird nicht nur verwendet, um Bilder zu korrigieren, sondern auch um eine Stimmung zu erzeugen. So wird in einigen Reality-Shows die Farbe angepasst, um der Szene einen fröhlichen Touch zu geben. Andererseits werden bei romantischen Szenen die Farben leicht übersättigt, um dem Klischee einer Bergwelt zu entsprechen. Oder es wird der Farbton herausgefiltert und kühl gestaltet, wenn die Szene negativ wirken soll oder Menschen unsympathisch wirken sollen.\n\nBeim Konvertieren von Videomaterial zwischen verschiedenen Fernsehsystemen (vom amerikanischen NTSC auf das deutsche PAL-System) ergeben sich oft Farbabweichungen, die – bei professionellem Qualitätsanspruch – eine Farbkorrektur erfordern.\n\n"}
{"id": "1564782", "url": "https://de.wikipedia.org/wiki?curid=1564782", "title": "AppArmor", "text": "AppArmor\n\nAppArmor (\"Application Armor\", auf Deutsch etwa \"Anwendungs(programm)-Panzerung\") ist eine freie Sicherheitssoftware für Linux, mit der Programmen einzeln bestimmte Rechte zugeteilt oder entzogen werden können. Mit dieser Erweiterung wird die Mandatory Access Control (MAC) implementiert.\n\nDie Software verwendet genau wie SELinux die Linux-Security-Modules-Schnittstelle. Sie läuft als Kernel-Modul und steuert direkt die Zugriffsrechte der einzelnen Prozesse auf höchster Systemebene. Durch diesen Präventivschutz sollen Anwendungen vor noch nicht öffentlich bekannten Sicherheitslöchern, sogenannten Zero-Day-Exploits, geschützt werden. Welchen Zugriff ein Programm benötigt, um normal zu arbeiten, bestimmen Profile mit individuellen Sicherheitsrichtlinien. Für standardmäßig verwendete Software auf einem GNU/Linux-System wie den Druckerserver CUPS werden vorgefertigte Profile mitgeliefert. Anwender und Systemadministratoren können auch eigene Profile für Anwendungen erstellen. Eine weitere Möglichkeit ist der Einsatz von lernfähigen Filtern, während sich ein Programm im Normalbetrieb befindet.\n\nAppArmor wurde zunächst von Immunix entwickelt. Im Jahr 2005 erfolgte eine Übernahme durch Novell, wo die Software weiter entwickelt und erweitert wurde. Im Oktober 2007 entließ jedoch Novell die daran arbeitenden Programmierer und trennte sich von der Entwicklung von AppArmor. Die entlassenen Entwickler planten, das Projekt unter der neu zu gründenden Firma \"Mercenary Linux\" fortzuführen. Mehrere Versuche AppArmor in den Linux-Kernel zu übernehmen scheiterten, wegen Bedenken, dass Dateien über ihren Dateinamen und nicht über ihre Attribute wie etwa bei SELinux erkannt werden. Seit 2009 arbeitet Canonical verstärkt an AppArmor. Mit Linux 2.6.36 wurde es Bestandteil des Kernels.\n\nAktuell wird AppArmor in den Distributionen openSUSE und Ubuntu genutzt. Mit der Version 2010.0 stieg Mandriva auf Tomoyo um.\n\n"}
{"id": "1566762", "url": "https://de.wikipedia.org/wiki?curid=1566762", "title": "EndNote", "text": "EndNote\n\nEndNote ist ein kommerzielles Literaturverwaltungsprogramm für Microsoft Windows und Mac OS X, welches die Onlinesuche in Datenbanken (z. B. PubMed) und das Anlegen/Verwalten von Literaturdatenbanken erlaubt.\n\n\nEndNote-Daten können von vielen anderen Literaturverwaltungen importiert werden; u. a. von\n\nEndNote X3 ist nicht mit Microsoft Word 2010 kompatibel und führt zum vollständigen Einfrieren von Word während des Starts. Die Version X4 von EndNote ist sowohl mit der 32- als auch mit der 64-Bit-Version von Microsoft Word 2010 kompatibel. Version X6 ist mit MS Office 2013 kompatibel.\n\n\n"}
{"id": "1567224", "url": "https://de.wikipedia.org/wiki?curid=1567224", "title": "OCAD (Software)", "text": "OCAD (Software)\n\nOCAD ist ein Grafikprogramm, das ursprünglich zum Zeichnen von Orientierungslaufkarten entwickelt wurde, aber heute auch in der Kartografie für Stadtpläne, topographische und thematische Karten benutzt wird.\n\n1992 wurde die Firma Steinegger Software von Hans Steinegger gegründet.\n\nIn seiner Freizeit entwickelte Steinegger bereits 1988 die erste Version von OCAD. Nach der Firmengründung widmete er sich vollzeitlich der Weiterentwicklung. Insbesondere hat er die Entwicklung von einem Spezialprogramm für Orientierungslaufkarten zu einem allgemeinen kartografischen Zeichnungsprogramm vorangetrieben.\n\nHans Steinegger betrieb in jungen Jahren Orientierungslauf als Eliteläufer. Er hat vor der Entwicklung von OCAD eine Anzahl Karten mit Rapidograph und Tusche gezeichnet. Diese praktische Erfahrung bildete neben dem beruflichen Wissen die Grundlage für die Entwicklung von OCAD. Hans Steinegger verstarb am 19. Juni 2004 an Herzversagen. Im Mai 2005 wurde die OCAD AG gegründet.\n\nBei der Erstellung von Orientierungslaufkarten ist das Programm inzwischen Standard. Vor allem ist es in Skandinavien sehr verbreitet. Auch in der kommerziellen Kartografie gewinnt OCAD zunehmend an Bedeutung. Es wird in verschiedenen Branchen eingesetzt: Verlagskartografie, kartografische Institute, Vermessungsämter, Städte-, Bezirks- und Gemeindeverwaltungen, Feuerwehren, Grafische Betriebe, Planungs- und Ingenieurbüros, Hochschulen, Universitäten, Militär, Sport- und Freizeitvereine etc.\n\nEs gibt 4 verschiedene Editionen, wobei eine davon für die Kartografie geeignet ist und 3 davon für den Orientierungslauf: \nFür Kartografie: Diese Edition ist auf die Produktion von Stadtplänen, topographischen und thematischen Karten ausgerichtet. Sie umfassen einen leistungsstarken Symboleditor, smarte Bearbeitungs- und Zeichnungs-Tools, Generalisierungs-Tools, Import und Visualisierung von Geodaten, Multi-Repräsentation, Kartenlayout Layer, Webkarten Export-Assistent, WMS-Verbindung, GPS Echtzeit-Datenerfassung, Step-by-Step Wizard zur Analyse von LiDAR-Daten, verschiedene Visualisierungsmethoden von thematischen Daten, sowie verschiedene Diagrammtypen und vieles mehr.\n\nFür Orientierungslauf: Diese Editionen sind speziell abgestimmt für die Ansprüche der Kartenerstellung im Orientierungslauf mit einem Step-by-Step Wizard zur Analyse von LiDAR-Daten, GPS Echtzeit-Datenerfassung, smarten Bearbeitungs- und Zeichnungs-Tools, Generalisierungs-Tools, Kartenlayout Layer, Bahnlegung für Orientierungslauf und vieles mehr.\n\nDurch den Vertrieb in ganz Europa und nach Übersee ist OCAD in 17 verschiedenen Sprachen erhältlich (Chinesisch (Traditionell), Deutsch, Englisch, Finnisch, Französisch, Italienisch, Japanisch, Katalanisch/Catalan, Norwegisch, Polnisch, Portugiesisch, Russisch, Schwedisch, Spanisch, Türkisch, Tschechisch und Ungarisch).\n\nOCAD unterscheidet sich wesentlich von anderen Grafikprogrammen dadurch, dass es nicht mit Layern, sondern mit (kartographischen) Symbolsätzen arbeitet, wobei jedem Symbol eine feste Hierarchiestufe zugeordnet ist. Beispielsweise werden Straßen stets über Wiesenflächen gedruckt, nicht umgekehrt. Dies erspart in der Kartographie mit ihren festen Über- und Unterordnungen viel Arbeit. Neben den üblichen Zeichenfunktionen und der Bearbeitung von Rastergrafiken, verfügt OCAD über die Möglichkeit einer Datenbankanbindung und zum Import von GPS-Daten. Auch die Erstellung von interaktiven Internetkarten ist möglich.\n\nOCAD unterstützt den Import der folgenden Dateiformate: AI, CSV, DXF, GML/XML, GPX, KML, NMEA, OSM, PDF, RCW, SHP, SOS, SVG, XYZ\n\nExportformate: AI, BMP, DXF, EPS, GIF, GPX, JPG, KML/KMZ, PDF, PNG, SHP, SVG, TIFF\n"}
{"id": "1567273", "url": "https://de.wikipedia.org/wiki?curid=1567273", "title": "GlobalPC", "text": "GlobalPC\n\nDer GlobalPC ist ein auf ROMDOS und PC/GEOS basierender Heimcomputer mit Embedded-Technologie. Er wurde im Jahr 2000 in hohen Stückzahlen produziert und durch das Unternehmen MyTurn Inc. hauptsächlich in den USA und Kanada vermarktet.\n\nAls internetfähiger Desktop-Computer kann er als moderner Nachfolger des, ab 1987 mit GEOS bestückten, C128 angesehen werden und stand so in direkter Konkurrenz zu dem 1998 erschienenen Apple iMac und zu Personal Computern, die mit Pentium-III-Prozessoren bestückt und mit Windows-Desktops ausgestattet waren.\n\nRobert Edward Turner IV., Sohn des CNN-Chefs Ted Turner, und einige weitere einflussreiche US-Persönlichkeiten benannten das zuvor aufgekaufte Polizeisoftware-Unternehmen Compudawn am 10. Juni 1997 in MyTurn.com um, gründeten das Tochterunternehmen e.TV-Commerce Inc. und kauften 1999 den kurz zuvor gegründeten Hersteller eines neuartigen Homecomputers GlobalPC, sowie Unternehmensbereiche der LocalNet Communication auf, um MyTurn.com als Aktienunternehmen an die US-Börse zu bringen. Ziel war spätestens mit Aufkauf von GlobalPC, die weltweite Vermarktung, des daraufhin als leicht zu erlernenden und preiswert beworbenen PC/GEOS 4.x Computer für Internet, Hobby und Büro, GlobalPC.\n\nDie zur Vermarktung des GlobalPC gehörige, mit CNN-Inhalten gespeiste Internetplattform www.MyTurn.com war der Versuch des „Ted-Turner-Imperiums“ dem damaligen Marktführer AOL Konkurrenz zu machen. Außerdem wollten MyTurn und AMD mit dem GlobalPC und bereits geplanten Nachfolgern das „Wintel“-Monopol, bestehend aus den Firmen Intel und Microsoft, brechen.\n\nDer GlobalPC verfügte über folgende Systemkonfiguration:\n\n\nEin Netzteil, PS/2-Tastatur und -Maus gehörten ebenso zum Lieferumfang, sowie Anschlussmöglichkeiten für einen Betrieb an einem Fernseher nach NTSC-Standard.\n\nAls Betriebssystembasis war ROMDOS des Unternehmens Datalight in der Version 6.22 vorinstalliert, während als grafische Benutzeroberfläche GEOS 4 diente. Die optional einschaltbare Oberfläche für fortgeschrittene Benutzer wurde GEOS 2000 genannt und ähnelte in ihrem Aussehen und ihrer Benutzung Windows-Systemen dieser Zeit.\n\nDer GlobalPC wurde nach einer professionellen Marktforschungsanalyse zuerst im Direktvertrieb über einen Strukturvertrieb vermarktet. Diese Vorgehensweise wurde aber nach einer nur wenige Wochen kurzen Testphase beendet, als erreicht werden konnte, den Computer in Warenhausketten wie Walmart zu platzieren.\n\nMit einer Werbekampagne über CNN und deren Verkaufskanal-Show mit CNN-Vizechefin Bella Shaw und der NFL-Sportlegende Terry Bradshaw, dem ehemaligen Quarterback der Pittsburgh Steelers, sollte der GlobalPC den 40 % US-Haushalten ohne Computer, schmackhaft gemacht werden. In verschiedenen Showblöcken der CNN-Verkaufskanälen wurde immer wieder das einfache Bedienkonzept betont und als „Small is Beautiful“-Philosophie angepriesen.\n\nDer entsprechend für Kino-Vorprogramme und die Verkaufsshow produzierte Werbespot „No Exit“ gewann den International Monitor Award 2001 der Associated of Imaging Technology and Sound in den Kategorien \"Best Achievement\" und \"Best Editing\". Der von Pictures in a Row zur GlobalPC-Markteinführung produzierte Spot sorgte in den USA unter Macintosh-Fans, aufgrund von Ähnlichkeiten mit dem \"1984\"-Macintosh-Werbefilm für große Aufregung.\n\nMit der Insolvenz von MyTurn.com im Jahr 2001, die auch nicht durch einen Ende 2000 geschlossenen Vertrag mit dem brasilianischen Hersteller TCE über 750.000 GlobalPCs verhindert werden konnte, verblieben zusätzlich zu den 100.000 in den USA gelagerten Geräten noch weitere 100.000 in China produzierte GlobalPCs in der Konkursmasse.\n\n\n"}
{"id": "1567464", "url": "https://de.wikipedia.org/wiki?curid=1567464", "title": "Extended Video Graphics Array", "text": "Extended Video Graphics Array\n\nExtended Video Graphics Array, abgekürzt EVGA, ist ein Standard der Video Electronics Standards Association (VESA) von 1991, der eine Vollbildauflösung von 1024 x 768 Pixeln bei einer maximalen Wiederholrate von 70 Hz beschreibt. EVGA ist der XGA von IBM ähnlich, aber nicht mit ihr identisch.\n\n"}
{"id": "1571479", "url": "https://de.wikipedia.org/wiki?curid=1571479", "title": "G4L", "text": "G4L\n\nG4L (früher eine Abkürzung für \"Ghost for Linux\") ist eine freie Software für Linux-Systeme, mit der die Dateninhalte ganzer Festplatten und Partitionen gesichert werden können. Die Software wird im Rahmen des Sourceforge.net-Entwicklungsmanagementsystems unter der GPL zur Verfügung gestellt.\n\n\nDer Quellcode von G4L wies Ähnlichkeiten mit dem des Programmes \"G4U\" (Ghost for UNIX) auf, woraus der G4U-Autor schloss, dass G4L die BSD-Lizenz von G4U verletze. Die Gründe dafür erläutert er auf seiner Website. Der Autor von G4U hat jedoch keine rechtlichen Schritte unternommen.\n\nNach Ansicht des aktuellen Entwicklers von G4L hat sich das G4L-Projekt inzwischen jedoch soweit fortentwickelt, dass diese Ähnlichkeiten weitgehend verschwunden sind. Trotzdem wird beim Start der aktuellen Version ein Hinweis auf mögliche Ähnlichkeiten zu G4U eingeblendet.\n\n"}
{"id": "1571946", "url": "https://de.wikipedia.org/wiki?curid=1571946", "title": "Compose-Taste", "text": "Compose-Taste\n\nDie Compose-Taste (englisch \"compose\", zusammensetzen) ist eine spezielle Tottaste auf einer Computertastatur, nach deren Drücken die folgenden Tastendrücke zusammengefasst werden, um ein nicht in der Tastaturbelegung vorhandenes Zeichen zu erzeugen. Sie ist hauptsächlich auf unixoiden Betriebssystemen zu finden.\n\nDas Ergebniszeichen ergibt sich üblicherweise durch eine relativ intuitive Überlagerung der Ursprungssymbole oder -buchstaben.\n\nEin Tastatursymbol für die Compose-Taste ist standardisiert in ISO/IEC 9995-7 als Symbol 15 ', sowie in DIN ISO 7000 ' als Symbol ISO-7000-2021. Dieses Zeichen ist in Unicode ab Version 3.0 im Block \"Verschiedene technische Zeichen\" als U+2384 (⎄) enthalten.\n\nDie Tastenkombinationen können je nach Implementierung und Spracheinstellung variieren. Unter X.Org lassen sich die Kürzel in einem in der Datei \"/usr/share/X11/locale/locale.dir\" angegeben Unterverzeichnis zur entsprechenden Locale nachsehen und modifizieren. Die Datei, welche alle möglichen Compose-Sequenzen enthält, ist oft unter \"/usr/share/X11/locale/en_US.UTF-8/Compose\" zu finden. Diese Datei wird bei den meisten Distributionen, entgegen der naheliegenden Vermutung, für alle UTF-8-Locales verwendet, wie zum Beispiel \"de_DE.UTF-8\".\n\nNur wenige Tastaturen, meist für Rechner bestimmter Hersteller (etwa Sun Microsystems), haben eine separate Compose-Taste. Unter vielen Linux-Distributionen wird sie über eine Kombination der Umschalttaste mit Alt Gr simuliert, oft wird auch die rechte Windows-Taste dafür verwendet. Verwendet man eine eigene xmodmap, kann die Compose-Taste mit Hilfe des Wertes \"\" ausgelöst werden.\n\nFür Benutzer anderer Betriebssysteme besteht teilweise die Möglichkeit, die Compose-Taste per Software zu emulieren. Für Windows zum Beispiel existiert ein Open-Source-Programm namens \"AllChars\", das dies im Rahmen der aktiven Zeichensatztabelle und des ausgewählten Zeichensatzes erlaubt; der portable Windowstreiber der Neo-Tastaturbelegung ermöglicht die Eingabe sämtlicher unixoider Composesequenzen.\n\n"}
{"id": "1572026", "url": "https://de.wikipedia.org/wiki?curid=1572026", "title": "HP 9000", "text": "HP 9000\n\nHP 9000 ist die Bezeichnung für die ab 1982 von Hewlett Packard gefertigten, HP-UX-basierten Workstations und Server-Systeme. Nachdem 1982 die Workstation HP 9020 (laut Werbung der Mainframe für den Desktop des Ingenieurs oder Entwicklers) mit der HP-eigenen 32-Bit-FOCUS-Architektur entwickelt wurde, entschied Hewlett-Packard, alle technischen Workstations als HP 9000 zu vermarkten. Aus der 32-Bit-Workstation HP-9020 wurde HP 9000 Model 520, danach folgte das 16-Bit-Modell HP-9836 (auf Motorola basierend), das zur HP 9000 Model 236 wurde. Ab 1985 waren alle HP-9000-Systeme mit 32-Bit-68k-CPUs aus dem Hause Motorola bestückt. Die neueren Systeme mit Motorola-Design wurden als HP 9000 Serie 300 vertrieben. 1989 übernahm HP den Workstation-Hersteller Apollo Computer und bot ab 1990 deren ebenfalls vorwiegend Motorola-68k-basierte Systeme als HP Apollo 9000 series 400 an. Neben HP-UX konnten die Workstations der Serie 400 alternativ auch mit dem von Apollo übernommenen Domain/OS betrieben werden. \nMit der Entwicklung der eigenen PA-RISC-CPU-Architektur wurden die Serien 700 für die Workstations und 800 für die Server eingeführt. In den ersten Jahren war diese Nummerierung die einzige Namensgebung für Server und Workstations (z. B. 735 Workstation) dieser Generation. Später wurde dazu übergegangen, die Systeme mit Buchstaben zu klassifizieren, um auch Leistungs-Kategorien gegeneinander abzugrenzen, die sich vorher nur kryptisch aus der Nummerierung herauslesen ließen. In der 700 Serie gab es auch Embedded-Computer mit VMEbus unter der Bezeichnung Industrial Workstation. \n\nAber auch den bis heute gültigen Buchstaben-Klassifizierungen liegen die Nummerierungen zugrunde. Entsprechende Systemmeldungen, zum Beispiel mit dem UNIX-Befehl \"uname\", liefern Systemnummern wie eine 785.\n\nMit der Umstrukturierung des Bezeichnungsschemas wurde auch nach und nach der hauseigene GSC-Bus abgelöst. War zunächst der PCI-Bus über einen Adapter an den GSC-Bus angebunden, wurde mit der Workstationserie B1000 endgültig auf PCI umgeschwenkt, um 2004 ebenfalls abgelöst zu werden. Als Ersatz, bei der bislang letzten PA-RISC-Workstation von Hewlett Packard, kam nun eine Kombination aus PCI-X und AGP zum Einsatz. \n\nWohl in Anspielung auf den allwissenden HAL 9000 aus Stanley Kubricks stattete HP erstmals seine Serie-500-Baureihen mit dem Namenszusatz 9000 aus. Ein Namenszusatz, der bis heute geblieben ist.\n\n"}
{"id": "1578909", "url": "https://de.wikipedia.org/wiki?curid=1578909", "title": "Olivetti Echos 44 Color", "text": "Olivetti Echos 44 Color\n\nDer Olivetti Echos 44 Color ist ein Personal Computer (PC) der italienischen Firma Olivetti der von Michele De Lucchi gestaltet wurde. Dank des besonderen Designs hat der Computer mehrere Designpreise gewonnen, unter anderem \"MAU Industrial Design Award-Selezione\" und \"Compasso D'Oro-Selezione, ADI\".\n\nGebaut wurde er ab 1993 und ist mittlerweile technisch veraltet. Ersatzteile gibt es nicht mehr, da die Firma Olivetti die Produktion von Personal-Computern eingestellt hat. In Internet-Auktionshäusern werden jedoch hin und wieder noch einige Exemplare angeboten, die meist Sammlern und Liebhabern als Ersatzteillager dienen.\n\nEs gibt einige Anhänger dieses frühen Laptops, welcher sich in einigen Punkten von seinen damaligen Konkurrenten unterscheidet und so viele Fans gewinnen konnte: Das sandfarbene Design ist preisgekrönt; der Echos hat eine gummierte Handablage, einen für damalige Verhältnisse sehr guten und großen farbigen LC-Bildschirm und war schon sehr flach und kompakt. Es gab außerdem schon einen Ruhezustand und der Akkumulator hatte eine Laufzeit von ca. 2,5 Stunden. Der Computer hatte alle nötigen Anschlüsse, war erweiterbar, transportabel und wegen der ungewöhnlichen Farbe auch sehr auffällig.\n\n\n\n"}
{"id": "1579814", "url": "https://de.wikipedia.org/wiki?curid=1579814", "title": "COMSOL Multiphysics", "text": "COMSOL Multiphysics\n\nCOMSOL Multiphysics, vormals FEMLAB, ist eine Software zur Simulation physikalischer Vorgänge, die mittels Differentialgleichungen beschrieben werden können.\n\nVertrieben wird das Programm heute durch direkte Niederlassungen (zum Beispiel COMSOL Multiphysics GmbH) und durch ein weltweites Netz von Distributoren (z. B. Humusoft (Prag), Addlink (Madrid), Pitotech (Taipeh)…).\n\nIm November 2005 fand die erste FEMLAB-Konferenz (heute: COMSOL-Konferenz) statt, die sich zum Ziel gesetzt hat, Interessenten aus Forschung, Lehre und Entwicklung eine gemeinsame Plattform zu bieten.\n\nDas Programm basiert auf der sogenannten Finite-Elemente-Methode (FEM) und wird in Forschung, Lehre und Entwicklung eingesetzt. Neben einfachen FEM-Berechnungen ist eine Kopplung von verschiedenen physikalischen Problemen (Multiphysik) auf einfache Art und Weise möglich. Dabei ist ein iteratives Hin- und Herschalten zwischen verschiedenen Anwendungen nicht nötig, gekoppelte Gleichungssysteme können simultan gelöst werden.\n\nDie Simulationssoftware ist modular aufgebaut. Neben dem Basispaket „COMSOL Multiphysics“ werden folgende optionale Pakete angeboten:\n\nBereich Elektromagnetik\nBereich Mechanik und Akustik\n\nStrömungsmechanik und Wärmetransport\n\nBereich Chemie und Verfahrenstechnik\nMultifunktional\nProgrammschnittstellen\n\nDie vorherigen Versionen von COMSOL Multiphysics wurden FEMLAB (FEM-laboratory) genannt. FEMLAB entstand aus einer Toolbox für Matlab, der Partial Differential Equation (PDE) Toolbox. Die Eingabe eigener partieller Differentialgleichungen ist Bestandteil des Basispakets.\n\nCOMSOL Multiphysics bietet eine bidirektionale Schnittstelle zu MATLAB und Simulink, welche eine Skriptsteuerung von COMSOL Multiphysics über die MATLAB-Skriptsprache ermöglicht (Erweiterung um ca. 650 neue Funktionen).\n\nWeitere Schnittstellen:\n\n\n"}
{"id": "1580043", "url": "https://de.wikipedia.org/wiki?curid=1580043", "title": "FSMO", "text": "FSMO\n\nFlexible Single Master Operations (FSMO) oder operations masters (Betriebsmaster) sind spezielle Aufgaben, die Domain Controller innerhalb des Active Directorys der Firma Microsoft übernehmen. Die Aufgaben können auf verschiedene Server verteilt werden, jedoch darf keine dieser Rollen von mehreren Servern gleichzeitig übernommen werden.\n\n\"Flexible Single Master Operations\" umfasst die im Folgenden genannten ‚Rollen‘.\n\nStandardmäßig werden dem ersten Domain Controller in einem Forest alle fünf FSMO-Rollen zugewiesen. Ein Domain Controller in einer Sub-Domain bekommt standardmäßig die 3 domainweiten Funktionen übertragen. Die gesamtstrukturweiten Rollen können nur Domänen-Controllern der ersten Stammdomäne der Gesamtstruktur zugewiesen werden.\n\nFSMO-Rollen können von Domain Controller (DC) zu Domain Controller beliebig übertragen werden (daher „Flexible“ im Namen). Dabei muss jedoch unterschieden werden, ob die Rolle übergeben oder übernommen werden soll. \nWird die Rolle übergeben, sind beide beteiligten Domain Controller online und bekommen diesen Transfer mit. Die Rolle wird dabei auf dem Quell-DC deaktiviert und auf dem Ziel-DC aktiviert. Beide Domain Controller können im Netzwerk verbleiben. Im Notfall ist es allerdings nicht immer der Fall, dass beide Domain Controller online sind. In diesem Fall kann die Rolle nur übernommen werden. Das Übernehmen ist ein erzwungenes Übertragen des Masters, was bedeutet, dass nicht beide Domain Controller an dem Rollentransfer beteiligt sind. Dies darf nur als letzte Aktion ausgeführt werden, wenn sichergestellt ist, dass der alte Server, der von der erzwungenen Übernahme nichts weiß, nie wieder online kommt. Aus diesen Gründen lässt Microsoft diese Übertragung nicht über GUI-Tools, sondern bewusst nur über Kommandozeilentools zu, und auch dort nur mit vielen ausdrücklichen Warnhinweisen, damit der Administrator sich des Schrittes bewusst wird. \nAls Beistellserver kann die Installation jedoch genutzt werden, wenn zuvor ein DCPROMO /\"forceremoval\" (natürlich ohne Netzwerk) gemacht wurde. Einen solchen Beistellserver wünscht sich jedoch niemand wirklich und ergibt wirklich nur Sinn, wenn noch andere Daten auf dem Server gespeichert sind und diese in das Netzwerk übernommen werden sollen. Die beste Lösung ist jedoch, den Server neu aufzusetzen. Dann kann das Gerät auch wieder Domain Controller werden.\n\n"}
{"id": "1582369", "url": "https://de.wikipedia.org/wiki?curid=1582369", "title": "Windows Defender", "text": "Windows Defender\n\nWindows Defender, früher unter dem Namen Microsoft AntiSpyware vermarktet, ist eine Sicherheitssoftware der Firma Microsoft zur Erkennung von potenziell unerwünschter Software (vorwiegend Malware wie Computerviren und Spyware). Windows Defender ist in Windows Vista, Windows 7, Windows 8 und Windows 10 vorinstalliert, steht jedoch auch kostenlos für Windows XP (Service Pack 2 oder höher) und Windows Server 2003 (Service Pack 1 oder höher) zur Verfügung.\n\nDas Programm hieß ursprünglich \"Microsoft Windows AntiSpyware\" und war in der Betaversion eins erhältlich, bevor es durch das neue Programm Windows Defender ersetzt wurde.\n\nAm 9. Dezember 2011 wurde eine im Beta-Stadium befindliche Offline-Version vorgestellt, die von optischen Datenträgern oder USB-Sticks starten kann. Der Download enthält lediglich einen Assistenten, der beim Erstellen einer CD/DVD oder eines USB-Sticks hilft. Der wiederum lädt seinerseits erst das 250 MB große Rettungssystem herunter.\n\nSeit Windows 8 sind die Microsoft Security Essentials, nun als \"Windows Defender\" bezeichnet, fester Bestandteil des Betriebssystems.\n\nIm April 2018 wurde Windows Defender als Chrome-Erweiterung veröffentlicht.\n\nDie Hauptfunktion von Windows Defender waren – bis einschließlich Windows 7 – die Vorbeugung gegen und die Entfernung von Spyware und unerwünschter Programme. Daneben hat das Programm aber auch die folgenden weiteren Funktionen.\n\nUnter Windows Vista (nicht mehr in nachfolgenden Versionen) kann der Endanwender im Windows Defender auch einige weitere Schutzoptionen nutzen:\n\nIn Windows Vista blockiert der Windows Defender automatisch alle Autostartanwendungen, die Administratorrechte erfordern. Dies erhöht die Sicherheit des Systems (siehe auch Benutzerkontensteuerung): Der Benutzer muss den automatischen Start eines Programms mit erhöhten Rechten explizit bestätigen oder die Rechte des Programms verringern.\n\nIm Dezember 2008 kündigte Microsoft die Entwicklung der Antivirenlösung „Morro“ an, das dann offiziell „Microsoft Security Essentials“ genannt wurde. Die kostenlose Sicherheitslösung ersetzt sowohl den Windows Defender als auch Windows Live OneCare. Nutzer von Windows Defender erhalten jedoch weiterhin Definitionsaktualisierungen.\n\nIn einem Vergleichstest Ende 2013 von 25 verschiedenen Virenscannern schnitten die MSE allerdings nicht sehr gut ab.\n\n\n"}
{"id": "1583877", "url": "https://de.wikipedia.org/wiki?curid=1583877", "title": "Macintosh Quadra 800", "text": "Macintosh Quadra 800\n\nDer Macintosh Quadra 800 wurde im Zeitraum von Mai 1992 bis Oktober 1995 von der Firma Apple Computer verkauft. Der Rechner wurde mit dem Prozessor 68040 von Motorola ausgeliefert. Für den Speicher waren 8 Bänke mit 72-Pin-SIMMs vorgesehen. Der Speicherausbau war bis max. 136 MB möglich (8 MB aufgelötet). Als Komponenten waren im Quadra eingebaut: 1,4-MB-Laufwerk, Festplatte, 5 NuBus-Slots, 1 PDS-Slot, Tonausgang, 2 serielle Schnittstellen. Der Quadra wurde mit MacOS 7.1 ausgeliefert.\n"}
{"id": "1585436", "url": "https://de.wikipedia.org/wiki?curid=1585436", "title": "Bildpersonalisierung", "text": "Bildpersonalisierung\n\nBildpersonalisierung ist ein Verfahren der digitalen Bildbearbeitung, mit dem beliebige Texte in Bilder eingefügt werden.\n\nDas Verfahren der Bildpersonalisierung wird hauptsächlich im Bereich des Direktmarketings verwendet, z. B. in Mailings, Broschüren, (Bild-)Kalendern oder Zeitschriften. Im Gegensatz zur reinen Textpersonalisierung, wo z. B. der Name des Empfängers in ein Anschreiben eingesetzt wird, können hier weit höhere Response-Raten erzielt werden.\n\nNeben der Möglichkeit des Direktmarketings gibt es einige Internetdienstleister, welche bildpersonalisierte Produkte für Endkunden und in Einzelstücken anbieten.\n\nPersonalisierte Bilder lassen sich entweder selbst mithilfe spezialisierter, käuflicher Software erstellen (DirectSmile, Fusion Pro Expressions, XMPIE) oder mit Software as a Service (AlphaPicture). Alle Anbieter von Software bieten auch eine Auswahl vorgefertigter Motive (\"Sets\") an. Im Regelfalle werden die personalisierten Inhalte auf Mailings und Websites eingesetzt. Eine andere Form der Personalisierung ist die Videopersonalisierung. Die Nutzung dieser Technologie wird in Zukunft noch weiter zunehmen.\n\nIm Normalfall werden hochauflagige Werbeaktionen im Offsetdruck hergestellt. Da dieses Druckverfahren eine nichtveränderliche Druckvorlage benötigt, wird für personalisierte Bilder auf den Digitaldruck zurückgegriffen. Im Vergleich zum Offsetdruck ist der Digitaldruck heute bei hohen Auflagen noch etwas teurer, bei Auflagen >5000 Stück ist er hingegen häufig günstiger. Allerdings kann mit der Bildpersonalisierung eine höhere Response bzw. Öffnungsrate erzielt werden als bei einem herkömmlichen Mailing. Mit keinen oder überschaubaren Mehrkosten kann also eine höhere Wirkung erzielt werden.\n\nEs gibt jedoch Techniken (z. B. PPML), die die Zeit für die Vorbereitung zum Druck auf dem RIP um ein Vielfaches verringern. Dies wird unter anderem durch die Wiederverwendung von wiederholenden Elementen ermöglicht. \n"}
{"id": "1586880", "url": "https://de.wikipedia.org/wiki?curid=1586880", "title": "FotoWorks XL", "text": "FotoWorks XL\n\nFotoWorks XL ist ein Bildbearbeitungsprogramm, das speziell für unerfahrene Benutzer und Digitalkamera-Besitzer ohne Vorkenntnisse im Bereich der Bildbearbeitung entwickelt wurde.\n\nÜber sogenannte TWAIN-Schnittstellen ist es möglich, Digitalbilder direkt von der Digitalkamera einzulesen. Die Bilder können entweder einzeln bearbeitet, oder komplette Bilderserien mit Hilfe einer Stapelverarbeitung verändert werden. FotoWorks enthält gewöhnliche Grafikfilter und Kunstfilter wie Verzerrungsfilter oder Schärfefilter wie Weichzeichnen und Unscharfmaskierung. Besonders unerwünscht bei Fotografie ist auch der Rote-Augen-Effekt, der sich mit dem Programm entfernen lässt.\n\nEs wird grundsätzlich ein Vorschaubild des Effektes angezeigt, bevor die Bildbearbeitung angewandt wird.\n\nFunktionsumfang und Maskentechniken stehen bei dieser Software nicht im Vordergrund, vielmehr wurde hier das Augenmerk auf Bedienerfreundlichkeit und Ergonomie gelegt. FotoWorks ist deshalb nicht als Konkurrenz zu Programmen wie Photoshop, PhotoPaint oder GIMP zu sehen.\n\nGeschrieben wurde es auf Basis der Programmiersprachen Delphi und C# für Windows XP und 2000-basierende Betriebssysteme.\n\n\nDie erste Version entstand durch die Idee, eine Software zu entwickeln, die für Computer-Laien einfach anwendbar ist; hierfür entwarfen die deutschen Softwareentwickler Toni Ilg und Elmar Natter ein Konzept mit vielen Zwischen- und Hilfsschritten für die Softwarebedienung.\n\nNach der Fertigstellung der ersten Version im Mai 2003 erreichte das Programm schnell einen hohen Bekanntheitsgrad. Das Programm wurde ab September 2005 von mehreren Entwicklern komplett überarbeitet und bedienerfreundlicher gestaltet. Die mehrmals jährlich erscheinenden Softwareaktualisierungen sind kostenlos.\n\n"}
{"id": "1588783", "url": "https://de.wikipedia.org/wiki?curid=1588783", "title": "OpenVZ", "text": "OpenVZ\n\nOpenVZ (\"Open VirtualiZation\") ist eine Software für Linux zur Virtualisierung des Betriebssystems.\n\nOpenVZ erstellt mehrere isolierte Container für Betriebssysteme. Alle Prozesse dieser Betriebssysteme werden in einem einzigen Kernel verarbeitet. Die Betriebssysteme in den Containern sind dennoch weitgehend unabhängig voneinander. Sie können beispielsweise unabhängig voneinander heruntergefahren werden und verfügen jeweils über ein eigenes Root-Konto.\n\nIm Vergleich zu Virtuellen Maschinen von VMware oder zu Paravirtualisierungen wie Xen bietet OpenVZ weniger Auswahl an Betriebssystemen: sowohl der Wirt als auch die Gäste müssen Linux sein, nur die Linux-Distributionen können sich unterscheiden. Andererseits bietet OpenVZ bessere Leistungsfähigkeit, Skalierbarkeit, dynamische Ressourcenverwaltung und einfachere Administration. Der Virtualisierungsaufwand oder Overhead durch OpenVZ ist vernachlässigbar gering.\n\nOpenVZ wurde im Jahr 2005 aus dem kommerziellen Virtuozzo heraus von dessen Hersteller als Open Source eingeführt.\n\nOpenVZ besteht aus Erweiterungen des Kernels und Werkzeugen auf Benutzerebene.\n\nDer OpenVZ-Kernel ist ein modifizierter Linux-Kernel, der den Begriff \"Virtual Environment\" (VE) einführt. Der Kernel gewährleistet die Funktionalität von Virtualisierung, Isolierung, Ressourcenverwaltung und Checkpointing.\n\nJedes VE ist eine separate Einheit, die vom Standpunkt ihres Besitzers wie ein physischer Server aussieht. Das bedeutet, jedes VE hat unter anderem eigene\n\n\nWeil alle VEs denselben Kernel nutzen, spielt die Ressourcenverwaltung die wichtigste Rolle. Tatsächlich muss jedes VE im Rahmen der zugewiesenen Ressourcengrenzen bleiben und darf nicht die anderen VEs beeinflussen. Genau das ist die Kompetenz der Ressourcenverwaltung.\n\nDie OpenVZ-Ressourcenverwaltung besteht aus drei Subsystemen: Zwei-Ebenen-Festplattenquota, CPU-Planer und User Beancounters. Alle diese Ressourcen lassen sich im laufenden Betrieb ändern, es ist dafür kein Neustart nötig. Soll einem VE beispielsweise mehr RAM zugewiesen werden, können die entsprechenden Parameter „on the fly“ geändert werden. Bei VM-basierten Virtualisierungslösungen ist dies nicht ohne weiteres möglich.\n\nDie erste Ebene ist die pro-VE Festplattenquota, die zweite Ebene ist die standardmäßige UNIX-Festplattenquota pro Benutzer und pro Gruppe innerhalb eines VEs.\n\nUm mehr Festplattenplatz zu einem VE zuzuweisen, braucht man nur die entsprechende Festplattenquota zu vergrößern.\n\nDer CPU-Planer in OpenVZ ist eine Zwei-Ebenen-Implementierung der fair-share-Planungsstrategie.\n\nAuf der ersten Ebene entscheidet der Planer, welches VE den CPU-Takt erhält. Das wird entsprechend dem per-VE cpuunits-Wert gemacht. Auf der zweiten Ebene entscheidet der standardmäßige Linux-Planer, welcher Prozess in ausgewähltem VE den CPU-Takt bekommen soll. Dabei werden wie immer die Standard-Linux-Prioritäten von Prozessen usw. benutzt.\n\nDer OpenVZ-Administrator kann verschiedene Werte von cpuunits für verschiedene VEs definieren. In diesem Fall wird CPU-Zeit proportional laut den angegebenen Werten der VEs verteilt.\n\nAußerdem steht die Möglichkeit zur Verfügung, die CPU-Zeit zu limitieren. D. h., man kann z. B. 10 % der CPU Zeit einem VE zuweisen.\n\nDie User Beancounters sind ein Set von pro-VE-Ressourcenzählern, Limits und Garantien. Es gibt etwa 20 Parameter, die sorgfältig ausgewählt werden müssen, um alle Aspekte der VE-Funktionalität zu berücksichtigen.\nDamit darf jedes einzelne VE nur die zugewiesenen Ressourcen nutzen und keinen Einfluss auf das Hostsystem oder andere VEs haben.\n\nDie kontrollierten Ressourcen sind RAM und verschiedene in-kernel-Objekte wie IPC shared memory segments, network buffers usw. Jede Ressource kann man in \"/proc/user_beancounters\" anschauen. Hier werden 5 Werte für jeden einzelnen Parameter angezeigt: Aktuelle Auslastung, maximale Auslastung, Soft-Limit, Hard-Limit und fail counter.\n\nDie Bedeutungen von Soft-Limit und Hard-Limit sind verschieden und hängen von Parametern ab. Generell gilt: wenn irgendeine Ressource das Limit überschreitet, wird der entsprechende fail counter erhöht. So kann der Besitzer des VEs, falls irgendein Problem im VE auftritt, die Ausgabe von \"/proc/user_beancounters\" analysieren und mögliche Ursachen ausfindig machen.\n\nLive-Migration und Checkpointing sind Funktionen, die von OpenVZ Mitte April 2006 veröffentlicht wurden. Sie ermöglichen, ein VE von einem physischen Server auf den anderen zu migrieren, ohne dabei das VE stoppen/neu starten zu müssen. Der Vorgang ist als Checkpointing bekannt, und die Hauptidee besteht darin, ein VE einzufrieren und alle Prozesse in eine Datei zu speichern. Diese Datei kann dann auf eine andere Maschine übertragen und alle Prozesse können dort wiederhergestellt werden. Die ganze Übertragung des VEs nimmt nur einige Sekunden in Anspruch und verursacht damit keine Downtime, sondern nur eine leichte Verzögerung.\n\nDie Tatsache, dass jeder Teil des VE-Status, wie z. B. geöffnete Netzwerkverbindungen, gespeichert wird, macht den ganzen Migrationsprozess für den Benutzer völlig transparent. Während des Verschiebens des VEs kann z. B. eine Transaktion mit einer Datenbank laufen, die viel Zeit benötigt. In diesem Fall merkt der Benutzer nicht, dass die Datenbank schon auf einem anderen Server läuft.\n\nDieses Merkmal ermöglicht, Szenarien wie das Upgrade eines Servers ohne Neustart durchzuführen. Wenn eine Datenbank oder andere Applikation in einem VE mehr RAM oder CPU-Ressourcen braucht, kann man einfach eine andere, bessere Maschine kaufen, dieses VE live darauf migrieren und dann die entsprechenden Limits vergrößern. Wenn es z. B. nötig ist, zusätzliches RAM hinzuzufügen, kann man alle VEs auf einen anderen Server migrieren, das Upgrade auf der Maschine durchführen und dann alle VEs zurück migrieren.\n\nOpenVZ hat sowohl Kommandozeilen-Werkzeuge für die Verwaltung von VEs (vzctl), als auch Werkzeuge für die Verwaltung von Applikationen in VEs (vzpkg).\n\nvzctl ist ein einfaches high-level Kommandozeilen-Werkzeug für die Verwaltung von VEs.\n\n\nvzlist zeigt die Liste der VEs an.\n\n\nTemplates sind vorgefertigte Images, die zum Erzeugen von VEs benutzt werden. Ein Template ist ein Set von Paketen, und ein Template-Cache ist ein Tar-Archiv einer chroot-Umgebung, in der alle Pakete installiert sind. Während der Ausführung von \"vzctl create\" wird das Tar-Archiv entpackt. Diese Technik ermöglicht, ein VE in wenigen Sekunden zu erzeugen.\n\nDie Entwickler stellen Template-Caches für die gebräuchlichsten Linux-Distributionen auf der Projekt-Webseite zum Download zur Verfügung.\n\nvzpkg ist ein Satz von Werkzeugen, mit dem das Erzeugen eines Template-Caches wesentlich vereinfacht wird. Es unterstützt rpm- und yum-basierende Repositories. Um ein Template, z. B. Fedora Core 5, zu erstellen, braucht man ein Set von (yum-) Repositories, in denen sich FC5-Pakete befinden, und auch ein Set von Paketen, die installiert werden müssen. Zusätzlich, falls es nötig ist, ein Template anzupassen, stehen auch pre- und postinstall-Skripte zur Verfügung. Alle oben dargestellten Parameter (Repositories, Paketlisten, Skripte, GPG keys usw.) werden als Template-Metadaten dargestellt. Mit Hilfe von Template-Metadaten kann der Template-Cache automatisch erstellt werden. Man braucht nur den \"vzpkgcache\" Befehl zu starten. Dabei werden alle angegebenen Pakete auf den Server hochgeladen und in ein temporäres VE installiert. Danach wird das entsprechende Tar-Archiv erzeugt.\n\nEs ist auch möglich, Template-Caches für nicht RPM-basierende Distributionen zu erstellen.\n\nOpenVZ benutzt das Ein-Kernel-Modell und ist deswegen wie der Linux-Kernel 2.6 skalierbar. Es unterstützt somit die Nutzung von bis zu 64 CPUs und 64 GB RAM. Eine einzelne VE kann auf das komplette Hostsystem skaliert werden, d. h. alle CPUs und das gesamte RAM des Hostsystems nutzen. Diese Vorgehensweise virtualisiert die Hardware des VEs: Das in der VE laufende Betriebssystem greift nicht mehr direkt auf die physische Hardware des Hostsystems zu, sondern nutzt die Schnittstellen von OpenVZ. Auf diese Weise ist es möglich, einen Server zur Laufzeit zu migrieren, um gestiegene Ressourcen zu nutzen oder um Hardware-Ausfälle des Hostsystems zu kompensieren.\n\nAuf dem Server mit OpenVZ können hunderte von Virtual Environments laufen, ihre Zahl ist hauptsächlich durch den vorhandenen RAM und die CPU-Leistung begrenzt.\nDer Administrator des OpenVZ-Servers kann auf Prozesse und Dateien von allen VEs zugreifen. Das erleichtert die Massenverwaltung vieler Server, Sicherheitsupdates in den VEs können durch ein einfaches Skript geschehen. Das ist ein Vorteil gegenüber Virtualisierungslösungen wie VMware oder Xen, die für jede virtuelle Maschine ein manuelles Update erfordern.\n\nDie folgenden Einsatzszenarien sind für alle Virtualisierungstechnologien gemeinsam. Der Hauptunterschied von Virtualisierungen auf Betriebssystem-Ebene besteht darin, dass der Virtualisierungsaufwand sehr gering ist. Genau das macht solche Szenarien sehr attraktiv.\n\n\nAndere Implementierungen von OS-Virtualisierung sind LXC (LinuX Containers) und Linux-VServer sowie FreeBSD Jails und Solaris Containers. Allerdings kann die VServer-Technologie komplett durch OpenVZ ersetzt werden.\n\n\n"}
{"id": "1588819", "url": "https://de.wikipedia.org/wiki?curid=1588819", "title": "Ab durch die Hecke", "text": "Ab durch die Hecke\n\nAb durch die Hecke (Originaltitel \"Over the Hedge\") ist ein US-amerikanischer Animationsfilm aus dem Jahre 2006. Er wurde von DreamWorks Animation produziert und in Deutschland von United International Pictures verliehen. Der Film basiert auf dem Comic Over the Hedge von Michael Fry und T. Lewis.\n\nDer Waschbär Richie stiehlt dem noch Winterschlaf haltenden Bären Vincent seine gesamten Vorräte. Dabei wird Richie erwischt und vom Bären gezwungen, alle Vorräte, die während des Diebstahlversuchs aus der Höhle auf eine Straße und vor einen LKW gefallen sind, innerhalb einer Woche wiederzubeschaffen, sonst werde er gefressen. Auf der Suche nach neuen Vorräten für Vincent lernt er die bunt zusammengewürfelte Familie der Schildkröte Verne kennen, die gerade ihren Winterschlaf beendet hat. Diese besteht aus Schildkröte Verne, Eichhörnchen Hammy, Stinktier Stella sowie zwei Opossums und fünf „Stachelschweinen“. (Letztere sind Eltern mit drei Kindern: Nordamerikanische Baumstachler.) Mit Hilfe dieser Gruppe will er in die neugebaute Vorstadt hinter der großen Hecke eindringen, die während des Winterschlafs der Gruppe gepflanzt wurde und nun deren Wald begrenzt. Richie will in der Siedlung die Vorräte für Vincent stehlen.\n\nNachdem Richie Verne als Familienoberhaupt verdrängt hat, der den Plänen eher skeptisch gegenübersteht, und selbst neuer Anführer der Gruppe geworden ist, unternehmen die Tiere mehrere Raubzüge bei den Menschen. Diese jedoch rufen einen Kammerjäger, um die Diebe einfangen zu lassen. Dieser scheitert vorerst, und Richie bekommt alles zusammen, was er dem Bären schuldet. Verne ist allerdings immer noch misstrauisch und will den Menschen den Karren samt der gestohlenen Nahrung zurückbringen. Darüber kommt es zum Streit zwischen Verne und Richie. Als sich ein debiler Haushund – der nur spielen will – einmischt, kommt es zu einer Verfolgungsjagd, bei dem der Karren zu Bruch geht und einige Gärten verwüstet werden. Richie gibt versehentlich zu, die Gruppe ausgenutzt zu haben. Verne erklärt ihm, dass sie ihm als Familie geholfen hätten, wenn er nur gefragt hätte. Daraufhin schleichen sich alle wieder in die Siedlung und stehlen die von Richie benötigte Nahrung ein weiteres Mal. Dabei wird die gesamte Familie, abgesehen von Richie, der die Beute zu Vincent bringt, vom Kammerjäger gefangen. Richie entscheidet sich im letzten Moment jedoch für die Familie, wirft die Vorräte für Vincent samt Karren zielstrebig auf die Straße vor den Laster des Kammerjägers und kehrt zu denen zurück. Vincent nimmt sofort die Verfolgung auf. Richie kann seine Familie in einer wilden Verfolgungsjagd aus dem Van des Kammerjägers befreien. Als Richie mit seiner Familie durch die Hecke in den Wald zurückkehren will, erscheint Vincent jedoch dort. Sie wollen zurück durch die Hecke, doch dort warten der Kammerjäger und die nervtötende Nachbarin Gladys mit einem Rasentrimmer. Es kommt zu einem Lebenskampf in der Hecke. Durch einen Trick Hammys wird Vincent zusammen mit dem Kammerjäger und Gladys von den (illegalen) Fallen des Kammerjägers versengt. Gladys und der Kammerjäger sollen verhaftet werden. Der Kammerjäger kann knapp über einen Zaun entkommen, während Vincent in ein Tierreservat gebracht wird. Richie ist somit frei und lebt fortan bei Vernes Familie.\n\n\"Richie\" der Waschbär ist die Hauptfigur des Filmes. \"Verne\" ist eine überängstliche Schildkröte und der Anführer der Familie. \"Hammy\" gehört zur Familie der Eichhörnchen und hat äußerst hyperaktive Züge. Er ist Richies treuester Anhänger. \"Stella\" ist ein Stinktier, welches in dem persischen Kater Tigerius das erste Wesen findet, welches sich nicht von ihrem Gestank vertreiben lässt, da er keinen Geruchssinn hat. \"Vincent\" ist ein großer, grober Bär. Er liebt eine besondere Kartoffelchipssorte. Richie musste Vincent dienen und ihn immer im Frühling aus dem Winterschlaf wecken.\n\nDie Synchronisation übernahm die Berliner Synchron GmbH Wenzel Lüdecke. Für das Synchronbuch und die Dialogregie war Oliver Rohrbeck verantwortlich.\nDie Story wurde auch als Spiel mit dem Titel \"Ab durch die Hecke\" für PC, Playstation, Game Boy Advance, GameCube, Xbox und Nintendo DS veröffentlicht. Diese Spiele erschienen zeitgleich zum Kinostart im Handel. Sie erzählen nach den ersten vier Leveln (welche dem Film entsprechen) eine erweiterte Handlung welche ein Jahr nach dem Film spielt. Es gibt ein weiteres Spiel welches nur für Playstation Portable, Nintendo DS und Game Boy Advance verfügbar ist mit dem Titel \"Ab durch die Hecke – Hammy dreht durch\".\n\n"}
{"id": "1590060", "url": "https://de.wikipedia.org/wiki?curid=1590060", "title": "CCleaner", "text": "CCleaner\n\nCCleaner (, früherer Name \"Crap Cleaner\") ist ein kostenloses Programm zur Optimierung für die Betriebssysteme Windows, macOS und Android. Windows wird ab Windows XP auf 32- und 64-Bit-Systemen unterstützt. Darüber hinaus gibt es für Windows weitere Versionen, die kostenpflichtig als \"Business Solutions\" angeboten werden.\n\nDas Programm wurde mehr als eine Milliarde Mal heruntergeladen (Stand: Dezember 2012).\n\nIm Jahr 2017 wurde Piriform Ltd. mit CCleaner vom tschechischen Softwareunternehmen Avast übernommen. Die Bekanntgabe erfolgte am 19. Juli 2017.\n\nDas Programm entfernt vor allem unbenutzte und temporäre Dateien. Auch der Verlauf von besuchten Webseiten und diverse andere Verläufe, wie beispielsweise zuletzt benutzte Dateien oder eingegebene Suchbegriffe der Windows-Suche, können bereinigt werden.\n\nZusätzlich kann es aus der Windows-Registrierungsdatenbank Fehler und nach Deinstallation von Programmen übriggebliebene Einträge entfernen. Mit Hilfe verschiedener Löschverfahren wie der Gutmann-Methode kann es sowohl sensible Dateien als auch ganze Datenträger unwiderruflich sicher löschen.\n\nDurch diese Maßnahmen soll das System beschleunigt und die Privatsphäre des Nutzers geschützt werden.\n\nErweiterungen\n\nIm offiziellen Support-Forum von Piriform wurden über längere Zeit Erweiterungen gesammelt, um Unterstützung für weitere Programme zu ermöglichen. Diese fanden Eingang in CCEnhancer, das über 1000 weitere Programme unterstützt. Dieses Programm nutzt eine von einer Mehrautorenschaft erstellte und aktuell gehaltene Version der Datei \"winapp2.ini\".\n\nDie Version 2.0 erschien am 13. August 2007. Mit dieser Version wurde das Programm in C++ von Grund auf neu geschrieben, um eine bessere Kompatibilität zu Windows Vista und 64-Bit-Betriebssystemen zu erreichen und um eine portable Version für USB-Sticks schaffen zu können. Außerdem soll das Programm nun schneller arbeiten und eine Option zum Ausschließen bestimmter Dateien wurde hinzugefügt. Die Benutzeroberfläche wurde ebenfalls überarbeitet.\n\nVersion 3.0 erschien am 28. Oktober 2010. Das Programm kann nun den freien Speicherplatz oder den gesamten Inhalt einer Festplatte und von Wechseldatenträgern sicher löschen. Die 64-Bit-Version wurde erneut verbessert, Benutzeroberfläche und das Icon wurden überarbeitet. Ansonsten gab es noch mehrere kleinere Neuerungen.\n\nAb Version 3.23 wird ebenfalls eine Anwendung in Windows 8 unterstützt.\n\nVersion 4.0 erschien am 26. März 2013. Es wurde ein Dateifinder zum Aufspüren und Entfernen doppelter Dateien eingebaut und das Programm optimiert. In der Pro-Version wurde eine System- und Browserüberwachung eingefügt. Dabei wird der Browser beim Beenden automatisch gereinigt. Außerdem kann das System einfach über die Taskleiste gereinigt werden.\n\nVersion 5.0 erschien am 25. November 2014. Die Benutzeroberfläche wurde an den neuen Windows 8/8.1 üblichen Metro Look angepasst. Die Fehlermeldungs-Routine und interne Programmarchitektur wurde für eine höhere Leistung optimiert.\n\nVersion 5.33 erschien am 15. August 2017 und war mit Malware infiziert. Die Datei war korrekt von Piriform signiert, was darauf hindeutet, dass die Entwicklungsumgebung von Piriform kompromittiert wurde. Die verseuchte Datei enthielt einen Downloader und eine nachzuladende Spionage-Komponente. Die Malware zielte nicht auf den typischen Endnutzer, sondern auf Nutzer in großen Technologie- und Telekommunikationsunternehmen in Japan und Russland, aber auch in Deutschland. Am 12. September wurde CCleaner 5.34 zum Download zur Verfügung gestellt. Am 18. September meldete Piriform die Infektion der Version 5.33 seiner Software. Die Kontrollserver, von denen aus die Malware gesteuert wurde, seien abgeschaltet worden. Die mit der Malware verseuchte Version hatten bis dahin insgesamt 2,7 Millionen Nutzer genutzt. Entgegen ersten Behauptungen, die Malware solle auf keinem einzigen PC aktiv geworden sein, gab der Hersteller wenige Tage später bekannt, der besagte Downloader soll auf mehreren hundert PCs aktiv geworden sein. Informationen zu mehr als 700.000 PCs waren in der Zwischenzeit von der Malware gesammelt worden. Diese Informationen ermöglichen es unter anderem, den jeweiligen PC eindeutig zu identifizieren. Kurioserweise empfiehlt die Firma Avast, der Piriform gehört, ein Programm wie Avast Antivirus zu nutzen, um derartige Infektionen in Zukunft zu erkennen.\n\nDie Gratis-Version der Version 5.45 lässt die Anwender nicht mehr selbst entscheiden, ob ihre Daten anonymisiert gesammelt und verwendet werden dürfen. Eine \"Heartbeat\" genannte Funktion sendet alle 12 Stunden Informationen an den Hersteller. Entfernt man das Häkchen bei \"Überwachung aktivieren\", wird es beim nächsten Schließen und erneuten Aufrufen der Anwendung wieder gesetzt. Außerdem lässt sich das Programm nicht mehr beenden, beim Schließen des Fensters bleibt das Programm im Hintergrund aktiv. \nAvast kündigte an, in der nächsten Version den Usern wieder mehr Kontrolle über die Daten zu geben. Viele Websites und Computerzeitschriften rieten, bis dahin die alte Version 5.44 zu benutzen und 5.45 nicht zu installieren.\n\nEine neue Regionsbeschränkung soll darüber hinaus laut Information auf der Website den Gebrauch der Software in von einem Embargo betroffenen Ländern verhindern.\n\nAls Reaktion entfernte Avast die Version 5.45 von der Website und bot bis zum Erscheinen der bereinigten neueren Version die Version 5.44 wieder an. Die Version 5.46 erschien Ende August 2018.\n\nIm Juni 2011 erschien die erste Beta-Version für das Betriebssystem Mac OS X ab Version 10.5. Seit Juni 2014 ist eine Version für Smartphones mit dem Betriebssystem Android verfügbar.\n\nCNET bewertete das Programm mit 5 von 5 Sternen, bezeichnete es als „sehr empfehlenswert“ und verlieh ihm im April 2009 den „Editor's Choice Award“. Tecchannel bewertet die Freeware positiv: „Es gibt mehrere Gründe, auf dem eigenen PC ein Aufräum-Tool zu verwenden, aber die beiden gewichtigsten sind Performance und Privatsphäre. Der kostenlos angebotene CCleaner verspricht, genau diese beiden Paradigmen umzusetzen.“ Freenet.de äußert sich ebenfalls positiv über das Programm: „Ein sehr nützliches Helferlein, das seine Arbeit sauber und zuverlässig erledigt. Dieses Tool gehört zur Pflege jeder guten Windows-Installation einfach dazu.“\n\nDie Zeitschrift Chip urteilt über den Testsieger im Test der besten Spurenvernichter in Ausgabe 1/2009: „Der CCleaner überzeugt mit einer klaren Oberfläche. Alle Funktionen sind gut erreichbar. Zusatzfeatures runden das Paket ab.“ Auch Chip.de bewertet das Programm positiv: „Datenlöschung im High-End-Format. Das kleine Putz-Tool für die Festplatte reinigt Ihr System porentief von unnötigem Ballast.“ Tim Aschermann weist in \"Chip.de\" aber darauf hin, dass die Benutzung anderer Programmteile wie \"Registry Cleaner\" und \"Extras\" die Stabilität des Systems beeinflussen kann. Sie seien „gefährliche Kategorien, bei denen schnell etwas schief gehen kann.“ macwelt.de schreibt über das Programm in seinem Testbericht vom 6. Juni 2011: „Der CCleaner ist auf der Windows-Plattform beliebt; jetzt ist eine erste Mac-Beta verfügbar. Das Tool eignet sich vor allem, um Surfspuren zu löschen.“\n\nBei Chip.de führt die Anwendung die Top-100-Download-Charts im Bereich „System-Cleaner“ mit mehr als 50 Millionen Downloads (Stand Dezember 2015) an, unter den „Top 100 Downloads des Jahres 2015“ steht CCleaner mit mehr als 4,8 Millionen Abrufen dort auf Platz 1. Bei heise.de steht CCleaner an Stelle 5 der 30 im Jahr 2014 „beliebtesten Gratis-Programme“ (im Vorjahr Platz 12, insgesamt Platz 12).\n\nCCleaner wird oft als \"CC-Cleaner\" bezeichnet statt als \"C-Cleaner\". Im FAQ-Bereich der Website wurde die Namensgebung erläutert: Der Name „CCleaner“ ist die Kurzversion des ursprünglichen Namens „Crap Cleaner“ und wird wie englisch „see cleaner“ ausgesprochen.\n\n"}
{"id": "1590818", "url": "https://de.wikipedia.org/wiki?curid=1590818", "title": "SGI Indy", "text": "SGI Indy\n\nDie Indy war eine Grafik-Workstation von Silicon Graphics Inc. (SGI) und kam in den USA im September 1993 auf den Markt. Das Gerät wurde damals als erschwinglicher Einstieg in die Welt der 2D- und 3D-Grafikworkstations angepriesen. Die Indy war äußerlich recht auffällig aufgrund ihres sehr flachen, leuchtend blauen Desktop-Gehäuses aus Recycling-Kunststoff, dessen Form sich aus zwei leicht gegeneinander verdrehten Halbschalen ergab. Die intensiv blaue bzw. violette Gehäusefarbe hatte sie mit den anderen Vertretern der damaligen, MIPS-basierten Workstation-Reihe von SGI (u. a. SGI Challenge, SGI Indigo, Indigo2 Impact, SGI Onyx, SGI O2), gemein.\n\nDie Indy verwendete wie alle damaligen SGI-Workstations das Betriebssystem IRIX, eine UNIX-Variante mit einem auf dem X Window System basierenden GUI. Diese Workstations waren für besonders hohe 2D- und 3D-Grafikleistung konzipiert und damit für Visualisierungs- und Bildsynthese-Anwendungen in Forschung, Entwicklung und in der Unterhaltungsindustrie prädestiniert. Die Indy bot eine Grafikleistung, die die Möglichkeiten der damals verfügbaren PC-Hardware weit überstieg; allerdings etablierte sich nur wenige Jahre später hochleistungsfähige 2D- und 3D-Beschleunigerhardware für gewöhnliche Desktop-Computer (zunächst Intel-basierte PCs, kurz darauf auch Apple Macintosh), so dass diese bald in der Lage waren, die Leistung der SGI-Spezial-Hardware zu erreichen und schließlich auch zu überholen. Gemessen an der 3D-Leistung heutiger Grafikkarten ist die 3D-Grafikleistung der Indy eher als rudimentär zu bezeichnen, wobei auch damals schon relativ leistungsfähige 2D-Grafikbeschleunigung zum Einsatz kam. Als die Indy in den USA vorgestellt wurde, waren Komplettsysteme einschließlich Monitor ab etwa 5000 US-$ erhältlich.\n\nSGI verwendete in ihren damaligen Workstations ein Modulkonzept; so waren auch bei der Indy sowohl CPU als auch Grafikhardware auf austauschbaren Bausteinen untergebracht. Die verfügbaren CPU-Module waren mit MIPS-Prozessoren vom Typ R4000, R4600, R4400 und R5000 bestückt, wobei der R4000 das leistungsschwächste Ende der Reihe darstelle. R4000 und R4600 waren jeweils in einer SC- und PC-Variante erhältlich, womit die Cache-Ausstattung unterschieden wurde; dabei stand SC für \"secondary cache\" (L2-Cache) und PC für \"primary cache\" (L1-Cache). Der SC-Typ enthielt einen L2- und L1-Cache und war damit leistungsstärker als der PC-Typ, der nur über einen L1-Cache verfügte. Die CPUs arbeiteten mit Taktfrequenzen von 100 MHz bis 200 MHz; so gab es z. B. eine R4600-Platine mit 133 MHz. Rechner mit neueren Prozessoren, wie dem R5000, waren bei gleicher Taktfrequenz wesentlich schneller als Geräte mit älteren Prozessoren.\n\nEs gab preiswerte Grafikmodule, die nur 8-Bit-Farben darstellen konnten, bis hin zu High-End-Modulen mit 24-Bit-Farbfähigkeit (Echtfarben) und einfacher 3D-Hardwarebeschleunigung. Die Grafikmodule konnten ihrerseits mit Tochtermodulen für zusätzliche Grafikfähigkeiten bestückt werden, so z. B. für die Videoausgabe oder erweiterte 3D-Grafikbeschleunigung (\"XZ Graphics\" mit bis zu 4 Geometrie-Engines, allerdings ohne Texturspeicher).\n\nDie Indy verwendete 72-polige einreihige RAM-Bausteine (SIMM) mit bis zu 32 MB Kapazität und bot Platz für 2 Bänke zu je 4 SIMMs, so dass die Indy auf 256 MB Arbeitsspeicher ausgebaut werden konnte.\n\nIm Gehäuse befanden sich zwei 3,5″-Laufwerksschächte für SCSI-Massenspeicher, die über 50-polige Flachbandkabel angeschlossen wurden. Im unteren Schacht befand sich die Festplatte; im oberen üblicherweise ein sogenanntes Floptical-Laufwerk, ein Hybridlaufwerk, das sowohl gewöhnliche 3,5″-Disketten als auch spezielle Floptical-Disketten mit 21 MB Kapazität beschreiben und lesen konnte. Weder konnte sich die Floptical-Technik etablieren, noch arbeitete das Laufwerk mit normalen Disketten besonders zuverlässig.\n\nDie Indy geizte nicht mit Anschlüssen, insbesondere für Video-/Audioein- und ausgabe, und bot darüber hinaus einige Möglichkeiten zum Anschluss von Spezial-Hardware für 3D-Visualisierungszwecke. Je nach Ausstattung können an einer Indy folgende Anschlüsse zu finden sein (auf der Gehäuserückseite von links nach rechts):\n\n"}
{"id": "1591454", "url": "https://de.wikipedia.org/wiki?curid=1591454", "title": "ΜClinux", "text": "ΜClinux\n\nµClinux (auch \"uClinux\", „you-see-linux“ ausgesprochen, für „Microcontroller Linux“) ist eine Linux-Distribution mit einem Kernel, der an Mikroprozessoren und Mikrocontroller ohne Memory Management Unit \"(MMU)\" angepasst ist.\n\nSeit Kernelversion 2.6 sind große Teile von µClinux für verschiedene Prozessoren im Linuxkernel enthalten. µClinux läuft auf vielen Eingebetteten Systemen, also Geräten, in denen ein kleiner Computer Funktionen steuert: LAN-Disks, DSL-Router, DVD-Player, Fotoapparate und andere. Ein Vorteil ist das große Angebot ausgereifter Software-Anwendungen für µClinux, z. B. an Netzwerkapplikationen.\n\nZum µClinux-Projekt gehört neben der Kernel-Entwicklung die Entwicklung einer uClibc genannten Standard-C-Bibliothek, die bei verringertem Speicherbedarf Kompatibilität zur glibc anstrebt. In der Distribution sind weitere auf geringe Speicherkapazität zugeschnittene Standardsoftware-Ersätze, wie BusyBox, enthalten.\n\nµClinux findet z. B. Anwendung \n\n"}
{"id": "1596063", "url": "https://de.wikipedia.org/wiki?curid=1596063", "title": "OllyDbg", "text": "OllyDbg\n\nOllyDbg ist ein von Oleh Yuschuk entwickelter 32-Bit-Debugger für Windows, eine 64-Bit-Version befindet sich in der Entwicklung. Hauptsächlich kann \"OllyDbg\" zur binären Codeanalyse verwendet werden, um beispielsweise eine Fehlerbereinigung von Programmen durchzuführen.\n\n\"OllyDbg\" arbeitet auf Ring-3-Ebene und zeichnet sich durch folgende Features aus:\n\n\nEiner der besonderen Vorteile von \"OllyDbg\" ist, dass der Debugger auch von mobilen Datenträgern gestartet werden kann. Er benötigt keinerlei Installation, erlaubt aber ein Add-In in den Windows Explorer. Durch die vielen erhältlichen Plugins, welche von Drittautoren aus der Reverse Engineering Szene stammen und ein Verstecken des Debuggers vor Anti-Debugging Methoden verschiedener Laufzeitpacker (besonders Themida und Execryptor) erlauben, sowie das OllyScript Plugin, welches in Verbindung mit Skripten die Automatisierung von wiederkehrenden Vorgängen ermöglicht, zählt dieser Debugger besonders bei privaten Reverse-Engineering-Enthusiasten zu den am häufigsten eingesetzten Werkzeugen. OllyScripts automatisieren Vorgänge wie beispielsweise das Umgehen von Anti-Debugging-Methoden oder das Suchen des ursprünglichen Einsprungpunktes (OEP) von mit Laufzeitpackern gepackten und verschlüsselten Programmen.\n\n"}
{"id": "1600829", "url": "https://de.wikipedia.org/wiki?curid=1600829", "title": "KES (Zeitschrift)", "text": "KES (Zeitschrift)\n\nDie <kes> – Die Zeitschrift für Informations-Sicherheit ist eine 1985 gegründete Zeitschrift zu Telekommunikations- und IT-Sicherheitsthemen. Das Akronym kes steht ursprünglich für \"Kommunikations- und EDV-Sicherheit\". Der Titel der Zeitschrift wurde beim umfassenden Redesign im Jahre 2003 geändert, um dem sich anbahnenden Paradigmenwechsel von der \"IT\"-Sicherheit zur \"Informations\"-Sicherheit Rechnung zu tragen.\n\nDie Hauptzielgruppe der Zeitschrift sind Unternehmen und Behörden im deutschsprachigen Raum. Dabei wendet sich die Zeitschrift an IT-Sicherheitsverantwortliche aus allen Bereichen einer Organisation. Neben der Behandlung von organisatorischen Themen, behandelt die Zeitschrift auch technische Themen und darüber hinaus nach eigenen Angaben \"sicherheitsrelevanten Themen von Audits über Sicherheits-Policies bis hin zu Verschlüsselung und Zugangskontrolle\".\n\nDie Zeitschrift ist das offizielle Organ des Bundesamtes für Sicherheit in der Informationstechnik (BSI) und enthält veröffentlichungspflichtige Informationen (zum Beispiel Zertifizierungsberichte).\n\nSie erscheint alle zwei Monate bei DATAKONTEXT, einem Unternehmen der Verlagsgruppe Hüthig Jehle Rehm. Bis Ende 2015 gehörte die <kes> zum SecuMedia Verlag (früherer Name Peter Hohl Verlag). 2015/2016 hatte die Zeitschrift nach eigenen Angaben eine durchschnittliche Druckauflage von 9117 und eine tatsächlich verbreitete Auflage (tvA) von 8679 Exemplaren.\n\n"}
{"id": "1604392", "url": "https://de.wikipedia.org/wiki?curid=1604392", "title": "Online Today", "text": "Online Today\n\nOnline Today war eine Internet-Zeitschrift des Verlags Gruner + Jahr. \n\nDie Zeitschrift wurde erstmals 1996 als Sonderheft der Fernseh-Programmzeitschrift \"TV Today\" unter dem Titel \"TV Today Online\" herausgegeben. Später wurde sie durch Umbenennung eigenständiger positioniert und erschien regelmäßig. Im Juni 2002 wurde sie schließlich eingestellt. Die Auflage erreichte nach intensiven Marketingmaßnahmen vorübergehend eine Höhe von über 200.000 Exemplaren, am Ende lag sie bei etwa 116.000 Exemplaren.\n\nAngelehnt an das Schwestermagazin \"TV Today\" war \"Online Today\" eine Programmzeitschrift für das sich in diesen Jahren zum Massenmedium entwickelnde Internet. \n\nDurch die Verbesserung von Suchmaschinen und Verzeichnissen des Internets selbst sowie durch bessere Kenntnisse der Nutzer sank jedoch der Bedarf an gedruckten Informationen. Anders als das Fernsehen präsentierte sich das Internet – nach einer Entwicklungsphase – selbst. Außerdem begann Ende 2000 die Krise der \"New Economy\", in deren Folge die bis dahin gewaltigen Werbeetats schrumpften oder wegfielen. Die Zeitschrift wurde schließlich wegen sinkender Auflage und Anzeigeneinnahmen eingestellt.\n\nEin Markenzeichen von \"Online Today\" waren die Comics ihres Hauszeichners \"Jamiri\".\n"}
{"id": "1606927", "url": "https://de.wikipedia.org/wiki?curid=1606927", "title": "AOL-Magazin", "text": "AOL-Magazin\n\nDas AOL-Magazin war eine Computerzeitschrift aus dem \"Magazin-Verlag am Fleetrand\" in Hamburg. Zielgruppe waren die Nutzer des Internetdienstanbieters AOL Deutschland.\n\nDas \"AOL-Magazin\" war eine vierteljährliche Zeitschrift, die am 15. Januar 2000 erstmals erschien. Das Magazin war eine Mischung aus Publikumszeitschrift und Kundenzeitschrift: Anders als reine Kundenzeitschriften wurde sie nicht an die eigenen Kunden vergeben, sondern ging in den Einzelverkauf, sollte aber mit passender Themenauswahl Kunden für den AOL-Onlinedienst interessieren. Der Preis betrug 5,00 DM, der Umfang belief sich auf 192 Seiten.\n\nDie Redaktion kooperierte intensiv mit AOL, der auch Beilagen schaltete, war aber inhaltlich vom Anbieter unabhängig. Das Konzept sah 168 Seiten Informationen aus der Online-Welt vor und einen 24-seitigen, von AOL selber beigesteuerten Wegweiser zum Einstieg in das Internet mittels AOL. Ein Markenzeichen des AOL-Magazin waren die Comics seines Hauszeichners \"Jamiri\".\n\nDas \"AOL-Magazin\" erschien beim \"Magazin-Verlag am Fleetrand\" (MVF), der Anfang der 1990er Jahre als hundertprozentige Tochter von Gruner+Jahr gegründet wurde und seit 2005 eine hundertprozentige Tochter der Münchner Hubert Burda Media-Gruppe ist. Mit 300.000 Exemplaren gestartet, pendelte sich die Auflage um zwischen 60.000 und 120.000 Exemplaren ein. In der Expansionsphase des Internet funktionierte das Konzept gut. Mit steigender Zahl von Internet-Nutzern und nachlassendem Informationsbedürfnis sank das Leserpotential, die Auflage rutschte endgültig auf rund 60.000 Exemplare. Im Jahre 2004 benannte der Verlag das Magazin in \"AOL Technik Internet Fun\" um, fand aber mit dem veränderten Konzept keine ausreichend große Leserschaft mehr. Ein Jahr später wurde es eingestellt.\n"}
{"id": "1607242", "url": "https://de.wikipedia.org/wiki?curid=1607242", "title": "PureFTPd", "text": "PureFTPd\n\nPureFTPd ist ein Open-Source-FTP-Server für Unix und unixähnliche Systeme. Unterstützt werden die Betriebssysteme GNU/Linux, viele BSD-Derivate, Solaris, Tru64 UNIX, Darwin, IRIX und HP-UX. Des Weiteren unterstützt das Programm LDAP-, MySQL-, PostgreSQL- und benutzerdefinierte Authentifizierung, sowie SSL/TLS-Verschlüsselung und das File Exchange Protocol (FXP).\n\nIm Gegensatz zu den meisten anderen FTP-Daemons wird PureFTPd nicht mittels Konfigurationsdatei (außer für LDAP und MySQL), sondern per Attribute konfiguriert, die dem Daemon beim Starten übergeben werden. Es existiert zwar auch eine Konfigurationsdatei (unter /usr/local/etc/). Die jedoch wird mittels eines Perl- oder Python-Skript, welches als Wrapper fungiert, in einen Konsolenbefehl umgewandelt. Optional existieren auch zwei grafische Frontends: kcmpureftpd, ein Modul für das KDE-Kontrollzentrum und PureAdmin, welches auf GTK2 basiert. Für Mac OS X gibt es den PureFTPd-Manager, welcher auf Cocoa basiert. Als Web Frontend existiert der \"User manager for PureFTPd\". Er benötigt einen Webserver, vorzugsweise Apache, eine PHP-Installation und eine MySQL-Datenbank in der die (virtuellen) FTP-Benutzer verwaltet werden.\n\nVirtuelle Benutzer, also Benutzer die nicht auf dem System, sondern nur in der PureFTPd-Datenbank existieren, werden ebenfalls unterstützt. Virtuelle Benutzer erben die Eigenschaften von einem „echten“ Benutzer. Dadurch wird Konfigurationsaufwand gespart und Sicherheit und Flexibilität erhöht.\n\nAb Version 1.0.15 steht das Programm unter BSD-Lizenz, vorher unter GPL.\n\nPureFTPd basiert auf Troll-FTPd, das von Arnt Gulbrandsen um 1995 geschrieben wurde, während er bei Trolltech arbeitete.\n\n"}
{"id": "1607763", "url": "https://de.wikipedia.org/wiki?curid=1607763", "title": "BusyBox", "text": "BusyBox\n\nBusyBox ist ein Computerprogramm, das verschiedene elementare Standard-Unix-Dienstprogramme in einem einzelnen Programm vereint. Es läuft auf verschiedenen POSIX-Umgebungen wie Linux, Android oder FreeBSD. Viele Werkzeuge sind jedoch so gestaltet, dass sie mit den Schnittstellen eines Linux-Kernels funktionieren. BusyBox wurde geschaffen, um auf eingebetteten Betriebssystemen mit sehr beschränkten Ressourcen arbeiten zu können.\n\nLaut der Projektseite ist BusyBox das „Schweizer Taschenmesser für embedded-Linux“. Um noch weniger Platz zu brauchen, wird BusyBox oft mit kleinen Bibliotheken wie etwa uClibc gelinkt.\n\nBusyBox wurde 1996 von Bruce Perens geschrieben. Er wollte ein auf eine einzelne Diskette passendes, vollständiges und bootbares Linux-System haben, das sowohl als Rettungssystem, als auch zur Installation eines Debian-Systems verwendbar wäre. Bis 1998 wurde es von Enrique Zanardi gewartet und an die Bedürfnisse des Debian-Installationsprogramms angepasst. Danach erweiterte es Dave Cinege für das „Linux Router Project“. Zwischen 1999 und 2006 war es in den Händen von Erik Andersen, und es verbreitete sich auf dem wachsenden Markt der eingebetteten Systeme. Seit 2006 ist der Maintainer Denys Vlasenko.\n\nGegen viele namhafte Hersteller, die BusyBox auf ihren Geräten einsetzen, wurden seit Dezember 2009 Klagen eingereicht, da laut Software Freedom Law Center (SFLC) die GPL verletzt oder gänzlich ignoriert wurde.\n\nDank seiner Vorteile für diese Systeme wird es zum Beispiel in Linux-Systemen auf dem Sharp Zaurus, dem Nokia 770, dem Nokia N900, dem Motorola ROKR Z6, auf OpenWrt basierenden Systemen wie dem Fon-Router La Fonera, auf AVM-Fritz!Boxen, TomTom-Navigationsgeräten, auf gerooteten Android-Images, Dreambox-Receivern, Screenplay Multimedia-Festplatten von IOMEGA, dem Acme Systems Foxboard, fast allen Linux-Installations-CDs (beispielsweise Ubuntu, Debian) oder dem GP2X verwendet. Es ist freie Software und unterliegt der GNU General Public License Version 2 (GPLv2).\n\nNeben der Verwendung in eingebetteten Systemen wird BusyBox auch für initramfs zum Starten von Betriebssystemen sowie als Rettungsprogramm eingesetzt. Werden z. B. wichtige Systembefehle wie /bin/env gelöscht, so kann man diese durch einen Symlink auf bzw. eine Kopie von BusyBox vorübergehend ersetzen, um dann mit dem nun wieder funktionsfähigen System das betroffene Paket (in diesem Falle binutils) neu zu installieren. Besonders ein statisch gelinktes Build von BusyBox ist hierbei interessant, da das System somit auch bei der Zerstörung von glibc geladen werden kann und mit entsprechender Konfiguration in einem solchen Falle die in BusyBox integrierte Almquist Shell startet.\n\n"}
{"id": "1609671", "url": "https://de.wikipedia.org/wiki?curid=1609671", "title": "Balloon Help", "text": "Balloon Help\n\nEine Balloon Help ist ein sprechblasenartiges Element in einer grafischen Benutzeroberfläche, das erscheint, wenn der Benutzer mit dem Mauszeiger eine bestimmte Zeit über einer Schaltfläche verweilt.\n\nEntwickelt wurde Balloon Help von Apple Inc., die es 1991 mit ihrem System 7 einführte. Nach dem Aktivieren bot die Balloon Help eine Erklärung zu einem mit der Maus überfahrenen Oberflächenelement. Die Erklärung umfasst ein bis zwei Sätze. Dieses war für Einsteiger, die ein Programm erlernen wollten, zwar sinnvoll, für den täglichen Umgang allerdings völlig ungeeignet, da die Sprechblase viel zu viel Platz in Anspruch nahm. Als Folge schalteten viele Benutzer sie sehr schnell komplett ab, was dazu führte, dass manche Funktionalitäten vergessen wurden.\n\nAufgrund dieser gravierenden Nachteile wurden Tooltips entwickelt, die diese Nachteile ausbesserten.\n"}
{"id": "1610244", "url": "https://de.wikipedia.org/wiki?curid=1610244", "title": "Lftp", "text": "Lftp\n\nlftp ist ein freier und konsolenbasierter FTP-Client für Unix und unixoide Betriebssysteme wie Linux. Er gehört zu den umfangreichsten seiner Art. Autor und Initiator ist Alexander Lukyanov.\n\nNeben FTP unterstützt das Programm die Protokolle FXP, HTTP, FISH, SFTP, HTTPS, FTPS und BitTorrent. Zusätzlich unterstützt lftp eine Fülle von Funktionen, darunter rekursives Spiegeln von Verzeichnisbäumen, Verwalten von Bookmarks, mehreren simultanen Sitzungen zu verschiedenen Servern in einer Shell (durch sogenannte „slots“), Zeitplanung von Transfers, Befehlswarteschlangen und ein Anpassen der nutzbaren Bandbreite.\n\nBesonders hebt sich der Client durch die Bash-ähnliche Shell hervor, mit der man nicht nur effizient interaktiv arbeiten, sondern lftp auch durch Skripte interaktiv steuern kann. Sie kann optional über globale oder benutzerspezifische Konfigurationsdateien angepasst werden. Unter anderem sind Aliase, Skripte und ein benutzerdefinierter Prompt möglich.\n\nInnerhalb der Shell dienen vorangestellte Ausrufezeichen als Escape-Symbole, d. h., sie werden nicht mit der lftp-Shell, sondern mit der Benutzer-Shell, von der lftp gestartet wurde, ausgeführt und somit lokal abgearbeitet. codice_1 innerhalb von lftp bewirkt also ein Listing des FTP-Verzeichnisses, codice_2 hingegen, dass der Inhalt des lokalen Verzeichnisses angezeigt wird. Das Mischen beider Betriebsarten in Skripten oder Warteschlangen ermöglicht sehr komplexe automatisierte Transfervorgänge.\n\nZum Lieferumfang von lftp gehört auch noch lftpget, mit dem Dateien direkt heruntergeladen werden können.\n\n lftp -u BENUTZERNAME,KENNWORT -p 22 -c \"cd ORDNERXY && put DATEIXY\" sftp://SERVERADRESSE \n\nErklärung: Der Parameter „-u“ übergibt den Benutzernamen, mit dem man sich am entfernten Server anmelden möchte. Das Kennwort wird nach einem Komma angehängt. Sonderzeichen im Kennwort müssen mit \\ markiert werden.\n\nDer Parameter „-p“ gibt den Port an, auf dem der Remoteserver erreichbar ist. Dies anzugeben ist nur nötig, wenn der Remoteport vom Standard abweicht. Da SFTP-Server standardmäßig auf Port 22 lauschen, ist die Angabe „-p 22“ im oben genannten Beispiel nicht nötig, da lftp auch ohne diese Angabe zum Port 22 am SFTP-Server verbinden würde.\n\nNach dem Parameter „-c“ können Befehle spezifiziert werden, die lftp ausführt und sich danach beendet. Im Beispiel oben wechselt das Programm in das Verzeichnis ORDNERXY (durch den Befehl „cd ORDNERXY“) und führt danach (was durch die „&&“ angegeben wird) den Befehl „put DATEIXY“ aus, der die lokale Datei „DATEIXY“ auf den entfernten Server kopiert. Im Beispiel oben verbindet sich lftp zu einem SFTP-Server, was durch das codice_3 vor „SERVERADRESSE“ angegeben wird.\n\nIm Gegensatz zu Parameter „-c“ können nach dem Parameter „-e“ Befehle spezifiziert werden, die lftp ausführt und sich danach nicht (!) beendet.\n\n"}
{"id": "1612476", "url": "https://de.wikipedia.org/wiki?curid=1612476", "title": "Kisekae Set System", "text": "Kisekae Set System\n\nDas Kisekae Set System, kurz \"KiSS\", ist eine virtuelle Umsetzung des Papier-Anziehpuppen-Prinzip, das Mitte der 1990er Jahre in Japan entwickelt wurde. \"Kisekae\" ist die Kurzform für \"\"kisekae ningyou\"\", der japanischen Bezeichnung für Anziehpuppe.\n\nKiSS bietet den Benutzer eine Art interaktives Bild auf virtuellem Papier mit verschiedene Elemente, die per Maus verschoben werden können. Hierbei liegt es an der Kreativität und den Möglichkeiten des Erstellers eines Moduls, ob man per Klick Kleidung oder Gegenstände verschieben, versteckte Elemente finden, Frisuren und Gesichtsausdruck wechseln oder kleine Animationen auslösen kann.\n\nTechnisch gesehen ist KiSS ein Grafik-Standard, der „2½ Dimensionen“ \"simuliert\", also mit Layer-Technik arbeitet, bei dem jedes Objekt ein eigenes oder gruppiertes Cel mit eigenen Tiefeninformationen ist.\n\nBeispiel: Socken verdecken zwar Füße, aber \"nicht\" die darüber geschobenen Schuhe, deren hintere Ebene von den Socken verdeckt wird.\n\nDie Idee für die erste Version von Kisakae Set System hatte ein Programmierer namens Yav beim Betrachten eines Mangas mit einem Paperdoll-Spiel im Jahr 1991. Hierbei bestanden die Möglichkeiten, innerhalb des Moduls daraus einige wenige statische Elemente auf dem Bildschirm verschieben zu können.\n\nHieraus entwickelte sich über Jahre hinweg eine Art \"virtuelles\" Papier, das durch die Programmstruktur, vergleichbar mit einer Webseite ist. Vor allem das Einfügen von Java, um neue Funktionen zu entwickeln, zeigt deutlich, dass die Grenzen zwischen einer Web-Seite und einem KiSS-Modul, schneller aufgehoben wurde, als man es in der Anfangszeit erwartet hätte.\n\nDie Verschmelzung von Kisekae-Modulen und Websites ist am besten mit dem Begriff \"Pseudo KiSS\" zu umschreiben, denn mit den entsprechenden Mitteln aus Flash oder Java kann man auf Webseiten durchaus ähnliches \"ohne\" KiSS-Viewer integrieren sind.\n\nMit dem Unterschied, dass man im Viewer durch verschiedene Sets (unterschiedlichen Ebenen) mit dem Nummernfeld blättern kann. Unter Umständen stehen auch verschiedene Farbpaletten für Hintergründe und Elemente zur Verfügung. Der größte Vorteil an Kisekae ist allerdings, dass man dafür nicht mit dem Internet verbunden sein muss, es also offline nutzen kann.\n\nAber auch in Spielen finden sich verwandte Funktionen, wie das Wechseln der Rüstung im \"RPG\"-Bereich oder der Modus \"Create-a-Sim\" (CAS) in Sims 2. Wobei die Modding-Szene des Simulators durchaus eine Art \"Verwandtschaft\" mit der Kisekae-Szene aufweist. Allerdings sind zumindest die Möglichkeiten der Erstellung von Charakter in der Kreativität nicht durch vorgegebene Maßstäbe, wie Größe des Körpers oder das Hineinversetzen in die Perspektive fertiger Kleidertextur, eingeschränkt. Die Möglichkeiten und Inhalte werden nur durch die Fähigkeiten und die Fantasie des Modul-Erstellers begrenzt.\n\nBei der Benutzung des Kisekae Set System muss man sich vor allem bewusst sein, dass es einen gravierenden Unterschied zwischen \"Viewern\" und \"Modulen\" gibt.\n\nKisekae-Viewer sind grundsätzlich Freeware-Programme, die für das Benutzen von Modulen benötigt werden. Sie werden von Usern für User permanent weiterentwickelt und sind inzwischen für jede Plattform, von Amiga bis Linux und sogar für einige PDAs zu finden. Hierbei ist vor allem \"UltraKiSS\" zu empfehlen, da es neben den üblichen Viewer-Funktionen auch umfangreiche Möglichkeiten für das Erstellen und Bearbeiten eigener Module bietet und mit sämtlichen Standards kompatibel ist.\n\nZu den integrierten Funktionen zählen z. B. ein Text-Editor, ein Farb-Editor, ein Zeichenprogramm und ein Mediaplayer. Zusätzlich steht dem Nutzer mit \"UltraKiSS-Portal\" ein einfacher Browser innerhalb des Programms zur Verfügung.\n\nHierbei ist zu beachten, dass es sich bei UltraKiSS um ein Open-Source-Projekt handelt, das für Windows, Mac und Linux kompatibel ist. Es wäre also nicht verwunderlich, dass es in Zukunft, eine Version geben könnte, in die z. B. die Möglichkeiten eines Web-Browsers wie Firefox integriert.\n\nDie Inhalte eines Moduls sind hauptsächlich Puppen, es können auch Modelle von Maschinen sein, bei denen man Teile austauschen kann oder z. B. Taschenrechner sein.\n\nEin Beispiel für versteckte Funktionen kann man im Ranma-½-Modul von Dov Sherman finden, in dem zwischen Ranma-kun und Ranma-chan inklusive angepasster Kleidung durch einen einfachen Klick wechseln kann.\n\nDie Module sind Datensätze, die man entpackt, um einen Ordner mit einer oder mehreren \"Dolls\" zu erhalten. Hierbei sind die Möglichkeiten, was man vorfinden und entdecken kann, nur durch den erstellenden Künstler eingeschränkt.\n\nSeit der Anfangszeit sind die Kisekae-Module in LZH-Dateien als im LHA-Standard auch gepackt von den Viewern ausgelesen werden können. Wobei Module im ZIP-Format inzwischen auch verarbeitet werden können.\n\nIm Allgemeinen setzen Kisekae-Module sich aus 3 Dateiformen zusammen:\n\nManchmal werden Module auch durch Textdateien oder Bilder ergänzt, weshalb es sich immer lohnt in den Ordner des Moduls hineinzuschauen, bevor man es öffnet.\n\nJugendschutz ist bei der Bereitstellung der Module durchaus ein Thema, das man beim Erstellen von Kisekae-Modulen beachten muss, um Probleme zu vermeiden. Hierbei sind nicht nur moralische, sondern auch gesetzliche Aspekte, für die mögliche Zielgruppe zu sehen. Denn wenn es aus anatomischer Sicht etwas \"zu\" korrekt gestaltet wurde, kann dies schwere Folgen für den Künstler haben.\n\nWeshalb in manchen Ländern die Programmier eher zurückhaltend mit eigenen Modulen sind, um nicht ins falsche Licht gerückt zu werden. Allerdings sind Links zu Modulen mit Adult-Inhalten, durch entsprechende Hinweise gekennzeichnet bzw. werden vom Administrator des Web-Archives durch gesicherte Bereiche möglichst unzugänglich für Kinder gemacht.\n\nAußerdem gibt es Einstellungsmöglichkeiten für eine diskrete Art von \"Kindersicherung\", wie eine erhöhte Fixierung von verschiedenen Kleidungsstücken, die sich nicht in jedem Viewer umgehen lassen.\n\nIm Allgemeinen sind Künstler in Kisekae Ningyou Clubs organisiert, die es auf Plattformen wie z. B. Yahoo gibt. In Japan, dem Heimatland des Kisake Set System, gibt es gewaltige Datenbanken, die sich noch heute im stetigen Wachstum befinden.\n\nAllen voran die Big KiSS Page, allerdings ist der Zugriff auf die meisten Module der Startseite zur Kostendeckung des Web-Hostings seit dem 16. März 2001 nur noch per Bezahlservice möglich. Wobei auf der Seite noch einer kleinen Sammlung \"freier\" Module auch eine Auswahl an Viewern und Editoren zu finden ist. Durch die Umstellung auf das Bezahlsystem ist die Anzahl der aktiven Künstler in diesem Bereich allerdings gesunken und die Sub-Szene der Sammler geschrumpft.\n\nWobei es in anderen Ländern teilweise nur mit großem Aufwand möglich ist, eine Datenbank oder einzelne Module auf Seiten, in der jeweiligen Muttersprache zu finden. Dies ist vor allem durch die Vielzahl der Konverter und Hilfen zurückzuführen, die größtenteils nur in Englisch oder Japanisch erhältlich sind.\n\nIn Deutschland z. B. beschränkt sich die Verbreitung von Modulen auf Heft-CDs auf die Mitte der 1990er und wenige Hefte wie:\n\nWobei dies auch letztendlich mit den veränderten Bestimmungen zum Inhalt der Heft-CD in nächster Zeit sich nicht ändern wird.\n\n"}
{"id": "1612586", "url": "https://de.wikipedia.org/wiki?curid=1612586", "title": "NC100", "text": "NC100\n\nDer Amstrad Notepad Computer ist ein ab 1992 von der Firma Amstrad in drei Modellvarianten (NC100, NC150, NC200) produzierter Computer. Als Haupt-Produktmerkmal wurde vom Hersteller die leichte Bedienbarkeit herausgestellt.\nUm die leichte Bedienbarkeit hervorzuheben, wandte sich der Amstrad-Präsident Alan Sugar im Handbuch in einem Vorwort an die Anwender. Darin schrieb er, er könne sogar als Chef eines Computerherstellers bisher \"nicht\" mit Computern umgehen. Seine Entwickler hätten daher den Auftrag erhalten, ein Gerät zu entwickeln, mit dem \"selbst er\" umgehen könne.\n\nDie Anwendungsprogramme (vor allem Textverarbeitung mit Rechtschreibprüfung, Taschenrechner und Organizer) sind fest im ROM installiert und sowohl nach den Maßstäben von 1992 als auch nach heutigen (2006) Maßstäben tatsächlich leicht bedienbar. Dazu trägt auch bei, dass keine Ladezeiten für das Betriebssystem nötig sind. Der Computer ist sofort nach dem Einschalten betriebsbereit. Der Computer kann mitten im Betrieb ausgeschaltet werden, alle Daten bleiben im batteriegepufferten RAM erhalten.\n\nFür gehobenere Ansprüche an die Leistungsfähigkeit kann die NC-Reihe auch mit einem vollwertigen BBC-BASIC oder in Assembler programmiert werden. Zur Datenfernübertragung steht eine Terminalemulation zur Verfügung.\n\nTechnische Daten:\nZ80-Prozessor, 64 KB RAM (NC150, NC200: 128 KB), parallele und serielle Schnittstelle, Einschub für Speicherkarten (PCMCIA, batteriegepufferte SRAM-Karten), Display mit 480 × 64 (NC200: 480 × 128) Pixel, Batteriebetrieb mit AA-Zellen möglich (Laufzeit etwa 40 Stunden).\n\n"}
{"id": "1613968", "url": "https://de.wikipedia.org/wiki?curid=1613968", "title": "Car-PC", "text": "Car-PC\n\nAls Car-PC oder Carputer wird ein PC bezeichnet, der fest in einem PKW oder LKW eingebaut ist, meist mit einem Touchscreen zur bequemen Steuerung.\n\nÜblicherweise werden aufgrund des geringeren Stromverbrauchs und der extremen Bedingungen in einem Fahrzeug (Erschütterungen, Hitze, Kälte) Komponenten eingesetzt, die für Notebooks gedacht sind. Häufig werden Car-PCs in sehr kleine Gehäuse verbaut, so dass sie unter einen Sitz oder in ein Handschuhfach passen, oder sie werden in der Ersatzradmulde oder im Kofferraum eingebaut.\n\nUm die Steuerung über den Touchscreen zu vereinfachen wird häufig eine spezielle Software verwendet, mit deren Hilfe die einzelnen Funktionen angesteuert werden können. Auch die Steuerung von Relais wird hierdurch ermöglicht. So kann z. B. das Fenster oder die Heizung über den PC angesteuert werden. Auch das Auslesen von Motordaten ist möglich, um sich etwa die aktuelle Geschwindigkeit und die Drehzahl auf dem PC anzeigen zu lassen.\n\nEin Car-PC ist ein gewöhnlicher Computer, der in ein Auto eingebaut wurde, häufig basierend auf den kleinen ITX-Mainboards, teilweise mit spezialisierten Prozessoren wie dem VIA C3. Weiterhin werden auch Barebones von Notebooks, eine ITX-Variante für Intel Pentium M oder normale ATX-Computer eingesetzt.\n\nBildausgabe und Eingabe erfolgen meist über einen kleinen Touchscreen, oder auch über einen TFT-Bildschirm und eine Maus. Käufliche 7\"-Touchscreenmonitore haben meist einen Standfuß, mit dem sie sich leicht befestigen lassen. Für höhere Ansprüche werden individuelle Konsolen hergestellt, die direkt auf das entsprechende Auto zugeschnitten sind. Es bietet sich an, den Monitor in die Mittelkonsole des Fahrzeuges zu verbauen. Viele neuere Fahrzeuge besitzen bereits ein Navigations-Display, ein integriertes Display im Combi-Instrument oder im Armaturenbrett. Diese meist schon recht hochauflösenden Original-Fahrzeug-Displays bieten sich für die Bildausgabe des Car-PC an.\n\nDie Datenspeicherung wird oft von einer Notebookfestplatte übernommen, neuere Modelle sind flüssigkeitsgelagert und sehr stoßbeständig, was vor allem bei Fahrzeugen mit Sport- oder Gewindefahrwerken sehr wichtig ist, da diese sehr hart federn und es sonst zu Schreib- oder Lesefehlern bis hin zum kompletten Ausfall der Festplatte kommen kann. Zum zusätzlichen Schutz wird die Festplatte in ein U-Profil mit einer speziellen Gummibandkonstruktion aufgehängt. Auf die gleiche Weise wird ein Laptop-CD/DVD-Slot-In-Laufwerk verwendet.\n\nIn einem Fahrzeug herrscht keine gleichmäßige Gleich- oder Wechselspannung, beim Motorstart sinkt z. B. die gesamte Bordspannung aufgrund der hohen Stromaufnahme des Anlassers auf unter 10 V ab. Es wird also ein spezielles Netzteil benötigt, um reibungslosen Betrieb zu gewährleisten. Der PC wird erst einige Sekunden nach Einschalten der Zündung hochgefahren. Diese Wartezeit dient zur Sicherung von genügend Energie für den Motorstart. Schaltet man die Zündung wieder aus, wird der PC nach einer Zeitspanne von wenigen Sekunden bis mehreren Stunden heruntergefahren. Weiter wird jedoch eine Betriebsspannung von 5 V aufrechterhalten, die abgeschaltet wird wenn der PC komplett ausgeschaltet ist, um Probleme mit der Batterie zu vermeiden, die durch die Stromaufnahme des PCs auch im abgeschalteten Zustand entstehen könnten.\n\nDa Tastatureingaben nur schwerfällig per Touchscreen-Bildschirmtastatur möglich sind, sollte eine Tastatur verbaut werden. Hier eignen sich beispielsweise solche im Laptopformat für Serveradministrationen. Auch Spracherkennung ist eine Möglichkeit zur Steuerung.\n\nBei Autos mit Multifunktionslenkrad kann dieses leicht über eine Relaiskarte mit dem PC verbunden werden. Mit dieser lassen sich Aktionen für den jeweiligen Stromkreis definieren, wie z. B. das Verändern der Musiklautstärke. Anstelle eines Multifunktionslenkrades lässt sich auch eine Lenkradfernbedienung nachrüsten, die Infrarotsignale aussendet, die wiederum mit dem passenden Empfänger verarbeitet werden können.\n\nDie meisten Mainboards verfügen über eine integrierte Soundkarte die als Basis für eine Hifi-Anlage ausreicht. Zusätzliche Soundkarten ermöglichen jedoch eine bessere Klangqualität oder 7.1-Kanalabmischung und bieten teilweise Cinch-Ausgänge für geringere Qualitätsverluste. Um die Lautsprecher mit dem Audiosignal der Soundkarte anzusteuern, wird ein zusätzlicher Verstärker benötigt, bzw. ein Radio oder auch „Headunit“ genannt, mit AUX-Eingang.\n\nZum Anschließen von genügend Erweiterungen ist ein aktiver USB-Hub sinnvoll, da ein passiver die Spannung über das PC-Netzteil und nicht direkt von der Autobatterie bezieht und daher unter Umständen nicht genügend Strom liefern kann.\n\nEine GPS-Maus ermittelt die Position des Fahrzeuges per GPS. Sie ist das Herzstück eines Navigationssystems.\n\nViele neuere Handys verfügen über einen Bluetooth-Anschluss, und mit einem Bluetooth-USB-Adapter kann ein solches mit dem PC vernetzt werden. Mit spezieller Software ist es z. B. möglich, bei ankommenden Anrufen die Musik automatisch leiser zu stellen und über ein Mikrofon zu telefonieren. Außerdem kann man per Spracherkennung SMS verschicken oder sich ankommende SMS vorlesen lassen.\nMit einem UMTS- oder auch einem schmalbandigeren GSM-Handy, das mit dem Car-PC verbunden wird, wird ein drahtloser Internetzugang ermöglicht.\n\nEine Webcam kann als Rückfahrkamera benutzt werden, die dem Fahrer über den Monitor den Blick nach hinten erlaubt. Neuere Kameras besitzen sogar Infrarotsensoren und können Nachtsichtaufnahmen machen. Damit kann man diese Einparkhilfe auch nachts nutzen.\n\nMit sogenannten Relaiskarten können Schaltungen vom PC gesteuert werden. Mit dieser Funktion kann die Bordelektronik ferngesteuert werden, wie z. B. die elektrischen Fensterheber oder die Klimaanlage. Die Relaiskarte kann auch Signale aufnehmen um z. B. auf Taster im Fahrzeug oder unterbrochene Stromkreise, wie sie bei defekten Glühlampen der Fall sind, zu reagieren. Eine spezielle Schnittstelle namens OBD-2 ermöglicht den Zugriff auf die Motorsteuereinheit des Fahrzeuges. So ist es möglich, während der Fahrt Diagnoseoperationen (z. B. Temperaturüberwachung, Kraftstoffverbrauch oder Leistungsprüfung) durchzuführen. Außerdem lassen sich über diese Schnittstelle verborgene Funktionen des Fahrzeuges aktivieren (z. B. das Mitleuchten der Frontblinker wie in einem US-Fahrzeug) oder die Einspritzkennfelder anpassen wie es z. B. beim Chiptuning betrieben wird. Zudem erspart das eigenständige Auslesen des Fehlerspeichers unter Umständen unnötige Werkstattbesuche.\n\nÜber LAN, WLAN oder einen USB-Stick können Daten einfach vom Heim-PC auf den Car-PC und umgekehrt transferiert werden.\n\nDa ein Touchscreen nur grobe Eingaben ermöglicht, ist eine spezielle Oberfläche hilfreich, die zudem meist alle wichtigen Funktionen bereits integriert hat, etwa einen Mediaplayer und häufig auch ein Navigationssystem. Vielfach lässt sich das Erscheinungsbild der Oberfläche an das eigene Auto anpassen, einige Programme verändern mit einer Tag-Nacht-Funktion ab einer bestimmten Uhrzeit Kontrast und Helligkeit.\n\nEine Übersicht der momentan aktuellen Oberflächen:\n\n\nBisher werden Car-PC nur als Zubehör – oft sogar als Bausatz – angeboten.\nEines der ersten Fahrzeuge mit serienmäßigem Car-PC ist die 2012 auf den Markt gekommene Elektro-Limousine Tesla Model S.\n\n\n"}
{"id": "1617859", "url": "https://de.wikipedia.org/wiki?curid=1617859", "title": "389 Directory Server", "text": "389 Directory Server\n\n389 Directory Server (früher Fedora Directory Server) ist ein freier LDAP-Server.\nEs ist eine Weiterentwicklung des Netscape Directory Servers, eines LDAP-Servers, den das Unternehmen Red Hat 2004 von AOL kaufte. Davor gehörte die Software dem Unternehmen Netscape Communications. Seit dem Beginn an der Universität Michigan im Jahr 1996 wurde die Software ständig weiterentwickelt. 389 Directory Server steht als freie Software unter der GNU General Public License.\n\n389 Directory Server unterstützt:\nAb Version 1.1:\n\nWeiterhin bietet der Server eine grafische, auf Java basierende Konsole, die zum eigentlichen Verzeichnisserver noch einen eigenen Adminserver benötigt. Das plattformunabhängige Programm erlaubt das Anlegen und Löschen von Servern, das Starten und Stoppen, die Konfiguration dieser und noch vieles mehr. Es gibt eine umfangreiche Dokumentation des Servers: Online-Hilfe in der Konsole, PDF-Bücher von Red Hat, HowTos und die Wikis auf der Projekt-Website.\n\nRed Hat verfolgt mit diesem Projekt eine ähnliche Strategie wie bei Fedora, der bekannten Linux-Distribution. Es gibt den unter der GPL stehenden 389/Fedora Directory Server und den unter kommerziellen Support stehenden Red Hat Directory Server. Die beiden Produkte unterscheiden sich vor allem durch eine etwas einfachere Installation und der professionellen Unterstützung der geschäftlichen Variante. Red Hat stellt wie bei RHEL seine Anleitungstexte für alle gratis auf die Webseite, da sie sich fast vollständig auf die Fedora-Variante übertragen lassen.\n\nZur gesamten früheren Netscape Enterprise Suite gehörten unter anderem ein Mail-, ein Applikations- und ein Kalenderserver. Diese wurden bis jetzt noch nicht freigegeben. 2005 kündigte Red Hat an, weitere Produkte öffnen zu wollen. Ob dies zum Beispiel für den Applikationsserver passiert, ist ungewiss: Red Hat unterstützt WildFly und Sun Microsystems entwickelt ihn bereits unter dem Projekt GlassFish weiter. Der Zertifizierungsdienst wird mit dem eigenen Projekt Dogtag Certificate System betreut.\n\nDie erste Release 7.1 (Versionsnummer noch von der Netscape-Zeit her) bildete die Basis für den Red Hat Directory Server 7.\n\nNach der ersten vollständig offenen Version 1.0.0, die nur mit Zeitbegrenzung lief (120 Tage), wurden die Versionen 1.0.1 bis 1.0.4 mit kleineren Fehlerkorrekturen und Verbesserungen (z. B. mehr unterstützte Kennwortverschlüsselungstechniken) herausgegeben. Man passte sie jeweils den neu erschienenen Distributionen Fedora und Red Hat Enterprise Linux an und packte sie dafür.\n\nAb dem Jahr 2007 mit Version 1.1 sind die Installationspakete nur noch über das Fedora Extra Repository bzw. einem eigenen Directory Server Repository mittels YUM verfügbar. Die inzwischen fertiggestellte Version 1.1 beinhaltet:\nEs werden Fedora 6 bis 10 und RHEL 5 ab Service Level 1 als Plattformen unterstützt. Parallel dazu gibt es jetzt Red Hat Directory Server 8.\n\nAus einem Zweig des Projekts entstand 2001 der ebenfalls populäre Sun Java System Directory Server aus der damaligen iPlanet-Allianz zwischen Netscape und Sun. So konnten sowohl der 389- und der Sun-Server, als auch ältere Netscape-Server-Varianten zu Replikationszwecken verbunden werden. Inzwischen wurde der Sun-Server durch Oracles Java-basiertem Oracle Unified Directory (OUD) ersetzt, wodurch diese Lösungen hinfällig wurden.\n\nBei Active Directory und NT4 von Microsoft wird die Synchronisation der Benutzerdaten unterstützt.\n\nBei OpenLDAP kann eine einseitige Replikation per slurpd zum 389-Server hin erfolgen. Sinnvollerweise sollte Letzterer dann für nur lesende Zugriffe freigegeben werden. Umgekehrt, aber wiederum nur in eine Richtung, sollte dies theoretisch auch möglich sein, die Vorgehensweise wurde jedoch noch nicht dokumentiert.\n\nAnders bei Novell eDirectory: dort gibt es (außer dem LDAP-Protokoll) keine Interoperabilität.\n\n389 ist Teil von Red Hats FreeIPA (Identitäten, Richtlinien, Überwachung), welches neben dem Verzeichnis noch vieles mehr bietet ([Kerberos], Richtlinien, bequemere Oberfläche...). FreeIPAs Einsatz ist dem des 389 meist vorzuziehen, da es bereits ein vollständiges Identitätsmanagement (IDM) bietet.\n\n"}
{"id": "1618059", "url": "https://de.wikipedia.org/wiki?curid=1618059", "title": "EasyTAG", "text": "EasyTAG\n\nEasyTAG ist eine freie Software zum Hinzufügen und Bearbeiten von Metadaten bei Audiodateien unter GNU/Linux, Windows und macOS. Das Programm ist optionaler Bestandteil vieler Linux-Distributionen.\n\nFür die grafische Benutzeroberfläche wird GTK+ verwendet. Für die ID3-Funktionalität wird id3lib eingesetzt; um neben ID3v2.3 auch ID3v2.4 zu unterstützen, wird seit der Entwicklerversion 2.1.1 (vom 4. Juli 2007) auch libid3tag verwendet.\n\nEasyTAG unterstützt:\n\n\nAbhängig vom verwendeten Dateiformat können dabei Stücktitel, Künstler, Album, Foto (beispielsweise Albumcover), Erscheinungsjahr, Stücknummer, Musikgenre, Komponist, ursprünglicher Künstler (wie bei Remixes und Neuvertonungen), Urheberrecht, Webseite, verwendetes Kompressionsprogramm und zusätzlicher Kommentar einzeln oder in mehreren selektierten Dateien bearbeitet werden. Darüber hinaus kann EasyTAG diese Felder automatisch über Voreinstellungen und selbsterstellte Eingabemasken ausfüllen und Dateien anhand ihrer Metadaten oder externer Textdateien automatisch umbenennen. Daneben kann es Informationen wie Stücklänge und Bitrate darstellen und externe Metadatenquellen wie die freedb nutzen.\n\nDie Benutzeroberfläche ermöglicht es, Dateien über eine Baumstruktur ähnlich einem Dateimanager zu durchstöbern und Dateien gezielt nach Künstler und Album ausgewählt anzuzeigen und bietet für Änderungen der Metadaten darüber hinaus eine Undo-Funktion. Ferner können auch Wiedergabelisten mit Hilfe von EasyTAG erstellt werden.\n\n"}
{"id": "1619007", "url": "https://de.wikipedia.org/wiki?curid=1619007", "title": "Testchart", "text": "Testchart\n\nEin Testchart, auch Charakterisierungschart genannt, wird benötigt, um im ersten Schritt beim Aufbau eines Farbmanagements die Gerätecharakterisierung für einen Scanner, einen Drucker oder Fotokameras zu erstellen.\n\nEin Testchart besteht aus einer begrenzten Anzahl von Farbfeldern, deren Zusammensetzung aus den Prozessfarben Cyan, Magenta, Gelb und Schwarz bekannt ist.\n\nTestcharts werden von verschiedenen Organisationen zur Verfügung gestellt, mit dem Ziel ein einheitliches Chart für alle Profilierungstools zu verwenden. Zum Beispiel das \"ECI 2002\" der European Color Initiative. Der bekannteste Vertreter dürfte das \"IT 8\" sein. Ein weiteres Testchart ist das \"TC3.5\".\n\nEs gibt zwei Arten von Testcharts: geordnete (visual) und ungeordnete (random), bei denen die Farbfelder zufällig angeordnet werden.\n"}
{"id": "1619136", "url": "https://de.wikipedia.org/wiki?curid=1619136", "title": "Box PC", "text": "Box PC\n\nMit Box PC stehen für Maschinen-, Anlagen- und Schaltschrankbauer besonders robuste Industrie-PC-Systeme für leistungsstarke aber auch platzoptimierte Applikationen zur Verfügung. Für unterschiedliche Anforderungen stehen unterschiedliche Geräteklassen zur Auswahl.\nEs gibt den so genannten „Shoe-Box“-Rechner, der wegen seiner Abmessungen ungefähr der Größe eines Schuhkartons entspricht. Dieser bietet Platz für ein oder zwei gewöhnliche PC-Steckkarten. Als weitere Variante gibt es Rechner, bei denen mindestens eine Seite sehr flach gefertigt ist und die direkte Anbringung eines flachen Displays möglich ist. Aus der Kombination ergibt sich dann der Panel-PC. Als dritte Variante gibt es Box-PC, welche sowohl ohne Lüfter als auch ohne Festplatte betrieben werden. Die Abwärme wird über einen großen in das Gehäuse integrierten Kühlkörper abgegeben. Als Massenspeicher werden Compact Flash Systeme eingesetzt. Diese Box-PC haben häufig die Ähnlichkeit mit einer Audio-Endstufe im Kfz.\n\nDie hohe Industrietauglichkeit zeichnet sich durch hohe Schwing-/Schockbelastung im Betrieb, hohen Temperatureinsatzbereich, hohe Servicefreundlichkeit, ausgeprägte Diagnose, Dauerbetrieb und teilweise auch lüfter- und festplattenlosen Betrieb aus, z. B. durch den Einsatz von Industrial Grade Compact Flash Karten.\n"}
{"id": "1619146", "url": "https://de.wikipedia.org/wiki?curid=1619146", "title": "Panel PC", "text": "Panel PC\n\nPanel PC sind Varianten von Industrie-PCs für den Einsatz in Standardschaltschränken, Pulten und Schalttafeln. Alternativ können sie auch als Komplettsystem auf einem Standfuß (z. B. als Visualisierungs-PC an einer Montagelinie) stehen. Typische Einsatzgebiete sind sowohl in der Fertigungs- als auch in der Prozessautomatisierung. Sie bestehen aus einer kompletten Einheit, dem Rechner und einem Display. Bei den Displays handelt es sich um TFT- oder LC-Bildschirme, meistens mit Touchfunktion oder einer untergeordneten Tastatur, welche direkt auf dem Rechner aufgebracht sind und intern mit Flachbandkabeln verbunden werden. Bei dem Rechner kann es sich um einen Box PC handeln, der zusammen mit dem Bildschirm eine Einheit zum Panel PC bildet. Bei modularen Panel PCs können Displays mit verschiedenen Größen flexibel mit einer Recheneinheit kombiniert werden.\n\nFür unterschiedliche Anforderungen stehen verschiedene Panel-PC von unterschiedlichen Herstellern zur Verfügung.\n\nMeistens haben diese gemeinsame Industriefunktionalitäten wie Schutzart IP65, NEMA 4, hohe elektromagnetische Verträglichkeit, CE-Kennzeichnung, ausgelegt für 24 Stunden Dauerbetrieb, hohe Umgebungstemperaturen im Betrieb.\n"}
{"id": "1624703", "url": "https://de.wikipedia.org/wiki?curid=1624703", "title": "XCircuit", "text": "XCircuit\n\nXCircuit ist ein Programm zur schematischen Darstellung von Stromkreisen und ermöglicht es, diese als Postscript- oder SPICE-Dateien zu speichern. Es ist sowohl unter unixartigen Betriebssystemen als auch unter Microsoft Windows lauffähig, setzt aber einen X-Server voraus.\n\nEs wurde 1993 von Tim Edwards an der Johns Hopkins Universität in Laurel als Zeichenprogramm für den Elektrotechnikunterricht entwickelt. Heute wird XCircuit größtenteils zu Präsentationszwecken und zur Entwurfsautomatisierung eingesetzt.\n\n"}
{"id": "1626490", "url": "https://de.wikipedia.org/wiki?curid=1626490", "title": "CloneDVD", "text": "CloneDVD\n\nCloneDVD ist ein Programm für Windows, das Film-DVDs kopiert und wahlweise auch die Filme neu komprimiert. Dabei kann gewählt werden, ob nur Teile der DVD (z. B. der Hauptfilm) oder die komplette DVD kopiert werden soll. Ebenso können Features wie Sprachen oder Untertitel entfernt werden, um die Filmdateien auf eine gewählte Größe herunterzurechnen. Dies ist meist erforderlich, da sich auf gepressten DVDs oft wesentlich mehr Material befindet, als ein handelsüblicher DVD-5-Rohling fassen kann.\n\nCloneDVD funktioniert mit fast allen DVD-Laufwerken, kann jedoch, um dem Urheberrecht der meisten EU-Länder zu genügen, keine kopiergeschützten Film-DVDs kopieren. Aus diesem Grund darf das Programm in Deutschland und vielen anderen Ländern legal vertrieben werden. Mithilfe der Zusatzsoftware AnyDVD ist auch das Kopieren geschützter Filme möglich.\n\nDas Programm wird von der Schweizer Firma Elaborate Bytes AG entwickelt und vertrieben. Ebenso kann das Programm auf den Seiten der Firma SlySoft erworben werden. Letztere vertreibt seit Anfang 2006 auch eine modifizierte Version namens \"CloneDVD Mobile\", die speziell für das Konvertieren in Formate mobiler Endgeräte (z. B. \"iPod Video\" oder \"Playstation Portable\") entwickelt wurde.\n\n"}
{"id": "1629272", "url": "https://de.wikipedia.org/wiki?curid=1629272", "title": "Volume Shadow Copy Service", "text": "Volume Shadow Copy Service\n\nVolume Shadow Copy Service (VSS), in lokalisierten Windows-Versionen \"Volumeschattenkopie\" genannt und umgangssprachlich kurz als „Schattenkopie“ bezeichnet, ist ein mit Windows XP eingeführter Systemdienst zur Erzeugung und Bereitstellung von Versionsständen.\n\nDer Volumeschattenkopie-Dienst wurde mit dem Betriebssystem Windows XP eingeführt und danach in erweiterter Form auch mit Windows Server 2003, Windows Vista, Windows 7, Windows Server 2008, Windows Server 2012, Windows Server 2016 und auch Windows 10 bereitgestellt. Er dient zur einfachen Erzeugung und Bereitstellung von Versionsständen (sog. Snapshots). Im Rahmen der zuvor bereitgestellten Festplattenkapazität speichert dieser Dienst Modifikationen an Dateien und Ordnern im Rahmen von bis zu 64 Schattenkopien, also älteren Versionsständen.\n\nDie Schattenkopien selbst sind schreibgeschützt. Der Vorteil dieser Technik liegt primär darin, dass Benutzer überschriebene ältere Versionen einer Datei selbständig wiederherstellen können, ohne auf einen Eingriff durch einen Administrator angewiesen zu sein.\n\nZusätzlich kann der Volume Shadow Copy Service dazu verwendet werden, Datensicherungen von konsistenten Zuständen der Dateisysteme oder Metadaten zu erstellen, die sonst durch Schreiboperationen blockiert sein können (z. B. die Registry oder die Systemdatenbanken).\n\nDafür können Programme sogenannte „VSS Writer“ implementieren, um Kopien der eigenen aktuell geöffneten Dateien in einem konsistenten Zustand in der Schattenkopie abzulegen. Der SQL-Server stellt beispielsweise eine solche Komponente zur Verfügung. Einige Kopierprogramme nutzen diese Funktionalität, um Systeme im \"laufenden\" Betrieb zu klonen.\n\nIn Windows XP ist eine stark eingeschränkte Version von VSS enthalten. Dauerhafte Aufbewahrung von älteren Versionsständen ist damit nicht möglich. Von jedem logischen Laufwerk kann nur eine temporäre Schattenkopie angelegt werden. Das wird z. B. von Backuplösungen wie Acronis, Paragon, SEP sesam, NTBackup, Langmeier Backup, ShadowProtect, Bacula, Duplicati und Syncback Pro genutzt, um alle Dateien während des Betriebes konsistent sichern zu können. Eine Schattenkopie lässt sich für Windows Versionen vor Server 2008 auch über das Kommandozeilenprogramm codice_1 aus dem VSS-SDK erstellen. Bei aktuelleren Versionen ist codice_2 bereits auf dem System vorhanden.\n\nZu beachten ist, dass Microsoft die Abkürzung VSS auch für Visual SourceSafe verwendet.\n\n"}
{"id": "1630428", "url": "https://de.wikipedia.org/wiki?curid=1630428", "title": "LingoPad", "text": "LingoPad\n\nBei LingoPad handelt es sich um eine als Freeware veröffentlichte Wörterbuchsoftware. Der Programmname LingoPad versteht sich als Akronym für Lingo4you Personal Advanced Dictionary. Obwohl ursprünglich ausschließlich für den Sprachbereich \"Englisch ↔ Deutsch\" konzipiert, sind mittlerweile zahlreiche andere Sprachen als Zusatzmodule installierbar. Im Gegensatz zu Onlinewörterbüchern ist der Datenbestand auch ohne Internetanbindung verfügbar.\n\n\nDie installierbaren Sprachenpakete unterscheiden sich außerordentlich hinsichtlich Qualität und Quantität. Einzelne Sprachmodule umfassen teilweise nur wenige tausend Wörter. Andere sind noch ungeprüft.\n\nDie vom „Programm“ LingoPad unabhängigen Sprachbausteine sind größtenteils Open Source Projekte, die von engagierten Freiwilligen zusammengestellt werden.\n\nFolgende Sprachen sind derzeit integrierbar:\n\n\n\nNach der letzten Veröffentlichung (Built 360) Ende Juli 2008 ist die Programmweiterentwicklung unter Windows vorläufig eingestellt. Es bestehen jedoch Pläne für die Programmierung eines komplett neuen, plattformunabhängigen \"LingoPads\" für Mac OS X, Linux und Windows.\n\nSeit Herbst 2010 befindet sich \"LingoPad Mobile\" für Apple iOS und Google Android in der Entwicklung.\n\n"}
{"id": "1633391", "url": "https://de.wikipedia.org/wiki?curid=1633391", "title": "Google File System", "text": "Google File System\n\nDas Google File System (GFS oder GoogleFS) ist ein proprietäres, auf Linux basierendes verteiltes Dateisystem, das Google LLC für seine Anwendungen benutzt. Es ist für Googles Websuche optimiert. Die Daten sind in teilweise mehrere Gigabyte großen Dateien gespeichert, die selten gelöscht, überschrieben oder verkleinert werden. Auch ist es für hohe Datendurchsätze optimiert.\n\nDas Google File System ist an die notwendigen Anforderungen der \"Websuche\" angepasst, die eine enorme Menge an zu speichernden Daten generiert. GFS entstand aus einem früheren Versuch Googles, welcher den Namen \"„BigFiles“\" trägt und von Larry Page sowie Sergey Brin während ihrer Forschungstätigkeit an der Stanford-Universität entwickelt wurde.\n\nDie Daten werden durchgehend in sehr großen, teilweise sogar mehrere Gigabyte großen Dateien gespeichert, welche nur in extrem seltenen Fällen gelöscht, überschrieben oder komprimiert werden; Daten werden üblicherweise angehängt oder ausgelesen. Das Dateisystem ist auch entworfen und optimiert worden, um auf Googles rechnenden Clustern laufen zu können, deren Netzknoten aus handelsüblichen PCs bestehen. Dies bedeutet allerdings auch, dass man die hohe Ausfallrate und den damit verbundenen Datenverlust individueller Netzknoten als Normalzustand ansehen muss. Das äußert sich auch darin, dass kein Unterschied zwischen normaler (Herunterfahren) und abnormaler Beendigung (Absturz) gemacht wird: Serverprozesse werden standardmäßig per Killbefehl beendet. Andere Designentscheidungen setzen auf hohe Datendurchsatzraten, auch wenn dies auf Kosten der Latenzzeit geht.\n\nEin \"GFS Cluster\" besteht aus einem \"Master\" und hunderten oder tausenden \"Chunkservern\". Die Chunkserver speichern die Dateien, wobei jede Datei in 64 MB große Stücke \"(„Chunks“)\" gespalten ist, ähnlich Clustern oder Sektoren in gebräuchlichen Dateisystemen.\n\nUm Datenverlust zu verhindern, wird jede Datei beim GFS standardmäßig mindestens dreimal pro Cluster gespeichert. Bei Ausfall eines Chunkservers treten nur verschwindend geringe Verzögerungen auf, bis die Datei wieder ihre Standardanzahl an Replikas besitzt. Je nach Bedarf kann die Anzahl auch höher liegen, etwa bei ausführbaren Dateien. Jedem Chunk wird eine eindeutige, 64 Bit lange Kennzeichnung zugewiesen, logische Mappings der Dateien zu den einzelnen Chunks werden beibehalten.\n\nDer Master speichert keine Chunks, sondern vielmehr deren Metadaten, wie etwa Dateinamen, Dateigrößen, ihren Speicherort sowie den ihrer Kopien, welche Prozesse gerade auf welchen Chunk zugreifen etc. Die Master erhalten jegliche Anfragen für eine Datei und liefern als Antwort die dazugehörigen Chunkserver und erteilen entsprechende Sperren an den Prozess. Ein Client darf allerdings für gewisse Zeit die Adresse der Chunkserver cachen. Fällt die Anzahl an verfügbaren Replikas unter die Normzahl, sind es auch die Master, die die Erstellung einer neuen Chunkkopie anstoßen. Die Metadaten werden aktuell gehalten, indem die Master regelmäßig Aktualisierungsanfragen an die Chunkserver senden (\"„heart-beat messages“\", auf Deutsch etwa: \"„Herzschlag-Nachrichten“\").\n\nDesign und Implementierung des GFS sehen nur einen Master pro Cluster vor. Dies hat den Anschein, ein Fehler im System zu sein, der dessen Skalierbarkeit und Zuverlässigkeit begrenzt, da die maximale Größe und Uptime von der Leistungsfähigkeit und Uptime des Masters abhängt, da dieser die Metadaten katalogisiert und fast alle Anfragen durch ihn laufen; Googles Techniker haben allerdings durch Messungen gezeigt, dass dies (zumindest bis jetzt) nicht der Fall und GFS sehr wohl skalierbar ist. Der Master ist im Normalfall der leistungsfähigste Netzknoten im Netzwerk. Um die Ausfallsicherheit sicherzustellen, gibt es mehrere \"„Schatten-Master“\", die den Hauptrechner spiegeln und notfalls, sollte der Master einmal ausfallen, sofort einspringen. Zusätzlich stehen die Schattenmaster auch für reine Leseanfragen, die ja den Haupttraffic ausmachen, zur Verfügung, so dass sich die Skalierbarkeit dadurch weiter erhöht. Engstellen gibt es nur selten, da Clients nur nach Metadaten fragen, die komplett im Arbeitsspeicher als B-Baum vorgehalten werden – sie sind sehr kompakt, pro Megabyte Daten fallen lediglich einige Bytes an. Durch den Einsatz nur eines Hauptknotens verringert sich die Softwarekomplexität drastisch, da Schreiboperationen nicht koordiniert werden müssen.\n\n\n\n"}
{"id": "1636719", "url": "https://de.wikipedia.org/wiki?curid=1636719", "title": "COSMO (Chemie)", "text": "COSMO (Chemie)\n\nCOSMO (kurz für „Conductor-like screening model“) ist eine Berechnungsmethode für die elektrostatische Wechselwirkung eines Moleküls mit einem Lösungsmittel.\n\nBei COSMO wird das Lösungsmittel anhand einer Dielektrizitätszahl \"ε\" und weiterer Parameter (Volumen der Moleküle, Atomradii, ...) als Kontinuum behandelt. Die Methode gehört daher zur Klasse der Kontinuumsmodelle (engl. \"continuum solvation models\"). Weiter wird angenommen, dass das Lösungsmittel bis an die „Grenzfläche“ des gelösten Moleküls reicht. Diese Grenzfläche wird als Einhüllende von Kugeln um die einzelnen Atome angesetzt (Van-der-Waals-Radius der Atome plus eine feste Distanz für die Lösungsmittel-Moleküle). Für die tatsächliche Berechnung wird diese Fläche durch ebene Teilstücke, z. B. Dreiecke, angenähert.\n\nWenn das Lösungsmittel ein idealer Leiter wäre, müsste das elektrische Potenzial an dieser Fläche verschwinden, daraus ließe sich bei bekannter Verteilung der Ladungen im Molekül leicht die Ladung \"q\" an der Fläche bestimmen.\n\nFür \"reale\" Lösungsmittel kann näherungsweise angenommen werden, dass die Ladung \"q\" um einen Faktor \"f\" geringer ist als die Ladung \"q\":\n\nDieser Faktor \"f\" ist näherungsweise\n\nDer Summand 0,5 im Nenner ist dabei eine empirisch gefundene Größe.\n\nAus den so bestimmten Ladungen \"q\" des Lösungsmittels und der bekannten Ladungsverteilung des Moleküls kann dann die Energie der Wechselwirkung zwischen dem gelösten Molekül und dem Lösungsmittel bestimmt werden.\n\nDie COSMO-Methode kann für alle Berechnungsmethoden der theoretischen Chemie verwendet werden, bei denen die Ladungsverteilung eines Moleküls bestimmt werden kann, beispielsweise semiempirische Rechnungen, Hartree-Fock-Rechnungen oder Dichtefunktionaltheorie-Rechnungen.\n\nWährend Modelle, die auf Multipolentwicklung der Ladungsverteilung eines Moleküls basieren, auf kleine oder annähernd Kugel- oder Ellipsoid-förmige Moleküle beschränkt sind, hat die COSMO-Methode den Vorteil, dass sie auch für große und unregelmäßig geformte Molekülstrukturen anwendbar ist.\n\nDie COSMO-Methode ist umso genauer, je höher die Dielektrizitätszahl des Lösungsmittels ist, weil sich die Flüssigkeit im Grenzfall unendlich hoher Dielektrizitätszahl wie ein idealer Leiter verhält; bei Wasser (ε ≈ 80) wird bereits eine recht gute Genauigkeit erzielt. Für Lösungsmittel mit geringer Dielektrizitätszahl wäre eine vollständige Lösung der elektrostatischen Gleichungen genauer, aber mit höherem Aufwand verbunden.\n\nIm Gegensatz zu Molekulardynamik-Rechnungen, bei denen die Bewegung der Lösungsmittelmoleküle berechnet und ihre Lage und Dichte über einige Zeit gemittelt wird, hat das COSMO-Modell, so wie alle Kontinuums-Modelle, den Vorteil eines wesentlich geringeren Rechenaufwands. Es ist jedoch grundsätzlich nicht in der Lage, Phänomene, die mit der Granularität des Lösungsmittels zusammenhängen, korrekt zu beschreiben.\n"}
{"id": "1639557", "url": "https://de.wikipedia.org/wiki?curid=1639557", "title": "Poedit", "text": "Poedit\n\nPoedit ist ein freies, grafisches Werkzeug zur rechnergestützten Übersetzung von Dokumentationen und Programmoberflächen.\nEs ist ein grafisches Frontend zu den Werkzeugen des GNU-gettext-Systems, dessen Übersetzungsdateien mit der Endung *.po namensgebend waren.\n\nEs bietet Übersetzungsspeicher- und Projektverwaltungs-Funktionalität und ist ansonsten recht schlicht gehalten.\nUn(fertig) übersetzte Textschnipsel werden hervorgehoben, Übersetzungskataloge können importiert und bekannte Übersetzungen aus dem Katalog automatisch übernommen werden.\n\nDie Quelltexte der Open-Source-Version stehen unter der MIT-Lizenz auf GitHub zur Verfügung. Die Software läuft unter Unix-ähnlichen (Linux, macOS, …) und Windows-Systemen. Bei vielen populären Linux-Distributionen kann es direkt aus den Standard-Paketquellen installiert werden.\n\nFür die Oberfläche wird die Klassenbibliothek wxWidgets verwendet. Für die Übersetzungsspeicher-Funktionalität wird die Berkeley DB verwendet.\n\nMit Version 1.1.1 wurde die Übersetzungsspeicher-Funktionalität eingeführt.\nAb Version 1.3.5 ist native Unterstützung für Mac-OS-X-Systeme enthalten.\n\nAb Version 1.6.1 gibt es zusätzlich eine kostenpflichtige Pro-Version, mit der sich WordPress-Themes übersetzen lassen. Dem Programm wurde eine eigene, proprietäre Lizenz hinzugefügt und für den vollen Funktionsumfang muss ein Lizenzschlüssel erworben werden. Die Open-Source-Version unter der MIT-Lizenz wird nicht mehr als vorkompilierte Binärdatei zum Download angeboten.\n\n"}
{"id": "1642093", "url": "https://de.wikipedia.org/wiki?curid=1642093", "title": "Samizdat (Kenneth Brown)", "text": "Samizdat (Kenneth Brown)\n\nSamizdat ist ein 2004 veröffentlichtes Werk zum Thema Open Source. Autor ist Kenneth Brown, der Präsident der Alexis de Tocqueville Institution (AdTI), eines politisch konservativ ausgerichteten Think Tanks. Es ist nicht gedruckt erschienen, steht aber im Internet zum Download bereit. Darin wird unter anderem behauptet, dass Linus Torvalds 1991 den ersten Kernel von Linux unmöglich allein geschrieben haben könne, sondern vielmehr von Minix abgeschrieben habe, ohne dieses System als Quelle zu benennen.\n\nDas Werk wurde von Open-Source-Vertretern und den Entwicklern der betroffenen Software als unwissenschaftlich kritisiert. Mehrere von Brown als Quellen angegebene Personen, unter anderem FSF-Präsident Richard Stallman und Unix-Entwickler Dennis Ritchie, gaben an, falsch oder missverständlich wiedergegeben worden zu sein. Eric S. Raymond nannte das Werk eine „Katastrophe“. Andrew Tanenbaum, der Autor von Minix, veröffentlichte einen ausführlichen Kommentar, in dem er Browns Behauptungen als unhaltbar zurückweist. Tanenbaum zitierte unter anderem eine von Brown in Auftrag gegebene Studie, die keine auffälligen Übereinstimmungen in den Quelltexten von Linux und Minix ergeben hatte, im Buch aber nicht erwähnt wird. Einer Onlinezeitschrift zufolge wurde der Autor der Studie von einem Freund gefragt, \"ob ich daran interessiert sei, ein wenig Codeanalyse für seinen Arbeitgeber, Kenneth Brown, durchzuführen. So kam es, dass ich etwa zehn Stunden damit verbrachte, frühe Linux Versionen mit Minix zu vergleichen um aus Minix kopierten Code ausfindig zu machen. Um es zusammenzufassen: meine Analyse gab absolut keinen Hinweis darauf, dass Code übernommen wurde. Als ich [Kenneth Brown] anrief, um zu fragen, ob er noch Fragen bezüglich der verwendeten Analysemethode oder der Resultate hätte und ob er möchte, dass die Analyse mit anderen Werkzeugen wiederholt werde, erwartete mich ein blaues Wunder. Anscheinend erwartete Ken, dass ich einen ganzen Haufen kopierten Quellcodes finden würde. Den Großteil der Unterhaltung verbrachte er damit, mich davon überzeugen zu wollen, dass ich irgendwo einen Fehler gemacht haben müsse, da es doch klar sei, dass eine einzelne Person unmöglich ein Betriebssystem schreiben könne und Codeklau stattgefunden haben müsse.\" \n\nTanenbaum äußerte, neben anderen, den Verdacht, der Zweck der Veröffentlichung sei es von vornherein gewesen, Linux oder Open Source allgemein in ein schlechtes Licht zu rücken. Tatsächlich wurde bekannt, dass die AdTI Fördermittel von Microsoft entgegengenommen hatte, einer Firma, die Linux als Bedrohung betrachtet und es zu bekämpfen sucht (vgl. Halloween-Dokumente).\n\n"}
{"id": "1642176", "url": "https://de.wikipedia.org/wiki?curid=1642176", "title": "Lotus Symphony", "text": "Lotus Symphony\n\nLotus Symphony bezeichnet zwei integrierte Programmpakete. Das erste wurde 1985–1992 für DOS, das zweite 2007–2012 basierend auf OpenOffice.org für Windows, Linux und macOS entwickelt. Entwickler war Lotus, heute eine Division der IBM. Es entspricht in seinen vergleichbaren Komponenten den Büroanwendungen anderer Wettbewerber zur jeweiligen Zeit.\n\nAm 27. Januar 2012 kündigte IBM an, die Weiterentwicklung von Lotus Symphony einzustellen und stattdessen das OpenOffice-Projekt zu unterstützen.\n\nDie früher unter diesem Namen erschienene Software für DOS enthielt eine Tabellenkalkulation (abgeleitet aus Lotus 1-2-3) sowie Textverarbeitung, Datenübertragung und Datenbankfunktionen.\n\nEin Ziel dieser Entwicklung war für das Unternehmen Lotus in den 1980er Jahren, ein integriertes Softwarepaket, vergleichbar mit AppleWorks, aber für das Betriebssystem DOS auf den Markt zu bringen und die vom Markt gut angenommene Tabellenkalkulation \"Lotus 1-2-3\" um eine integrierte Textverarbeitung zu erweitern.\n\nSymphony ist ein DOS-Programm. Über die Funktionstaste Alt+F10 ist es möglich, zwischen folgenden fünf sogenannten „Funktionsbereichen“ umzuschalten:\n\nEs war damit bereits in der Zeit vor Windows möglich, den Bildschirm aufzuteilen und in den jeweiligen Bildschirmhälften mit unterschiedlichen Funktionsbereichen nebeneinander zu arbeiten. Dabei wirkten sich Änderungen auf der einen Seite, z. B. der Datenbank, gleich auf der anderen Seite, z. B. der Textverarbeitung, aus. Das war einer der interessanten Aspekte der Software.\n\nDie Datenhaltung innerhalb des Programms findet vollständig in einem tabellenkalkulationsartigen Zellenformat (Dateierweiterung: *.wr1) statt. Die anderen Module greifen darauf zu, nur die Darstellung und die angebotenen Bearbeitungsfunktionen unterscheidet sich von der einer Tabellenkalkulation.\n\nSymphony ist darauf ausgelegt, vollständig in dem verfügbaren Hauptspeicher eines 286er-Prozessors von 640 KB ablaufen zu können, dazu kommt noch ggf. das durch Treiber als Expanded Memory konfigurierte Extended Memory oberhalb von 640 KB.\n\nÄhnliche und vergleichbare Programme waren SmartWare, Microsoft Works, Context MBA, Ashton-Tates Framework, Enable und Ability Office. Lotus Jazz war die Parallelentwicklung von Lotus für den Apple Macintosh.\n\nDer Programmkern der Tabellenkalkulation entsprach vollständig derjenigen in Lotus 1-2-3.\n\nVerglichen mit den häufig eingesetzten Textverarbeitungsprogrammen jener Zeit, wie WordStar 3.3 von Micropro, WordPerfect 4.2 oder Microsoft Word 2.0, war die Textverarbeitung von Symphony weniger vielseitig, aber einfacher und schneller zu erlernen und zu benutzen.\n\nDer Datenbankteil war, verglichen mit den gängigen Paketen wie Ashton-Tates dBase III, MDBS Knowledgeman und Borlands Datenbanken Paradox 2.0 oder Reflex 1.0, jedoch wenig leistungsfähig und ließ die ausgefeilten Abfragemöglichkeiten von Reflex oder die pseudo-relationalen Fähigkeiten von dBase III vermissen. Die Datenbank war jedoch schnell und konnte innerhalb der Tabellenkalkulation benutzt und einfach (u. a. mit VLOOKUP) abgefragt werden.\n\nDarüber hinaus enthielt Symphony wie bereits sein Vorgänger Lotus 1-2-3 eine genügend leistungsfähige Programmiersprache (eine sogenannte Makrosprache). Entscheidend war jedoch die Integration von Makros: Sie waren von den verschiedenen Programm-Modulen (Textverarbeitung, Tabellenkalkulation usw.) aus benutzbar.\n\nZu seiner Zeit war es eines der wenigen Programme, die eine Datenübertragung z. B. von Börsendaten auf den PC und anschließende Auswertung nach bereits vorgegebenen oder interaktiv eingegebenen Kriterien erlaubten und diese innerhalb einer Tabellenkalkulation darstellen, berechnen, in einer Geschäftsgrafik darstellen und ausdrucken konnten. Das war auch im unbeaufsichtigten Batchmodus zu vorgegebenen Tagen und Zeiten möglich.\n\n1995 übernahm IBM die Firma Lotus und das Programm \"Lotus 1-2-3\" wurde Teil von Lotus SmartSuite.\n\nDie von IBM für 2007 angekündigte und 2008 vorgestellte Version basiert auf OpenOffice.\n\nEine Betaversion war seit dem 18. September 2007 verfügbar. Im Mai 2008 stellte IBM eine neue Version von Lotus Symphony vor. Das Produkt basiert auf OpenOffice.org 1.x, Eclipse RCP, Lotus Expeditor und benutzt OpenDocument als Standardformat. Es enthält als Teilanwendungen die Textverarbeitung \"Documents\", das Präsentationsprogramm \"Presentations\" sowie die Tabellenkalkulation \"Spreadsheets\". IBM Lotus Symphony verwendet auch Tabs, so dass mehrere, auch verschiedene, Dokumente in einem Fenster angezeigt werden können. IBM Lotus Symphony verfügt über eine zeitgemäße, kontextsensitive Benutzeroberfläche. Ein weiterer Unterschied sind die Dateifilter für Lotus SmartSuite, mit deren Hilfe sich Dokumente öffnen und bearbeiten lassen, die mit \"Lotus WordPro\", \"Lotus 1-2-3\" usw. erstellt wurden. Am 30. August 2008 kam die Version 1.1 heraus, bei der Sicherheitsaktualisierungen vorgenommen worden sind. Die im Juni 2009 erschienene Version 1.3 bietet u. a. Importfunktionen für die Dateiformate aus Microsoft Office 2007.\n\nIm Oktober 2010 erschien Lotus Symphony 3.0, welches auf den Programmcode von OpenOffice.org 3.2 aufsetzt und die jeweiligen Erweiterungen von IBM enthält. Lotus Symphony 3.x unterstützt unter anderem VBA-Skripte, die Spezifikationen des offenen Dokumentenstandards ODF 1.2 und die OLE-Schnittstelle von Windows. Die Dateifilter für die Lotus SmartSuite wurde entfernt.\n\nDie Software ist kostenlos für die Betriebssysteme Windows, macOS und Linux erhältlich.\n\n"}
{"id": "1643070", "url": "https://de.wikipedia.org/wiki?curid=1643070", "title": "Ransomware", "text": "Ransomware\n\nRansomware (von für „Lösegeld“), auch \"Erpressungstrojaner\", \"Erpressungssoftware\", \"Kryptotrojaner\" oder \"Verschlüsselungstrojaner\", sind Schadprogramme, mit deren Hilfe ein Eindringling den Zugriff des Computerinhabers auf Daten, deren Nutzung oder auf das ganze Computersystem verhindern kann. Dabei werden private Daten auf dem fremden Computer verschlüsselt oder der Zugriff auf sie verhindert, um für die Entschlüsselung oder Freigabe ein Lösegeld zu fordern.\n\nDie Bezeichnung setzt sich zusammen aus \"ransom\", dem englischen Wort für Lösegeld, und \"ware\", entsprechend dem für verschiedene Arten von Computerprogrammen üblichen Benennungsschema (\"Software\", \"Malware\" etc.). Im zweiten Quartal 2012 gab es laut \"Kindsight Security\" etwa 123.000 neue Varianten.\n\nDie Idee geht auf das Jahr 1989 zurück, als der Schädling \"AIDS TROJAN DISK\" mit Hilfe einer infizierten Diskette Daten verschlüsselte. Der Virus behauptete, eine Lizenz sei abgelaufen, und nannte den Namen eines Unternehmens, bei dem der Lizenzschlüssel erworben werden kann. Das Vorgehen war somit nicht unmittelbar als Erpressung erkennbar. Der Autor dieses Schädlings, Joseph Popp, konnte überführt werden und wurde zu einer Haftstrafe verurteilt, die er wegen einer psychischen Erkrankung jedoch nicht antreten konnte. Er kündigte an, das erpresste Geld an die AIDS-Forschung zu spenden. Einer der ersten Angreifer, der Ransomware zur Verbreitung über das Internet einsetzte, ist der Trojaner \"TROJ_PGPCODER.A\", für dessen Entschlüsselung mehrere hundert US-Dollar gefordert wurden.\n\nIm polizeilichen Kriminalitätsbericht des Landes Sachsen-Anhalt von 2011 wird ein Fall beispielhaft erwähnt. Ein Täter hatte 831 Computer in diesem Bundesland mit einer Erpressungssoftware infiziert.\n\nInzwischen sind kostenpflichtige sowie kostenfreie Baukastensysteme, sogenannte Crimeware-Kits, in Untergrundforen aufgetaucht, mit deren Hilfe Ransomware erstellt werden kann.\n\n2016 ist der Kryptotrojaner Locky aufgetaucht, welcher zehntausende PCs und unter anderem das Fraunhofer-Institut in Bayreuth infizierte. Der Tesla X3-Cryptovirus befiel im Februar 2016 u. a. Rechner des Rathauses in Rheine. Vom 1. Dezember 2015 bis zum 29. Februar 2016 wurden nach Angaben des Landeskriminalamts 156 Anzeigen wegen Angriffen durch Ransomware erstattet, die Dunkelziffer wird weit darüber vermutet. Betroffen waren 113 Firmen und Einrichtungen, unter denen sich etliche Kliniken sowie das Ministerium für Inneres und Kommunales des Landes Nordrhein-Westfalen in Düsseldorf befanden, welches im Dezember 2015 einen Angriff erlitt.\n\nIm März 2016 wurde KeRanger gefunden, eine Variante eines Kryptotrojaners für OS X. Anfang Juni 2016 informierte das Fraunhofer-Institut für Sichere Informationstechnologie darüber, dass auch Smartphones durch Ransomware betroffen sein können, insbesondere falls diese mit Security-Apps versehen sind, die Sicherheitslücken enthalten, wie sie vom Fraunhofer-Institut in sämtlichen der sieben exemplarisch getesteten Anwendungen gefunden und dem jeweiligen Hersteller zur Behebung gemeldet wurden.\n\nIm Mai 2017 befiel WannaCry unter anderem mehrere global tätige große Unternehmen in sehr kurzer Zeit; es wurden über 230.000 Computer in 150 Ländern infiziert. Aufgrund dieser Ausmaße bezeichnete das Europäische Polizeiamt den Ausbruch als noch nie da gewesenes Ereignis.\nNeben der üblichen Verbreitung durch E-Mail-Anhang besitzt WannaCry Wurm-Eigenschaften und versucht, weitere Rechner über Sicherheitslücken in Betriebssystemen aktiv und ohne Nutzerzutun zu infizieren. Die auf aktuellem Update-Stand (April bei Microsoft) befindlichen Systeme seien nicht betroffen gewesen. Bestimmte Datei- und Druckerdienste müssen freigegeben sein, womit WannaCry die Ausbreitung vor allem in Unternehmens-internen Datennetzen mit teilweise lange fehlerbehafteten Rechnersystemen gelang.\n\nRansomware kann auf den gleichen Wegen wie ein Computervirus auf einen Computer gelangen. Zu diesen Wegen zählen präparierte E-Mail-Anhänge, die Ausnutzung von Sicherheitslücken in Webbrowsern oder über Datendienste wie Dropbox.\n\nSo werden etwa E-Mails versandt, die vorgeben, eine im Anhang befindliche ZIP-Datei enthalte eine Rechnung oder einen Lieferschein über bestellte Ware. Auch wird manchmal behauptet, das Bundeskriminalamt, die Bundespolizei, die GEMA oder Microsoft habe illegale Aktivitäten auf dem Computer festgestellt und diesen daraufhin gesperrt.\n\nEin befallener Computer kann auf unterschiedliche Weise blockiert werden.\n\nEinfachere und harmlosere Erpressungsversuche äußern sich nur in einem Hinweisfenster, das bei jedem regulären Systemstart erscheint und nicht geschlossen werden kann. Auch der Taskmanager wird blockiert. Unerfahrene PC-Benutzer wissen nicht, wie sie diese Blockade beenden können. Es scheint nur den Ausweg zu geben, das Lösegeld zu zahlen, indem beispielsweise eine Paysafecard oder Ukash-Karte gekauft wird. Der Betrag wird dem Erpresser gutgeschrieben, indem man die Gutscheinnummer des Bezahlsystems am befallenen PC eingibt, wodurch sie dem Täter elektronisch mitgeteilt wird. Als weitere anonyme Bezahlmethode wird die Kryptowährung Bitcoin eingesetzt.\n\nBesonders bösartige Varianten der Ransomware haben ein größeres Schadpotenzial: Sie verschlüsseln Dateien auf dem Computer; vorzugsweise Dateien, für die anzunehmen ist, dass sie für den Besitzer des Computers sehr wichtig und möglicherweise unwiederbringlich sind. Auf Windows-Systemen beginnt Ransomware in der Regel daher im Ordner \"Eigene Dateien\" und bevorzugt dort mit Office-Anwendungen erstellte Dokumente, sowie u. a. auch E-Mails, Datenbanken, Archive und Fotos. Ohne Entschlüssel-Passwort hat der Benutzer keinen Zugriff mehr auf ihre Inhalte.\nIm Gegensatz zu Spyware werden hier also keine großen Datenmengen verschoben.\n\nUm die von der Ransomware verschlüsselten Daten wieder entschlüsseln zu können, wird der geschädigte Benutzer von dem Eindringling aufgefordert, ein Lösegeld zu bezahlen, damit er eine Software zur Entschlüsselung bzw. das benötigte Passwort erhalte. Mitunter wird er dazu zunächst zu einer gesonderten Kontaktaufnahme mit dem Ransomware-Erzeuger aufgefordert, beispielsweise per E-Mail an eine bestimmte E-Mail-Adresse, über den Aufruf einer bestimmten Webseite oder über eine Formularmaske. Häufig drohen die Kriminellen, dass bei einer Kontaktaufnahme mit der Polizei sämtliche Daten vernichtet würden.\n\nDer befallene Computer kann durch die Schadsoftware noch weiter manipuliert und überwacht sein; er darf daher nicht für weitere Arbeiten, insbesondere nicht für Tätigkeiten, die ein Passwort benötigen, verwendet werden. Das Lösegeld vom betroffenen Rechner aus per Onlinebanking zu überweisen ist als grobe Fahrlässigkeit zu werten.\n\nIn einigen Fällen ist die Möglichkeit der Entschlüsselung der verschlüsselten Dateien von Seiten des Angreifers gar nicht vorgesehen, so dass diese Dateien unwiderruflich verloren sind, sofern keine Sicherheitskopie der verschlüsselten Dateien existiert.\n\nDie \"Melde- und Analysestelle Informationssicherung MELANI\" der Schweiz hat auf ihrer Website Empfehlungen für Privatnutzer sowie für Unternehmen veröffentlicht. Das deutsche Bundesamt für Sicherheit in der Informationstechnik hat eine Situationsanalyse veröffentlicht, in der auch umfangreiche Empfehlungen zu Schutz- und Gegenmaßnahmen aufgeführt sind, sowie die empfohlene Verhaltensweisen im eingetretenen Fall. Die Analyse richtet sich an professionelle Anwender und IT-Verantwortliche in Unternehmen, Behörden und anderen Institutionen. Die Website \"No More Ransom\" ist eine Initiative der National High Tech Crime Unit der niederländischen Polizei, Europols europäischem Cybercrime Center und zwei Cyber Security-Unternehmen mit dem Ziel, Nutzer Ransomware zu erklären, ihnen Gegenmaßnahmen zu empfehlen, um eine Infektion wirksam zu verhindern, sowie Opfern von Ransomware bei der Entschlüsselung zu helfen.\n\nErste Maßnahme beim Feststellen eines Befalls des Computers ist, den Computer sofort hart auszuschalten (\"nicht\" „Herunterfahren“, sondern vom Strom trennen!) - auch wenn das Ransomware-Fenster dies „verbietet“, damit möglichst viele noch nicht verschlüsselte Dateien unverschlüsselt bleiben.\nAn einem anderen, nicht betroffenen Computer kann dann das weitere Vorgehen recherchiert werden.\n\nObwohl einer Umfrage 2010 zufolge rund ein Viertel der Opfer ein Lösegeld zahlen würde, rät auch das Bundesamt für Sicherheit in der Informationstechnik (BSI), nicht auf die Forderungen einzugehen. Selbst nach Bezahlung des Lösegelds sei nicht sicher, ob die Daten tatsächlich wieder entschlüsselt würden. Da zudem die Zahlungsbereitschaft des Opfers identifiziert würde, sind weitere Forderungen nicht auszuschließen. Bei einer Zahlung mittels Kreditkarte würden dem Täter darüber hinaus weitere private Informationen zugänglich. Es wird geraten, Anzeige zu erstatten.\n\nBei den im Zeitraum 2011 bis Februar 2012 weit verbreiteten Schadprogrammen wurde zwar der Zugriff auf die Daten verhindert, es fand jedoch keine Verschlüsselung statt. Handelsübliche Antivirusprogramme konnten einige dieser Schädlinge entfernen. Dazu waren kostenlose Programme, beispielsweise MBAM oder Avira, ausreichend.\nSämtliche Säuberungs-, Entschlüssel- und andere Maßnahmen sind von einem „sauberen System“ aus durchzuführen - niemals „aus dem betroffenen Betriebssystem selbst heraus“.\n\nTeilweise gelingt es Sicherheitsforschern, Ransomware zu knacken und Entschlüsselungswerkzeuge zur Verfügung zu stellen, mit denen die verschlüsselten Daten dann wieder entschlüsselt werden können. So ist es beispielsweise im Februar 2016 gelungen, die Verschlüsselung von TeslaCrypt 2 bis zur Version 2.2.0 zu brechen. Im April 2016 wurde zeitweilig die Verschlüsselung des Erpressungstrojaners Petya (Version bis Dezember 2016) geknackt. Die Software \"hack-petya\" erzeugte einen Schlüssel, mit welchem die Daten wieder entschlüsselt werden konnten.\n\n"}
{"id": "1648879", "url": "https://de.wikipedia.org/wiki?curid=1648879", "title": "Seitenkanalattacke", "text": "Seitenkanalattacke\n\nDie von dem amerikanischen Kryptologen Paul C. Kocher 1996 bekannt gemachte Seitenkanalattacke (, sinnhaft übersetzt, aber unüblich: \"Nebenkanal-Angriff\"), auch Seitenkanalangriff, bezeichnet eine kryptoanalytische Methode, die die physische Implementierung eines Kryptosystems in einem Gerät (z. B. einer Chipkarte, eines Security-Tokens oder eines Hardware-Sicherheitsmoduls) oder in einer Software ausnutzt. Dabei wird nicht das kryptographische Verfahren selbst, sondern nur eine bestimmte Implementierung angegriffen, d. h. andere Implementierungen können von dem Angriff unberührt bleiben.\n\nDas Prinzip beruht darauf, ein kryptographisches Gerät bei der Ausführung der kryptologischen Algorithmen zu beobachten und Korrelationen zwischen den beobachteten Daten und dem verwendeten Schlüssel zu finden. Diese charakteristische Information kann durch die Analyse der Laufzeit des Algorithmus, des Energieverbrauchs des Prozessors während der Berechnungen oder der elektromagnetischen Ausstrahlung gewonnen werden. Aktive, invasive Angriffe bestehen darin, in das Gerät einzugreifen und Fehler bei der Ausführung des kryptologischen Algorithmus einzubringen. Um dies zu verhindern, ist eine Seitenkanalanalyse daher Bestandteil der Schwachstellenanalyse in der Common-Criteria-Zertifizierung von Chipkarten und ähnlichen Geräten.\n\nDie von Paul Kocher 1996 entdeckten \"Timing Attacks\" messen die Rechenzeit des implementierten kryptographischen Verfahrens für verschiedene (in der Regel vom Angreifer gewählte) Eingaben. Kryptosysteme benötigen leicht unterschiedliche Ausführzeiten, um unterschiedliche Eingaben zu verarbeiten. Diese Charakteristiken bei der Performance sind sowohl vom Schlüssel als auch von den Eingabedaten (Klar- oder Chiffretexte) abhängig. Durch die Laufzeitanalyse kann der Schlüssel nach und nach rekonstruiert werden.\n\nTiming Attacks sind sowohl gegen Chipkarten als auch gegen Software-Implementierungen veröffentlicht worden.\n\nWenn sich Prozesse auf einem Rechner Speicherbereiche teilen, können sie aus der Nutzung des Speichers durch den anderen Prozess auf die durchgeführten Operationen schließen. Ein entsprechender Angriff gegen OpenSSL nutzte die gemeinsame Nutzung des Level-1-Cache beim Hyper-Threading des Pentium 4 aus.\n\nSimple Power Analysis ist eine Methode, bei der der Energieverbrauch eines Mikroprozessors während kryptographischer Berechnungen direkt aufgezeichnet wird. Der Energieverbrauch variiert abhängig von den jeweils ausgeführten Mikroprozessorbefehlen. Er gibt somit Aufschluss über die ausgeführten Operationen sowie über den Schlüssel.\n\nEine Spur ist eine Menge von Energieverbrauchsmessungen, die von einer kryptologischen Operation erhalten wurden. Der Vergleich von Spuren entdeckt Muster wie etwa DES-Runden oder RSA-Operationen. Unterschiede in den Spuren liefern Rückschlüsse auf den Schlüssel.\n\nDifferential Power Analysis vergleicht Spuren, indem sie zusätzlich zur SPA-Technik statistische Methoden einsetzt.\n\nEin Bug-Angriff nutzt fehlerhaft implementierte Funktionen in Mikroprozessoren aus (etwa Pentium-FDIV-Bug).\n\nDie von einem Rechner oder Gerät bei Berechnungen erzeugten elektromagnetischen Felder lassen sich oft noch in einiger Entfernung messen und erlauben ebenfalls Rückschlüsse auf die durchgeführten Operationen. Diese Angriffe sind als Van-Eck-Phreaking oder \"TEMPEST\" bekannt.\n\nEine Analyse der Betriebsgeräusche eines Computers, mithilfe günstiger Mikrophone, kann zur Extraktion von RSA-Schlüsseln verwendet werden.\nNadeldrucker erzeugen Geräusche, die Rückschlüsse auf die gedruckten Zeichen zulassen. Nach einer Lernphase und Kenntnis des Kontexts ist eine Texterkennung besser als 70 % erreichbar.\n\nManche kryptographische Implementierungen reagieren auf falsche Eingaben unterschiedlich, abhängig davon, an welcher Stelle der Verarbeitung ein Fehler auftritt. Die Art der Reaktionen liefert einem Angreifer daher bereits Informationen über den verwendeten geheimen Schlüssel. Ein solcher Angriff wurde z. B. gegen weit verbreitete Implementierungen von SSL veröffentlicht.\n\nGlitch-Attack ist eine Methode, um einen Kryptoprozessor zu kompromittieren, indem man die Ausführung von Maschinenbefehlen unterbricht. Der Angreifer beobachtet die bei der Programmausführung abgegebenen Signale. Genau in dem Augenblick, in dem eine Vergleich- oder Sprunganweisung ausgeführt wird, fügt er eine Störung zu, die die Befehlsausführung blockiert. Auf diese Weise könnte man z. B. eine kritische Authentifizierungsroutine umgehen. Auf diesem Wege wurde bei der Xbox 360 der Bootloader „ausgetrickst“.\n\nDifferential Fault Analysis ist eine Methode, eine kryptographische Einheit zu untersuchen, indem man ihr Fehler zufügt. Das wird meistens durch Veränderung der Spannung, Manipulation der Systemuhr oder Strahlung erzeugt. Der Eingriff kann zu vier Ergebnissen führen: kein Effekt, falsche Resultate, was ausgenutzt werden kann, keine Antwort, physikalische Zerstörung.\nBei diesem Angriff wird derselbe Klartext, der unbekannt sein kann, zweimal verschlüsselt: einmal unter regulären Bedingungen und einmal unter Testbedingungen. Die beiden Chiffretexte werden dann verglichen. Bitdifferenzen liefern Rückschlüsse auf z. B. das RSA-Signaturschema.\n\nGegenmaßnahmen wirken spezifisch gegen eine oder mehrere Angriffsformen. Dazu zählen:\nLaufzeitglättung durch konstante Codeausführung, (Einfügen von Redundanzen, um Maschinenbefehle datenunabhängig auszuführen, Vermeiden von bedingten Sprüngen), physikalisches Shielding gegen EM-Abstrahlungen, Einfügen von Rauschen (Code Obfuscation, Gatter Obfuscation, Signalrauschen, etc.).\n\n"}
{"id": "1648974", "url": "https://de.wikipedia.org/wiki?curid=1648974", "title": "Gucharmap", "text": "Gucharmap\n\ngucharmap („GNOME Unicode Character Map“) ist ein Unicode-Zeichen-Darstellungsprogramm. Sie greift auf das GTK+ Toolkit zurück, und läuft auf jeder Plattform, welche GTK unterstützt. Die Zeichen von gucharmap können in viele andere Programme eingefügt werden, wenn dort (Sonder)Zeichen benötigt werden, die nicht über die Tastatur verfügbar sind. gucharmap enthält alle Unicodezeichen und somit die Zeichen fast aller Schriftsysteme. Seit Gnome 2.4 ist sie in GNOME enthalten.\n\ngucharmap ordnet die Zeichen nach Unicode-Gruppen und bietet eine Volltextsuche für die Zeichendetails an. Ab Version 1.8 enthält es Unterstützung von Unicode 5.0.\n\nMit der Version 8.0 wurde das Versionierungsschema geändert. Entsprach die Versionsnummer vorher der entsprechenden Version von GNOME, änderte sich mit GNOME 3.20 dieses Schema. Fortan entspricht die Versionsnummer von gucharmap der aktuellen Version von Unicode.\n\nUm die entsprechenden Zeichen in gucharmap grafisch darstellen zu können, müssen unter Linux die entsprechenden ttf-Pakete installiert sein.\n\n"}
{"id": "1652577", "url": "https://de.wikipedia.org/wiki?curid=1652577", "title": "Heartbeat (Informatik)", "text": "Heartbeat (Informatik)\n\nEin Heartbeat (engl. für \"„Herzschlag“\") ist eine Netzwerkverbindung zwischen zwei (oder mehr) Rechnern in einem Cluster, um sich gegenseitig darüber zu benachrichtigen, dass sie betriebsbereit sind und ihre Aufgaben noch erfüllen können, also „am Leben“ sind. Im Umfeld von Netzwerkprotokollen, wie z. B. HSRP oder OSPF, beschreiben \"keepalive\" und \"hello\"-Nachrichten diese Funktion.\n\nWenn die Benachrichtigungen eines anderen Rechners ausbleiben, geht ein Programm auf dem „überlebenden“ Rechner davon aus, dass dieser Partner-Pendant nicht mehr verfügbar ist (z. B. durch einen Defekt oder einen Programmfehler) und dass es dafür sorgen soll, dass diese Aufgaben von einem noch funktionierenden Rechner übernommen werden.\n\nEr findet auf Netzzugangsschicht, meist über Nullmodem-Kabel, Ethernet oder Fibre Channel, statt.\n\nAußerhalb der Clustertechnik wurde der Begriff auch für eine zur Fehleranalyse verwendete Funktion bei der Ethernet-Verkabelung über Yellowcable (10 Mbit/s) verwendet. Der Heartbeat konnte für jeden Transceiver ein- oder ausgeschaltet werden.\n\nSplit Brain ist eine Situation, wenn die Heartbeat-Verbindung zwischen den Rechnern (etwa via Ethernet oder serieller Schnittstelle) unterbrochen wird und nicht innerhalb der benötigen Zeit wieder zustande kommt. Obwohl die Rechner jeder für sich einwandfrei funktionieren, müssen die Kontrollprogramme auf diesen Rechnern davon ausgehen, dass der jeweils andere ausgefallen ist.\n\nDanach weiß kein Knoten, welche Rolle er aktuell spielen soll und macht sich automatisch selbst zum Primärknoten. Dies führt bei Aktiv-/Passiv-Konfigurationen zum Ausfall des Clusters, der angebotenen Dienste und kann beim Einsatz eines gemeinsam genutzten Datenspeichers (Storage Backends wie zum Beispiel DRBD) dazu führen, dass beide Systeme versuchen, gleichzeitig auf denselben Speicher zu schreiben.\n\nWenn zwei oder mehr Rechner dasselbe Betriebsmittel benötigen, um eine Aufgabe zu erfüllen, zum Beispiel eine Netzwerk-Adresse, MAC-Adresse oder ein Dateisystem, besteht unter Umständen die Notwendigkeit sicherzustellen, dass dieses Betriebsmittel nie von mehr als einem Rechner gleichzeitig benutzt wird. In der englischsprachigen Literatur ist hierfür der Begriff \"Node Fencing\" gebräuchlich, was so viel bedeutet wie \"Rechner-Abzäunung\".\n\nSTONITH ist eine Möglichkeit dieses Ausschlusses. Wenn beide Rechner an ein STONITH-Gerät angebunden sind (in der Regel über eine serielle Schnittstelle), kann ein Rechner in einer \"Splitbrain\"-Situation den gegenüberliegenden Rechner abschalten. Es gibt zwei Arten, das STONITH-Prinzip einzusetzen: Auf Applikations- oder Hardware-Ebene. Letzteres hat den Vorteil, dass es nicht auf eine Software (zum Beispiel einen SSH-Daemon) angewiesen ist. Um die Auswirkung von Hardware-Ausfällen zu minimieren sind \"Heartbeat\"-Netze häufig mit redundanten Switches aufgebaut und jedes beteiligte System mit zwei oder mehr Netzwerkkarten angebunden.\n\nDie Benennung der bis dahin massivsten Sicherheitslücke im Internet beruhte auf einem Wortspiel. Da diese Sicherheitslücke, von der Anfang 2014 zwei Drittel aller Websites weltweiten betroffen waren, zu einem Herausfließen -also im übertragenen Sinn Herausbluten- von vitalen Nutzerdaten während der Heartbeat-Funktionalität führt, etablierte sich der Begriff \"heartbleed bug\".\n\n\n"}
{"id": "1661063", "url": "https://de.wikipedia.org/wiki?curid=1661063", "title": "Hacker (Computersicherheit)", "text": "Hacker (Computersicherheit)\n\nHacker aus dem Bereich der Computersicherheit beschäftigen sich mit Sicherheitsmechanismen und deren Schwachstellen. Während der Begriff auch diejenigen beinhaltet, die Sicherheitslücken suchen, um sie aufzuzeigen oder zu korrigieren, wird er von den Massenmedien und in der allgemeinen Öffentlichkeit häufiger für Personen benutzt, die unerlaubt in fremden Systemen solche Lücken ausnutzen. Entsprechend ist der Begriff stark positiv beziehungsweise negativ belegt, wobei \"Hacker\" abgrenzbar von \"Scriptkiddie\" ist: Ein Hacker besitzt tiefe Grundlagenkenntnisse, ein Scriptkiddie nicht.\n\nAbhängig von der Motivation und Loyalität zu den Gesetzen, wird unterschieden zwischen White-Hat-, Grey-Hat- und Black-Hat-Hackern, wobei insbesondere Black-Hats und Scriptkiddies auch als Cracker bezeichnet werden.\n\nNachdem eine Gruppe jugendlicher Hacker, bekannt als The 414s, 1983 in zahlreiche Computersysteme der Vereinigten Staaten eindrang, forderte der Kongressabgeordnete Dan Glickman eine Untersuchung und neue Gesetze gegen das Hacken. Neal Patrick, der damals 17-jährige Sprecher der Hackergruppe, wurde am 26. September 1983 vor dem Repräsentantenhaus der Vereinigten Staaten über die Gefahren des Hackens befragt, und noch im gleichen Jahr wurden sechs Gesetzesentwürfe zur Computerkriminalität in das Repräsentantenhaus eingebracht. In Deutschland wurde im August 1986 Computersabotage im Allgemeinen, und die unbefugte Manipulation von Daten im Besonderen, als spezielle Form der Sachbeschädigung in das Strafgesetzbuch aufgenommen (, und des StGB).\n\nNach der Einführung der Gesetze zur Computerkriminalität begannen sich \"White-Hat-\", \"Grey-Hat-\" und \"Black-Hat-\"Hacker voneinander abzugrenzen, abhängig von der Gesetzmäßigkeit ihrer Tätigkeiten:\n\n\nMangels klarer Trennlinie zwischen \"gut\" und \"böse\" nimmt diese Unterteilung in der Praxis wenig Bezug auf real existierende Personen und steht vielmehr als Begrifflichkeit für eine bestimmte Art des Hackens.\n\nAls Reaktion auf schlechte Presse vertritt das Jargon File seit 1990 den Standpunkt, dass der Begriff \"Hacker\" für die Personengruppen, die ihre Aktivitäten betont auf die Umgehung von Sicherheitsmechanismen legen, \"ungeachtet ihrer Motivation\" zu missbilligen ist und schlägt stattdessen Cracker vor. Die Forderung, ein anderes Wort zu verwenden, wurde jedoch von der Presse nicht wahrgenommen oder weitestgehend ignoriert.\n\nHacker aus dem Bereich der Computersicherheit, insbesondere der Teil, der sich als gesetzestreu versteht, erheben weiterhin einen Mitverwendungsanspruch auf den Hackerbegriff und akzeptieren die Bezeichnung als Cracker nur für die dunkler gefärbten Richtungen. Auch von ihnen wird mitunter eine deutliche Abgrenzung zwischen Hacker und Cracker gefordert. Ein Teil derart abgegrenzter Cracker möchte sich jedoch ebenfalls als Hacker bezeichnet wissen.\n\nDaneben zählen Scriptkiddies innerhalb der Computersicherheit zu den Crackern. Sie nutzen vorgefertigte Automatismen, um (meist unter schriftlicher Anleitung) in fremde Computersysteme einzudringen oder sonstigen Schaden anzurichten. Obgleich ihnen die beim Hackerbegriff notwendige tiefe Grundlagenkenntnis der Materie fehlt, werden Scriptkiddies innerhalb des Boulevardjournalismus gewöhnlich als \"Hacker\" betitelt.\n\n\nChronisten der Hackerkultur gehen bei ihrer Suche nach dem Ursprung teilweise zurück bis in die Antike. Die griechische Erfindung des trojanischen Pferdes gilt manchen als erster Hack überhaupt. Operatoren der Telegrafen- (seit Mitte der 1840er) und Telefonnetze (seit Ende der 1870er), die häufig ebensolche Technikenthusiasten waren, wie die Hacker heute, nutzten ihr Wissen, um das Netz für ihre eigenen Zwecke zu verwenden. Sie gelten als Vorläufer der heutigen Hacker. Einer der berühmtesten unter ihnen war der Erfinder Thomas A. Edison. Die entsprechende Verwendung des Wortes Hacker ist eng mit der Geschichte des Computers verbunden, wobei Hacker aus dem Bereich der Netzwerk- und Computersicherheit aus der Subkultur des Phreaking hervorgegangen sind:\n\n1971 veröffentlicht der Yippie Abbie Hoffman in seinem Buch \"Steal This Book\" und einem Rundbrief namens \"Youth International Party Line\" Methoden, um die Gebührenzahlung an Telefongesellschaften zu umgehen. Im selben Jahr erscheint auch ein entsprechender Bericht im Hochglanzmagazin \"Esquire\", sowie ein Jahr später im radikalen Magazin \"Ramparts\". Infolgedessen entsteht die Ära des kostenlosen Telefonierens, das sogenannte \"Phreaking\". Dies stellt die erste markante Assoziation zwischen dem Begriff \"Hacken\" und dem Überwinden von Sicherheitsbarrieren dar, in dessen Zusammenhang oft der Hacker John T. Draper, auch bekannt als \"Captain Crunch\", und Joybubbles erwähnt wird.\n\n1973 sind die beiden späteren Gründer von Apple, Steve Wozniak und Steve Jobs, auch im Phreaking-Umfeld aktiv und bauen zusammen mit John T. Draper Blue-Boxes.\n1981 wird der Chaos Computer Club (CCC) gegründet, ein deutscher Verein von und für Hacker, der im deutschen Raum hauptsächlich für die Belange im Bereich Datenschutz, Informationsfreiheit und Datensicherheit tätig ist und für ein Menschenrecht auf Kommunikation eintritt. Er wird gegründet, um Hackern eine Plattform zu geben, so dass sie über Aktivitäten und entdeckte Sicherheitslücken berichten können, ohne Strafverfolgung befürchten zu müssen.\n\n1982 bricht eine Gruppe von sechs Teenagern in etwa 60 Rechnersysteme von Institutionen ein, die sich von Laboratorien aus Los Alamos bis Manhattans Krebszentrum \"Sloan-Kettering\" erstrecken, bevor sie festgenommen werden. Die Hackergruppe nennt sich nach der Vorwahl ihres Ortes Milwaukee \"The 414s\". Sie werden im darauf folgenden Jahr vom FBI gefasst, wodurch der Fall eine große Popularität erlangt. Aufgrund der damaligen Gesetzeslage werden die meisten von ihnen jedoch nicht angeklagt. In der Cover-Story des \"Newsweek\"-Artikels \"Beware: Hackers at play\" vom 5. September 1983 findet sich ihre Geschichte wieder. Das ist die erste Benutzung des Worts \"Hacker\" in überregionalen Medien, die den Begriff in abwertender Weise verwenden.\n\n1983 erscheint der Film \"WarGames – Kriegsspiele\" und führt in der breiten Öffentlichkeit zum Phänomen der Massenparanoia vor Hackern und ihren mutmaßlichen Fähigkeiten, durch Hacken eine nukleare Katastrophe herbeiführen zu können. Gleichzeitig erhält der Geheimdienst Secret Service eine Abteilung für Kreditkarten- und Computerbetrug.\n\n1984 startet der erste alljährliche Chaos Communication Congress, die älteste und größte internationale Hackerkonferenz in Europa. Im selben Jahr stellt der CCC mit dem BTX-Hack eine Schwachstelle im bislang als sicher titulierten BTX-System der Bundespost unter Beweis. Ebenfalls 1984 gründet jemand, der sich \"Lex Luthor\" nennt, eine Hackergruppe namens \"Legion of Doom\" (LoD/H), die später eine der bekanntesten Hackergruppen wird und sich mit einer konkurrierenden Gruppe \"Masters of Deception\" einen erbitterten Kampf liefert. In den frühen 1990er Jahren werden beide Hackergruppen in Zusammenarbeit zwischen dem Secret Service und dem FBI zerschlagen, wobei viele ihrer Mitglieder verhaftet werden.\n\n1985 wird Loyd Blankenship (ein bekannter US-amerikanischer Hacker, der sich selbst \"The Mentor\" nennt) verhaftet, woraufhin er ein noch heute oft zitiertes Schreiben mit dem Titel \"Hacker’s Manifesto\" veröffentlicht. Es verschafft einen groben Einblick in die Gefühlswelt eines damaligen Hackers der Phreaking-Kultur. Im selben Jahr beginnt eine Hannoversche Hackergruppe um Karl Koch und Markus Hess mit einer Reihe von Einbrüchen in verschiedene westliche Computersysteme, um die Daten an den russischen Geheimdienst (KGB) zu verkaufen. Die Hacks werden unter anderem durch einen Bug in der Emacs-Komponente \"movemail\" möglich. Erst im März 1989 gelingt es der Polizei und dem Bundesnachrichtendienst die Hackergruppe endgültig zu zerschlagen, wobei der KGB-Hack in der Öffentlichkeit auf sich aufmerksam macht, da er den ersten bekannten Cyberspionagefall darstellt.\n\n1987 wird die Organisation \"Computer Emergency Response Team\" (CERT) gegründet, die sich durch öffentliche Mittel finanziert und möglichst zeitnah Warnungen vor Sicherheitslücken herausgibt. Im selben Jahr gelingt es norddeutschen Hackern, Zugriff auf die Systeme im von NASA und ESA betriebenen SPANet zu erhalten, was später als NASA-Hack bezeichnet wird.\n\n1988 schreibt Robert Tappan Morris aus Neugierde ein Programm, welches auf dem UNIX-System automatisiert nach bekannten Schwachstellen sucht. Es ist in der Lage, diese Schwachstellen zu gebrauchen, um sich auf andere Systeme zu kopieren und dort auszuführen. Als sein Versuch außer Kontrolle geriet, sieht sich die Computerwelt mit dem ersten Wurm konfrontiert, der sich über das ARPAnet (dem Vorgänger zum Internet) verbreitet und dank seiner permanent arbeitenden Verbreitungsroutine über 6.000 vernetzte Computer der Regierung und Universitäten blockiert. Über ein unzureichend gesichertes Computersystem gelingt es im selben Jahr erstmals einem Eindringling, die First National Bank von Chicago um 70 Millionen US$ zu erleichtern. Wenig später wird der Hacker Kevin Mitnick, alias \"condor\", verhaftet, weil er die E-Mail von Sicherheitsmitarbeitern des \"MCI Communications\" und \"Digital Equipment Corporation\" (DEC) insgeheim überwachte. Acht Monate in Einzelhaft und weitere sechs Monate im \"Half Way House\" sind die Folge seiner Tat. Danach soll er, größtenteils mit Hilfe von Social Engineering, mehrfach in das Netzwerk des Pentagon eingedrungen sein. Auch legt man ihm den Einbruch in das System der NSA und das Eindringen in das NORAD-Netzwerk zur Last, wobei er selbst vor allem Letzteres immer bestritten hat. Mehr als fünf Jahre lang gilt er als die meistgesuchte Person in den USA, bis er 1995 erneut vom FBI verhaftet und zunächst zwei Jahre ohne Gerichtsverhandlung gefangen gehalten wird. Ebenfalls im Jahr 1988 wird Kevin Poulsen beschuldigt, Telefonanlagen manipuliert zu haben. Zu einer erfolgreichen Anklage kommt es jedoch erst 1993, in der ihm und zwei seiner Freunde, Ronald Austin und Justin Peterson, vorgeworfen wird, zwischen 1990 und 1993 zahlreiche Radiogewinnspiele manipuliert zu haben. Das Trio erlangte Kontrolle über alle Telefonleitungen der Radiostation und stellte damit sicher, dass ausschließlich ihre eigenen Anrufe durchkamen, wodurch sie zwei Porsche, 20 000 US$ und einige Reisen gewannen. Kevin Poulsen verbringt daraufhin fünf Jahre seines Lebens im Gefängnis.\n\n1990–1999 Das Aufkommen von Würmern und Viren nimmt in dieser Zeit rapide zu. 1993 startet die erste DEF CON, eine alljährliche Hackerkonferenz, in Las Vegas. Mitte der 1990er Jahre berichtet der US-amerikanische Bundesrechnungshof, dass im Schnitt 250 000 Mal im Jahr Hacker versuchen, auf Dateien des Verteidigungsministeriums zuzugreifen. Nach deren Bericht sind etwa 65 Prozent der Versuche erfolgreich. 1997 dringt ein 15 Jahre alter kroatischer Jugendlicher in die Computer einer Luftwaffenbasis in Guam, USA, ein. Eine Gruppe von Hackern um \"Natasha Grigori\", Gründerin von antichildporn.org, nutzen erstmals in der Hackergeschichte ihre Fertigkeiten, um die Verteiler von Kinderpornografie gezielt zu verfolgen und ihre Informationen an die Hüter der Gesetze weiterzugeben. 1998 werden zwei Hacker von einem Gericht in China zum Tode verurteilt. Ende der 1990er Jahre gibt es die ersten organisierten, politisch motivierten Hackerattacken in den USA.\n\n2000–2005 Anfang 2000 werden DDoS-Attacken populär, eine Variante von DoS, welche automatisiert von mehreren Rechnern gleichzeitig ausgeführt wird. Politisch motivierte Hacker verunstalten Webseiten der indischen und israelischen Regierungen, um auf die Unterdrückung in Kaschmir und Palästina aufmerksam zu machen. Permanenten Hackerattacken ausgesetzt, unterbricht Microsoft seine Entwicklung und schickt erstmals über 8 000 Programmierer zu einer Schulung, die dazu dienen soll, programmiertechnische Schwachstellen künftig zu vermeiden.\n\n2015–2016 Die Verbreitung von IOT-Geräten eröffnet Angreifern die Möglichkeit Bot-Netzwerke in noch nie dagewesener Größe zu schaffen. Aufgrund mangelnder oder fehlender Sicherheitsmechanismen können IOT-Geräte (u. a. IP-Kameras, SmartHome-Geräte, ...) teilweise vollautomatisch angegriffen und mit Schadware infiziert werden. Diese Geräte sind im Gegensatz zu PCs – den üblichen Opfern von Schadware – meist unbeaufsichtigt von Nutzern, wodurch das Fehlverhalten der Geräte selten erkannt wird. Diese verteilten Bot-Netzwerke eignen sich hervorragend für DDoS-Attacken. Dieser Methodik folgte auch die Attacke auf das Netzwerk von Dyn.\n\nZum Informationsaustausch unter Hackern wurden seit den 1980ern eine Reihe von Untergrund-Magazinen gegründet. Beispiele sind das \"2600 magazine\" und das inzwischen nur noch unregelmäßig veröffentlichte \"Phrack\". Diese Entwicklung wurde von den Phreaks der frühen 1970er Jahre angeschoben, die in illegalen Untergrund-Magazinen wie der \"TAP\" ihre Informationen weitergaben.\n\nEs gibt jedoch auch Magazine, die völlig legal sind. Ein bekanntes deutschsprachiges Magazin ist die vom Chaos Computer Club unregelmäßig herausgegebene Datenschleuder.\n\n\n\n"}
{"id": "1664520", "url": "https://de.wikipedia.org/wiki?curid=1664520", "title": "Osmosis Jones", "text": "Osmosis Jones\n\nOsmosis Jones ist eine Filmkomödie, die größtenteils aus animierten Szenen besteht und durch vereinzelte reale Filmszenen unterbrochen wird. Diese gehören ebenfalls zur Handlung.\n\nDer ungesund lebende Zoowärter Frank steckt sich bei der Arbeit mit einem gefährlichen Virus an. Dieses gelangt über ein Ei, das kurze Zeit auf dem Boden lag, in Franks Körper. Sofort beginnen die Speichelschiffe in seinem Mund damit, das Ei zu beseitigen, doch das Virus bleibt unbemerkt.\n\nDer computeranimierte Filmheld Osmosis Jones macht sich zunächst zum Gespött aller weißen Blutkörperchen, da er eine übliche Keimbakterie nicht unschädlich machen kann.\n\nDer Chef des Dezernates ist sauer, gewährt ihm allerdings die Aufgabe, sich um Franks mittlerweile angeschwollenen Hals zu kümmern. Als Unterstützung kommt die Erkältungstablette DRIX ins Spiel.\n\nAlles scheint beseitigt, und DRIX möchte sich über die Blase wieder aus Franks Körper entfernen, jedoch ist das Virus, Thrax, immer noch im Körper. Mit den Gehilfen aus den Achselschweißdrüsen plant er sein Vorhaben und möchte Frank in der Rekordzeit von 48 Stunden töten.\n\nFranks Tochter ist auf einem Schulausflug, als dieser von der Attacke überwältigt wird und ins Krankenhaus kommt. Das hohe Fieber wird zur Lebensgefahr.\n\nThrax offenbart seinen Plan, nach Frank auch dessen Tochter umzubringen, in noch kürzerer Rekordzeit.\n\nDoch gelingt es Osmosis Jones, das Virus in einem Glas mit reinem Alkohol unschädlich zu machen und schließlich wieder in Franks Körper zurückzugelangen.\n\nSchließlich wird Osmosis als Held gefeiert und Frank hat aus dem Vorfall gelernt, stellt seine Ernährung um und unternimmt mehr sportliche Aktivitäten mit seiner Tochter.\n\nThrax (La muerte roja): Dieses Virus wird als eines der Schlimmsten beschrieben: Es tötete einen alten Mann in nur drei Tagen, und sein größter Wunsch ist es nun, in einem medizinischen Buch verewigt zu werden. Daher will er Frank auch in einer Rekordzeit von nur zwei Tagen töten. \"La muerte roja\" bedeutet \"Der rote Tod\".\n\nLexikon des Internationalen Films: \"Bei weitem nicht so originell und witzig wie manch liebevoll ausgemalte Details ist die eigentliche Story des Films – eine schlichte Parodie auf Cop- und \"Buddy\"-Movies. Insgesamt jedoch eine lustige Mischung aus Realfilm und fantasievoller Animation mit leichten satirischen Seitenhieben auf das moderne Leben, überzeugend gespielt.\"\n\n\n"}
{"id": "1675016", "url": "https://de.wikipedia.org/wiki?curid=1675016", "title": "Protowall", "text": "Protowall\n\nProtowall ist ein sogenannter „IP-Blocker“, eine Software, die gezielt den Kontakt des eigenen PCs mit IP-Adressen von unerwünschten Unternehmen, Behörden oder sonstigen Einrichtungen verhindert.\n\n\"Protowall\" richtet im System einen Netzwerktreiber ein, mit welchem es der Software möglich ist, an erster Stelle ein- und abgehende Datenpakete zu kontrollieren. Mit Hilfe einer bereitliegenden schwarzen Liste kann \"Protowall\" nun entscheiden, ob der Rechner einem eingehenden Datenpaket antwortet oder ein ausgehendes passieren lässt. Stößt \"Protowall\" dabei auf ein Datenpaket, das an eine der gelisteten IP-Adressen adressiert ist bzw. von dieser stammt, wird das betreffende Paket abgefangen. Eine Kommunikation zwischen eigenem Rechner und einem unerwünschten Unternehmen wird somit unterbunden.\n\n\"Protowall\" ist in der Lage folgende Netzwerkprotokolle zu beobachten:\n\nIP, ICMP, TCP, UDP, HOPOPTS, IGMP, GGP, IPV4, ST, EGP, PIGP, RCCMON, NVPII, PUP, ARGUS,\nEMCON, CHAOS, MUX, MEAS, HMP, PRM, IDP, TRUNK1, TRUNK2, LEAF1, LEAF2, RDP, IRTP, TP,\nBLT, NSP, INP, SEP, 3PC, IDPR, XTP, DDP, CMTP, TPXX, IL, IPV6, SDRP, ROUTING, FRAGMENT,\nIDRP, RSVP, GRE, MHRP, BHA, ESP, AH, INLSP, SWIPE, NHRP, MOBILE, TLSP, SKIP, ICMPV6, NONE\n, DSTOPTS, AHIP, CFTP, HELLO, SATEXPAK, KRYPTOLAN, RVD, IPPC, ADFS, SATMON, VISA, IPCV,\nCPNX, CPHB, WSN, PVP, BRSATMON, ND, WBMON, WBEXPAK, EON, VMTP, SVMTP, VINES, TTP, IGP, DGP,\nTCF, IGRP, OSPFIGP, SRPC, LARP, MTP, AX.25, IPEIP, MICP, SCCSP, ETHERIP, ENCAP, APES, GMTP, IPCOMP, PIM, PGM.\n\nIm Internet gibt es zahlreiche Unternehmen und Einrichtungen, welche Internetbenutzer ausspionieren. Angefangen mit dem Beobachten der Vorlieben eines Benutzers – um ihn z. B. gezielt mit Werbung bedienen zu können – über das Erstellen von Statistiken bis hin zur Kontrolle auf illegale Aktivitäten (Stichwort: RIAA und MPAA) reicht die Palette. Um dies im großen Stil bewerkstelligen zu können, werden Standleitungen benötigt, die über große Bandbreiten verfügen und eine statische IP-Adresse besitzen. Dank dieser Tatsache ist es möglich, per Whois-Abfrage Listen über besagte Unternehmen zu führen und diese mit Hilfe eines \"IP-Blockers\" oder einer Firewall vom eigenen Rechner fernzuhalten. Firewalls sind jedoch meist nicht dafür konzipiert, große Listen an IP-Adressen zu verarbeiten, so dass es hier oftmals zu starker Systemauslastung oder gar einem Absturz kommt (wobei der Rechner im ungünstigsten Fall ungeschützt zurückgelassen wird). \"IP-Blocker\" hingegen haben nur die Aufgabe, \"IPs\" zu blockieren, und können dies mit einer meist kaum messbaren Systemauslastung bewerkstelligen.\n\nDer Einsatz eines \"IP-Blockers\" wie \"Protowall\" ist als provisorische Sicherheitsmaßnahme zu bezeichnen. Zum einen ist es kaum möglich, sämtliche IP-Adressen von Unternehmen ausfindig zu machen, und zum anderen können diese auch ebenso leicht auf dynamische IP-Adressen zurückgreifen.\n\nHinter \"Protowall\" steht eine Internetgemeinschaft namens \"Bluetack Security Solutions\". Diese Gemeinschaft besteht zum Teil aus Programmierern wie \"DudeZ\" (Hauptprogrammierer von \"Protowall\") sowie aus einer Reihe Freiwilliger, die IP-Adressen von Unternehmen ausspähen. \"Bluetack\" führt unter anderem eine Reihe von schwarzen Listen, welche in Kategorien unterteilt sind (z. B. Werbung, Universitäten, Regierungseinrichtungen, Anti-Piraterie-Organisationen usw.). \"Bluetack\" hat keinen kommerziellen Hintergrund und finanziert sich durch Spenden.\n\nWie \"Protowall\" ist \"Blocklist Manager\" eine weitere Software von \"Bluetack\". Sie dient zum Verarbeiten von IP-Listen und ist unter anderem in der Lage, Listen direkt vom Bluetack-Internetportal herunterzuladen und in unzählige Formate (für verschiedene Programme) zu konvertieren. Ferner werden noch andere Bearbeitungsmöglichkeiten geboten. \"Bluetack\" rät dazu, \"Protowall\" und \"Blocklist Manager\" kombiniert zu verwenden, um gewährleisten zu können, dass die IP-Listen stets aktuell sind.\n\n"}
{"id": "1675178", "url": "https://de.wikipedia.org/wiki?curid=1675178", "title": "Vixie cron", "text": "Vixie cron\n\nVixie cron ist ein cron-Daemon, geschrieben 1987 von Paul Vixie.\n\nVersion 3 des Vixie cron wurde Ende 1993 veröffentlicht. Diese Version wird, mit ein paar kleineren Bugfixes, in den meisten Linux- und BSD-Distributionen für cron und crontab verwendet.\n\n"}
{"id": "1680003", "url": "https://de.wikipedia.org/wiki?curid=1680003", "title": "MCS Alpha 1", "text": "MCS Alpha 1\n\nDer ALPHA-1 des Berliner Unternehmens MCS (\"Micronic Computer Systeme GmbH\") ist ein früher Homecomputer, der 1977 auf den Markt kam. Er ist stark vom Design des KIM-1 inspiriert, wurde aber deutlich verbessert und \nerweitert. Im Gegensatz zu damals erhältlichen Systemen war der Alpha sofort nach dem \nAuspacken betriebsbereit.\n\nDer ALPHA-1 wurde in drei Ausführungen angeboten: Typ 1 im Alugehäuse mit aufgesetzter CPU-Karte, Typ 2 im Alugehäuse mit eingebauter CPU-Karte, Typ 3 wie Typ 1 im futuristischen Plexiglas-Gehäuse. Der Typ 1 wurde auch als Bausatz angeboten.\n\nZum Lieferumfang gehörte eine umfangreiche Dokumentation (Handbuch mit Schaltplänen und kommentiertem Monitor-Listing), die MOS-Bücher \"Programmier Handbuch\" und \"Hardware Handbuch\" in deutsch sowie Datenblätter von MOS Technologies zum Prozessor 6502 und den I/O-Bausteinen 6532 sowie (informativ) zum 6520, der nicht eingebaut war.\n\nDie herausragenden Merkmale waren Alu-Gehäuse, eingebautes Netzteil und DIN-Buchsen für zwei Kassettenrekorder, 25-polige Anschlussbuchse für Terminal, Drucker und Lochstreifenleser und -stanzer, 20-poliger DIL-Stecker für den freien Ports des 6532 und CPU-Karte im Europakartenformat mit 6502 und 1 Kilobyte RAM. Sämtliche ICs waren gesockelt. Ein Umschalter diente für die Betriebsarten \"Keyboard\" und \"Terminal\", ein weiterer beeinflusste den Programmablauf: In der Mittelstellung liefen Programme in Echtzeit, ebenso war ein Einzelschrittmodus vorgesehen oder ein timergesteuerter \"Slow Step Modus\". Als große Erleichterung ist der eingebaute \"Disassembler\" zu sehen, der die 6502-Mnemonics auf der 7-Segment-Anzeige als Klartext anzeigen konnte. Nach drücken der MN-Taste zeigte das Display beispielsweise statt \"A9\" dann \"STA\" an.\nSoftware: Der Maschinensprachemonitor (MONA= MONitor Alpha) ist in einem 2 Kilobyte großen EPROM von Texas Instruments eingebaut (TMS 2716), welches sich noch den Luxus von drei Betriebsspannungen erlaubt. \n\nNeben den üblichen Funktionen sind der eingebaute Disassembler zu erwähnen, der mit den Einschränkungen des \"7-Segment-Alphabets\" leben muss (Buchstaben wie \"K\" oder \"X\" sind nicht darstellbar). Dieser Nachteil wird bei Benutzung eines Video-Terminals aufgehoben. Das Betriebssystem MONA wurde im Typ 1 und 3 mit einer Digitaluhr-Routine geliefert, um \neinen schnellen Erfolg in der Bedienung des Alpha zu zeigen. In drei Adressen auf der \"Zeropage\" wurden Stunde, Minute und Sekunde eingegeben, eine weitere Adresse diente als Steuerregister und nach Start des Monitorprogramms an Stelle FFB2 hatte man eine sechsstellige Digitaluhr. Im Alpha Typ 2 war stattdessen eine Autobaud-Routine eingebaut.\n\nAuf der mitgelieferten Programmkassette waren drei fertige Programme gespeichert: hinter \"Einarmiger Bandit\" und \"Bauer Brösel\" verbargen sich die angepassten Programme \"Farmer Brown\" und \"Bandit\" von Jim Butterfield aus dem \"First Book of KIM-1\". Ebenfalls war ein Programm enthalten, um Speicherblöcke (Programme) zu verschieben. Weitere Programme konnten extra erworben werden, die sich zum Teil stark an dem \"First Book of KIM\" orientierten: Mondlandung, Schach, Musikbox und Meteoritensturm seien hier genannt. Aber auch Eigenentwicklungen wie Alarmanlage oder \"frei programmierbare \nSteuerung\" waren erhältlich.\n\nMCS hat die CPU-Platine des Alpha als Europaplatine mit 64-poliger VG-Leiste entwickelt, die so auch in einem 19-Zoll-Gehäuse Verwendung finden konnte. Dieses System wurde \"BETA-8\" genannt und konnte umfangreich konfiguriert werden. Als Zusatzkarten standen beispielsweise verschiedene ROM-, RAM- und IO- Karten zur Verfügung. Ein Video-Interface und Floppys mit zugehörigem Controller waren dann weitere Schritte zum Entwicklungssystem. Als Software-Erweiterungen wurden BASIC, ASSEMBLER- Editor, Debugger und Disassembler angeboten. Für die 2 mal acht Bits freien Ports war ein einfacher I/O Adapter mit Schaltern und Leuchtdioden sowie ein aufwändigerer \"I/O-Tester\" erhältlich.\n\n"}
{"id": "1681045", "url": "https://de.wikipedia.org/wiki?curid=1681045", "title": "Chess Query Language", "text": "Chess Query Language\n\nChess Query Language (CQL) ist eine Sprache zur Abfrage von bestimmten Situationen in Schachpartien oder Schachstudien. Die Partien bzw. Studien müssen in der Portable Game Notation vorliegen und werden nach der in CQL zu beschreibenden Situation durchsucht. CQL wird unter anderem zur wissenschaftlichen Auswertung von Schachpartien genutzt.\n\nEin verwandtes Abfragesystem für Schachpositionen ist \"Query by Example\" (QBE). Dabei wird jede Position einer Partie gehasht (meist per Zobrist-Hashing) und in einer Hashtabelle gespeichert. Zur Abfrage einer bestimmten Position wird deren Hash berechnet und die passenden Ergebnisse aus der Datenbank zurückgegeben. Dieser Ansatz ist effizient auch auf sehr große Spielsammlungen anzuwenden.\n\nDer größte Nachteil dieser Methode ist, dass damit nur exakte Treffer gefunden werden können. Selbst minimal andere Stellungen führen zu einem völlig anderen Hashwert und werden per QBE nicht gefunden. CQL umgeht diesen Nachteil, indem eine Näherungssuche möglich gemacht wird. Dazu wird ein boolescher Filter eingesetzt, der die gewünschte Position exakt spezifiziert. Die Abfrage\n\nfindet beispielsweise alle Stellungen mit einem weißen Turm oder einer weißen Dame auf dem Feld b2 und einem schwarzen Läufer auf g8. Dieser Ansatz ist jedoch auch bei nur moderat großen Datenbanken erheblich langsamer als die hashbasierte Suche mit QBE.\n\nEine weitere Einschränkung stellt die boolesche Natur der Abfrage dar: Sie kann nur exakte Treffer zurückgeben, diese aber nicht nach Ähnlichkeit mit einer gewünschten Stellung gewichten.\n\n"}
{"id": "1683702", "url": "https://de.wikipedia.org/wiki?curid=1683702", "title": "Digitale Edition", "text": "Digitale Edition\n\nUnter dem Stichwort Digitale Edition diskutiert die Fachwissenschaft (Computerlinguistik, Editionsphilologie, Historische Fachinformatik), die Auswirkungen der neuen Medien (Computer) auf die kritische Edition von Texten (vergleiche Textkritik) beziehungsweise Dokumenten. Eine der zentralen Fragen ist dabei das Verhältnis zwischen der Textvorlage beziehungsweise dem zu edierenden Dokument und der Digitalisierung zum Beispiel mittels Textcodierung.\n\nDie Diskussion um die Digitale Edition begann in den 1990er Jahren, als die CD-ROM als billiger Datenträger kommerziell verwendet wurde. Die älteren Versuche, den Computer für kritische Editionen zu verwenden, waren häufig am Vorbild der gedruckten Edition orientiert. Dieser Typus ist inzwischen unter der Bezeichnung \"elektronische Edition\" geläufig. Eine Digitale Edition versucht stattdessen, ein informationswissenschaftliches Modell der kritischen Edition zu entwickeln, das zum Beispiel in XML-Formaten realisiert werden kann.\n\n\n"}
{"id": "1683846", "url": "https://de.wikipedia.org/wiki?curid=1683846", "title": "CSpace", "text": "CSpace\n\nCSpace ist ein plattformunabhängiger Instant Messenger, welcher als freie Software unter der GNU General Public License veröffentlicht wird. Die Software arbeitet dezentral unter Verwendung des Kademlia-Protokolls.\n\nDas Programm verwendet standardmäßig eine Verschlüsselung und baut Verbindungen mit Hilfe von OpenSSL auf.\nAlle Benutzer bekommen 2048 Bit RSA-Schlüssel. Ein Benutzer sieht nur den RSA-Schlüssel und den Benutzernamen eines anderen Benutzers, weitere Angaben sind bei der Erstellung eines Profils nicht nötig.\nJeder Nutzer wird unverfälschbar an seinem öffentlichen RSA-Schlüssel erkannt, der private Schlüssel wird nicht weitergegeben.\n\nBei der Anmeldung weist man seinem persönlichen RSA-Schlüssel – der Benutzerfreundlichkeit halber – einen Nickname zu, der zentral verwaltet wird.\n\n\"CSpace\" bietet die Möglichkeit, mit einem Kontakt Screen-Sharing zu betreiben. Es wird dabei das VNC-Protokoll verwendet. Diese Funktion ist beispielsweise interessant, um anderen Personen bei PC-Problemen unter die Arme zu greifen.\n"}
{"id": "1684368", "url": "https://de.wikipedia.org/wiki?curid=1684368", "title": "Mac Pro", "text": "Mac Pro\n\nDer Mac Pro ist ein Workstation-Computer der Firma Apple. Von 2006 bis 2012 hatten die Modelle „Tower“-Gehäuse und waren durch den Benutzer selbst mit RAM-Modulen, Festplatten, PCI-Express-Steckkarten (Grafik, Controller usw.), optischen Laufwerken einfach erweiterbar. Äußerlich waren die aus Aluminium gefertigten Gehäuse mit denen der Vorgänger \"Power Mac G5\" nahezu identisch.\n\nDer Mac Pro wurde erstmals am 7. August 2006 auf Apples WWDC vorgestellt und mit einem oder zwei Intel-Xeon-Prozessoren ausgeliefert. Aufgrund der damals neuen Core-2-basierten Intel-Architektur war der erste Mac Pro laut Apple-Marketing etwa doppelt so schnell wie die vorherige Generation des Power Macs, der auf der PowerPC-Architektur basierte.\n\nAm 8. Januar 2008 wurde eine weitere Revision des Mac Pro mit i5400X-Chipsatz und Xeon-5400-CPUs vorgestellt.\n\nZwei Jahre später, am 9. August 2010, folgte eine Weiterentwicklung mit einem bzw. zwei Intel-Xeon-Prozessoren, die auf der Nehalem- bzw. Westmere-Architektur basieren. Die letzte Aktualisierung des Mac Pros der 1. Generation wurde am 11. Juni 2012 durchgeführt, diese Version besitzt bis zu zwei Intel-Xeon-E5645-Prozessoren.\n\nAb dem 1. März 2013 verkaufte Apple in Europa den Mac Pro vorübergehend nicht mehr, da das Gerät laut Apple die geänderte IEC-Richtlinie 60950-1 nicht erfüllt und für den Verkauf eine Änderung an den Lüftern des Mac Pros nötig wäre.\n\nAm 10. Juni 2013 stellte Apple einen neuen Mac Pro vor. Statt der bisherigen Tower-Form hat das Gerät nun die Form eines deutlich kleineren schwarzen Alu-Zylinders. Die Hardware ist vom Nutzer anders als bisher kaum noch intern erweiterbar. Das neue Gerät ist seit Dezember 2013 erhältlich.\n\nDie nächste Generation des Mac Pro wird für das Jahr 2019 erwartet. Geplant sei es, wieder zu einem modularen System zu wechseln. Apple stellte in einer News-Mitteilung klar, dass der auf der WWDC 2017 vorgestellte iMac Pro keinesfalls die Mac Pro Reihe ersetzen soll.\n\nJeder Mac Pro aus dem Jahr 2006 (Mac Pro 1.1) besitzt mindestens eine 64-Bit Intel Xeon CPU (Vierkernprozessoren, bis zu 3,2 GHz), oder zwei 64-Bit Intel Xeon CPUs (Doppelkernprozessoren, Nehalem 2,26 GHz, 2,66 GHz oder 2,93 GHz mit 8 MB L3-Cache), was zu einer Gesamtkernzahl von vier bzw. acht, bei späteren Modellen sechs bzw. zwölf Kernen führt. Die Taktfrequenz der beiden FSB beträgt bei den Modellen der ersten Generation 1,33 GHz ; jeweils zwei Kerne teilen sich einen gemeinsamen (\"engl.\" ) Level-3-Cache von 4 bzw. 8 MB .\nDas Nachfolgemodell kann bis zu zwei Westemere 6-Kern-Prozessoren mit je 3,06 GHz besitzen.\n\n\nDer Mac Pro setzt \"DDR2-FBDIMM-RAMs\" mit 667 MHz und Fehlerkorrektur (ECC) ein, die dank des Intel-5000X-Chipsatzes je nach Bestückung im Einkanal-, Zweikanal- oder Dreikanalbetrieb genutzt werden. Die standardmäßige Ausstattung des Mac Pro sieht 1 GB RAM vor, die auf den acht vorhandenen Steckplätzen auf bis zu 64 GB (von Apple unterstütztes Limit) erweitert werden können. Je vier der RAM-Steckplätze befinden sich auf einer der zwei sogenannten Riser-Karten. Apple verbaut handelsübliche FB-DIMMs verschiedener Hersteller. Da FB-DIMMs bauartbedingt im Betrieb sehr warm werden, besitzen diese Speichermodule generell Kühlkörper. Apple unterstützt einen maximalen Speicherausbau von 64 GB in Form von acht 8-GB-Modulen, wobei generell maximal 8-GB-Module unterstützt werden. Allgemein ist es ratsam, bei Speicheraufrüstungen auf FB-DIMMs mit geringerem Stromverbrauch zu achten.\n\nStandardausstattung ist eine PCIe-Grafikkarte vom Typ ATI Radeon HD 2600XT mit 1024 MB GDDR5 Grafikspeicher. \nAn die ATI Radeon HD 5770 können aufgrund ihres Dual-Link-DVI-Anschlusses sowie den zwei Mini-DisplayPorts bis zu drei 30-Zoll-Apple Cinema Displays angeschlossen werden. Um an den Mac Pro weitere Bildschirme anzuschließen, kann man bis zu vier gleiche Karten verbauen.\n\nApple bietet außerdem gegen Aufpreis folgende Grafikkarten an: eine zweite ATI Radeon HD 5770 sowie eine ATI Radeon HD 5870 mit 1024 MB Grafikspeicher. Alle optionalen Grafikkarten benötigen eine aktive Kühlung; allerdings erhöhen sie durch die zusätzlichen Lüfter das Betriebsgeräusch.\n\nAm 29. Oktober 2018 veröffentlichte Apple eine Liste mit offiziell unterstützten Grafikkarten, die in dem Mac Pro nachträglich verbaut werden können, um die zu dieser Zeit aktuelle Betriebssystemversion codice_1 zu nutzen. Darunter die codice_2, die Leistungsstärkste Karte aus der Liste, gefolgt von codice_3, codice_4, codice_5 und codice_6.\n\n\n\n\n\nDer 2013er Mac Pro besitzt einen 64-Bit Intel Xeon Hauptprozessor (CPU) der Baureihe E5 (Mehrkernprozessor). Ausstattungsmöglichkeiten sind:\n\nDer Mac Pro setzt \"DDR3-RAMs\" mit 1866 MHz und Fehlerkorrektur (ECC) ein (wichtig für den Betrieb mit ZFS). Die standardmäßige Ausstattung des Mac Pro sieht je nach Modell 12 GB oder 16 GB RAM vor, die auf den vier vorhandenen Steckplätzen auf bis zu 64 GB (von Apple unterstütztes Limit) erweitert werden können. Apple unterstützt einen maximalen Speicherausbau von 64 GB in Form von vier 16-GB-Modulen. Seit dem Frühjahr 2014 werden von Drittanbietern (Transcend, Other World Computing (OWC)) allerdings auch Module mit einer Kapazität von 32 GB angeboten, wodurch der maximale Speicherausbau auf insgesamt 128 GB steigt.\n\nStandardausstattung sind Dual-Grafikkarten vom Typ AMD FirePro D300 mit je 2048 MB GDDR5-Grafikspeicher. An die Thunderbolt-Anschlüsse können bis zu sechs 27-Zoll-Apple-Thunderbolt-Bildschirme oder bis zu drei 4K-Monitore angeschlossen werden, außerdem gibt es einen HDMI-Anschluss.\n\nApple bietet gegen Aufpreis folgende Grafikkarten an: \nDie Grafikkarten sind seit dem Mac-Pro-Modell von 2013 nicht mehr vom Benutzer selbst austauschbar.\n\nBei dem Mac-Pro-Modell von 2013 wird als Massenspeicher bzw. Systemspeicher nur noch PCIe-basierter Flash-Speicher verwendet. Standardmäßig stehen 256 GB zur Verfügung. Optional kann man auch 512 GB oder 1 TB wählen. Der Flash-Speicher ist eines der wenigen Teile, die beim neuen Mac Pro noch vom Benutzer selbst gewechselt werden können.\n\nSeit dem Mac Pro 2013 wird kein optisches Laufwerk mehr verbaut.\nEs können aber optische Laufwerke über USB angeschlossen werden.\n\n\n\n"}
{"id": "1685788", "url": "https://de.wikipedia.org/wiki?curid=1685788", "title": "Metasploit", "text": "Metasploit\n\nDas Metasploit-Projekt ist ein Projekt zur Computersicherheit, das Informationen über Sicherheitslücken bietet und bei Penetrationstests sowie der Entwicklung von IDS-Signaturen eingesetzt werden kann. Das bekannteste Teilprojekt ist das freie Metasploit Framework, ein Werkzeug zur Entwicklung und Ausführung von Exploits gegen verteilte Zielrechner. Andere wichtige Teilprojekte sind das Shellcode-Archiv und Forschung im Bereich der IT-Sicherheit.\n\nWie vergleichbare Lösungen, z. B. Canvas (von Immunity) oder Core Impact (von Core Security Technology), kann Metasploit unter anderem von Red Teams eingesetzt werden, um in Auftrag die Schwachstellen von Computersystemen zu prüfen und diese Schwachstellen bei Bedarf schließen zu lassen. Andererseits kann es wie jedes Werkzeug auch missbraucht werden, um in fremde Systeme einzubrechen, womit unter Umständen verschiedene Tatbestände der Computerkriminalität erfüllt werden.\n\nDie Arbeit mit dem Framework gliedert sich in folgende grundlegende Schritte:\n\nDiese Modularität, die es erlaubt, jeden Exploit mit jeder kompatiblen Nutzlast zu kombinieren, ist einer der großen Vorteile des Frameworks, da es eine Trennung der Aufgaben von Entwicklern (von Nutzlasten und Exploits) und Angreifern ermöglicht.\n\nAb der Hauptversion 3 wurde das Metasploit-Framework in der Programmiersprache Ruby implementiert. Es ist unter Linux und macOS sowie unter Microsoft Windows lauffähig, in spezialisierten Linux-Distrubtionen wie Kali Linux fixer Bestandteil, und kann per Kommandozeile oder über eine in Java geschriebene grafische Benutzeroberfläche bedient werden. Das Metasploit-Framework lässt sich durch externe Add-Ons in verschiedenen Sprachen erweitern.\n\nUm einen Exploit und eine Nutzlast zu wählen, benötigt man einige Informationen über das Zielsystem und die darauf installierten Netzwerkdienste. Diese Informationen können durch den Einsatz eines Portscanners wie Nmap erlangt werden, der auch die Erkennung des Betriebssystems durch OS-Fingerprinting ermöglicht. Vulnerability Scanner wie OpenVAS, Nessus oder NeXpose können zusätzlich eingesetzt werden, um Sicherheitslücken auf dem Zielsystem zu entdecken.\n\nDie Shellcode-Datenbank enthält in Assemblersprache geschriebene Nutzlasten (Payloads) mit Quelltext, die vom Metasploit Framework eingesetzt werden.\n\nUm praktische Erfahrung mit Metasploit sammeln zu können wurde eine Testumgebung unter der Bezeichnung \"Metasploitable\" mit bewusst eingebauten Schwachstellen zusammengestellt. \"Metasploitable\" stellt eine fertig konfigurierte virtuelle Maschine (VM) dar, welche unter anderem unter VMware oder VirtualBox in einer Testumgebung betrieben werden kann. Der Betrieb als virtuelle Maschine hat den Vorteil, dass durch die Verwendung von \"snap shots\", das sind Systemzustände die zu einem bestimmten Zeitpunkt angefertigt werden und leicht restauriert werden können, auch verschiedene destruktive Angriffsverfahren effizient und wiederholend in verschiedenen Variationen durchprobiert werden können. Die erste Version von \"Metasploitable\" wurde am 21. Mai 2012 durch \"Metasploitable 2\" abgelöst, welche als direkter Nachfolger angesehen wird. Es wurden einige Neuerungen und praktische Beispiele eingearbeitet, um nun auch aktuellere Szenarien zu demonstrieren und zu trainieren. Gleichzeitig wurde ein offizieller Benutzungsleitfaden veröffentlicht, um die Bedienung zu erleichtern und Beispiele zu erläutern.\n\n"}
{"id": "1688158", "url": "https://de.wikipedia.org/wiki?curid=1688158", "title": "Linux Virtual Server", "text": "Linux Virtual Server\n\nLinux Virtual Server \"(LVS)\" ist eine Software zur Lastverteilung. Sie erweitert den Linux-Kernel um Methoden zur transparenten Zuweisung von Anfragen aus dem Netzwerk an mehrere Server. Die erlaubt die Realisierung von hochverfügbaren Serverfarmen mit freier Software.\n\n\"Serverfarmen\" bestehen aus mehreren Rechnern, die Anfragen über ein Rechnernetz erhalten und bearbeiten, und einem oder mehrerer Lastverteiler (), die die Anfragen auf die zur Verfügung stehenden Rechner aufteilen (engl. ). Da Rechner dynamisch zu diesem Verbund hinzugefügt und entfernt werden können, lassen sich so Skalierbarkeit und Verfügbarkeit erhöhen. \"LVS\" übernimmt in einer solchen Installation die Rolle des Lastverteilers.\n\n\"LVS\" stellt vier Strategien zur Verfügung, um Anfragen aufzuteilen:\n\nFür die Rückantwort der Server an den anfragenden Rechner gibt es ebenfalls verschiedene Möglichkeiten. \"LVS\" implementiert die folgenden Techniken:\n\nFür eine \"hochverfügbare\" Installation werden noch weitere Komponenten benötigt, für die es ebenfalls Freie-Software-Projekte gibt.\n\nAdministratives Werkzeug zur Konfiguration von LVS ist codice_1. Dieses kann nur mit dem Root-Konto benutzt werden.\n\n ipvsadm -A -t 192.168.0.1:80 -s rr\n\nErste Zeile fügt auf der IP-Adresse 192.168.0.1 den TCP-Port 80 zum LVS hinzu. Anzuwendende Strategie der Lastverteilung ist hierbei Round-Robin (-s rr).\nDie folgenden zwei Zeilen fügen jeweils einen realen Server dieser virtuellen Adresse (192.168.0.1:80) hinzu. Hierbei sollen die weitergeleiteten Pakete maskiert werden (-m).\n\n\n"}
{"id": "1688299", "url": "https://de.wikipedia.org/wiki?curid=1688299", "title": "Autodesk AutoSketch", "text": "Autodesk AutoSketch\n\nAutoSketch war ein 2D-Vektorgrafik-Programm von \"Autodesk\", das mittlerweile eingestellt wurde.\nEs unterstützte im Gegensatz zu \"AutoCAD\" oder \"AutoCAD LT\" keine 3D-Darstellungen.\nMit der Software konnte man beispielsweise Schaltpläne, Grundrisse und konzeptionelle Skizzen erstellen. Auch unter Unfallsachverständigen ist das Programm weit verbreitet.\n\nAutoSketch benutzte zuerst SKD und in späteren Versionen SKF als eigenes Datenformat, unterstützt aber auch die Formate von AutoCAD, DWG und DXF.\n\nAutosketch wurde 1987 erstmals für DOS veröffentlicht.\nDie erste Windows-Version kam im Jahr 1993 auf den Markt. In der 1995 herausgebrachten letzten 16 Bit-Version 2.1 für Windows war die Verwendung von Makros noch integriert, was später in den 32-Bit-Versionen wieder entfernt wurde.\n\nIm Jahr 1998 erschien mit der Version 5 erstmals eine 32 Bit-Version der Software, die nun auch über deutschsprachige Menüs verfügte.\n\nDie letzte Version von Autosketch, Autosketch 10, erschien am 14. November 2008.\n\nDie Computerzeitschrift Chip bewertete AutoSketch 7 im Mai 2000 mit 1,87.\n"}
{"id": "1688812", "url": "https://de.wikipedia.org/wiki?curid=1688812", "title": "Corel Linux", "text": "Corel Linux\n\nDas Corel Linux Desktop OS war eine kommerzielle Linux-Distribution, die Debian als Basis für verschiedene Applikationen aus dem Hause Corel adaptierte.\n\nCorel Linux 1.0 wurde 1999 erstveröffentlicht. Erklärtes Ziel war, ein eigenes Desktop-Betriebssystem zu liefern, und zwar das benutzerfreundlichste. Darunter verstand Corel: Der Nutzer sollte sich besonders wenig um das unterliegende Betriebssystem kümmern müssen. Soweit möglich konfigurierte Corel Linux sich selbst. Die notwendigsten vom Anwender vorzunehmenden Einstellungen wurden in einem \"Control Center\" unter KDE zusammengefasst. Corel erweiterte den KDE File Manager erheblich zum \"Corel File Manager\" als integrale Steuerzentrale, die in etwa den Funktionsumfang des Explorer unter Windows einnahm. Laufwerke wurden vollautomatisch gemounted. Außerdem wurde als \"Corel Update\" ein Installer als GUI implementiert.\n\nCorel Linux 1.0 erschien in drei verschiedenen Varianten, die sich im Umfang der enthaltenen Software unterschieden. Insgesamt war der Softwareumfang gegenüber üblichen Distributionen stark reduziert. Die Download- und die Standardvariante enthielten eine abgespeckte Variante des von Corel erworbenen WordPerfect. Die Variante \"Deluxe\" brachte ein WordPerfect 8.0 in Vollversion inklusive ClipArt-Sammlung mit, ein Backup-Utility sowie eine Vierteljahreslizenz für einen internetbasierten Fax-Dienst. Als Bildbearbeitung war zunächst GIMP enthalten.\n\n\nMitte 2000 wurde kostenlos eine unter Linux lauffähige Version von Photopaint und später kommerziell CorelDRAW 9 freigegeben. Die (für Corel damals existenziell notwendigen) Umsatzziele wurden dennoch nicht schnell genug erreicht.\n\n2001 verkaufte Corel seine Linuxentwicklung an das damalige Startup Xandros u. a. gegen eine Beteiligung von 5 % an Xandros.\n\nDie Corel-Open-Source-Entwicklerwebsite blieb bis März 2002 online.\n\n"}
{"id": "1692778", "url": "https://de.wikipedia.org/wiki?curid=1692778", "title": "Direct Rendering Manager", "text": "Direct Rendering Manager\n\nDer Direct Rendering Manager (abgekürzt DRM) ist ein Hardware-spezifisches Kernel-Modul (Treiber), der auch ohne einen X-Server wie X.org-Server Zugriff auf den Speicher (DMA, AGP) der Grafikkarte gewährt. Außerdem stellt der DRM sicher, dass die definierten Sicherheitsregeln eingehalten und die Zugriffe auf die Hardware verwaltet werden. DRM ist ein Teil der Direct Rendering Infrastructure (DRI).\n\nDer DRM unterstützt die DRI in dreierlei Hinsicht:\n\nSo wie die Direct Rendering Infrastructure selber, unterliegen auch ihre Komponenten einer steten Weiterentwicklung.\n\n\n\nDurch die neuen Render-Nodes können Anwendungen über mehr als einen Knotenpunkt im Linux-Kernel auf Grafikeinheiten, auch auf mehrere, zugreifen. Vorher durfte lediglich eine Anwendung, etwa der Displayserver, KMS vornehmen, und das nur mit Root-Rechten. Render-Nodes stellen eine API, über die userspace nicht-privilegierte GPU-Befehle ausführen lassen können, etwa für GPGPU.\n\n\n"}
{"id": "1698843", "url": "https://de.wikipedia.org/wiki?curid=1698843", "title": "PCgo", "text": "PCgo\n\nPCgo, publiziert von WEKA Media Publishing, ist eine monatlich erscheinende Computerzeitschrift, die sich vor allem mit den anwenderspezifischen Aspekten von Computern beschäftigt. Schwerpunkt sind Tipps und Workshops.\n\nPCgo erscheint üblicherweise in drei Auflagen: als „Premium Gold Edition“ mit drei DVDs, als „DVD-Ausgabe“ mit einer DVD und als CD-Ausgabe.\n\nDie Zeitschrift wurde 1993 erstmals veröffentlicht. Sie war die erste Computer-Zeitschrift in Deutschland, die regelmäßig mit einer DVD erschienen ist.\n\nDie durchschnittliche verbreitete Auflage , lag bei Davon sind Abonnenten. PCgo ist im gesamten deutschsprachigen Raum erhältlich.\n\n"}
{"id": "1700621", "url": "https://de.wikipedia.org/wiki?curid=1700621", "title": "Vvvv", "text": "Vvvv\n\nvvvv ist eine grafische Entwicklungsumgebung für „Creative Coding“, die von der vvvv-group (Joreg, Max Wolf, Sebastian Gregor, Sebastian Oschatz) entwickelt wird. vvvv dient der Erzeugung und Manipulation von Video-, Grafik- und Datenströmen in Echtzeit.\n\n1998 initiierte die Firma \"Meso Digital Media Systems Design\", heute \"MESO Digital Interiors & MESO Digital Services\", die Entwicklung der Software vvvv, die ursprünglich als firmeninterne Anwendung gedacht war. Sie hatte ein schmaleres GUI mit dem man zur Laufzeit Parameter einstellen, aber keine neuen Elemente hinzufügen konnte.\n\nEines der ersten Projekte, in denen die Software zum Einsatz kam, war die gemeinsam von Meso und 3deluxe realisierte Installation Cyberhelvetia auf der Expo 2002 in der Schweiz. Hierzu wurde mit Hilfe von vvvv eine große Reihe von interaktiven Anwendungen entwickelt, welche auf Sprache, Bewegungen und das Wetter reagierten. Im Laufe der letzten Jahre wurden zahlreiche weitere Projekte mit Hilfe von vvvv realisiert, besonders erwähnenswert ist dabei die Umsetzung des kompletten Licht-, Video- und Raumkonzeptes des Frankfurter Cocoon Clubs und des Fußball-Globus.\n\nvvvv läuft grundsätzlich in Echtzeit, Änderungen am „Programmcode“ werden direkt ausgeführt – vvvv kann somit in die Kategorie der Datenstromorientierten Programmiersprachen eingeordnet werden.\n\nIm Gegensatz zu herkömmlichen texturalen Programmiersprachen werden bei vvvv grafische Objekte, sog. „Nodes“, zur Entwicklung von Programmen genutzt. Einzelne Nodes verfügen über Ein- und Ausgabepins, welche sich mit der Maus über virtuelle Kabel miteinander verbinden lassen und so Daten untereinander austauschen können. Eingabepins sind oben angeordnet, Ausgabepins sind unten angeordnet.\n\nAngelehnt an Programmiersprachen wie APL und J können über jede Verbindung Vektoren von Daten (sogenannte Spreads) übertragen werden, die von den Nodes parallel verarbeitet werden können.\n\nIm Vergleich mit der klassischen Programmierung kann ein Node am ehesten mit einer Funktion verglichen werden – wobei die Eingabepins analog zu den Funktionsparametern und die Ausgabepins analog zur Funktionsrückgabe gesehen werden kann. Im Gegensatz zu Sprachen, die auf einer eindimensionalen Zeichenkette basieren, ist man jedoch nicht darauf angewiesen, dass ein unbenannter Rückgabewert in genau einer aufrufenden Funktion benutzt wird.\n\nAufgrund der modularen Programmstruktur und der Fähigkeiten zur Echtzeit-Grafik ist vvvv besonders für den Einsatz in multimedialen Umgebungen gedacht. Ein kurzer Auszug der Möglichkeiten im Folgenden:\n\n\nMit vvvv ist es nicht möglich eigenständige Anwendungen zu generieren, zur Ausführung eines Programms wird immer die vvvv Laufzeitumgebung benötigt. Aus diesem Grund ist vvvv auch nur bedingt dazu geeignet, Anwendungen im Sinne von klassischen Benutzerprogrammen zu entwickeln.\n\nVergleichbar ist vvvv am ehesten mit Max/MSP der Firma Cycling74 und dessen Open Source Pendant Pure Data. Beides sind jedoch Anwendungen, die ursprünglich eher zur Midi-Steuerung und Audioverarbeitung entwickelt wurden und erst nachträglich auf die Erzeugung von 3D-Echtzeitgrafik adaptiert wurden. Schwachstellen bestehen auch bei der gleichzeitigen Verarbeitung von Objekten. So arbeiten die Module in vvvv grundsätzlich mit sogenannten Spreads, was bedeutet, dass mehrere parallele Berechnungen in einem Arbeitsschritt stattfinden, was die Programmierung wesentlich erleichtert.\n\n"}
{"id": "1702144", "url": "https://de.wikipedia.org/wiki?curid=1702144", "title": "Xfig", "text": "Xfig\n\nXfig ist ein Vektorgrafik-Zeichenprogramm, welches auf den meisten Unix-kompatiblen Betriebssystemen unter dem X Window System läuft und mit offenem Quellcode zu Bedingungen ähnlich der BSD-Lizenz frei verfügbar ist.\n\nDie erste Version stammt aus dem Jahr 1985 von Supoj Sutanthavibul. Es geht insgesamt auf Ideen und Anregungen von Donald E. Fussell (Professor an der University of Texas at Austin) zurück.\n\nMit Xfig können Zeichnungen angefertigt werden, die aus Objekten wie Kreisen, Rechtecken, Linien, Polygonen, Splines, Text usw. bestehen. Weiterhin sind Bilder in Formaten wie PNG, GIF, JPEG, EPSF (PostScript) usw. importierbar. Diese Objekte können erzeugt, gelöscht, bewegt, oder verändert werden. Verschiedene Attribute wie Farben oder Linienstile sind verfügbar. Für eingefügten Text stehen 35 Schriftarten zur Auswahl.\n\nXfig speichert die Grafiken in seinem eigenen, textbasierten \"Fig Format\", kann aber mit Hilfe des zugehörigen Transfig Programmes in verschiedene andere Formate wie (encapsulated) PostScript, PDF, GIF, JPEG, HP-GL und andere mehr exportieren.\n\nDie Benutzung von Dialogen verläuft auf etwas ungewöhnliche Weise: Zum einen verfügt jedes Textfeld über eine permanente Schreibmarke in Form eines Zirkumflexes, zum anderen wird der Schreibfokus ohne Anklicken automatisch auf ein Textfeld gelegt, sobald sich der Mauszeiger darüber befindet.\n\nEine besondere Eigenschaft von Xfig besteht darin, dass Zeichnungen mit LaTeX-Beschriftungen versehen werden können. So kann die Ausgabe in zwei Dateien erfolgen: ein graphischer Teil in PostScript oder PDF und ein textueller Teil mit LaTeX-Kommandos. Diese Möglichkeiten werden durch die Einbindung von Transfig erzielt.\n\nDas Programm \"JFig\", das auf der plattformunabhängigen Programmiersprache Java basiert, kann ebenfalls Dateien im .fig-Format bearbeiten. Damit können .fig-Dateien auf allen Plattformen genutzt werden, auf denen Java zur Verfügung steht. Windows-Anwender können außerdem Xfig mit der Bibliothek \"Cygwin\" lauffähig machen oder .fig-Dateien mit dem Programm \"WinFIG\" bearbeiten. Im Gegensatz zu dem für Unix erhältlichen Xfig sind sowohl JFig als auch WinFig nicht kostenlos erhältlich, sondern nur gegen Lizenzgebühren.\nFür AmigaOS, AROS und MorphOS steht AmiFIG als Open Source zur Verfügung.\n\n"}
{"id": "1702567", "url": "https://de.wikipedia.org/wiki?curid=1702567", "title": "Siemens PC-D", "text": "Siemens PC-D\n\nDer PC-D bzw. PC-X ist ein Personal Computer, den Siemens von 1982 (PC-X) bzw. 1984 (PC-D) bis 1986 verkaufte. Der PC-D war der erste MS-DOS-PC der Siemens AG, allerdings nur eingeschränkt IBM-PC-kompatibel.\n\nDie PC-D Linie wurde zugunsten der Produktion des PCD-2 aufgegeben.\n\nGrundsätzlich sind der Siemens PC-D und PC-X baugleich. Der PC-D war mehr für Privatanwender konzipiert und wurde als erster PC von Siemens mit MS-DOS (2.11, zuletzt auch 3.20) ausgeliefert, der PC-X dagegen mit Sinix, dem siemenseigenen Unix-Derivat. Der PC-X war somit auf professionellere Anwendungen zugeschnitten. Außerdem erhielt er standardmäßig 1 MB RAM, eine Festplatte und eine MMU.\n\nDer PC-D bzw. PC-X arbeitet mit einem Intel-80186-Prozessor mit 8 MHz und verfügt über 128 KB bis maximal 1 MB Arbeitsspeicher. Die Basisvariante verfügte lediglich über ein Diskettenlaufwerk, optional war ein zweites Diskettenlaufwerk oder eine Festplatte mit 13 oder 20 MB erhältlich. Der Rechner ist teilweise zum IBM PC kompatibel. Die auffälligsten Unterschiede sind:\n\nSiemens verkaufte diverses Zubehör für den PC-D / PC-X. Dazu gehörten u. a. eine Centronics-Schnittstelle, eine Maus und die Nadel- und Tintenstrahldrucker PT88/89 im DIN A4- bzw. im DIN A3-Format mit neun Nadeln bzw. Düsen und serieller Schnittstelle.\n\nDas Softwareangebot für den PC-D war vergleichsweise überschaubar. Es gab aber unter anderem ein MS-DOS bis Version 3.20, Microsoft Word, Microsoft Multiplan, Microsoft Chart, dBase II, einen GW-BASIC-Interpreter und -Compiler und sogar Microsoft Windows (1.02). Es gab auch eine Sammlung vergleichsweise einfacher Spiele. Eine Kostbarkeit war eine gepatchte Version des Microsoft Flight Simulator.\nDie meisten DOS-Anwendungen für den IBM PC waren auf dem PC-D nicht ohne Änderung lauffähig, Die meisten Windows-Anwendungen hingegen konnten zwischen beiden Systemen ausgetauscht werden. Grund dafür war, dass auf dem PC-D mit DOS/Windows zwar DOS oder Windows system calls unterstützt wurden, nicht aber die (von DOS Programmen häufiger verwendeten) lower level/hardware system calls. Verwendete eine Anwendung diese lower level calls, so musste sie (z. B. mit dem Debugger) gepatched und/oder ggf. recompiled werden um auf der nicht 100 % IBM-kompatiblen Siemens PC-D Hardware lauffähig zu werden. So gepatchte Anwendungen waren dann im Gegenzug normalerweise nicht mehr auf normalen IBM-Kompatiblen lauffähig.\n\n\n"}
{"id": "1704643", "url": "https://de.wikipedia.org/wiki?curid=1704643", "title": "Das Fußball Studio", "text": "Das Fußball Studio\n\nDas Fußball Studio (\"DFS\") ist eine Software, mit der Fußballligen verwaltet und ausgewertet werden können.\n\n\"Volker Mallmann\" programmierte das Fußball Studio erstmals 1989.\nDamals handelte es sich noch um eine Version für Atari-Computer.\n1991 erschien erstmals in einer Zeitschrift ein Bericht über \"Das Fußball Studio\", in dem es als sehr gut bewertet wurde. Damals handelte es sich bei dem Programm allerdings noch nicht um Freeware. Zu dieser Zeit wurde die Software auch von der ARD/ZDF-Videotextzentrale eingesetzt. Die Weiterentwicklung dieses \"Urstudios\" wurde von \"Volker Mallmann\" 1993 eingestellt.\n\nZehn Jahre später wurde die Entwicklung wieder aufgenommen, die Entwicklung der jetzt verfügbaren Version für Windows-PCs begann. Inzwischen gibt es mehrere Dutzend User, die Datenbanken für das Programm im Internet zum Download anbieten. Außerdem arbeiten mehrere Benutzer im Team an der Weiterentwicklung des Programms.\n\nDas Programm bietet die Möglichkeit, Spielpläne zu erstellen und Ergebnisse einzugeben. Zudem kann man die Aufstellungen der Mannschaften mit allen Daten erfassen und die Spieler einzeln ansehen und z. B. feststellen, in welchen Spielen der Spieler eingesetzt wurde. Auch Mannschaften können einzeln angesehen werden.\nMan kann sowohl eine bereits erstellte Datenbank für das Programm aus dem Internet herunterladen, als auch in Eigenarbeit die Daten einer Liga erfassen.\n\nDas Flaggschiff, die Bundesliga-Datenbank, beinhaltet die vollständigen Daten der Top-Ligen des deutschen Fußballs seit Gründung der Ligen in 1963 bzw. 1974: Die 1. Bundesliga, die 2. Bundesliga sowie Aufstiegsrunden/Relegationsspiele. Ab Saison 2008/09 ist auch die neue 3. Liga enthalten.\n\nDie Bundesliga-Datenbank mit annähernd einer Million Datensätze umfasst:\n\n\nDarüber hinaus werden mehr als 200 weitere Datenbanken angeboten. Seien das die deutschen Regionalligen, Oberligen und Verbandsligen wie auch ausländische Ligen von allen Kontinenten.\nDazu Datenbanken mit den wichtigsten Fußballturnieren der Welt wie beispielsweise die Weltmeisterschaften, alle Kontinentalmeisterschaften, die Champions League, der UEFA-Pokal und der DFB-Pokal.\n\nDie Datenbanken können gratis heruntergeladen werden. Sie werden ständig überprüft, aktualisiert und erweitert.\n\n\nAuf der Website findet man verschiedene Ligen aus der ganzen Welt zum Download.\nNeben den Datenbanken findet man auch die erforderlichen Wappen von Vereinen sowie Nationalflaggen zum Download.\nIm Benutzerforum werden Themen rund um den Fußball diskutiert. Außerdem bekommt man hier kompetenten Support bei Fragen zum Programm.\nDie Website wurde im Juli 2006 und nochmals im März 2017 grundlegend überarbeitet.\n\n"}
{"id": "1705191", "url": "https://de.wikipedia.org/wiki?curid=1705191", "title": "Windows-1251", "text": "Windows-1251\n\nWindows-1251 ist eine 8-Bit-Codepage zur Darstellung von Sprachen im kyrillischen Alphabet wie Russisch. Sie wird auch häufig für Bulgarisch verwendet.\n\nWindows-1251 und KOI8-R (oder seine ukrainische Variante KOI8-U) sind viel weiter verbreitet als ISO 8859-5. Zukünftig könnten sie durch UTF-8 (Unicode) verdrängt werden.\nIm Januar 2019 verwenden 1,0 % aller Websites Windows-1251, ISO-8859-5 wird von weniger als 0,1 % verwendet.\n\n\"SP\" (\"space\") auf Position 20 ist das Leerzeichen, \"NBSP\" (\"no-break space\", auch \"non-breaking space\") auf Position A0 ist das geschützte Leerzeichen und \"SHY\" (\"soft hyphen\") an Position AD ist der bedingte Trennstrich, der normalerweise nur am Zeilenende sichtbar ist.\n\n"}
{"id": "1705866", "url": "https://de.wikipedia.org/wiki?curid=1705866", "title": "RSSOwl", "text": "RSSOwl\n\nRSSOwl ist ein freier, plattformunabhängiger Feedreader für RSS-, RDF- und Atom-Web-Feeds. Entwickelt wurde er in Java mit SWT als schneller, nativer Grafik-Bibliothek. RSS ist eine Dokumentspezifikation, welche es dem Benutzer ermöglicht, Nachrichten zu sammeln, zu organisieren und zu aktualisieren. Die Software wird nicht mehr weiterentwickelt und der Entwickler rät von der Nutzung aufgrund von Sicherheitslücken ab.\n\nRSSOwl begann Ende Juli 2003 als kleines Projekt auf SourceForge. Nach 18 Monaten Entwicklungszeit wurde RSSOwl 1.0 am 19. Dezember 2004 veröffentlicht.\n\nRSSOwl kann Nachrichten in PDF-, RTF- sowie HTML-Dokumente exportieren. Zudem unterstützt es RSS und RDF in den Versionen 0.91, 0.92, 1.0 sowie 2.0. Daneben wird Atom ab Version 1.0 unterstützt. RSSOwl beinhaltet eine Newsfeed-Suchmaschine mit Schlüsselwort-Suche. Es passt sich mit seinem Aussehen dem Betriebssystem an, auf welchem es läuft. Empfehlenswerte Nachrichten können an verschiedene Kontakte weitergeleitet werden. Das Programm besitzt eine Programmanzeige im Benachrichtigungsfeld. Innerhalb der Software ist eine einfache Navigation durch Tabs möglich. Das Programm merkt sich die gelesenen Nachrichten beim Neustart und öffnet beim Starten automatisch bestimmte Newsfeeds. Man kann Newsfeeds in Kategorien einteilen, sowie ein bestimmtes Aktualisierungsintervall festlegen. Sind Feeds fehlerhaft, werden sie dahingehend gekennzeichnet. Eine Import- und Exportfunktion von Favoriten-Newsfeeds OPML sowie der RSSOwl-Konfiguration, um sie auf einem anderen Computer wieder zu verwenden, sind ebenfalls vorhanden. Webseiten können im integrierten oder in einem externen Webbrowser betrachtet werden. Eine Verbindung via Proxy-Server ist ebenfalls möglich. Die Authentifikation erfolgt über Base64, Digest und NTLM.\n\n"}
{"id": "1707700", "url": "https://de.wikipedia.org/wiki?curid=1707700", "title": "Fujitsu Lifebook", "text": "Fujitsu Lifebook\n\nLifebook (offizielle Schreibweise \"LIFEBOOK\") bezeichnet die Notebook-Baureihen der Firma Fujitsu Technology Solutions \"(vormals Fujitsu Siemens Computers)\", welche sich an Geschäftskunden richtet. Diese unterscheiden sich von Baureihen für Konsumenten beispielsweise durch eine modulare Erweiterbarkeit des Laufwerkschachtes und durch die Anschlussmöglichkeit für einen Port-Replikator.\nDie Baureihen gliedern sich dabei auf in die Serien Lifebook A, B, C, E, P, S, Q und T. Die Namensgebung der Baureihen ist, ähnlich wie die der Handys der Siemens AG, ursprünglich an die Baureihen von Mercedes-Benz-PKW angelehnt. Die Baureihen werden von Fujitsu selbst gefertigt, im Gegensatz zur \"Amilo-Baureihe\", die zu großen Teilen zugekauft wird.\n\nHier werden alle, auch ehemaligen Serien aufgeführt; aktuell (2017) werden die Lifebook A Serie eher für den preiswerteren Privatbereich und die Serien E, P, S, T, U meist eher für den Buisnessbereich fortgeführt. Stark ist Fujitsu traditionell im Berührbildschirm- (Touchscreen-) und Tablet-Bereich (bei den Lifebook S, T, und U-Serien). Zudem sei auch auf die Stylistic-Serie verwiesen.\n\nDie \"A-Serie\" wurde 2010 eingeführt und bestand anfangs aus den \"Allround\"-Modellen A530, AH530 und AH550, die in verschiedenen Varianten angeboten werden. Gemeinsamkeiten waren Displays mit 39,6 cm (15,6 Zoll) Diagonale, LED-Hintergrundbeleuchtung und 1366 × 768 Pixeln (Bildformat , mit oder ohne Blendschutz), sowie der verbaute Chipsatz Intel HM55 und Tastaturen mit Ziffernblock. Die Geräte werden mit Mobilprozessoren überwiegend aus der Intel Core-i Serie angeboten. Auch heute (2017) handelt es sich bei der A-Reihe, etwa mit den Modellen A555 und A557, um verhältnismäßig preiswerte größere Laptops (15,6 Zoll) die als \"Allrounder\" oder als Privat-Laptops angeboten werden.\n\nDie \"B-Serie\" war die Biblo-Klasse für die Subnotebooks. Die ersten Modelle (B110 und B112, 1998) waren sehr kompakt (DIN A5 Größe und 1,1 kg) und verfügten über ein 8.4\" Farb-Display. Das besondere an den größeren (DIN A4 Format) Nachfolgemodelle B213x (1999) war der berührungsempfindliche 10,4\"-TFT-Bildschirm und der Eingabestift. Die B-Serie wird nicht mehr gebaut und wurde durch die T-Serie bzw. P-Serie ersetzt.\n\nDie \"C-Serie\" war bis 01/2008 die Einsteiger-Baureihe für professionelle Anwender. Es war einfach und robust aufgebaut, jedoch waren einige Zusatzoptionen wie 3D-Grafikkarten nicht verfügbar, und unterschied sich rein äußerlich kaum von der E-Serie.\n\nDie \"E-Serie\" ist eine Reihe von Desktop-Replacement-Notebooks. Sie sind besonders robust und haben in der Regel leistungsfähigere Komponenten als die C-Serie (schnellere Prozessoren, mehr RAM etc.) verbaut, was sich auch im Preis niederschlägt. Die E-Serie hat in der Regel einen hochwertigeren, kontrastreichen 15/15,4-Zoll-Bildschirm verbaut, der besonders für den Büroeinsatz konzipiert ist, da keine spiegelnden Displays zum Einsatz kommen und größtenteils 4:3-Formate erhältlich sind.\n\n46,7 cm Bildschirmbreite. Multimedia und Gaming.\n\nUnter der \"P-Serie\" sind mehrere ultraportable Notebooks erhältlich. Dazu gehört z. B. das P1620, das mit einem Gewicht von 1 kg einer der leichteste Convertible Tablet PC ist. Das P steht für Piccolo.\n\nDie \"Q-Serie\" sind Lifestyle-Notebooks, die sich durch Klavierlack sowie durch ergonomische Auflagen im Edelstahldesign von den anderen Baureihen abheben und eine anspruchsvolle Käuferschicht ansprechen sollen. Diese Baureihe ist besonders auf den Mobilbetrieb optimiert, weswegen ausschließlich Ultra-Low-Voltage-Prozessoren der Intel-Core-Architektur zum Einsatz kommen, der Hauptspeicher fest verlötet ist und zwei Akkus mit einer Laufzeit von mehr als 10 Stunden verwendet werden können.\n\nDie \"S-Serie\" ist eine Notebookreihe, die ursprünglich für Vielreisende gedacht ist. Die Leistungsfähigkeit ist ungefähr mit der E-Serie vergleichbar, aber die Bauweise ist etwas leichter und die Notebooks sind durch 14/13-Zoll-Displays kleiner.\n\nDie \"T-Serie\" besteht aus Convertible Tablet PCs. Durch Drehung des Bildschirms verwandeln sie sich in ein \"Tablet\". Das \"T\" steht hier für Tablet. Die T-Serie wurde im September 2003 mit dem T3010 eingeführt, welches zur Markteinführung der leistungsstärkste Tablet PC und der erste Convertible von FTS überhaupt war. FTS hat zwar vorher schon lange Zeit mit einem Stift bedienbare Computer (Stylistic) gebaut, aber diese waren ohne Zusatzgeräte ausschließlich für die Stifteingabe geeignet (vgl. Slate-Tablet-PCs).\n\nDer T4210 wurde im Juni 2006 auf den Markt gebracht und war der erste Tablet PC mit einem Intel-Core-Duo-Prozessor. Das Toshiba Tecra M7 wurde etwa einen Monat später auf den Markt gebracht. Das LIFEBOOK T4215 war der erste Convertible-Tablet-PC mit embedded UMTS. Aktuell (2017) stehen mit dem T936 und T937 schmale und trotzdem leistungsstarke 'Convertible' im Programm.\n\nFujitsu Japan hat im Mai 2007 einen extrem kleinen und leichten convertible Tablet PC vorgestellt. Das nur 580 g schwere Gerät wurde als UMPC vermarktet und hat etwa die Größe eines PDAs. Heute (2017) werden in der Serie leistungsstarke Notebook die leicht sind, aber nicht extrem klein sind vertrieben, die meist eine 13,3 Zoll oder 14 Zoll Bildschirmdiagonale haben (U747, U757, U937).\n\nAndere Baureihen von Fujitsu sind:\n\n"}
{"id": "1711717", "url": "https://de.wikipedia.org/wiki?curid=1711717", "title": "ZynAddSubFX", "text": "ZynAddSubFX\n\nZynAddSubFX ist ein freier polyphoner und multitimbraler Software-Synthesizer für GNU/Linux, Mac OS X und Microsoft Windows. Die Ansteuerung erfolgt über MIDI. Zur Erzeugung des Klanges benutzt die Software additive, subtraktive sowie Fourier-Klangsynthese. Zudem sind verschiedene klassische Effekte anwendbar. ZynAddSubFX ermöglicht Mikrointervalle mit bis zu 128 Noten pro Oktave und die Nachbildung alternativer Stimmungen. Unter Linux ist ZynAddSubFX kompatibel mit dem JACK-Soundserver. \n\nSeit der ersten Veröffentlichung im Jahre 2002 wird ZynAddSubFX von Paul Nasca entwickelt.\n\n"}
{"id": "1713902", "url": "https://de.wikipedia.org/wiki?curid=1713902", "title": "Linux-Musterlösung", "text": "Linux-Musterlösung\n\nDie Linux-Musterlösung (LML) ist eine am Landesmedienzentrum Baden-Württemberg im Rahmen der \"Medienoffensive Schule II\" weiter entwickelte Server-Distribution zum Einsatz in pädagogischen Schulnetzwerken, die ursprünglich durch die Zentrale Planungsgruppe Netze (ZPN) des Lehrerfortbildungsreferats am Kultusministerium Baden-Württemberg entwickelt wurde und im Jahr 2003 an das Landesmedienzentrum Baden-Württemberg übergeben wurde. Bis zur Version 2.3 basiert das System auf der Linux-Distribution SUSE Linux; ab Version 3.0 auf Debian. Ab Version 6.0, die im August 2014 freigegeben wurde, basiert das System auf UCS@School.\n\nDie Musterlösung ist Teil einer pädagogischen Schullösung, die ab Version 3.0 unter dem Namen \"paedML\" (früher \"Musterlösung des Landes Baden-Württemberg\") auf drei Betriebssystemen (Debian, Novell’s Open Enterprise Server und Windows Server 2003) entwickelt und vertrieben wird.\nEin wesentlicher Bestandteil der Linux-Musterlösung ist das Prinzip der selbstheilenden Arbeitsstationen (SheilA), das bis Version 3.0 mittels Rembo / mySHN umgesetzt wurde. Ein beschädigtes System wird somit beim Neustart einfach und sicher wiederhergestellt. Ab Version 4.0 können alternativ Rembo5/Tivoli und das kostenlose Open-Source-Produkt LINBO, das von den Knoppix-Autoren entwickelt wurde, eingesetzt werden.\n\nDie Musterlösung wurde 2006, 2008 und 2010 mit dem Comenius-Siegel der \"Gesellschaft für Pädagogik und Information\" (Berlin) ausgezeichnet. Mit diesem Siegel werden seit 1995 Multimediaprojekte prämiert, die inhaltlich, pädagogisch und gestalterisch von besonderem Wert sind.\n\nIm Februar 2007 wurde \"paedML\" als Wortmarke beim Deutschen Patent- und Markenamt angemeldet, welche es im März 2007 ins Register einpflegte. Die Veröffentlichung erfolgte im April 2007. Seitdem ist paedML als Marke geschützt und unter der Nummer „30708010“ in der amtlichen Publikations- und Registerdatenbank zu finden.\n\nDas Gesamtprodukt \"paedML\", bestehend aus Software und Support, konnte ab Mitte 2008 für rund eineinhalb Jahre nur noch von Schulen des Landes Baden-Württemberg bezogen werden.\n\nAls reine Open-Source-Lösung stellte das Landesmedienzentrum Baden-Württemberg die \"Freie Linux-Musterlösung\" oder \"OpenML\" zum Herunterladen bereit, bei dem alle nicht freien Teile (mySHN, Rembo, Tivoli) und das Layout der Schulkonsole entfernt wurden. Diese Version der Musterlösung wurde von einer Entwicklergemeinde gepflegt und enthielt das von den Knoppix-Autoren entwickelte kostenlose LINBO als Image-System für die selbstheilenden Arbeitsstationen. Hinweise zur Installation und Anwendung finden sich nach wie vor im TracGuide der LML, auch wenn inzwischen mit linuxmuster.net ein offizieller Fork der Freien Linux-Musterlösung besteht.\nIm Mai 2012 wurde die Version 5.1 veröffentlicht.\n\nDas Landesmedienzentrum kündigte im Juli 2012 an, die bisherige Entwicklung der paedML Linux an eine Firma vergeben zu wollen. Mit der Ankündigung stellte sie auch die bisherigen entwickelnden Lehrer von ihrer Verpflichtung im Rahmen der für die Abordnung an das LMZ vergebenen Deputatsstunden frei.\n\nAbweichend von der ursprünglichen Roadmap gab das Landesmedienzentrum nach einem dreistündigen Symposium Ende September 2012 bekannt, künftig den Univention Corporate Server @ school, der Firma Univention GmbH als Grundlage für die paedML Linux einzusetzen. Der Auftrag zur Entwicklung sollte ebenfalls an die Firma vergeben werden.\nEine Integration des Imaging-Systems LINBO in künftige Versionen war unklar.\nErste Beta-Versionen der „neuen“ paedML Linux waren für das Schuljahr 2013/2014 (Sommer 2013) vorgesehen.\n\nAm 26. Februar 2013 gab die Univention GmbH die Partnerschaft mit dem Landesmedienzentrum bekannt.\nDas Landesmedienzentrum informierte (mit der Veröffentlichung der Univention Pressemitteilung) die Öffentlichkeit am 4. März 2013 über die eingegangene Partnerschaft.\n\nDie Zentrale Entwicklungsgruppe Netze (ZEN) verkündete Ende März 2013 die weitere Entwicklung. Ein Bestandteil war der Austausch des Betriebssystems (Ubuntu 10.04 zu Debian 6) des mitgelieferten Clients im zweiten Quartal 2013. Daneben sollte MediaManager School, eine zentrale server- und datenbankgestützte Anwendung für die Verwaltung von Medien aus der Online-Distributionsplattform SESAM, im dritten Quartal 2013 erscheinen. Durch MediaManager School erhalten Lehrer und Schüler Zugriff auf die gesammelten Medien im pädagogischen Netz.\n\nAm 8. Juli 2014 präsentierte das Landesmedienzentrum Baden-Württemberg und Univention die paedML Linux 6.0 den IT-Schuldienstleistern und der Öffentlichkeit., die Veröffentlichung ist im August 2014 erfolgt. Sie wird ausschließlich als Paket für einen virtuellen Server ausgeliefert. Anstelle von iptables und IPCop wird nun die Firewall pfSense aus dem FreeBSD-Umfeld eingesetzt. Besonders an UCS ist, dass dieses ein \"Active Directory\" mitbringt, welches es nun zulässt, Windows-Gruppenrichtlinien auf den Clients anzuwenden. Zusätzlich ersetzt OPSI das zuvor verwendete LINBO zur Softwareverteilung (Silent-Installationen) von Arbeitsstationen. Mit Errata 2 wurde am 14. Juli 2015 ein größeres Update veröffentlicht, das Serversoftware und andere Komponenten auf den aktuellen Stand bringt.\n\nSeit der Ankündigung im Juli 2012 arbeitet die Entwicklergemeinde an einem Fork der freien Linux-Musterlösung (OpenML) unter dem Namen Linuxmuster.net. Der Name wurde zur Vermeidung von markenrechtlichen Problemen mit der Firma Silicon Graphics International, als Inhaber des Markenrechts der Open Multimedia Library, geändert.\n\nDiese Abspaltung ist eine konsequente Weiterentwicklung und soll möglichst nicht durch ein eigenes Installationsmedium, sondern mit den bestehenden Grundsystemen (Ubuntu, IPCop später IPFire) installiert werden und Änderungen (sofern möglich) per Skript erhalten. Eine Integration von Subnetting/VLANs ist für Version 6.1.0 geplant. Samba4 wird anstatt wie ursprünglich geplant in 6.1, erst in einer späteren Version unterstützt.\n\nDie Kommunikation läuft über ein eigenes Forum auf Basis von Discourse. Zuvor lief es in den Anfängen über eine Mailingliste und einem Forum, welches das quelltext-offene, PHP-basierte Internet-Newsboard-Programm Unclassified NewsBoard (UNB) nutzte. Als Bugtracker wird eine unabhängige Instanz von Flyspray genutzt.\n\nDer Quelltext des Projekts ist auf GitHub einsehbar.\n\nMit der Gründung von linuxmuster.net (e. V.) besteht seit dem 27. Januar 2013 ein Verein, mit dem die Arbeit des Projekts unterstützt werden kann.\n\nDie finale Version von Linuxmuster.net 6.0 erschien am 4. März 2013.\n\nIm Dezember 2013 startete die Betaphase der Version 6.1. Die zu testenden Neuerungen sind neben Bugfixes und der Ersetzung von Samba-Bindmounts durch Samba-Shares, die Unterstützung von Subnetting und VLANs. Mit dem Start der Testphase veröffentlichten sie auch so genannte Virtual Appliances im Open Virtualization Format und für die Linux-Kernel-Infrastruktur für Virtualisierung (Libvirt/KVM).\n\nNach rund eineinhalbjähriger Entwicklungszeit wurde im Juni 2015 die Version 6.1 fertiggestellt. Zusätzlich zu den bereits in der Betaphase enthaltenen Funktionen wechselte man die Firewall von MAC-Adressen auf IP-Basis. Daneben können detaillierte Berechtigungen für die bereitgestellten Verzeichnisse durch ACLs vergeben werden und es ist auch möglich Linux-Clients mit einem vorkonfigurierten Ubuntu 14.04-Betriebssystem auszurollen.\n\nMitte Juli 2016 ist die Version 6.2 ausgeliefert worden. Neuerungen gegenüber 6.1 finden sich vor allem in der Schulkonsole, LINBO und der Firewall. Dazu wurde die Schulkonsole unter Verwendung von JavaScript und jQuery überarbeitet. LINBO in Version 2.3. erhielt ein Kernel-Update auf 4.2. Damit gibt es native Unterstützung von 64-bit-fähiger Hardware. Den Betrieb von UEFI-Clients ermöglicht der Wechsel auf GRUB 2. Die Aktualisierung der Firewall IPFire erfolgt nun vom Server mit Hilfe des Skripts codice_1.\n\n\n"}
{"id": "1714881", "url": "https://de.wikipedia.org/wiki?curid=1714881", "title": "Yahoo Widget Engine", "text": "Yahoo Widget Engine\n\nYahoo Widget Engine (eigene Schreibweise \"Yahoo! Widget Engine\"), zuvor Konfabulator, ist eine inzwischen eingestellte JavaScript-Widget-Engine für Windows und Mac OS X, die von Yahoo als Freeware vertrieben wurde.\nMithilfe dieses Programmes kann man verschiedene Mini-Programme (Widgets) auf dem Desktop anzeigen wie zum Beispiel das aktuelle Wetter oder Nachrichten. Nachdem Yahoo im Juli 2005 Konfabulator aufkaufte, kamen die Versionen von Konfabulator von da an unter dem Namen Yahoo Widget Engine heraus.\n\nAb Version 4.5 konnten auch Flash-Animationen eingebunden werden.\n\nSeit dem Erscheinen der Version 4.5.2 im Jahr 2007 gab es keine weitere Entwicklung der Software. Mit Einschränkungen ist sie aber unter Microsoft Windows 7 und Mac OS X 10.9 nutzbar.\n\nDas Download-Angebot und die Unterstützung der Desktop-Version wurden am 11. April 2012 eingestellt.\n"}
{"id": "1720318", "url": "https://de.wikipedia.org/wiki?curid=1720318", "title": "Wonderful Days", "text": "Wonderful Days\n\nWonderful Days (Hangeul: , \"wondeopul deijeu\") ist ein südkoreanischer Science-Fiction-Animationsfilm aus dem Jahr 2003. Der Originaltitel des auch als \"Sky Blue\" bekannten Films ist kein Koreanisch, sondern gibt \"Wonderful Days\" mit Hilfe der koreanischen Alphabetschrift Hangeul lautmalerisch wieder.\n\nDer Film spielt im Jahr 2142. Die Umweltverschmutzung durch den Menschen hat zu einer Vielzahl von Umweltkatastrophen geführt und die Menschheit stark dezimiert. Eine elitäre Gruppe von Wissenschaftlern und anderen Intellektuellen hat auf einer Insel eine abgeschottet hochtechnisierte Stadt namens \"Ecoban\" gebaut, die eigentlich eine gigantische organische Fabrik zur Reinigung der Luft ist. Um existieren zu können, benötigt Ecoban viel Energie, die sie einzig aus diesem Reinigungsprozess bezieht.\n\nDie privilegierten Bewohner von Ecoban sind nicht die einzigen Bewohner der Insel. Eine Gruppe Flüchtlinge hat sich ebenfalls auf der Insel angesiedelt. Sie leben in einem Ghetto, da ihnen wegen ihrer Verseuchung der Zutritt zu Ecoban verwehrt wird. Die Bewohner Ecobans behandeln diese \"Marrianer\" wie Menschen zweiter Klasse, deren einzige Daseinsberechtigung darin besteht, für sie zu schuften. Dies wird am Anfang des Films deutlich, wo eine Anzahl Marrianer nur deshalb stirbt, weil die Rettung einer technischen Installation der Ecobaner über ihr Leben gestellt wird. Die Ecobaner können sich deshalb wie Feudalherren aufführen, weil sie viel besser ausgerüstet sind als die Marrianer.\n\nBei solchen Zuständen wundert es nicht, dass sich unter den Marrianern Unmut breit gemacht und sich eine kleine Widerstandsgruppe gebildet hat, die zu gewalttätigem Widerstand bereit ist. Doch das ist nicht die einzige Bedrohung für Ecoban. Die wesentlich größere Gefahr für Ecoban ist Ecoban selbst. Natürliche Vorgänge und der Metabolismus der organischen Stadt Ecoban haben die Luft so weit gereinigt, dass dieser Erfolg die Existenz der Stadt bedroht, da sich damit die Energiequelle der Stadt erschöpft.\n\nDie Führer Ecobans haben sich mit den Jahrzehnten an ihr Feudalherrentum gewöhnt und ihren ursprünglichen Auftrag, die Erde wieder bewohnbar zu machen, längst vergessen. Um ihre Pfründe zu sichern, planen Sie, das gesamte Gebiet um Ecoban zu verseuchen. Dass dabei alle Marrianer getötet werden, nehmen sie bewusst in Kauf. Bei einem solchen Ausgangszustand kann die Situation nur noch eskalieren.\n\nMit Produktionskosten von 30 Millionen US-Dollar ist \"Wonderful Days\" der teuerste Animationsfilm, der bislang in Südkorea produziert wurde. Bei der Produktion des Films wurden traditionelle 2D-Animation, 3D-Computeranimation und Miniaturmodellen verwendet. Auch beim Ton wurde ein erheblicher Aufwand getrieben, so sind mit erheblichem Aufwand eigens angefertigte Tonaufnahmen von echten Motorrädern in allen möglichen Fahrsituationen für die Vertonung der animierten Motorräder verwendet worden.\n\nDer Film feierte am 26. April 2003 seine Premiere auf dem Waterloo Festival for Animated Cinema in Kanada. In den folgenden Monaten wurde er auf mehreren weiteren Filmfestivals gezeigt, unter anderem bei den Internationalen Filmfestspielen von Cannes 2003 und auf dem Sundance Film Festival 2004. Am 17. Juli 2003 kam \"Wonderful Days\" in die koreanischen Kinos.\n\nIn Deutschland ist der Film auf DVD in einer Ausgabe erhältlich, auf der \"Wonderful Days\" sowie auf Koreanisch \"Wunderbare Gespräche\" (아름다운 이야기) zu lesen ist. Die DVD umfasst nicht nur die Kinofassung, einen um sieben Minuten längeren Director’s Cut und eine DVD mit Interviews mit den Machern, sondern enthält zusätzlich noch einen kompletten Soundtrack und kam am 2. Juni 2004 auf den Markt.\n\nAuf dem Gérardmer Film Festival 2004 gewann der Film den Grand Prix in der Kategorie Animation. Der Hauptpreis ging ebenfalls an einen koreanischen Film, \"A Tale of Two Sisters\" von Kim Ji-woon. Auf dem Fantasporto 2005 war \"Wonderful Days\" als \"Bester Film\" nominiert, konnte sich aber nicht gegen Vincenzo Natalis \"Nothing\" durchsetzen.\n\nKevin Thomas schrieb in der Los Angeles Times vom 31. Dezember 2004: „Wie viele andere asiatische Science-Fiction-Anime auch: eine erstaunlich vorgestellte, von eindimensionalen Figuren bevölkerte Zukunftswelt, verfangen in einer abgedroschenen Handlung.“ (“Like a lot of other Asian sci-fi anime: a stunningly imagined world of the future populated with one-dimensional characters caught up in a trite plot.”)\n\nDie Filmzeitschrift VideoWoche schrieb über \"Wonderful Days\": „Im ersten abendfüllenden Big-Budget-Cartoon von der Halbinsel treffen ‚Matrix‘ und ‚Mad Max 2‘ auf ‚Romeo und Julia‘, wenn in mitunter berückend schönen Bildern eine vergleichsweise schlichte Endzeitstory ihren vorhersehbaren Lauf nimmt. Für Eastern- und Animefans zweifellos ein Tip.“\n"}
{"id": "1721488", "url": "https://de.wikipedia.org/wiki?curid=1721488", "title": "Free Internet Chess Server", "text": "Free Internet Chess Server\n\nDer Free Internet Chess Server, kurz FICS, ist ein Schachserver zum Online-Spielen von Live-Partien. Jeder darf sich kostenlos an Spielen beteiligen.\n\nGegründet 1995 und seit 1998 eine gemeinnützige Organisation, ist FICS heute der größte freie Schachserver seiner Art. Die Benutzer bekommen durch das Glicko-System ein Rating, sodass es leicht ist, Spieler gleicher Stärke zu finden. Außerdem bietet der Server regelmäßig Turniere und internationale Schachevents können live verfolgt werden.\n\nDer erste Internet Schach Server (engl.: ICS) wurde 1980 gestartet. Er wurde von freiwilligen Helfern programmiert und konnte kostenlos benutzt werden. 1995 wurde er in Internet Chess Club (ICC) umbenannt und war nicht mehr kostenlos nutzbar.\n\nVerärgert darüber, dass ihre Idee kommerziell ausgenutzt wurde, fanden sich einige Programmierer unter Leitung von Chris Petroff (Sparky) und gründeten FICS. Der Server nahm am 5. März 1995 seine Arbeit auf. Am 18. Juli 2013 wurde der Server gecrackt und war für acht Tage nicht am Netz. Am 25. August 2013 brachten erneut böswillige Cracker den Server in ihre Gewalt.\n\nGenerell ist der Schachserver auch über eine einfache Telnet-Verbindung nutzbar. Allerdings ist es angenehmer, eine grafische Schnittstelle zu benutzen. Hierfür stehen dem Benutzer auf der Webseite das \"Jin Applet\" oder auch \"Javaboard\" zur Verfügung.\n\nEs ist allerdings zu empfehlen, eines der vielen Schachprogramme zu verwenden, da diese mehr Funktionen besitzen. Eine nicht ganz aktuelle Liste ist auf der FICS-Homepage zu finden. Beliebte Programme sind:\n\nAußer dem normalen Schach ist es auf FICS auch möglich, einige Schachvarianten zu spielen. Diese sind:\n\n\nFICS lässt auch Spieler mit Lag zu. Zwar wird die Übertragungsverzögerung durch ein Zeitsiegel kompensiert, doch kann gerade in einer Blitzpartie das Zeitgefühl beeinträchtigt werden. Andere Server, wie zum Beispiel ICC, lassen Spieler mit hohem Lag keine Partien starten oder paaren sie gegen andere Spieler mit schlechten Verbindungen.\n\n"}
{"id": "1732136", "url": "https://de.wikipedia.org/wiki?curid=1732136", "title": "Electric Sheep", "text": "Electric Sheep\n\nElectric Sheep ist ein Bildschirmschoner, bei dem der Rechner Videos animierter Fraktalbilder abspielt und sich zusammen mit allen anderen Rechnern, auf denen der Bildschirmschoner läuft, an der aufwendigen Berechnung neuerer Fraktalbilder und ihrer Animation beteiligt. Da die Rechner z. T. selbst bestimmen, wie die neuberechneten Fraktale aussehen werden, liegt es nahe, sie als „Träume“ der Rechner zu bezeichnen, bzw. als \"Schafe\", in Anlehnung an den Roman \"Träumen Androiden von elektrischen Schafen?\" von Philip K. Dick (verfilmt als „Blade Runner“).\nElectric Sheep hatte Anfang 2011 eine halbe Million Benutzer.\n\nDer Bildschirmschoner spielt mehrere auf der Festplatte zwischengespeicherte MPEG-2-Animationen mit ineinander übergehenden zufällig generierten Fraktalbildern, die als \"Schafe\" (engl. \"sheep\") bezeichnet werden. Jedes Schaf hat eine Art genetischen Code, nämlich eine komplexe Gleichung, die mathematisch sein Aussehen und seine Animation beschreibt. Während Electric Sheep auf dem Rechner läuft, verbindet er sich mit anderen Rechnern, auf denen gerade auch dieser Bildschirmschoner läuft und gemeinsam nutzen diese Rechner ihre freie Rechenkapazität, um sich neue Schafe „auszudenken“, Einzelbilder der Animationen zu berechnen (rendern) und fertigberechnete Animationen der Schafe mit anderen Rechnern über BitTorrent auszutauschen.\n\nDie Benutzer können abstimmen, welche Schafe ihnen gut gefallen und welche nicht. Schöne Schafe lassen die Rechner weiter mutieren, versuchen ähnlich gestaltete Animationen zu produzieren, sozusagen die Nachkommen oder Abkömmlinge dieser Schafe auszurechnen. Schafe, die wenig Anklang bei den Benutzern finden, werden bald vom Zwischenspeicher auf der Festplatte gelöscht und die Rechner hören auf, sie fortzuentwickeln und zu reproduzieren. Benutzer können auch selbst Schafe entwickeln und zum weiteren Fortbestand in die \"Schafherde\" (engl. \"flock\") einbinden.\n\nAufbauend auf iterierten Funktionssystemen hat Scott Draves 1992 sog. \"Fractal Flames\" (algorithmen-generierte Fraktalbilder und -animationen) entwickelt. Die Software, die Fractal Flames rendern konnte, hat Draves als Open Source im Internet veröffentlicht. Da Heimrechner nur mit großem Zeitaufwand Bilder und Animationen mit dieser Software rendern konnten, wurde sie anfangs nur von Unternehmen für computergenerierte Spezialeffekte auf Großrechnern eingesetzt. Als 1999 SETI@home die gekoppelte Rechenkraft zahlreicher Heim-PCs für komplexe Berechnungen zu nutzen wusste, schrieb Draves Electric Sheep, einen SETI@home-ähnlichen Bildschirmschoner, mit dem er die Berechnung von Fractal Flames auf beliebig viele Rechner verteilen konnte. \n\nZunächst wollte Draves das Aussehen der Fraktal-Animationen allein der „Phantasie“ der Rechner (d. h. dem Zufall) überlassen. Die Nutzer und Fans seines Bildschirmschoners haben aber bald gelernt, durch Versuch und Irrtum den „genetischen Code“ der Schafe (sprich die Parameter ihrer Definitionsgleichung) so zu modifizieren, dass ästhetisch ansprechendere Animationen entstanden. Draves entschied sich, die Kreationen seiner Benutzer in den Genpool der „Schafsherde“ aufzunehmen. \n\nDie heutigen Schafe werden überwiegend von Fraktalgrafik-Fans entworfen. Die Rechner lassen sie mutieren und berechnen fließende Übergänge von einer Animation in die andere. Die Übergangsanimationen sind aber wiederum große Inspirationsquelle und Grundlage für die Schaf-Designer.\n\nSeit 20. April 2012 gibt es auch eine Wallpaper Version für Android.\n\n\n"}
{"id": "1735287", "url": "https://de.wikipedia.org/wiki?curid=1735287", "title": "Gutenprint", "text": "Gutenprint\n\nGutenprint (ehemals Gimp-Print) stellt eine Sammlung freier Druckertreiber dar. Der Name des Projektes wurde geändert, da „Gimp“ im Namen die Vermutung nahelegte, dass diese Druckertreiber lediglich mit GIMP funktionieren.\n\nDie Treiber für Canon, Brother, Epson, Kyocera, Lexmark, Sony, Olympus und PCL-Drucker kommen in CUPS, Foomatic und GIMP zum Einsatz. Der Schwerpunkt des Einsatzes liegt somit in freien Betriebssystemen wie Linux. Gutenprint kommt aber auch in anderen unixbasierten System wie macOS zum Einsatz. Über 700 verschiedene Drucker werden unterstützt.\n\nDie Gimp-Print-Treiber waren zunächst tatsächlich die Druckertreiber für das Grafikprogramm GIMP und wurden 1999 von Michael Sweet geschrieben.\n\nDie erste Version, die auf der Internet-Entwicklungs-Plattform SourceForge veröffentlicht wurde, trug die Nummer 3.1. Im November 2000 wurde die Version 4.0 veröffentlicht.\n\nVersion 4.2 wurde im November 2001 veröffentlicht, hier wurde CUPS unterstützt. Nach dem Erscheinen von Apples macOS stellte sich heraus, dass viele Druckerhersteller ihre Treiber für ältere Drucker nicht mehr aktualisierten, woraufhin Gimp-Print für viele Nutzer zur einzigen Möglichkeit wurde, ihren alten Drucker weiterhin zu betreiben. Aufgrund der stetig wachsenden Zahl der Leistungsmerkmale neuer Drucker wurde jedoch bald klar, dass ein größerer Schritt für eine neue Version nötig würde. Der Sprung auf die Versionsnummer 5 sollte verdeutlichen, dass viele neue Funktionen hinzugekommen waren. Außerdem beschloss man im Herbst 2004 eine Namensänderung, da das Projekt inzwischen fast nichts mehr mit GIMP zu tun hatte. Der neue Name „Gutenprint“ ist an den Erfinder des Buchdrucks Johannes Gutenberg angelehnt.\n\nAm 30. Juli 2006 wurde nach vier Jahren Entwicklungszeit Version 5.0 veröffentlicht. Diese enthielt nicht, wie ursprünglich geplant, echtes Farbmanagement.\n\n"}
{"id": "1738552", "url": "https://de.wikipedia.org/wiki?curid=1738552", "title": "Digital Performer", "text": "Digital Performer\n\nDigital Performer ist der erste MIDI-Sequenzer der für die Macintosh-Plattform entwickelt wurde und eine Digital Audio Workstation (DAW) der amerikanischen Firma Mark of the Unicorn (MOTU) zur Musikproduktion und vorwiegend in amerikanischen Tonstudios darstellt.\n\nDie Software wurde erstmals 1985 veröffentlicht, war bis zur Version 7 ursprünglich ausschließlich für Apple Macintosh verfügbar und ist ab Version 8, veröffentlicht am 27. September 2012, auch für das Windows-Betriebssystem (Windows 7 und 8) erhältlich.\n\nUrsprünglich war Digital Performer eine reine MIDI-Software und wurde schrittweise um Audiofunktionen erweitert. Die ausgefeilte Funktionalität im Bereich MIDI-Editing gilt als herausragend, auch im Vergleich zum Branchenstandard Pro Tools. Viele Musikproduzenten kombinieren Digital Performer deshalb mit Pro Tools, zumal das Programm – im Gegensatz zu anderen – die Digidesign-TDM-Hardware direkt unterstützt. Digital Performer ist insbesondere unter Komponisten von Filmmusik sehr beliebt.\n\nEine stark vereinfachte Version ohne MIDI-Funktionen mit Namen AudioDesk legt MOTU seinen Audio-Interfaces bei. AudioDesk ist aber auch einzeln als Download erhältlich.\n\nDigital Performer unterstützt, neben der hauseigenen Plug-in-Schnittstelle MAS (MOTU Audio System), auch Virtual Studio Technology (VST) und Audio Unit.\n\n\n"}
{"id": "1742844", "url": "https://de.wikipedia.org/wiki?curid=1742844", "title": "Skale Tracker", "text": "Skale Tracker\n\nDer Skale Tracker ist ein Rastersequenzer, programmiert und compiliert von Baktery mit einer grafischen Unterstützung von Awesome.\n\nEr wurde ursprünglich in einem frühen Alpha-Stadium als \"FastTracker 3\" veröffentlicht, da die gesamte Oberfläche so nahe wie möglich dem FastTracker 2 nachempfunden war. Aus rechtlichen Gründen musste der Name geändert werden, der Grundaufbau und generelle Ähnlichkeit zum FastTracker blieben jedoch gleich.\n\nDer Skale Tracker benutzt auch Technologien wie ASIO, WAV-Renderer, Unterstützung von SF2- und Akai-Instrumenten, MIDI I/O, Unterstützung für VST-Instrumente und mehr.\n\nDas Programm ist für Windows und Linux verfügbar und die letzte Version ist 0.81 vom 25. Dezember 2005.\n\n"}
{"id": "1746666", "url": "https://de.wikipedia.org/wiki?curid=1746666", "title": "Maschinengenauigkeit", "text": "Maschinengenauigkeit\n\nDie Maschinengenauigkeit ist ein Maß für den Rundungsfehler, der bei der Rechnung mit Gleitkommazahlen auftritt. Andere gebräuchliche Bezeichnungen für die Maschinengenauigkeit sind Rundungseinheit () und Maschinenepsilon (bzw. macheps).\n\nAufgrund der endlichen Mantisse in der Gleitkommadarstellung lassen sich Zahlen auf einem Computer nicht beliebig genau darstellen. Es muss gerundet werden. Statt formula_1 verwendet der Computer die Zahl formula_2 für die weitere Rechnung.\n\nFalls die Rundung zur nächstgelegenen normalisierten Gleitkommazahl erfolgt (kaufmännisches Runden oder mathematisches Runden), gilt für den dabei auftretenden relativen Rundungsfehler:\n\nDabei wird formula_4 als Maschinengenauigkeit bezeichnet. formula_5 ist die Basis der Gleitkommadarstellung und formula_6 die Mantissenlänge. Die Maschinengenauigkeit gibt also den maximalen relativen Rundungsfehler an.\n\nFalls die Rundung zu einer der beiden benachbarten normalisierten Gleitkommazahlen erfolgt (Abrunden, Aufrunden, Rundung durch Abschneiden), gilt für den dabei auftretenden relativen Rundungsfehler:\n\nDie angegebene Abschätzung für den Rundungsfehler gilt nur für normalisierte Gleitkommazahlen. Nähert man sich der Zahl Null, so kann der relative Rundungsfehler auch größer werden und steigt bis auf 100 % (für formula_8).\n\nEs sind auch andere Bezeichnungen für die Maschinengenauigkeit gebräuchlich. Insbesondere sind dies \"Rundungseinheit\" () und manchmal auch \"Maschinenepsilon\" (bzw. macheps), wobei der Begriff Maschinenepsilon auch für den maximalen relativen Abstand zweier benachbarter normalisierter Gleitkommazahlen verwendet wird. Dieser hat die Größe formula_9. Daraus ergibt sich die Abschätzung des relativen Rundungsfehlers bei Rundung zu einer benachbarten normalisierten Gleitkommazahl: Falls etwa im schlechtesten Fall formula_1 knapp größer ist als eine normalisierte Gleitkommazahl und formula_2 durch Aufrundung die nächstgrößere normalisierte Gleitkommazahl ist, so ist der relative Abstand von formula_1 zu formula_2 kleiner als der maximale relative Abstand zweier benachbarter normalisierter Gleitkommazahlen.\n\nAls Beispiel soll ein Zahlensystem zur Basis 2 mit der Mantissenlänge 3 genommen werden. Das Bild zeigt die entsprechenden Gleitkommazahlen im Bereich 1 bis 8.\n\nDie Zahl 4,2 wird in diesem System auf 4 gerundet werden. Der absolute Rundungsfehler ist dann:\n\nDer relative Rundungsfehler ergibt sich aus:\n\nDieser ist natürlich kleiner als die Maschinengenauigkeit für dieses Beispiel formula_16. Die Maschinengenauigkeit ist also im Allgemeinen eine sogenannte Worst-Case-Abschätzung.\n\nDas Ergebnis einer Rechnung ist wesentlich von der Maschinengenauigkeit abhängig. Zunächst können die Eingangsdaten nicht beliebig genau dargestellt werden. Daraus resultiert ein Fehler im Ergebnis. Dieser Fehler wird über die Kondition des Problems beschrieben. Multipliziert man die Kondition mit der Maschinengenauigkeit erhält man eine Abschätzung dieses Fehlers. Die zweite Fehlerquelle entsteht aus der Ungenauigkeit des verwendeten Algorithmus. Diese Fehlerverstärkung wird als Stabilität bezeichnet. Auch hierfür lässt sich manchmal die entsprechende Stabilitätskonstante angeben. Ein schlecht konditioniertes Problem oder ein mäßig stabiler Algorithmus erfordern also eine hohe Maschinengenauigkeit oder eine geeignete Problemumformulierung beziehungsweise die Verwendung eines stabileren Algorithmus.\n\nHeutige Computer arbeiten meist nach IEEE 754. Die Maschinengenauigkeit für die dabei verwendeten Datentypen ist\nformula_17 für einfache Genauigkeit (single precision) und formula_18 für doppelte Genauigkeit (double precision).\n\nIn der Praxis wird die Maschinengenauigkeit als kleinste positive Gleitkommazahl formula_4 ermittelt, für die auf der betreffenden Maschine die Bedingung\nerfüllt ist. Da die Zwischenergebnisse der folgenden Programme aufgrund der Verwendung von 2er Potenzen, bzw. 1.0 + 2er Potenz, entweder exakt oder gerade nicht mehr darstellbar sind, berechnen die folgenden Programme den relativen Abstand zweier Gleitkommazahlen. Die Maschinengenauigkeit bei symmetrischer Rundung ergibt sich dann aus der Hälfte des Ergebnisses.\n\nAb Fortran 90 kann die Maschinengenauigkeit durch Aufruf der Intrinsic-Funktion \"epsilon()\" berechnet werden. Für Fortran 77 und früher können folgende Statements verwendet werden (Variable vom Typ \"real\"):\n\n10 UMACHN = 0.5*UMACHN\n\n private static float calculateMachineEpsilonFloat() {\n\nfunction machine_epsilon: double;\nvar one_plus_halfepsilon: double;\nbegin\nend;\n"}
{"id": "1747256", "url": "https://de.wikipedia.org/wiki?curid=1747256", "title": "CalculiX", "text": "CalculiX\n\nCalculiX ist ein freies, unter der GPL stehendes Finite-Elemente-Programm. Es wird von Guido Dhondt und Klaus Wittig, beides Mitarbeiter der Firma MTU Aero Engines, zur dreidimensionalen Strukturberechnungen entwickelt. Es nutzt dabei das Abaqus-Eingabeformat für den Gleichungslöser. Daher lassen sich zahlreiche Prä- und Postprozessoren nutzen.\nBei numerischen Strömungssimulationen versteht sich CalculiX mit den freien CFD-Programmen \"duns\", \"ISAAC\" und OpenFOAM. Auch mit den kommerziellen FEM-Programmen Nastran und Ansys, dem freien FEM-Programm Code Aster und der Cloud-basierten Plattform SimScale kann CalculiX zusammenarbeiten.\n\nIm universitären Umfeld wird CalculiX beispielsweise von der \"FAM - Fachgruppe Angewandte Mechanik\" an der Universität Paderborn eingesetzt.\n\nNeben dem Einsatz in Linux oder anderen Unix-Versionen wie MacOSX stehen auch Windowsinstallationen zur Verfügung. Zu den bisherigen kommt nun in Windows 10 ab Version 1709 das Subsystem Linux (WSL). Dabei wird ein Linux wie Ubuntu oder Suse installiert und zusammen mit einem X-Server für Windows können nun tausende Linux-Programme wie Calculix auch mit Fenstern in Windows 10 ohne virtuelle Maschinen direkter genutzt werden.\n\n\n"}
{"id": "1747879", "url": "https://de.wikipedia.org/wiki?curid=1747879", "title": "Linuxwochen Österreich", "text": "Linuxwochen Österreich\n\nDie Linuxwochen sind eine österreichische Veranstaltungsreihe zum Thema Linux und freie Software, welche seit dem Jahr 2002 jeweils in den Monaten Mai bis Juli stattfindet. Dabei finden die einzelnen Veranstaltungen meist an einem Wochenende in einem jeweils anderen Bundesland statt. Die Linuxwochen sind die größte Veranstaltung zum Thema „Freie Software“ in Österreich.\n\nIm Jahr 2001 fanden in St. Pölten die „österreichischen Linuxtage“ statt. Es sollte dies ein Pendant zu ähnlichen Veranstaltungen in Deutschland sein, wie etwa dem LinuxTag. Die Veranstaltung wurde aber nicht der erhoffte Erfolg. Die österreichische Opensource-Community war nur wenig eingebunden und der Veranstaltungsort lag zu weit entfernt vom Zielpublikum. \n\nDeshalb wurde im folgenden Jahr begonnen, die Veranstaltung durch eine Veranstaltungsreihe zu ersetzen, die von der Community selbst organisiert wurde und verteilt im ganzen Land stattfinden sollte.\n\nSeit 2005 existiert ein Verein, welcher die Organisation der Linuxwochen betreibt. Getragen werden die Linuxwochen aber hauptsächlich von regionalen Vereinen und Nutzergruppen wie\n\nDie regionalen Veranstaltungen in den Bundesländern werden meist selbstständig von der lokalen Usergroup organisiert und durchgeführt. Der Eintritt zu den Veranstaltungen der österreichischen Linuxwochen ist in der Regel frei. Die Finanzierung erfolgt durch Sponsoren.\n\n\n"}
{"id": "1749917", "url": "https://de.wikipedia.org/wiki?curid=1749917", "title": "T2 SDE", "text": "T2 SDE\n\nT2 ist eine flexible quelloffene System-Entwicklungsumgebung (\"System Development Environment\", kurz SDE), die es erlaubt, automatisch angepasste Betriebssysteme mit neuen Technologien und Komponenten zu erstellen. Es wird oft auch als Distributionsbaukasten denn als übliche Linux-Distribution bezeichnet, da es durch die eigenen Automatismen zum Erstellen angepasster Systeme hervorstechen möchte und zudem über Linux hinaus an der Integration von Hurd-, Minix- und BSD-Kerneln arbeitet.\n\nT2 begann als eine Abspaltung von \"ROCK Linux\" um eine dezentralere Entwicklung und professionelle Basis für industrielle Anwendungen zu bieten. T2 war dabei der interne Projektname für „try two“ (second try), zu Deutsch also „zweiter Versuch“ und „technology two“, auf Deutsch etwa „zweite Technologie [-Generation]“.\n\nT2 ist weniger eine weitere Linux-Distribution, sondern mehr ein flexibler Baukasten, mit dem sich angepasste linuxbasierte Systeme erstellen lassen. Die Bandbreite reicht von eingebettete Systeme mit kleinem Speicherverbrauch, hochsicheren, spezialisierten Servern oder kompletten Desktop-Systemen.\n\nDurch die offene unter der GNU General Public License stehende Softwareumgebung können sich sowohl Privatanwender als auch Firmen gleichermaßen einbringen. Die von der Gemeinschaft getragene Entwicklung sorgt für eine schnelle Weiterentwicklung des Systems – dabei werden stetig neue Erweiterungen und Pakete zu T2 beigesteuert. Auch industrielle Projekte profitieren von der ständig wachsenden Nutzerzahl, indem sie Zugriff auf die dort gebündelten Ressourcen und Verbesserungen erhalten.\n\nT2 verfolgt die Philosophie möglichst nur originalbelassene Programmpakete zu verwenden, distributionsspezifische Modifikationen zu vermeiden und möglichst standardkompatibel zu sein. T2 folgt daher dem Filesystem Hierarchy Standard und der Linux Standard Base. Die Konfigurationen sind mit Schwerpunkt auf Sicherheit angelegt. Indem möglichst wenig Annahmen über althergebrachte Unixeigenschaften gemacht werden, sollen hinderliche Anachronismen vermieden werden.\n\nT2 besitzt ein automatisiertes Build-System, das den gesamten Prozess der Übersetzung durchführt. Zuerst wird eine Toolchain erstellt, um alle Pakete in einer Sandbox zu bauen, in der wiederum der Inhalt der zu installierenden Pakete geprüft und die zum Bauen notwendigen Vorbedingungen ermittelt werden. Erzeugte Dateien und Abhängigkeiten werden protokolliert. Cross-Builds zwischen verschiedenen Rechnerarchitekturen sind ebenfalls möglich. Zusätzlich werden regelmäßig automatische Regressionstests mit Cross-Builds zu den unterstützten Rechnerarchitekturen durchgeführt und somit der Status der einzelnen Pakete ermittelt.\n\nDas T2-Framework ermöglicht es dabei individuelle Zielsysteme zu definieren, unter anderem durch Auswahl von Paketen und der C-Bibliothek, Anpassung von Konfigurationen und vielem mehr. Das Buildsystem kombiniert all diese Definitionen und kontrolliert den Übersetzungsprozess. Abhängigkeiten können dabei komfortabel aufgelöst werden. Der Entwickler erhält mittels generischer Mechanismen zur Transformation von Compiler-Optionen, Bestimmung von Dateinamen und Eingriffsmöglichkeiten in den Programmablauf des Buildsystems die volle Kontrolle über das erstellte System. Wahlweise lassen sich installierbare CD-Abbilder und ROM-Speicherabbilder erstellen oder übersetzte Pakete via Netzwerk weiterverteilen.\n\nAufgrund der ungepatchten Quellpakete und des automatisierten Build-Systems ist T2 sehr portabel. Zu den bereits unterstützten Architekturen gehören ARM, Alpha, AVR32, Blackfin, HPPA, IA-64, MIPS, MIPS64, PowerPC, PowerPC64, SPARC, UltraSPARC, SuperH, x86 und x86-64. Das SDE lässt sich vom Anwender einfach um andere Zielarchitekturen erweitern.\n\nT2 will daher aufgrund der breiten Prozessorunterstützung und seinem flexiblen Buildsystem auch eine interessante Entwicklungsumgebung für eingebettete Systeme darstellen. Bei der Produktentwicklung entstehen dadurch Vorteile gegenüber der häufig üblichen Methode, von Grund auf anzufangen: Ein bereits definiertes Zielprodukt kann sofort reproduziert werden und es ist einfach, Modifikationen durchzuführen und dann den Übersetzungsprozess neu zu starten, ohne die gesamte Arbeit von Hand erneut zu erledigen. Beim Aktualisieren von Binärpaketen existiert ein Sicherungsmodus für bereits veränderte Konfigurationsdateien. Die Unterstützung verschiedener Compiler in Kombination mit Optionen wie die Verwendung der diet libc und uClibc ermöglichen es das System an den knappen Speicher eingebetteter Systeme anzupassen.\n\nAnders als bei konkurrierenden Paket-Systemen wie RPM oder DEB muss der Entwickler bei T2 keinen Quelltext schreiben, um Pakete zu erstellen. Stattdessen wird ein einfaches ASCII-Format verwendet, mit dem sich die Spezifikationen und Einstellungen eines Paketes festlegen lassen anhand dessen das System das Paket erstellt.\n\nT2 bietet über 3170 aktuelle Pakete als Basis für Eigenentwicklungen. Darin sind bereits das X Window System X.Org, bekannte Desktop-Umgebungen wie KDE und Gnome sowie viele Server- und Sicherheitsanwendungen enthalten.\n\nDie T2-Hardware-Erkennung wurde um den Linux-Hotplug-Mechanismus herum entwickelt. Auf diese Weise soll das gleiche Systemverhalten garantiert werden, egal ob Geräte schon beim Hochfahren vorhanden sind oder erst zur Laufzeit vom Nutzer angeschlossen werden.\n\nNetzwerke lassen sich mit einem bereitgestellten modularen Framework konfigurieren. Dieses unterstützt Netzwerkprofile, elementare IP-Konfiguration, mehrere Interfaces, Routing, stateful Firewalls, W-LAN, PPP einschließlich analoger Modems, PPPoE (Kabel und DSL) sowie CSD und GPRS für die Nutzung von Mobiltelefonen.\n\nT2 enthält die Möglichkeit eine Installations-CD mit vollständigem Installationsprogramm zu erstellen. Dieses erlaubt es Festplatten zu partitionieren, Dateisysteme zu erstellen, Mountpunkte zu definieren, Pakete auszuwählen und vieles mehr. Das Konfigurationsprogramm STONE ermöglicht es Administratoren Systemdienste, Netzwerke und Systemverhalten zu konfigurieren. Durch Verwendung systemeigener Konfigurationsdateien sind manuelle Änderungen im Normalfall ohne Konflikte möglich.\n\nDa bei der Entwicklung großer Wert auf Stabilität gelegt wird und regelmäßig neue Versionen herausgegeben werden, wird T2 gerne als Basis für externe Entwicklungen genommen. Beispiele hierfür sind unter anderem die kompakte Linux-Distribution Puppy Linux sowie Archivista, eine kommerzielle Lösung für Dokumentenmanagement und Archivierung der gleichnamigen Schweizer Firma und der Berliner „Platform Provider“ ExactCODE GmbH.\n\n\n"}
{"id": "1755462", "url": "https://de.wikipedia.org/wiki?curid=1755462", "title": "Sad Mac", "text": "Sad Mac\n\nDer (engl. für \"trauriger Mac\") ist ein Symbol, das bei älteren Computern aus der Apple Macintosh-Reihe (Old World ROM) verwendet wird, um einen beim Start des Systems aufgetretenen Fehler anzuzeigen, der den weiteren Start des Systems unmöglich macht. Es zeigt eine kleine Darstellung eines Macintosh 128k, mit dem dieses Symbol erstmals eingeführt worden ist, dessen eingebauter Monitor ein trauriges Gesicht mit nach unten gezogenen Mundwinkeln und ausgekreuzten (toten) Augen darstellt.\n\nUnterhalb des \"Sad Mac\"-Icons befindet sich eine Anzeige, die mit Hilfe von mehreren Hexadezimalziffern Aufschluss über Art und Grund des aufgetretenen Fehlers gibt. In den ersten, MC68000-basierten Apple Macintosh-Computern erfolgt die Anzeige ohne Ton. Spätere Modelle, die den \"Sad Mac\" verwenden, spielen bei einem solchen Fehler auch einen kurzen Klang oder eine Melodie. Die Tonfolge variiert je nach Fehler und lässt geübten Servicetechnikern Rückschlüsse auf die Art des Fehlers zu; bei der häufigen Ursache fehlerhafter Speicher z. B. auf die betroffene Speicherbank.\n\nDer \"Sad Mac\" kann gezielt hervorgerufen werden, indem beim Start die \"Unterbrechen\"-Taste gedrückt wird (wenn das entsprechende Gerät über eine solche verfügt), oder indem nach dem Startton die Tastenkombination \"Kommandotaste + Ein-/Ausschalttaste\" gedrückt wird.\n\nWährend eines erfolgreichen Starts wird ein ähnliches Bild mit einem glücklichen Gesicht gezeigt.\n\n"}
{"id": "1755506", "url": "https://de.wikipedia.org/wiki?curid=1755506", "title": "Bombe (Fehlermeldung)", "text": "Bombe (Fehlermeldung)\n\nDas Symbol einer Bombe im Rahmen einer Fehlermeldung wurde ursprünglich von Susan Kare entworfen und wird unter dem Betriebssystem Mac OS (jedoch nicht mehr seit macOS) angezeigt, wenn das Betriebssystem abstürzt. Zuerst wurde die Bombe im 1984 eingeführten Macintosh 128k eingesetzt.\n\nDie Anzeige enthält oft eine Fehlermeldung in Textform und in manchen Fällen eine Schaltfläche, mit dem das fehlerhafte Programm beendet werden konnte, ohne das ganze Gerät neu zu starten. Ebenso enthalten sein kann eine Schaltfläche, mit der der Rechner per Mausklick neu gestartet werden kann. Bei einigen kritischen Fehlern funktionieren diese Schaltflächen jedoch nicht mehr, obwohl sie angezeigt werden. Die Darstellung der Fehlermeldung wurde oft kritisiert, weil sie kaum Rückschlüsse auf den tatsächlichen Grund des Fehlers zulässt. Dies war jedoch eine bewusste Entscheidung der Entwickler mit dem Ziel, für die meisten Benutzer irreführende oder unnütze Informationen auszuschließen. Durch den Einsatz eines Debuggers (üblicherweise MacsBug oder mit ResEdit) können diese Informationen jedoch trotzdem ermittelt werden.\n\nmacOS wurde nicht auf Basis des Vorgängers Mac OS entwickelt und enthält daher dieses Symbol nicht mehr in Fehlermeldungen. Im Fall eines Systemabsturzes erscheint hier, wie bei anderen Betriebssystemen aus der Unix-Familie, eine Kernel panic.\n\nSeitdem es fest in die Computer als ROM-Bausteine eingesetzt wurde, benutzt das Betriebssystem TOS, das auf den Computern der Atari-ST-Reihe und deren Nachfolger eingesetzt wird, ebenfalls kleine Bombensymbole, um einen Fehler anzuzeigen. Hier erscheint jedoch nur eine bestimmte, von der Art des Problems abhängige Anzahl von Bomben am linken Rand des Bildschirms, auf halber Höhe. Fehler in einzelnen Anwendungen haben hier oft nicht den Absturz des Systems zur Folge, da TOS ursprünglich nur die Ausführung eines Programmes zu jedem Zeitpunkt erlaubt (mit Ausnahme von sogenannten \"Accessories\") und somit parallel laufende Anwendungen nicht, wie bei einem Multitasking-Betriebssystem, beeinflusst werden können. In einem solchen Fall verschwindet die Anzeige nach kurzer Zeit wieder, und das Gerät kehrt zur Benutzeroberfläche des Betriebssystems zurück (solange keine so fatalen Fehler auftraten, die dies unmöglich machen). Bei den ersten Geräten, die im Spätsommer 1985 ausgeliefert wurden und das Betriebssystem noch auf Diskette mitgeliefert bekamen, wurden statt der Bomben (Atom‑)Pilze verwendet.\n\n"}
{"id": "1757585", "url": "https://de.wikipedia.org/wiki?curid=1757585", "title": "Initramfs", "text": "Initramfs\n\ninitramfs steht für \"initial ram filesystem\" (sinngemäß übersetzt \"Ausgangsdateisystem im Arbeitsspeicher\") und ist der Nachfolger von initrd. Das initramfs ist ein komprimiertes Archiv, das für den Systemstart benötigte Dateien enthält. Es kann vom Linux-Kernel beim Booten als Stammverzeichnis eingehängt werden. Anschließend wird ein auf dem initramfs vorhandenes Programm (init) gestartet. Das gestartete Programm kann unterschiedliche Aufgaben erfüllen. Bei eingebetteten Systemen kann die ganze Funktionalität des Systems im initramfs enthalten sein. Personal Computer nutzen das initramfs oft nur als einen Zwischenschritt, um Treiber zu laden und andere Vorbereitungen für den Start des eigentlichen Systems zu treffen. Durch das initramfs bzw. initrd wurde es möglich, den Bootprozess unter Linux flexibler zu gestalten und Funktionalität aus dem Kernel in den Userspace auszulagern.\n\nDer Linux-Kernel kann ab Version 2.5.46  von einem initramfs booten. Das initramfs-Archiv kann im Kernel selbst enthalten sein oder vom Bootloader aus einer Datei in den Arbeitsspeicher geladen werden. Der Kernel dekomprimiert das initramfs-Archiv und hängt das entpackte Archiv dann als Stammverzeichnis ein. Als Nächstes wird versucht, das Programm /init aus dem initramfs zu starten. Schlägt das Starten fehl, versucht der Kernel, das eigentliche Root-Device einzuhängen und dort /sbin/init zu starten.\n\nDas initramfs selbst ist ein cpio-Archiv, das meist eine Unix-Shell (oft BusyBox) und andere grundlegende Programme enthält. In diesem Fall ist /init ein einfaches Shellskript, das die im initramfs enthaltenen Programme auf die gewünschte Weise verknüpft. Es ist aber auch möglich, dass /init ein C-Programm ist, das gegen eine kleine Variante der libc gelinkt wurde. Die letzte Aufgabe von /init ist es meist, das eigentliche Root-Device über das Stammverzeichnis einzuhängen und /sbin/init zu starten.\n\n\n"}
{"id": "1767043", "url": "https://de.wikipedia.org/wiki?curid=1767043", "title": "Cain &amp; Abel", "text": "Cain &amp; Abel\n\nCain & Abel ist laut des Entwicklerteams unter Massimiliano Montoro ein Passwort-Rettungswerkzeug für Windows, ist aber eher ein Multifunktionswerkzeug.\n\nEs erlaubt das einfache Auslesen aller Passwörter, die im Browser gespeichert wurden, außerdem das Cracking verschlüsselter Passwörter (Hashwerte) mit Hilfe von Wörterbüchern, Brute-Force und Rainbow-Tables sowie das Aufzeichnen von Passwörtern und VoIP-Unterhaltungen im Netz via ARP-Spoofing. Dadurch ist es ebenfalls in der Lage, Man-in-the-middle-Angriffe gegen eine Reihe von SSL-basierten Diensten und RDP durchzuführen.\n\nDiverse Informationen von Windows-Systemen auszulesen und das Analysieren von Routing-Prozessen ist ebenfalls möglich.\n\nAbel, das mitgelieferte Clientprogramm, kann ferngesteuert über das Windows-Netzwerk installiert werden und liest die TCP/UDP-Tabellen, die LSA-Secrets und die Hashwerte der Benutzerkonten aus. Es verschafft dem Cain-Nutzer außerdem Remote-Konsolenzugriff. Abel verbirgt sich dabei nicht vor Benutzern des Systems.\n\nCain & Abel verwendet die WinPcap-Treiber, der AirPcap-Adapter wird ab Version 4.0 unterstützt. Mit letzterem ist das passive Mitlesen von Datenverkehr in WLANs sowie Angriffe auf WEP möglich. Ab Version 4.9.1 ist es auch möglich, Angriffe gegen mit WPA-Handshake und WPA-PSK gesicherte WLANs durchzuführen.\n\nDie von Cain aufgezeichneten Passwort-Hashes können auch an andere Programme wie John the Ripper oder Distributed Password Recovery weitergegeben werden. Cain selbst kann Aufzeichnungen von Netzwerkverkehr im Datenformat von libPcap/WinPcap lesen und extrahiert dann automatisch Passwörter bzw. deren Hashwerte.\n\nDie Besonderheit von Cain ist die Zusammenfassung zahlreicher Funktionen unter einer einzigen Oberfläche, es existiert kein weiteres Werkzeug dieser Art.\n\nDa Cain & Abel Sicherheitsvorkehrungen umgeht, muss es nach Inkrafttreten des sogenannten Hackerparagrafen (§ 202c StGB) in Deutschland als Computerprogramm zum Ausspähen von Daten aufgefasst werden. Somit kann die illegale Benutzung der Software unter Strafe gestellt werden.\n\n"}
{"id": "1767640", "url": "https://de.wikipedia.org/wiki?curid=1767640", "title": "Pango", "text": "Pango\n\nPango ist eine freie Programmbibliothek für das Zeichnen und Layout von internationalisiertem Text. Pango wird beispielsweise in GTK+ ab Version 2 und in Mozilla Firefox sowie Thunderbird zum Zeichnen der Schriften eingesetzt. Der Name Pango setzt sich zusammen aus dem griechischen „Pan“ (, „alle“) und dem japanischen „Go“ (, „Sprache“) und soll die Internationalisierungsfähigkeiten von Pango hervorheben.\n\nDurch die Verwendung von Cairo sind Effekte wie Kantenglättung möglich.\n\nAuch der text-to-postscript-Konverter \"paps\" (Pango-based postscript converter) basiert auf Pango.\n\n"}
{"id": "1767894", "url": "https://de.wikipedia.org/wiki?curid=1767894", "title": "Windows-Systemdienst", "text": "Windows-Systemdienst\n\nEin Windows-Systemdienst (auch kurz einfach Dienste oder ) ist ein Programm, das als spezialisierter Dienst im Hintergrund von Windows läuft und Funktionalitäten des Betriebssystems bündelt um sie Dritten zur Verfügung zu stellen. Vom Konzept her ist er dem Unix-Daemon ähnlich.\n\nWindows-Systemdienste bilden sozusagen das „Rückgrat“ von Windows und vermitteln dabei oftmals zwischen Hardware- und Software-Ebene. Ein gutes Beispiel hierfür ist der „Plug-and-Play“-Dienst: ohne diesen könnten weder Applikationen die angeschlossene Hardware (z. B. eine Maus) nutzen, noch könnte sich ein Gerät automatisch am Betriebssystem anmelden. Durch einen sogenannten Dienstvertrag (auch Schnittstellenspezifikation) wissen sowohl Hardware als auch Software im Voraus genau, wie sie einen Dienst ansprechen müssen, um eine bestimmte Funktionalität zu nutzen.\n\nDie eigentliche Implementierung des Dienstes hängt dabei vom Umfeld (Windows-Version, 32- oder 64-Bit-System usw.) ab, die Schnittstellen des „Plug & Play“-Dienstes sind aber auf allen Windows-Systemen (ab XP) vom Prinzip her fast gleich oder zumindest rückwärtskompatibel.\n\nDienste kommunizieren dabei nicht direkt mit dem Anwender, sie selbst besitzen keine Benutzerschnittstelle. Häufig gibt es zur Konfiguration und Steuerung eines Dienstes separate Programme, in Windows werden die meisten dieser Programme in der Systemsteuerung zusammengefasst.\n\nWindows stellt den \"Service Control Manager\" codice_1 bereit, der das Starten und Anhalten von Diensten verwaltet. Er ist ein RPC-Server. Seine Benutzerschnittstellen sind die Microsoft Management Console und der Kommandozeileninterpreter codice_2. Ein Programm, das als Dienst gestartet werden soll, muss so geschrieben sein, dass es mit den Befehlen codice_3 des \"Service Control Managers\" umgehen kann.\n\nIn der Regel liegen als Dienst auszuführende Programme als ausführbare Datei vor. In einer Dynamic Link Library vorliegende Programme werden über die ausführbare Datei codice_4 (\"service host\") aufgerufen, die die Dienste lädt, ausführt und gegebenenfalls beendet. Ein Dienst kann \"automatisch\" beim Hochfahren des Betriebssystems gestartet werden, \"manuell\" auf Anforderung anderer Programme gestartet werden oder \"deaktiviert\" sein.\n\nEin Dienst wird installiert, indem sein Name, die ausführbare Datei und andere Angaben in die Registrierungsdatenbank eingetragen werden.\nStandardmäßig arbeiten Dienste als \"lokales System\" mit umfassenden Zugriffsrechten. Sie können aber auch so eingerichtet werden, dass sie unter einem Benutzerkonto oder mit minimalen Zugriffsrechten als \"Netzwerkdienst\" oder \"lokaler Dienst\" arbeiten.\n\nDienste werden mittels *.INF-Skripts von \"SetupAPI\" installiert und deinstalliert; ein neu installierter Dienst kann dabei gestartet werden, ein laufender Dienst kann vor der Deinstallation gestoppt werden.\n\nDienste können mit dem MMC-Snap-In \"Services.msc\" verwaltet werden. Erweiterte Möglichkeiten wie das Erstellen, Löschen und Definieren der Abhängigkeiten von Diensten bietet das Kommandozeilen-Tool \"sc.exe\". Dieses ist seit Windows XP bzw. Windows Server 2003 in der Standardinstallation von Windows enthalten, kann aber auch unter anderen Windows-Versionen über das Resource Kit nachinstalliert werden.\n\nEinige grundlegende Systemfunktionen werden von Diensten bereitgestellt. Solche Dienste werden ungeachtet der Variante von Windows automatisch mit dem Betriebssystem gestartet.\n\nBeispiele:\n\nAuch Programme, die nicht zum Lieferumfang von Windows gehören, arbeiten regelmäßig als Dienst. Typische Beispiele dafür sind:\n\n"}
{"id": "1771768", "url": "https://de.wikipedia.org/wiki?curid=1771768", "title": "Denemo", "text": "Denemo\n\nDenemo ist ein grafisches Notensatzprogramm. Denemo ist Freie Software unter der GPL und basiert auf der freien Bibliothek GTK+. Zur Ausgabe der gesetzten Noten in Druckqualität wird Lilypond benutzt. Mit einem internen Sampler können die Noten abgespielt werden. Wahlweise existiert auch eine flexiblere Schnittstelle über JACK.\n\nZiel des Programms ist es, effektiv und in hoher Geschwindigkeit Notation für den LilyPond Music Engraver zu erstellen. Der Benutzer braucht dazu nicht die komplexe Lilypond-Syntax zu lernen. Komponieren, Transkribieren, Arrangieren und Playbackfunktionen werden durch die PC-Tastatur, MIDI-Keyboards oder ein Mikrofon gesteuert. Denemo soll nicht nur ein Notationsprogramm sein, sondern eine vollständige Komponier- und Renderumgebung (Noten→Klang).\n\nDenemo verwendet ein eigenes XML-Format zur Speicherung der Notendaten (\"Dateiendung: .denemo\"). Alternativ werden folgende Formate unterstützt (Im- und Export):\nEs besteht außerdem die Möglichkeit, Dateien in den Formaten PDF oder PNG zu exportieren.\n\n"}
{"id": "1776403", "url": "https://de.wikipedia.org/wiki?curid=1776403", "title": "NoteEdit", "text": "NoteEdit\n\nNoteEdit ist ein freies Musik-Notensatzprogramm für GNU/Linux.\n\nEs unterstützt (polyphone) Stimmen in unbegrenzter Anzahl und Länge, MIDI-Wiedergabe von geschriebenen Noten, Akkorden, Texten und enthält eine Anzahl von Export- und Import-Filtern zu vielen verschiedenen Formaten wie MIDI, MusicXML, ABC, MUP (Music Publication Program), PMX, MusiXTeX und LilyPond.\n\nEs eignet sich als graphisches Interface zur Eingabe von Noten, deren Druckfassung man dann noch mit den mächtigen Satzprogrammen LilyPond oder MusiXTeX optimieren kann.\n\nNoteEdit ist in C++ geschrieben, verwendet die Qt-Bibliothek und ist das K Desktop Environment (KDE) für Unix eingebunden.\n\nDie Entwickler von NoteEdit arbeiten inzwischen an einem neuen Projekt namens \"Canorus\", das zum Nachfolger von NoteEdit werden soll, und das für verschiedene aktuelle Betriebssysteme zur Verfügung steht.\n\n"}
{"id": "1779100", "url": "https://de.wikipedia.org/wiki?curid=1779100", "title": "Audio Unit", "text": "Audio Unit\n\nEine Audio Unit (AU) ist ein Plug-in in der Core-Audio-Technologie von Apples macOS. Ihre Aufgabe ist die Bearbeitung von Tonmaterial (als Effekt) oder die Umwandlung von MIDI-Daten in Audiosignale (als Software-Instrument). Dieser Prozess kann in Echtzeit geschehen (je nach Rechenaufwand mit zeitlicher Verzögerung) oder bei sog. Offline-Berechnung noch schneller.\n\nDas Prinzip der Audio Units ist die Sammlung aller Plugins an einem Ort. Ein beliebiges Programm, die sogenannte Host-Software, muss Core Audio unterstützen, um so Zugriff auf alle Plugins zu erhalten. Die Audio Units lösen damit unter macOS und im Besonderen dem Sequenzer-Programm Logic Steinbergs VST-Schnittstelle ab, die ab Version 6 nicht mehr von Logic unterstützt wird. Im Gegensatz zu VSTs sind AUs jedoch als Teil von Core Audio plattformgebunden an macOS und laufen nicht unter anderen Betriebssystemen wie Windows oder Linux, was auch ihre Verbreitung begrenzt. Die Dateinamenserweiterung der Audio Unit Plugins ist in der Regel \"component\".\n\nAudio Units können von anderen Herstellern entwickelt sein und zusätzlich installiert werden, einige sind bereits im Betriebssystem integriert. Die meisten Hersteller von Software-Instrumenten und -Effekten portierten ihre VSTs nach Bekanntgabe der neuen Schnittstelle und stellten AU- sowie VST-Versionen bereit. Das Plugin „VST to Audio Unit Adapter“ des Unternehmens FXPansion macht es möglich, VST-Plugins auch in eine AU-Schnittstelle einzubinden, indem es für den AU-Host als Plugin und für das VST-Plugin wiederum als Host fungiert.\n\nEine weitere verbreitete Audio-Plugin-Schnittstelle ist Real Time AudioSuite, entwickelt von Digidesign.\n\n"}
{"id": "1788167", "url": "https://de.wikipedia.org/wiki?curid=1788167", "title": "TX-0", "text": "TX-0\n\nDer TX-0 (\"Transistorized Experimental computer zero\"), auch tixo genannt, gilt als der erste transistorbasierte Computer und wurde 1955 am MIT Lincoln Laboratory entwickelt und ab 1956 eingesetzt. Er war Nachfolger des Whirlwinds, der noch nicht über Transistoren verfügte, und Vorgänger der PDP-1. Ursprünglich sollte er nur die Fähigkeiten von Transistoren demonstrieren und das Nachfolgemodell TX-2 unterstützen.\n\nDie Entwicklung wurde von Ken Olsen überwacht, beteiligt war auch der Computeringenieur Wesley A. Clark, der die Logik entwickelte.\nDer Computer besteht aus Transistoren, der Arbeitsspeicher basiert auf Magnetkernspeichern. Die Spitzengeschwindigkeit betrug 83 kOPS (OPS: Operationen pro Sekunde). Wie bei der PDP-1 besteht der Hauptspeicher aus 18 Bit großen Worten. In der Grundversion war die Speicherkapazität 65.536 Worte. 1958 wurde der Speicher auf den Nachfolgerechner TX-2 übertragen und die TX-0 wurde mit einem Speicher von 4096 Worten ausgestattet. 1959 wurde die Kapazität auf 8192 Worte erweitert . Die Adressgröße wurde von 16 auf 13 Bit reduziert.\n\nAb 1957 gab es ein 12 Zoll Oszilloskop (512 × 512 Pixel) als Monitor und ab 1958 einen Lichtgriffel. Außerdem verfügte das Gerät über einen Lautsprecher. Als Peripherie gab es Drucker und Bandlaufwerke (Magnetbänder und Lochstreifen).\n\nDer TX-0 wurde in den ganzen 1960er Jahren am MIT eingesetzt. Da besonders die teuren Magnetkernspeicher für das Nachfolgeprojekt TX-2 requiriert wurden, wurde der TX-0 im Lincoln Lab 1958 ausgesondert und dem Research Laboratory of Electronics des MIT übergeben, in dem in den 1960er Jahren die Anfänge der Künstlichen Intelligenz und der Hackerkultur gelegt wurden.\nZwischen dem ersten Videospiel Tennis for Two und dem Computerspiel Spacewar! gab es bereits einige Demos und einfache, größtenteils textbasierte Spiele, sowie Schach und Tic-Tac-Toe.\n\nDer TX-0 gilt als einer der ersten modernen transistorisierten Computer. Mit der Möglichkeit der direkten Programmierung (ohne Lochkarten) entstanden die ersten Hacker-Clubs.\n\n\n\nDer Emulator M.E.S.S. emuliert sowohl den TX-0 als auch die PDP-1.\n\n\n"}
{"id": "1789337", "url": "https://de.wikipedia.org/wiki?curid=1789337", "title": "Kdenlive", "text": "Kdenlive\n\nKdenlive ist eine nichtlineare Videoschnittsoftware für die KDE-Plattform und für unixartige Betriebssysteme wie Linux und FreeBSD, MacOS sowie für Windows. Kdenlive steht unter der freien GNU General Public License und kann kostenlos genutzt und weitergegeben werden.\n\nMit Kdenlive ist es möglich, mehrere Bild- und Tonspuren zu bearbeiten. Kdenlive verwendet die MLT Video Rendering Engine. Die aktuelle Version unterstützt den KDE Plasma Desktop. Für die \"K-Desktop-Environment\"-3.5-Serie ist Kdenlive in der Version 0.5 verfügbar.\n\nDer relativ große Funktionsumfang siedelt das Programm in etwa auf dem Niveau von kommerziell erhältlicher professioneller Software an.\n\nDer Name Kdenlive steht für „KDE Nicht-Linearer Video-Editor“.\n\nDas Projekt wurde 2002 von Jason Wood ins Leben gerufen.\n\nKdenlive ist seit 2015 Bestandteil der KDE Software Compilation.\n\nIm Gegensatz zu den meisten anderen freien Videoschnittsystemen bietet Kdenlive die Möglichkeit, die Bedienungsoberfläche auf ein bei professioneller Videoschnittsoftware übliches \"Look and Feel\" einzustellen. Es integriert sich nahtlos in die KDE-Oberfläche.\n\n"}
{"id": "1790440", "url": "https://de.wikipedia.org/wiki?curid=1790440", "title": "BESM (Computer)", "text": "BESM (Computer)\n\nBESM (russisch БЭСМ) ist der Name einer sowjetischen Großrechnerserie. Er steht für „Быстродействующая Электронно-Счётная Машина“ (wörtliche Übersetzung: „Schnellarbeitende Elektronen-Rechenmaschine“).\n\nBESM-1 war die erste Rechenanlage aus der Serie und hatte 5000 Vakuumröhren. Nur eine BESM-1 wurde gebaut. Als sie 1952 fertig war, war sie zunächst der schnellste Rechner in Europa. Gleitkommazahlen wurden als 39-Bit-Wörter kodiert, es wurden 32 Bit für den numerischen Teil, 1 Bit für das Vorzeichen und 1+5 Bit für den Exponenten verwendet. Der Schreib/Lese-Speicher war ein Ferritkernspeicher. Der externe Speicher bestand aus 4 Magnetbandspeichern, die jeweils 30 000 Wörter speichern konnten. Außerdem war ein Magnettrommelspeicher angeschlossen mit einer Kapazität von 5120 Wörtern und einer Zugriffsrate von 800 Wörtern/Minute. Die Rechenleistung betrug 8–10 KFlops. Ohne Berücksichtigung des Kühlsystems verbrauchte der Röhrencomputer etwa 30 kW. \n\nBESM-2, BESM-3M und BESM-4 bestanden ebenfalls aus Röhren.\n\nBESM-4a war der erste Transistorrechner des sozialistischen Weltteils.\n\nBESM-6 war ein komplett neu entwickeltes Supercomputersystem, wurde 1965 am Institut für Präzisionsmechanik und Computertechnologie entwickelt und ab 1967 produziert, auch für den Export. Die BESM-6 wurde zum Beispiel an der Technischen Universität Dresden und beim Kombinat (VVB) Schiffbau in Rostock eingesetzt. Insgesamt wurden bis 1987 355 Exemplare hergestellt.\n\nBESM-6 war der erste sowjetische Rechner mit einem Betriebssystem. Als Programmiersprache wurde Fortran-4 verwendet.\n\nNachfolger von BESM wurde Elbrus.\n"}
{"id": "1792502", "url": "https://de.wikipedia.org/wiki?curid=1792502", "title": "Numerische Simulation", "text": "Numerische Simulation\n\nAls numerische Simulation bezeichnet man allgemein Computersimulationen, welche mittels numerischer Methoden wie zum Beispiel mit Turbulenzmodellen durchgeführt werden. Bekannte Beispiele sind Wetter- und Klimaprognosen, numerische Strömungssimulation oder Festigkeits- und Steifigkeitsberechnungen.\n\nNumerische Simulationen lassen sich in folgende Schritte unterteilen:\n\nIn der Modellierung (Modellaufbau) werden die grundlegenden Eigenschaften einer Simulation in Form mathematischer Modelle formuliert. Die Modelle werden in der Regel unabhängig von einer konkreten Aufgabenstellung entwickelt.\n\nBei der Parametrisierung werden Modelle ausgewählt, mit konkreten Rechenwerten ausgestattet und so miteinander verknüpft, dass das Gesamtmodell möglichst gut einen konkreten Anwendungsfall darstellt. Ungenaue Kenntnis der Modelle oder der Randbedingungen ist die häufigste Fehlerquelle bei Simulationen.\n\nBei den numerischen Methoden handelt es sich um besondere Rechenverfahren, die unter das Teilgebiet der numerischen Mathematik fallen.\nDie eigentliche Berechnung erfolgt durch Starten eines Lösungsprogrammes, des so genannten \"Lösers\". Dieses führt die eigentliche Berechnung durch und speichert die Berechnungsergebnisse. Da eine geschlossene Lösung der Systeme in der Regel nicht möglich ist, werden iterative Lösungsverfahren angewendet, um eine Näherungslösung zu finden. Bei nahezu allen Simulationsberechnungen müssen sehr große Datenmengen verarbeitet werden. Dennoch kann die Rechenzeit je nach Simulationsverfahren stark variieren. Daher werden in diesem Bereich häufig Parallelrechner, Vektorrechner oder PC-Cluster verwendet, bei denen viele Einzelrechner gleichzeitig an einem Ergebnis arbeiten. Allerdings lässt sich die Geschwindigkeit solcher Berechnungen nicht beliebig steigern, da mit der Zahl der beteiligten Rechenkerne in der Regel auch der Kommunikationsaufwand steigt (Skalierbarkeit). \n\nDie Ergebnisse der Berechnung bezeichnet man als Rohdaten. Diese liegen als digitale Ergebnisdateien vor, die nun so aufbereitet werden müssen, dass sie für Menschen verständlich sind. Die dazu erforderliche Auswertung ist ein elementarer Bestandteil der Simulation. Für die Auswertung kommen zum einen statistische Methoden zum Einsatz, die Daten zusammenfassen oder analysieren. Ein wichtiger Aspekt liegt aber auch in der Möglichkeit, Daten grafisch aufzubereiten.\n\nDie mathematischen Probleme numerischer Simulationen lassen sich oft auf die Lösung von Differentialgleichungen, Lösung von Eigenwert- und Eigenvektor-Problemen, Lösung von linearen Gleichungssystem oder Berechnung von Integralen zurückführen. Aufgrund der Komplexität der Simulationsprogramme sowie der Unsicherheit der angesetzten Parameter und Randbedingungen werden zur Ergebniskontrolle oft parallel auch begleitende Verfahren, wie beispielsweise analytische Berechnungen, eingesetzt.\n\nDie Komplexität verschiedener numerischer Simulationen ist sehr unterschiedlich. Daher gehören Probleme wie Festigkeitsberechnungen oder Schwingungsanalysen von Gebäuden und Maschinenteilen mittlerweile zum Standardwerkzeug der Konstrukteure – bei anderen Vorgängen (Wettervorhersagen, Klimaberechnungen) bewegt man sich dagegen an den oder jenseits der Grenzen der Leistungsfähigkeit moderner Computer. Hinzu kommen noch grundsätzliche Probleme wie das chaotische Verhalten vieler dynamischer Systeme.\n\nDie Einsatzgebiete von numerischen Simulationen sind vielfältig. Einige wichtige oder bekannte Beispiele sind:\n\n\n\n\n\n\nEin Bereich in denen numerische Simulationen eingesetzt werden sind Strömungssimulationen. Luftströmungen werden durch ein Rechenmodell ermitteln, dessen Raum in ein Gitter bestehend aus Zellen oder Voxel eingeteilt ist (Diskretisierung). \n\nDer Vorgang hat eine gewisse Ähnlichkeit mit der digitalen Darstellung von Fotos am Computer, die nun aus einzelnen Bildpunkten (Pixeln) bestehen. Jedes Pixel besitzt nur einen einzigen Farbwert, obwohl das reale Bild eigentlich kontinuierlich ist, d. h., es werden Bereiche zu gleichfarbigen Flächen zusammengefasst. Bei ausreichend großem Betrachtungsabstand fließen selbst dann die Farbwerte für das Auge scheinbar wieder zu einem kontinuierlichen Bild zusammen. Ist die Auflösung der digitalen Bilddarstellung zu gering, dann wirkt das Foto unscharf oder treppenartig. \n\nAnders als bei einem Pixelbild, das nur zwei räumliche Dimensionen und eine Farbinformation hat, bestehen Strömungssimulationen normalerweise aus drei räumlichen Dimensionen. Für jeden der Punkte gibt es – je nach Problem – mehrere Kenngrößen, die ihrerseits voneinander abhängig sein können. Die physikalischen Größen (z. B. Druck oder Temperatur) benachbarter Gitterpunkte ändern sich im Verlauf der Berechnung durch gegenseitige Beeinflussung. \n\nBei der numerischen Simulation auf einem Gitter gelten für die Auflösung ähnliche Regeln wie bei der Darstellung von Fotos am Computer. Ist die räumliche Auflösung zu gering (große Zellen), dann wird die Physik nicht gut abgebildet und es kommt zu Ungenauigkeiten. Daher ist man an einer möglichst hohen räumlichen Auflösung interessiert. Andererseits wirken sich bei einer hohen Auflösung die Rechenleistung oft nicht ausreichend, um in akzeptabler Zeit ein Ergebnis zu erhalten. Die Aufteilung in 100×100×100 Zellen ergibt beispielsweise eine Million Punkte. Halbiert man die Kantenlänge dieser Zellen, so erhöht sich die Zahl auf acht Millionen. Auch bei modernen Rechnern stößt die Auflösung daher sehr schnell an Grenzen der Rechenleistung.\n\nSimulationen in anderen Einsatzbereichen verwenden Systeme, die nicht nur aus drei räumlichen Dimensionen, sondern beispielsweise aus drei räumlichen und einer zeitlichen Dimension bestehen. Für jeden der Gitterpunkte kann es zudem eine Vielzahl von Kenngrößen geben. Neben der beschriebenen kubischen Gitterform, die sich oft aus der Diskretisierung der Dimensionen ergibt, werden auch andere Gitterformen für die Simulation verwendet, beispielsweise bei der Finite-Elemente-Methode. Des Weiteren gibt es Simulationen die keine Gitterstruktur nutzen, Teilchensystemen wie das einfache Modell harter Kugeln sind ein Beispiel hierfür.\n"}
{"id": "1793373", "url": "https://de.wikipedia.org/wiki?curid=1793373", "title": "Black Hat Briefings", "text": "Black Hat Briefings\n\nDie Black Hat ist der Name verschiedener Konferenzen zur Informationssicherheit, die seit 1997 an verschiedenen Orten stattfinden, darunter regelmäßig Las Vegas, Amsterdam, Barcelona und Abu Dhabi. Die einzelnen Veranstaltungen werden unterteilt in die Black Hat Briefings und die Black Hat Trainings.\nDer Name ist abgeleitet von der Hacker-Bezeichnung Black Hat.\n\nBlack Hat wurde 1997 von Jeff Moss, dem Veranstalter der DEF CON, gegründet, mit dem Ziel, IT-Sicherheitsbeauftragte von Unternehmen und der öffentlichen Verwaltung in Kontakt mit dem \"Untergrund\" der Hacker zu bringen. Auf den Konferenzen werden von den Vortragenden der aktuelle Wissensstand zu neuen Sicherheitslücken, Verteidigungsmechanismen und Trends in der IT-Sicherheitsbranche erläutert. Neben den Konferenzen (\"Black Hat Briefings\") umfasst das Portfolio Dienstleistungen wie Codereview und Sicherheitsuntersuchungen (\"Black Hat Consulting\") und Sicherheitsschulungen (\"Black Hat Training\").\n\nIm Jahr 2005 übernahm die Firma \"CMP Media\" Black Hat, Jeff Moss fungiert weiterhin als Veranstalter der Konferenzen. 2008 wurde CMP Media umbenannt in United Business Media, die Black-Hat-Konferenzen werden von dem Geschäftsbereich TechWeb veranstaltet.\n\nDie Hauptveranstaltung findet seit 1997 jedes Jahr in Las Vegas, Nevada, statt. Seit 2000 gibt es weitere Veranstaltungsreihen u. a. in Asien und Europa, die jedoch nicht jedes Jahr durchgeführt wurden.\n\n"}
{"id": "1795519", "url": "https://de.wikipedia.org/wiki?curid=1795519", "title": "Dashcode", "text": "Dashcode\n\nDashcode ist eine Entwicklungsumgebung von Apple für Mac OS X Leopard 10.5 und neuer, mit der man einfach Widgets für das Dashboard von Mac OS X sowie Web-Anwendungen für das iPhone und Apple Safari erstellen kann. Beide basieren auf Web-Standards wie HTML, CSS und JavaScript.\n\nDashcode bietet einen Code-Editor, eine große Sammlung an vorgefertigten Elementen, die der Entwickler per Drag und Drop auf der Arbeitsfläche platzieren und mit eigenen oder vorgegebenen JavaScript-Snippets verbinden kann, und einen Debugger.\nMit letzterem kann man den JavaScript-Code über Haltepunkte unterbrechen und Schritt für Schritt ausführen und damit debuggen.\nDie Oberfläche von Dashcode orientiert sich dabei an Xcode und Interface Builder (Icons, Panels).\n\nDashcode war auf der WWDC 2007 vorgestellt worden, und war zum ersten Mal bei Mac OS X Leopard 10.5 in die Xcode Tools 3.0 integriert. Es existierte auch eine Version für Mac OS X Tiger 10.4, die aber schnell nicht mehr unterstützt wurde.\nBei Markteinführung des iPhones waren mit Dashcode programmierte Web-Apps die einzige Möglichkeit, Programme von anderen Anbietern auszuführen. Das änderte sich erst im Frühjahr 2008, als Apple das iPhone SDK 2.0 vorstellte.\n\nBei Xcode 4.3, das den alten Developer-Ordner in einer einzigen Anwendung (Xcode.app) zusammenfasst, ist Dashcode nicht mehr Bestandteil der Developer Tools. Es kann aber nach wie vor kostenlos über Apples Entwickler-Downloadportal heruntergeladen werden (eine kostenfreie Registrierung ist dafür nötig.)\nIn OS X Mavericks 10.9 wird die aktuelle Version von Dashcode, 3.0.5, nicht mehr unterstützt. Auf Anfrage teilt Apple mit, dass Dashcode nicht mehr weiterentwickelt wird.\n"}
{"id": "1796740", "url": "https://de.wikipedia.org/wiki?curid=1796740", "title": "UltraVNC", "text": "UltraVNC\n\nUltraVNC (auch Ultr@VNC, Uvnc) ist eine VNC-Software für Windows und dient zur Fernwartung von Computern. Neben allen VNC-Funktionen implementiert Ultravnc zudem erheblich effizientere Komprimierungsalgorithmen sowie sehr systemnahe und damit leistungsfähige Techniken zum Abfangen des Serverbildschirms (\"Grabbing\"). UltraVNC nutzt spezielle Windows-Dienste und bietet daher – abgesehen von einem Java-Viewer – auch nur Client/Server-Software für Windows-Betriebssysteme an.\n\nUltraVNC ist in der Programmiersprache C++ programmiert. Das plattformunabhängige UltraVNC-Javaclient-Applet ist in Java programmiert. UltraVNC läuft auf allen Windows-Versionen von Windows 95 bis Windows 10 und wird unter der GPL entwickelt.\n\nMithilfe eines UltraVNC-Viewers (Client) ist man in der Lage, auf einen UltraVNC-Server (über TCP/IP) zuzugreifen und Eingaben und Veränderungen auf diesem Remoterechner durchzuführen, um im Gegenzug von diesem die Bildschirmausgaben zu empfangen. Auf diese Weise gewinnt der Betrachter, der das Viewer-Programm benutzt, den Eindruck, direkt vor dem entfernten Rechner (\"remote\") zu sitzen.\n\nPrinzipiell kann der UltraVNC-Viewer auch mit anderen VNC-Servern Kontakt aufnehmen sowie der UltraVNC-Server auch von anderen VNC-Viewern kontaktiert werden. Dabei stehen dann allerdings nur die grundlegenden Funktionen (Steuerung von Maus und Tastatur sowie Empfang des Bildschirminhalts) zur Verfügung und nicht der volle Funktionsumfang des Programmes, und zwar im Detail:\n\n\nSchwachstelle von UltraVNC ist die Speicherung des Zugangspasswortes, das nur mit DES verschlüsselt wird. Mit dieser in den 1970ern von IBM entwickelten Verschlüsselung werden nur die ersten acht Zeichen mit maximal 56-Bit verschlüsselt. Jedes weitere Zeichen eines Passwortes wird unverschlüsselt kodiert. Die Passwortverschlüsselung und die damit verbundene Sicherheit kann nicht direkt verbessert werden, da sie eine Altlast vom Design des Remote-Framebuffer-Protokolls ist, d. h. in dessen Spezifikation so definiert ist. Durch die Verwendung der neuen DSM-Verschlüsselungserweiterung von Adam Walling kann dieses Manko beseitigt werden.\n\n\n"}
{"id": "1798205", "url": "https://de.wikipedia.org/wiki?curid=1798205", "title": "All Purpose Electronic X-Ray Computer", "text": "All Purpose Electronic X-Ray Computer\n\nEin All Purpose Electronic X-Ray Computer (APEXC) ist eine frühe Serie von einfach strukturierten Computern, die ab 1952 von Andrew D. Booth am Birkbeck College in London entwickelt wurden. Seit 1943 forschte er im Bereich der Kristallstrukturanalyse. Es gab verschiedene Modelle und das X im Namen wurde bei späteren Modellen durch einen anderen Buchstaben ersetzt. So spricht man auch von der APEC-Serie.\n\n\nDie Beschreibung gilt für den APEXC (nach Dokumenten von 1957).\n\nDer APEXC verfügte über 32 Magnettrommelspeicher, aber weder über RAM noch ROM. Zur Vereinfachung waren sowohl sämtliche Befehle, als auch Operatoren 32 Bit lang. Die Speicheradressen hatten eine Länge von 10 Bit. \n\nDa es den üblichen Befehlszähler (PC) nicht gab, war die Startadresse des nächsten Befehls in den Befehlen mit enthalten. Es gab lediglich 15 Befehle.\n\nZur Eingabe diente eine Tastatur mit 32 Tasten oder der Lochstreifen. Die Ausgabe erfolgte über einen Drucker oder ebenfalls per Lochstreifen.\n\nDer APEXC wird unterstützt von dem Emulator M.E.S.S..\n\nDer APEXC war nicht der erste Computer, den Andrew Donald Booth schuf. Nach dem ARC (Automatic Relay Computer, 1947–1949), entwickelte er 1949 den SEC (Simple Electronic Computer).\n\n\n"}
{"id": "1799825", "url": "https://de.wikipedia.org/wiki?curid=1799825", "title": "Median Cut", "text": "Median Cut\n\nZentralwert-Schnitt (engl. \"median cut\", in einigen Programmen auch als Median-Schnitt bezeichnet) ist ein Sortierverfahren für n‑dimensionale Daten. Diese werden schrittweise in Gruppen ähnlicher Werte unterteilt, indem eine Wertegruppe an ihrem Zentralwert unterteilt wird.\n\nDer Algorithmus kann unter anderem zur Farbreduktion bei digitalen Bildern genutzt werden. Er operiert dazu auf einem dreidimensionalen Histogramm des Bildes und produziert eine ausgewogene Verteilung der ursprünglichen Farben auf die Farben des farbreduzierten Bildes. Der Farbraum des Bildes wird durch das Verfahren in immer kleinere Würfel unterteilt, bis die Anzahl der Würfel der Anzahl der gewünschten Farben entspricht.\n"}
{"id": "1800158", "url": "https://de.wikipedia.org/wiki?curid=1800158", "title": "Computer Persönlich", "text": "Computer Persönlich\n\nComputer Persönlich (kurz \"CP\") war ein deutschsprachiges gemischtes Computermagazin aus dem Markt+Technik Verlag, das 14-täglich erschien und Anfang der 1980er Jahre (ab etwa Februar 1982) zum ersten Mal publiziert wurde. Die Erstausgabe des neuen Jahres erschien bereits am Ende des Vorjahres.\n\nComputer Persönlich galt als das „seriöse“ anwenderorientierte Computermagazin des Markt+Technik Verlags, das sich in den 1980er Jahren nach kurzer Zeit hauptsächlich auf die Berichterstattung über IBM-PC-Themen konzentrierte, wohingegen die von 1983 bis 1990 erschienene Schwesterzeitschrift \"Happy Computer\" dessen Spaßmagazin, das sich mit Heimcomputerthemen befasste, war. Neben Informationen und Praxis zu Computersystemen, vorwiegend aus dem PC-Bereich, gab es auch Hard- und Softwaretests. Von den Heften 4/1987 bis 25/1990 enthielt die Zeitschrift die Beilage \"Software-Journal\", die sich mit Softwaretests und -tipps befasste. In den Anfängen wurde auch die Programmierung der Homecomputer berücksichtigt. 1991 wurde das \"PC-Magazin Plus\" und 1992 die \"Computer Live\" mit \"Computer Persönlich\" fusioniert. Die Redaktionsmitglieder der \"Computer Live\" gingen zur \"Computer Persönlich\". In Computer Persönlich wurden einige der Rubriken von \"Computer Live\" übernommen. Von Dezember 1992 bis Januar 1993 gab es eine kurzlebige Beilage \"Tele-communication\". Aus \"Computer Persönlich\" ging die von 9/1993 bis 1/1995 erschienene Computerzeitschrift \"PC-Windows\" hervor, die sich speziell mit dem Betriebssystem Microsoft Windows befasste und in der \"PCgo\" aufging. Ab 1994 lag der \"Computer Persönlich\" eine CD-ROM mit Software bei. Mit Ausgabe 1/1995 wurde das Magazin Ende 1994 eingestellt.\n\n"}
{"id": "1800159", "url": "https://de.wikipedia.org/wiki?curid=1800159", "title": "Computer Live", "text": "Computer Live\n\nComputer Live war eine Publikation des Markt+Technik Verlags und ging aus der Zeitschrift Happy Computer durch Umwandlung hervor. Während sich letztere als systemübergreifende Publikation vornehmlich für Heimcomputer-Fans verstand, war die Computer Live als seriöses PC-Anwendermagazin konzipiert.\n\nDas neue Heftkonzept fand daher bei den Abonnenten der Happy Computer nur geringen Anklang, welche bereits durch die Abspaltung des bisherigen Spieleteils als eigenständige Publikation Power Play eine Abwertung der unter sogenannten Freaks beliebten „Happy“ sahen: Die Zwangsumstellung der laufenden Happy-Computer-Abonnements auf Computer Live führte zu einer Kündigungswelle, so dass der Computer Live nur eine vergleichsweise kurze Lebensspanne beschieden war. Sie erschien von Ausgabe 03/1990 bis 11/1992.\n\nDie Redaktion der Computer Live wechselte zur Computer Persönlich, welche bereits in den 1980er Jahren das „seriöse“ Computermagazin des Markt+Technik Verlags darstellte. In dieser wurden einige Rubriken der Computer Live fortgeführt.\n"}
{"id": "1801929", "url": "https://de.wikipedia.org/wiki?curid=1801929", "title": "KolourPaint", "text": "KolourPaint\n\nKolourPaint ist ein freies einfaches Zeichenprogramm für die grafische Benutzeroberfläche KDE, das ab der Version 3.3, die im August 2004 herauskam, seinen Vorgänger KPaint ablöste. Es besitzt einfache Zeichenwerkzeuge, ermöglicht jedoch keine komplizierten Manipulationen von Fotos. Mit KolourPaint kann man\n\nKolourPaint unterstützt eine ganze Reihe verschiedener Bildformate, so auch JPG, PNG, PCX, XPM und GIF, jedoch keine Formate für Vektorgrafiken.\n\nDas Programm wird als KDE-Äquivalent zum Programm \"Paint\" von Microsoft Windows angesehen.\n\n"}
{"id": "1802869", "url": "https://de.wikipedia.org/wiki?curid=1802869", "title": "Pixel cars", "text": "Pixel cars\n\nAls Pixel cars oder Mangacars werden kleine Bilder von Autos bezeichnet, die meist mit Microsoft Paint erstellt und bearbeitet werden. Typisch für Pixel cars ist, dass bei einem Bild immer die Vorder-, Seiten- und Heckansicht dargestellt wird.\n\nDer Ursprung der ersten Pixel cars liegt in Japan. Ein unter dem Pseudonym „KuruKuru“ bekannter User erstellte unter Paint einige seiner Lieblingswagen in gestauchter Form. Diese waren sehr einfach erstellt und im Comic-, bzw. Mangastil gehalten. Alle Pixel cars besitzen bis heute eine schwarze Kontur, die nach und nach ausgemalt wird. Bis heute wird diese Form der Pixel cars „KK“ in Anlehnung an ihren Erfinder (KK; KuruKuru) genannt.\nEinige andere User wurden darauf aufmerksam und veränderten diese Wagen nach ihren Wünschen und die ersten Modifizierungen (auch „Tunes“) entstanden.\nWaren Pixel cars anfangs eher Karikaturen, entstand parallel zur weltweiten Verbreitung eine zweite Kunstform, „scaled“ (von „scale“; engl. für Maßstab). Erklärtes Ziel dieser anfänglichen Unterart war es die Wagen möglichst Wahrheitsgetreu abzubilden. Heutzutage ist es die am häufigsten anzutreffende Form.\nInzwischen sind Pixel cars über die ganze Welt verbreitet und es gibt Tausende von Bases und Tunes.\n\nAls Stock-Pixel cars oder Bases bezeichnet man Autos, welche in einem Bildbearbeitungsprogramm (in den meisten Fällen Paint) den „echten Autos“ im Serienzustand nachgepixelt werden.\nIn den meisten Fällen werden Blueprints, die im Internet frei zugänglich sind, entsprechend verkleinert und dann, einfach gesagt, ausgemalt. Die Position des fiktiven Lichteinfalls ist immer direkt über dem Wagen, so dass das Shading meistens an der Fensterlinie mit der hellsten Farbe beginnt und zum Boden hin dunkler wird.\nWaren es früher noch ca. fünf Farben, die zum shaden üblich waren, sind es heute meist über zehn Farbabstufungen. Somit haben heutige Pixel cars schon fast fotorealistische Qualität.\nEine weitere Errungenschaft ist das Anti Aliasing, kurz „AA“ genannt. Bei dieser Technik wird die Kontur der Autos mit unterschiedlichen Grautönen weichgezeichnet. Im Gegenzug werden die Farben des Shadings zur Aussenkante hin immer dunkler, damit ein harmonischer Übergang vom Auto zum Hintergrund entsteht.\n\nWeitere Techniken\n\nEs gibt auch noch die Möglichkeit, ein schon bestehendes Auto zu „Reshaden“ oder „Remaken“. Dies ist wohl die einfachste Möglichkeit, eine neue Base zu entwerfen. Ein solches Remake besteht darin, das Shading zu verbessern, sowie ggf. AA hinzuzufügen, da meistens schon etwas ältere Bases überarbeitet werden.\n\nDes Weiteren gibt es auch noch die Möglichkeit, eine Base zu entwickeln, ohne dass Blueprints oder vergleichbares verwendet werden. Hierzu werden nur Fotos als Vorlage verwendet oder die Base alleine „aus dem Kopf heraus“ gezeichnet. Diese Methode gilt als die schwierigste und wird nur in Ausnahmefällen verwendet (z. B. wenn es noch keine Blueprints zum jeweiligen Auto gibt.).\n\nAls Tune bezeichnet man Pixel cars, die mit Bildbearbeitungsprogrammen verändert wurden. Wie in der echten Tuningszene gibt es hier keine Grenzen, was man alles verändert. Man kann entweder ein echtes Auto nachempfinden (sogenannte „Replikas“) oder einfach der Phantasie freien Lauf lassen.\nZum Erstellen braucht man im Prinzip keine speziellen Programme. Das simple Microsoft Paint, welches auf jedem PC mit Windows enthalten ist, reicht dafür aus. Viele User verwenden auch Adobe Photoshop.\n\n\nDa gerade Anfänger nicht alle Tuningteile selbst erstellen können, greifen diese oftmals auf bereits fertig gepixelte „Parts“ zurück.\nDamit niemand diese als seine eigenen ausgibt und auch die Arbeit der „Erschaffer“ der Tuningteile gewürdigt wird, hat man die Regelung getroffen, dass man alle Nicknamen derjenigen Leute angibt, deren Teile man verwendet. So sind z. B. bei ca. 90 % der veröffentlichten Tunes die Felgen keine Eigenproduktion.\n\n"}
{"id": "1806811", "url": "https://de.wikipedia.org/wiki?curid=1806811", "title": "IBM RT", "text": "IBM RT\n\nDer IBM RT (IBM 6150/6151/6152) war ein Unix-Mikrocomputer der ersten Generation aus dem Hause IBM. RT steht hierbei für \"RISC Technology\". Es war der Nachfolger des experimentellen IBM 801 und Vorgänger der erfolgreichen RS/6000-Serie von IBM. Er wurde 1986 zunächst als RT PC vorgestellt, aufgrund von Namensverwechslungen wie \"PC RT\" aber schließlich auf seinen endgültigen Namen umgetauft.\n\nEr wurde auf der CeBIT 1986 in den deutschen Markt eingeführt und war entweder im Tower- (IBM 6150) oder Desktopgehäuse (IBM 6151) lieferbar. Er besaß einen 32-bit Prozessor des Typs ROMP mit in der Grundausstattung 5,88 MHz, der etwa die Leistung des damals aktuellen 80286 bei 12 MHz entfaltete. Es waren auch fortgeschrittene Prozessorkarten mit 10 oder 12 MHz und einem Motorola 68881-Gleitkommaprozessor erhältlich. Der Arbeitsspeicher reichte von 4 MB in der Grundausstattung bis 16 MB im Maximalausbau. Das Gerät benutzte als Betriebssystem AIX (bis Version 2.2.1), Academic Operating System (AOS) oder das Pick Operating System. Als IBM 6152 war später ein gewöhnliches PS/2 Model 60 mit einer zusätzlichen Prozessorkarte verfügbar, das das AOS von einem im Netzwerk befindlichen RT laden konnte.\n\nWie an späteren IBM-Unix-Maschinen war auch am IBM RT eine zweistellige Siebensegmentanzeige angebracht, die den POST-Code beim Starten angezeigt hat, da der Videoadapter zum Bootzeitpunkt noch nicht initialisiert war, um dort z. B. Fehlerausgaben machen zu können. Zur Systemerweiterung dienten bis zu acht ISA-Steckkarten. Zur Datensicherung konnte auf ein DC600-¼-Zoll-Bandlaufwerk zurückgegriffen werden. Das Plattensystem bestand aus bis zu 3 Fullsize-5¼-Zoll-ESDI-Festplatten von je 40 bis 300 MB. Die Installation des Betriebssystems wurde von 5¼-Zoll-Disketten (ca. 32 Stück bei AIX) durchgeführt. Das System besaß bis zu zwei solcher Laufwerke mit 1,2 MB Kapazität.\n\nDer IBM RT wurde gerne als CAD-Arbeitsplatz in Zusammenhang mit einem Grafikterminal von Tektronix benutzt. CAD-Programme wie CATIA, AutoCAD V3 oder DOGS2D konnten unter AIX die mit über das X-Window-System (Version 9 oder 10) angesteuerten Grafikterminals umgehen.\n"}
{"id": "1806835", "url": "https://de.wikipedia.org/wiki?curid=1806835", "title": "Carry-Select-Addierer", "text": "Carry-Select-Addierer\n\nDer Carry-Select-Addierer (von Übertrag, (aus-)wählen) oder kurz CSCA ist ein beschleunigtes Addiernetz, welches zur Addition mehrstelliger Binärzahlen verwendet wird.\n\nDer CSCA unterteilt die gesamte \"Wortbreite n\" in \"M Blöcke\".\n\nIm gegebenen Bildbeispiel sind die Blockbreiten 2, 3 und 4 Bit.\nEs handelt sich also um eine Addition von zwei 2 + 3 + 4 = 9 Bit breiten Binärzahlen.\n\nDas Prinzip dieses Addiernetzes lässt sich mit dem Begriff „parallelisierte Vorabberechnung“ beschreiben, denn jeder der Blöcke besteht aus jeweils zwei Carry-Ripple-Addierern (kurz CRA), die gleichzeitig die Berechnung für ihren Bit-Anteil der Binärzahlen ausführen. Dabei liegt an einem der CRA ein Übertragsbit an (c=1), während der Carry-Eingang des anderen auf c=0 gesetzt ist. Somit werden pro Block beide möglichen Fälle parallel ausgerechnet und an einen Multiplexer angelegt.\nDieser schaltet schließlich in Abhängigkeit vom höchstwertigen Übertragungsbit des vorherigen Blocks auf die richtige Lösungsvariante, welche im Idealfall schon fertig berechnet ist.\n\nUm eine optimale Laufzeit zu erhalten, ist es sinnvoll, die \"beliebig variable Blockwortbreite\" wachsen zu lassen, da so die Berechnung im Block synchron mit dem Anlegen des endgültigen Übertragungsbits abschließt.\n\nIm folgenden Rechenbeispiel wird davon ausgegangen, dass dies genau dann der Fall ist, wenn der Wortbreitenzuwachs 1 Bit pro Block entspricht (siehe Beispiel).\n\n\nformula_4\nformula_5\n\nformula_6\n\nformula_7\n\nAuf unser spezielles Beispiel (formula_8) angewandt:\n\nformula_9 (0,1,2 – entspricht drei Blöcken)\n\nAdditionszeit:\n\nformula_10\n\nformula_11\n\nmit\n\nformula_12\n"}
{"id": "1810785", "url": "https://de.wikipedia.org/wiki?curid=1810785", "title": "KiCad", "text": "KiCad\n\nKiCad ist ein freies ECAD-Programmpaket zur Erstellung von elektronischen Leiterplatten. Es wird von einer Gruppe von freiwilligen Entwicklern und zwei Wissenschaftlern des CERN entwickelt und steht unter GP-Lizenz. Neben dem Quellcode wird KiCad als vorkompiliertes Paket für Linux, Microsoft Windows und OS X angeboten.\n\nDer Initiator des Projektes, Jean-Pierre Charras, ist Wissenschaftler am \"Laboratoire des Images et des Signaux (LIS)\" in Grenoble, Frankreich und Lehrer am \"IUT de Saint-Martin-d’Hères\". Derzeitiger Projektleiter (Maintainer) ist Wayne Stambaugh.\n\nKiCad beinhaltet die folgenden Programmteile:\n\nKiCad basiert auf dem WxWidgets-Framework. Erhältlich ist es für die Plattformen Linux und Windows (ab 2000). Auf Solaris und FreeBSD ist es ebenfalls einsetzbar.\n\nMit KiCad können Leiterplatten mit bis zu 32 Ebenen erstellt werden. Die Schaltpläne können an Spice weitergegeben werden.\n\nZuerst wird mit EESchema (dem Schaltplanmodul von KiCad) ein Schaltbild der zu entwickelnden Platine unter Verwendung der Schaltplansymbole aus der Symbolbibliothek erstellt. Dabei unterstützt EEschema sogenannte hierarchische Schaltpläne, das heißt, ein Schaltplan kann als „Blackbox“ Unterschaltpläne enthalten, die wiederum weitere Unterschaltpläne enthalten können. Umgekehrt kann auch aus vorhandenen Unterschaltplänen durch passendes Einbinden in übergeordnete Schaltpläne sehr schnell ein Schaltplan modular aufgebaut werden.\n\nSchaltplansymbole können mit dem in EESchema enthaltenen Symboleditor angepasst oder komplett neu erstellt werden. Des Weiteren enthält EESchema ein Tool für Annotation (Automatisches Vergeben von Referenzbezeichnern für die verwendeten Bauteile) und für einen ERC (Electrical rule check), der den Schaltplan grob auf Fehler untersucht, zum Beispiel, ob alle Pins angeschlossen sind, mit Ausnahme derer, bei denen ausdrücklich kein Anschluss gewollt ist. Des Weiteren kann eine Netzliste erstellt werden, die in verschiedenen Formaten, wie für Spice oder den Specctra Autorouter, exportiert werden kann.\n\nDanach wird diese Netzliste in CVpcb eingelesen. Dort kann jedem Bauteil ein Footprint (in KiCad \"Module\" genannt) zugewiesen werden. Bei einem Technologiewechsel (z. B. beim Übergang von \"Through hole-\" auf SMD-Technik) können hier auch nachträglich andere Footprints eingetragen werden. Nach erneutem Abspeichern der Netzliste kann diese nun in das Platinenlayoutmodul von KiCad, PCBnew, eingelesen werden.\nEin anderer Ansatz ist der direkte Verweis auf Footprints, der in ein Feld des Symbols eingetragen wird. Diese Footprints erscheinen dann als Voreintrag in CVpcb, wo sie auch noch editiert werden können. Fehlt der Verweis auf den Footprint im Symbol, bleibt die Liste in CVpcb an der Stelle leer, und muss dort editiert werden.\n\nIn PCBnew können die Bauteile auf der Platine verteilt und verbunden werden. Auch können Netzklassen definiert werden, die z. B. Leiterbahnbreiten und Isolationsabstände festlegen. Das Verbinden kann manuell oder über den mitgebrachten Autorouter erfolgen. Auch ein externer Autorouter, der irgendwo auf einem Server läuft oder ganz fremde Software, wie z. B. der Specctra Autorouter, kann verwendet werden.\n\nDas manuelle Routen wird von einem abschaltbaren permanenten DRC (\"design rule check\", überprüft, ob Leiterbahnbreiten und Abstände gemäß der Netzlistendefinition eingehalten werden) unterstützt, der das Platzieren nicht DRC-konformer Leiterbahnen unterbindet. Der DRC kann auch nach Abschluss der Arbeit extra gestartet werden, falls man ihn z. B. abgeschaltet hatte, um Ausnahmen durchzuführen. In diesem Fall werden Ausnahmen und alle anderen DRC-Verletzungen gemeldet, so dass man entscheiden kann, ob man die Regelverletzung beseitigt oder als Ausnahme zulässt.\nDie Ausgabe der Platine kann als Extended Gerber, PostScript, DXF, HPGL, SVG oder direkt auf einen Drucker erfolgen. Bohrdatenfiles, Pick+Place-Daten für SMD-Bestückungsroboter und eine Stückliste (BOM) können erstellt werden. Die Stückliste kann als klassische Textliste oder als CSV-Datei erzeugt werden.\n\nDes Weiteren beherrscht PCBnew „Push and Shove“ sowie \"matched pair\", was das manuelle Routen sehr erleichtert. Allerdings basiert dieses auf der Hardwareunterstützung durch die Grafikkarte mit openGL, so dass es auf älteren Rechnern oder bei nicht unterstützter Hardware nicht verwendet werden kann. Gewöhnliches manuelles Routen funktioniert aber dann noch. Der interaktive Push & Shove-Router ist eine gute Alternative zu Autoroutern, besonders wenn man bedenkt, dass die Ergebnisse von Autoroutern ja im Allgemeinen auch noch manuell überarbeitet werden müssen.\n\nPCBnew unterstützt auch das Einbinden schon vorhandener gerouteter Platinen, so dass aus verschiedenen Platinen Ausschnitte entnommen und zu einer neuen verbunden werden können. Allerdings müssen alle dafür nötigen Annotationen von Hand vorgenommen werden.\n\nPCBnew enthält weiter ein HF-Tool, mit dem bequem Stubs und Gaps definierter Abmessung erzeugt werden können. Des Weiteren können Polygone eingelesen werden, die als Shapefile (eine Liste von Koordinaten) vorliegen. Auf die Art und Weise lassen sich HF-Filterstrukturen und Antennen erzeugen, aber auch andere Kupferstrukturen wie Sensorflächen oder „Lötjumper“.\n\nEine Besonderheit stellt die Fähigkeit von KiCad dar, „Extended Gerber“ mit dem mitgebrachten Gerberviewer „Gerbview“ nicht nur anzusehen, sondern auch als Layout in PCBnew importieren zu können.\n\nDort kann man die Platine bearbeiten, z. B. zu größeren Nutzen vervielfachen, und wieder als Extended Gerber exportieren. Eine weitergehende Bearbeitung ist aber nur möglich, wenn eine Netzliste besteht. Diese könnte durchaus von Hand unter Benutzung von Gerbview und PCBnew erstellt werden. Insofern ist KiCad für \"reverse engineering\" geeignet.\n\nDer Programmteil Bitmap2component wandelt Bitmaps wahlweise in Symbole oder in Footprints um. Auf diese Weise können also auch Logos oder spezielle Muster für HF-Anwendungen in KiCad importiert werden, sofern sie als Bitmap vorliegen. Diese Funktion ist allerdings sehr neu (im Frühjahr 2011 eingefügt) und eher als experimentell zu bezeichnen.\n\nDer Programmteil PCB Calculator enthält einige kleine Berechnungsprogramme bzw. Tabellen. Z. B. können die Dimensionierungswiderstände von Spannungsreglern berechnet werden, die ähnlich dem LM317 arbeiten, dazu die Wellenwiderstände diverser Leitungen, Leiterbahnbreiten, Leiterbahnwiderstände etc.\n\nKiCad ermöglicht auch die 3D-Vorschau der erstellten Leiterplatten sowie einen Export des mechanischen Leiterplattenmodels (mit Bauteilen) im VRML- oder STEP-Format. Voraussetzung ist, dass für die verwendeten Bauteile nicht nur Footprints (in KiCad \"Module\" genannt), sondern auch 3D-Modelle als WRL- (VRML) oder STEP-Dateien hinterlegt wurden. KiCad bindet diese Dateien lediglich ein. Zum Bearbeiten bzw. Erstellen der 3D-Modelle der Bauteile ist externe Software (Wings 3D, FreeCAD oder Blender (ebenfalls open source)) erforderlich.\n\nMit dem externen Werkzeug TTConv können AutoCAD-dxf-Dateien im- und exportiert werden.\n\nDurch die Arbeit einer aktiven Community rund um KiCad stehen viele Bauteilbibliotheken zur Verfügung, die aus einem Repository heruntergeladen werden können. Des Weiteren können EAGLE-Bibliotheken direkt importiert werden. Mittlerweile gibt es auch externe Anbieter von Bibliotheken, wie z. B. SnapEDA, die einen Export ihrer Bibliotheken auch für KiCad ermöglichen, oder der Bauteilehändler Digi-Key, der ebenfalls Footprints und 3D-Modelle zu seinem Bauteilangebot zum Download auch für KiCad anbietet.\n\nKiCad besitzt eine Python-Schnittstelle (Python 2.6) die aber zurzeit nur für das Board implementiert ist. Geplant ist etwas Ähnliches, wie Eagle es mit den ULPs bereits eingeführt hat. Zusätzlich kann durch das offene, klarschriftartig lesbare Dateiformat jede beliebige Programmiersprache herangezogen werden, um die Dateien extern zu manipulieren.\n\nIm Laufe des Jahres 2012 wurde das Dateiformat für Boards umgestellt. Die Dateien endeten im alten (Legacy) Format auf „.brd“ und im neuen auf „.kicad_pcb“. Aktuelle Kicad-Versionen können beide Formate einlesen und beide nach Wahl abspeichern.\n\nEntwicklungsversionen von KiCad hatten im Herbst 2016 eine Schnittstelle zum Schaltplansimulationstool Ngspice.\n\nEnde des Jahres 2015 veränderte das KiCad-Team mit Version 4.0.0 den Release-Mechanismus. Zuvor gab es keine offizielle Installationsdatei zum Download und Nutzer mussten sich behelfen, indem sie den Quellcode selbst kompilierten. In Zukunft sollen regelmäßig neue Versionen erscheinen, des Weiteren sollen Patches für Bugs zur Verfügung gestellt werden, sofern diese das Programm zum Absturz bringen.\n\nFür das KiCad-Projekt existieren umfangreiche offizielle Dokumentationen und Tutorials in verschiedenen Sprachen. Auf GitHub gibt es das offizielle \"KiCad documentation project\".\n\n\n\n"}
{"id": "1816644", "url": "https://de.wikipedia.org/wiki?curid=1816644", "title": "Open School Server", "text": "Open School Server\n\nDer Open School Server (OSS) ist eine auf Basis des SUSE Linux Enterprise Servers 9 (SLES9) entwickelte GNU/Linux-Server-Distribution zum Einsatz in pädagogischen Schulnetzwerken. Er wird mit kostenpflichtigem Support und weiterführenden Serviceleistungen angeboten. Es handelt sich dabei um das Programm mit der größten Sperrliste für jugendgefährdende Seiten im Internet.\n\nNachdem zunächst die SUSE Linux GmbH im Jahre 2002 im Rahmen einer Kooperation mit der Stadt Fürth einen Schulserver namens „SUSE Linux School Server“ (SLSS) entwickelte, dessen Weiterentwicklung und Vermarktung nach dem Verkauf einiger Lizenzen aber eingestellt wurde, übernahm im Jahre 2004 die Firma Extis GmbH die komplette Weiterentwicklung und den Support und brachte kurze Zeit später mit dem OSS 2.0 die erste Nachfolgeversion des SLSS heraus.\n\nIm Dezember 2005 fand in Erlangen eine erste übergreifende „Schulserver-Entwickler-Tagung“ mit Entwicklern verschiedener freier Schulserver statt, um sich über gemeinsame Standards und zukünftige Zusammenarbeit zu unterhalten. Einige der Ergebnisse wurden in einem eigenen Wiki zusammengefasst und sollen in zukünftigen Schulserver-Entwicklungen berücksichtigt werden. Der Open School Server hält sich in der neuesten Version an viele dieser neuen Standards.\n\nWesentlicher Bestandteil des Open School Servers ist die einfache Administration und Integration verschiedener (Partner-)Produkte.\n\nDie Entwickler legen − laut eigener Aussage − besonderen Wert auf die Zusammenarbeit mit Schulen, deren Wünsche und Erweiterungsvorschläge in kommende Versionen einfließen. Dabei werden installierte Systeme derzeit über YaST aktuell gehalten und bekommen so neue Features direkt über ein Online-Update eingespielt.\n\nEinige Eigenschaften des Open School Servers:\n\nOpen School Server ist ohne Einschränkung im Funktionsumfang kostenlos als Downloadversion erhältlich, allerdings wird dann kein Support gewährt.\n\nDie Firma Extis kooperiert mit verschiedenen Firmen, die pädagogische EDV-Lösungen für Schulen anbieten und bietet selbst sowohl kostenpflichtige Schulungen als auch Supportverträge für Schulen an. Ziel ist den Schulen einen festen Ansprechpartner bei ihren Fragen und Problemen zu bieten. Es gibt kostenpflichtige Versionen in verschiedenen Preiskategorien, die je nach Preis E-Mail-Support beinhalten oder auch die Installation in der Schule. Schulungen für Administratoren und Lehrpersonal werden auch angeboten.\n\n\n\n"}
{"id": "1819414", "url": "https://de.wikipedia.org/wiki?curid=1819414", "title": "Datenveränderung", "text": "Datenveränderung\n\nDatenveränderung ist in Deutschland gemäß des Strafgesetzbuches (StGB) ein Vergehen, das mit Freiheitsstrafe bis zu zwei Jahren oder Geldstrafe bestraft wird.\n\nJegliches rechtswidrige Verändern, Löschen, Unterdrücken oder Unbrauchbarmachen fremder Daten ist nach dem deutschen Strafrecht eine Datenveränderung.\n\nDer Wortlaut von § 303a StGB ist (seit der letzten Änderung zum 11. August 2007):\n\n\"Löschen\" ist das unwiederbringliche Unkenntlichmachen von Daten, d. h. die Daten sind nicht wiederherstellbar. Von \"Unterdrücken\" spricht man, wenn dem Berechtigten der Zugriff auf seine Daten unmöglich gemacht wurde. \"Unbrauchbarmachen\" bedeutet, dass Daten nicht mehr bestimmungsgemäß gebraucht werden können. Ein \"Verändern\" von Daten liegt vor, wenn sich ihr Informationsgehalt ändert.\n\nDie Norm erfasst inhaltliche Änderungen von Daten. Die Tat ist vollendet, sobald ein Einwirkungserfolg eingetreten ist. Eines Vermögensschadens bedarf es nicht. Dabei muss es sich nicht um fremde Daten handeln, aber um Daten die einem fremden Nutzungsrecht unterliegen. So ist die Datenveränderung nach § 303a StGB im reinen internen Bereich nicht möglich, wenn der Handelnde aufgrund seiner Rechtsposition umfassenden Zugriff auf die veränderten Daten hatte. Geschützt sind nur solche Daten, die einem anderen zugeordnet sind. Eine strafbare Tat liegt nur dann vor, wenn sich die Handlung des Täters auf fremde Daten bezieht, an denen also das unmittelbare Recht des Anderen auf Verarbeitung, Löschung oder Nutzung besteht. Das Tatbestandsmerkmal der Rechtswidrigkeit entfällt, wenn der Täter selbst Verfügungsberechtigter ist oder mit Einverständnis des Verfügungsberechtigten auf die Daten einwirkt. Insofern wirkt die Nutzungserlaubnis an den Daten als tatbestandsausschließendes Einverständnis.\n\nGemäß StGB wird die Tat in den Fällen der §§ 303 bis 303b StGB nur auf Antrag verfolgt, es sei denn, dass die Strafverfolgungsbehörde wegen des besonderen öffentlichen Interesses an der Strafverfolgung ein Einschreiten von Amts wegen für geboten hält. Wird ein Antrag gestellt, erhebt die Strafverfolgungsbehörde allerdings auch nur dann Anklage, wenn sie ein (einfaches) öffentliches Interesse bejaht ( StPO). Andernfalls hat der Verletzte die Möglichkeit, Privatklage zu erheben ( Abs. 2 StPO).\n\nIn der deutschen polizeilichen Kriminalstatistik (PKS) wurden 2015 insgesamt 3.537 Delikte von Datenveränderung bzw. Computersabotage erfasst.\n\nBei den Computerstraftaten überwiegen männliche erwachsene Tatverdächtige ab 21 Jahren.\n\nAnhand von Statistiken (PKS, Verurteiltenstatistik usw.) lässt sich das genaue Ausmaß der Delikte nicht ermitteln. Wegen unterschiedlicher Erfassungszeiträume/-daten und anderen Einflussfaktoren, sind diese Statistiken in Deutschland nicht vergleichbar.\n\nIn der Rechtswissenschaft wurde die Vorschrift als Straftatbestand „ohne erkennbaren Unrechtskern“ bezeichnet.\n\nIn der Stellungnahme des Bundesrates zum Entwurf des Strafrechtsänderungsgesetzes zur Bekämpfung der Computerkriminalität wurde gerügt, dass § 303a StGB vielfach wegen seiner erheblichen Unbestimmtheit (Art. 103 II GG) kritisiert wird. Die Unbestimmtheit bezieht sich z. B. auf die Frage, woran die Verfügungsberechtigung über Daten festzumachen ist. Gerade bei Daten in vernetzten Systemen ist dieses Problem weitgehend ungeklärt. Daraus lassen sich Bedenken hinsichtlich der Verfassungsmäßigkeit der Norm herleiten. Allerdings erscheint fraglich, ob der Gesetzgeber derzeit in der Lage ist, das Problem zu lösen. In der rechtswissenschaftlichen Literatur hat sich bislang kein Lösungsansatz eindeutig durchsetzen können, und für die Rechtspraxis scheint das Problem keine große Rolle zu spielen.\n\n\n"}
{"id": "1820020", "url": "https://de.wikipedia.org/wiki?curid=1820020", "title": "Ausspähen von Daten", "text": "Ausspähen von Daten\n\nDas Ausspähen von Daten ist gemäß dem deutschen Strafgesetzbuch (StGB) ein Vergehen, welches mit Freiheitsstrafe bis zu drei Jahren oder Geldstrafe bestraft wird.\n\nGeschützt wird die Verfügungsbefugnis über Daten. Diese Norm ist sozusagen die allgemeine Strafbestimmung gegen den „elektronischen Hausfriedensbruch“. Primär geht es um das Verschaffen von Daten. Dabei ist es nicht relevant, ob geschäftliche oder private Daten ausgespäht werden. §202a StGB erfasst unter anderem den Softwarediebstahl, das Ausspähen von Daten, den Wirtschaftsverrat und das Verschaffen von Unternehmensgeheimnissen. Nach Meinung einiger Juristen ist das Einhacken in fremde Datensysteme ohne das Verschaffen von Daten nicht gesetzwidrig, diese Einschätzung ist jedenfalls nach dem neuen Wortlaut der Norm, die die Strafbarkeit bereits mit der Erlangung des Zugangs beginnen lässt, nicht mehr haltbar. Das uneingeschränkte Lesen der illegal beschafften Daten erfüllt jedoch den Tatbestand des § 202a.\n\nPhishing, also das Verschicken von E-Mails unter dem Namen tatsächlich existierender Kreditinstitute an Bankkunden, mit denen die Empfänger unter einem Vorwand aufgefordert werden, auf einer verlinkten und ebenfalls gefälschten Webseite Zugangsdaten einzugeben, dient zwar der Vorbereitung eines Computerbetrugs gemäß § 263a StGB, stellt aber kein Ausspähen von Daten gemäß § 202a StGB dar.\n\nZukünftig soll bereits der bloße unbefugte Zugang zu Computer- und Informationssystemen („Hacking“) strafbar sein. Bisher gilt dies erst, wenn sich jemand Daten verschafft.\n\nDa das Europarat-Übereinkommen die Strafbarkeit von bestimmten Vorbereitungshandlungen für Computerstraftaten vorschreibe, soll der im deutschen Recht bestehende Tatbestand des vorbereitenden Computerbetrugs auf das Ausspähen und Abfangen von Daten erweitert werden. Auch Vorbereitungshandlungen zu Datenveränderung und Computersabotage sollten in diesem Zusammenhang erfasst werden.\n\nIn der deutschen polizeilichen Kriminalstatistik (PKS) wurden 2008 insgesamt 7.727 Delikte erfasst. Die Fallzahlen der letzten Jahre können dem Diagramm (PKS 2000–2008) entnommen werden.\n\nBei den Computerstraftaten überwiegen männliche erwachsene Tatverdächtige ab 21 Jahren.\n\nAnhand von Statistiken (Polizeiliche Kriminalstatistik, Verurteiltenstatistik usw.) lässt sich das genaue Ausmaß der Delikte nicht ermitteln. Wegen unterschiedlicher Erfassungszeiträume/-daten und anderen Einflussfaktoren sind diese Statistiken in Deutschland nicht vergleichbar.\n\n\n"}
{"id": "1822300", "url": "https://de.wikipedia.org/wiki?curid=1822300", "title": "Maildrop", "text": "Maildrop\n\nMaildrop ist ein Mail Delivery Agent (MDA) und Mailfilter für Mailserver, der als MDA des Courier Mail Servers entstand, aber zur Verwendung mit anderen Mail Transfer Agents und Message Stores auch separat erhältlich ist und zu diesem Zweck neben Maildir auch mbox unterstützt.\n\nMaildrop kann E-Mails anhand diverser Eigenschaften filtern, wie zum Beispiel:\n\n\nMaildrop wird häufig als Alternative zu procmail genutzt, da es auch aktiv betreut wird und im Gegensatz zu \"procmail\" eine weit mächtigere und verständlichere Syntax unterstützt, die der von Perl ähnelt. So unterstützt maildrop beispielsweise sehr mächtige Verzweigungen mittels \"if–elseif–else\".\n\nDas folgende Beispiel für eine codice_1 leitet eingehende E-Mails an SpamAssassin weiter und sortiert sie danach entsprechend der Markierungen.\nif ( $SIZE < 262144 )\n\nif (/^X-Spam-Status: *YES/)\nelse\n\nErläuterung: Als erstes wird geprüft, ob die Nachricht kleiner als 256 kB (262144 Bytes) ist, um SpamAssassin nicht mit zu großen Nachrichten zu belasten. Erfüllt sie das Größenkriterium, wird sie nun über das Kommando codice_2 per Pipe an SpamAssassin weitergereicht.\nDanach wird überprüft, ob SpamAssassin die Nachricht als Spam markiert hat (codice_3). Für diesen Fall wird die Nachricht in den Ordner codice_4 im Maildir sortiert, anderenfalls wird sie ganz normal in die Maildir zugestellt.\n"}
{"id": "1824077", "url": "https://de.wikipedia.org/wiki?curid=1824077", "title": "Macintosh Performa", "text": "Macintosh Performa\n\nMacintosh Performa bezeichnet eine Serie von Computern, die Apple im Rahmen ihrer Produktfamilie von Macintosh-Personalcomputern von 1992 bis 1997 produzierte.\n\nBei der Performa-Serie handelte es sich nicht um eine eigene, einheitliche Baureihe, sondern um eine Auswahl von insgesamt 67 bereits bestehenden Produkten und Produktvarianten, die nachträglich zusätzlich unter dieser Serienbezeichnung zusammengefasst und vermarktet wurden. Apple versuchte mit dieser Serie zum ersten Mal, Heimanwender für ihre sonst eher im professionellen Bereich verwendeten Rechner zu gewinnen.\n\nBekannte Modelle dieser Serie waren der Performa 200 (eigentlich Macintosh Classic II), der Performa 400 (eigentlich Macintosh LC II) und der Performa 5200 (eigentlich Power Macintosh 5200LC). Im Unterschied zu den regulären Apple-Produkten dieser Zeit wurde die Performa-Serie als Paket mit Monitor und Tastatur und mit vorinstallierter Software (unter anderem ClarisWorks) verkauft. Darüber hinaus war das Betriebssystem leicht modifiziert.\n\nViele frühe Geräte der Performa-Serie folgten der heute noch im iMac verwendeten Bauweise, bei der Monitor, Hauptplatine und Laufwerke gemeinsam im selben Gehäuse untergebracht sind. Die Modelle unterschieden sich stark in Prozessorleistung und Ausstattung. Besonders beliebt war der Performa 5200, der mit eingebautem TV-Tuner erhältlich war und als kompaktes Fernsehgerät benutzt werden konnte.\n\nDer Performa-Serie wurden ab April 1996 keine neuen Geräte mehr hinzugefügt. Die Produktion des letzten Modells, des Performa 6400, wurde im August 1997 endgültig eingestellt.\n"}
{"id": "1824240", "url": "https://de.wikipedia.org/wiki?curid=1824240", "title": "Molekulardynamik-Simulation", "text": "Molekulardynamik-Simulation\n\nMoleküldynamik oder Molekulardynamik (MD) bezeichnet Computersimulationen in der molekularen Modellierung, bei denen Wechselwirkungen zwischen Atomen und Molekülen und deren sich daraus ergebende räumliche Bewegungen iterativ berechnet und dargestellt werden. Bei der Modellierung von komplexen Systemen mit einer Vielzahl an beteiligten Atomen werden hauptsächlich Kraftfelder oder semiempirische Methoden verwendet, da der Rechenaufwand zur Anwendung von quantenmechanischen Verfahren (ab-initio-Methoden) hierbei zu groß wäre. Durch die stetig steigende verfügbare Rechenleistung werden allerdings zunehmend quantenchemische Methoden (ab initio Molecular Dynamics) auch für mittelgroße Systeme möglich.\n\nDer Begriff Moleküldynamik wird manchmal auch als Synonym für die Discrete element method (DEM) gebraucht, weil die Methoden sehr ähnlich sind. Die Partikel in DEM müssen aber keine Moleküle sein.\n\nDie MD-Methode hat ihre Ursprünge in den späten 1950er und frühen 1960er Jahren und spielt eine große Rolle in der Simulation von Flüssigkeiten, wie z. B. Wasser oder wässrigen Lösungen, wo strukturelle und dynamische Eigenschaften in experimentell schwer zugänglichen Bereichen (z. B. von Druck und Temperatur) berechnet werden können. Pioniere waren Ende der 1950er Jahre Bernie Alder und Thomas E. Wainwright (Modell harter Kugeln) und in den 1960er Jahren Aneesur Rahman, Loup Verlet und Bruce J. Berne (mit seinem Studenten George Harp).\n\nAus Sicht der statistischen Physik erzeugt eine MD-Simulation Konfigurationen, die bestimmten thermodynamischen Ensembles entsprechen. Einige dieser Ensembles werden im Folgenden aufgelistet.\nMonte-Carlo-Simulationen erzeugen vergleichbare Konfigurationen unter Verwendung der Zustandssumme dieser Ensembles.\n\nDas mikrokanonische Ensemble beschreibt ein System, das isoliert ist und keine Partikel (N), Volumen (V) oder Energie (E) mit der Umgebung austauscht.\n\nFür ein System mit formula_1 Partikeln, zugehörigen Koordinaten formula_2 und Geschwindigkeiten formula_3 kann man folgendes Paar gewöhnlicher Differentialgleichungen aufstellen:\n\nDabei beschreibt\n\nDie Parametrisierung eines Kraftfeldes mit einem großen Anwendungsbereich ist eine große Herausforderung. Bei der Durchführung von MD-Simulationen ist die Wahl des richtigen Kraftfeldes eine wichtige Entscheidung. Generell sind Kraftfelder immer nur auf solche Systeme anwendbar, für die sie parametrisiert sind (z. B. Proteine oder Silikate).\n\nDas kanonische Ensemble zeichnet sich im Gegensatz zum mikrokanonischen durch konstante Temperatur aus. Um es zu realisieren, wird zusätzlich ein Thermostat benötigt. Beispielsweise kann das Andersen-Thermostat, das Langevin-Thermostat oder das Nose-Hoover-Thermostat verwendet werden. Teilweise (insbesondere zur Äquilibrierung) wird auch noch das Berendsen-Thermostat oder Weak-Coupling-Thermostat verwendet. Dieses erzeugt jedoch kein korrektes NVT-Ensemble. Thermostate beruhen auf dem Äquipartitionstheorem.\n\nUm das NPT-Ensemble zu realisieren, benötigt man neben einem Thermostat zusätzlich ein Barostat. Beispielsweise kann das Andersen-Barostat, das Parrinello-Rahman Barostat oder das Berendsen-Barostat verwendet werden. Barostate beruhen auf dem Clausiusschen Virialtheorem.\n\nDas simulierte Volumenelement wird am Anfang mit den zu untersuchenden Teilchen gefüllt. Anschließend folgt die Equilibrierung: Es werden für jedes Teilchen die Kräfte berechnet, die auf es aufgrund seiner Nachbarn wirken, und die Teilchen entsprechend dieser Kräfte in sehr kleinen Zeitschritten bewegt. Nach einigen Schritten (bei einem guten, passenden Kraftmodell) gelangt das Probevolumen in ein thermisches Gleichgewicht, und die Teilchen fangen an, sich „sinnvoll“ zu bewegen. Nun können aus den Kräften und Bewegungen der Teilchen Druck und Temperatur berechnet und schrittweise verändert werden. Die Teilchen können dabei vollständige Moleküle aus einzelnen Atomen sein, die auch Konformationsänderungen durchlaufen können. Größere Moleküle werden oft aus mehrere Atome umfassenden, in sich starren Bauteilen zusammengesetzt (Discrete element method), was den Rechenaufwand minimiert, allerdings sehr gut angepasste Kraftfelder erfordert.\n\nMD-Simulationen finden meist unter periodischen Randbedingungen statt: Jedes Teilchen, das das simulierte Volumen auf einer Seite verlässt, taucht auf der gegenüberliegenden wieder auf, alle Wechselwirkungen finden auch über diese Grenzen hinweg direkt statt. Dazu werden identische Kopien des simulierten Volumens nebeneinandergesetzt, sodass der dreidimensionale Raum die Oberfläche eines flachen, vierdimensionalen Torus bildet. Da dabei zu jedem Teilchen in den benachbarten Zellen Kopien entstehen, werden kurzreichweitige Wechselwirkungen nur zu dem einen, nächstliegenden dieser identischen Bildteilchen berechnet („Minimum Image Convention“).\n\nDie Molekulardynamik-Methode kann auch zur Simulation von Systemen verwendet werden, die sich nicht im thermodynamischen Gleichgewicht befinden. Beispielsweise kann ein Teilchen mit einer konstanten externen Kraft durch eine Lösung gezogen werden.\n\n\n"}
{"id": "1825856", "url": "https://de.wikipedia.org/wiki?curid=1825856", "title": "Mark-8", "text": "Mark-8\n\nMark-8 ist ein Mikrocomputer-Design aus dem Jahre 1974, das auf dem Intel 8008 basierte. Mark-8 wurde durch den Absolventen Jonathan Titus entworfen und wurde als Bausatz zur Selbstmontage in der Juli-Ausgabe von Radio Electronics vorgestellt.\n\nDabei wurde eine Broschüre für 5 US-Dollar angeboten, in der die Platinenlayouts, Anleitungen und Beschreibungen zur Konstruktion dokumentiert waren. Titus handelte mit einer Firma aus New Jersey ein Angebot aus, mit dem die Leser für 50 US-Dollar die benötigten Platinen bestellen konnten. Ein paar tausend Broschüren und mehrere hundert Platinen wurden verkauft. Angehende Konstrukteure des Mark-8 mussten die verschiedenen Elektronik-Bauteile aber selbst organisieren.\n\nMark-8 wurde in \"R-E\" als „Your Personal Minicomputer“ vorgestellt. Mit dem Wort „Minicomputer“ war das gemeint, was später und bis heute allgemein als Mikrocomputer bezeichnet wird.\n\nObwohl er kommerziell nicht sehr erfolgreich war, brachte Mark-8 die Redakteure von Popular Electronics dazu, im Januar des folgenden Jahres mit dem Altair 8800 ein ähnliches, aber zugänglicheres Mikrocomputer-Projekt zu publizieren.\n\n"}
{"id": "1831834", "url": "https://de.wikipedia.org/wiki?curid=1831834", "title": "SiSy", "text": "SiSy\n\nSiSy [], (Abkürzung von Simple System) ist ein Visualisierungsprogramm zur Darstellung von Modellen wie Managementmodelle oder Softwaremodelle, also ein Werkzeug für die Geschäftsprozessmodellierung, das Abbilden eines Qualitätsmanagementsystems, den Softwaresystementwurf, die Datenmodellierung und andere mehr. „SiSy“ ist ein Markenname der Laser & Co. Solutions GmbH und seit 1992 auf dem Markt. Beim Markt und Technik Verlag erschien 1993 ein Buch mit einer der ersten SiSy-Versionen auf einer Begleitdiskette. Eine Konzentration auf eine bestimmte Entwicklungsrichtung oder eine bestimmte Branche ist nicht zu erkennen. Das Werkzeug gibt es sowohl für rein betriebswirtschaftliche Anwendungsfälle wie auch als Softwareentwicklungsumgebung. In mancher Hinsicht erscheint SiSy von der Gestaltung der GUI her veraltet oder nicht Windows-konform. Betrachtet man jedoch die Entwicklung der Versionen seit 1992 so ist hier Kontinuität in der GUI-Gestaltung zu bescheinigen. Die zum Teil gewöhnungsbedürftige Benutzeroberfläche stellt bei den Anwendern neben teilweise verspäteter Portierung auf aktuelle Betriebssystemversionen einen der Hauptkritikpunkte dar.\n\nDer gegenwärtige Preis der Professional-Version beträgt für private Nutzung 990 €, für geschäftsmäßige Nutzung 25000 €.\n\nMit \"SiSy\" kann man Geschäftsprozessmodelle (Organisationsstruktur = Organigramm, Informationsstruktur = Entity-Relationship-Modell, Ablaufstruktur = Geschäftsprozesse) erstellen. Man kann aus den erstellten Modellen automatisch eine Dokumentation für die Geschäftsprozesse generieren.\nDiese Dokumentation eignet sich besonders zur Darlegung von QM-Systemen. Daraus ergibt sich offensichtlich auch die speziell für diesen Anwendungsfall angebotene QM-Version von SiSy. Laut Aussage des Herstellers wurde jedoch die Weiterentwicklung dieser Version eingestellt.\nUm ein gesamtes Geschäftsprozessmodell in SiSy erstellen zu können, muss man zuvor die Organisation und die Informationsstruktur und nötigen Dokumente abbilden. Erst wenn die Organisation, die Daten und die Dokumente abgebildet sind, kann man den Geschäftsprozess vollständig abbilden (WER-WAS-WANN-WOMIT). Die verschiedenen Modelle werden durch das Referenzieren von Objekten (vgl. einer Verknüpfung/Link) miteinander verbunden. Geschäftsprozesse lassen sich in SiSy mit drei verschiedenen Notationen abbilden. Zum einen mit den sogenannten Prozessketten, zum anderen mit einer Notation ähnlich einem Programmablaufplan bzw. den Möglichkeiten der UML.\n\nIn \"SiSy\" ist es möglich, die Organisation eines Unternehmens als Organigramm abzubilden und zu dokumentieren. So kann \"SiSy\" die Organisation hierarchisch oder auch vernetzt abbilden. Der Anwender kann den Stellen in einer Organisation natürliche Personen zuordnen. Die grafischen Gestaltungsmöglichkeiten von Organigrammen gegenüber Programmen wie Visio sind jedoch eher bescheiden. Dafür handelt es sich aber nicht nur um ein Bild, sondern um ein Modell der Organisation auf der Basis einer speziellen Datenbank, einer sogenannten Repository, welche automatische Auswertungen bis hin zu vollständig generierten Stellenbeschreibungen und Organisationshandbüchern ermöglicht.\n\n\"SiSy\" ermöglicht das Erstellen von Datenbanken. Dazu kann ein Entity-Relationship-Diagramm erstellt werden, um aus diesem Modell heraus automatisch die nötigen SQL-Statements zu generieren. Voraussetzung ist ein ODBC-Treiber für die gewünschte Zieldatenbank. Für die Notation des ERD stellt SiSy unterschiedliche Möglichkeiten bereit. Die Standardnotation erfolgt nach Chen, des Weiteren wird eine Min-Max-Notation und die Krähenfußnotation angeboten. Die Generierung der Datenbank schlägt jedoch bei manchen Zieldatenbanken fehl. Ursache ist, dass der in diesem Fall ausgewählte ODBC-Treiber proprietäre SQL-Statements erwartet. Der Anwender muss in diesem Fall die automatisch generierten Statements von Hand nachbessern. Offensichtlich sind die automatisch generierten Statements vor allem auf Microsoft Access abgestimmt.\n\nIn der ursprünglichen Version bezeichnete der Hersteller \"SiSy\" als CASE-Tool, welches ausgehend von der Analyse über den Entwurf bis zur Realisierung den gesamten Entwicklungszyklus einer Software unterstützte. Dabei war in den 1990er Jahren die Generierung des Quellcodes aus Struktogrammen eine Besonderheit. Damals war es eher üblich, aus dem Quellcode das Struktogramm zu generieren (Reverse Engineering). Die damals angebotenen Techniken waren in \"SiSy\" auf die strukturierte Analyse, das strukturierte Design (Jackson-Diagramm), das Entity-Relationship-Diagramm und das Struktogramm begrenzt. Im weiteren Verlauf der Entwicklung wurde vom Hersteller vor allem die Bezeichnung Modellierungswerkzeug verwendet. Diese Bezeichnung spiegelt die Entwicklung von SiSy zu einem Werkzeug wider, welches auf der Basis eines Metamodells arbeitet. Daraus erklärt sich, dass mit ein und demselben Basisprogramm \"SiSy\" durch Hinzufügen von recht einfachen Erweiterungen (Beschreibungsskripten für das Metamodell), so unterschiedliche Modelle bearbeitet werden können. Zugleich stellt diese Universalität offensichtlich auch Einschränkungen hinsichtlich der Spezialisierung auf bestimmte Modelle dar.\n\nIn den aktuellen Versionen des Modellierungswerkzeuges \"SiSy\" (dem Autor steht die Version 3.02 zur Verfügung) ist deutlich der Schwerpunkt in der Entwicklung der UML-Fähigkeiten zu erkennen. Dabei bleibt das Werkzeug offensichtlich dem Konzept der kompletten Generierung des Quellcodes aus dem Modell treu. Es verzichtet auf die sonst übliche Synchronisation zwischen IDE und UML-Tool, also von Code und Modell. Das Einbetten in eine IDE und das Reverse Engineering von objektorientierten Quellcodes wird nicht angeboten. Der Diagrammaustausch mit anderen UML-Werkzeugen ist in der vorliegenden Version nicht möglich. Die Programmierung erfolgt ausschließlich in SiSy. Das UML-Klassendiagramm ist somit in \"SiSy\" sehr konzentriert auf die Generierung von Quellcode ausgerichtet und erlaubt zügiges arbeiten. Dadurch ist jedoch die Modellierung von plattformunabhängigen Klassendiagrammen in SiSy eher unkomfortabel. Eine Besonderheit stellt die von \"SiSy\" angebotene Lösung für das Sequenzdiagramm dar. Dieses wird innerhalb des Klassendiagramms für die jeweils selektierte Klassenmethode dynamisch aus dem zugehörigen Code generiert. Seit Kurzem bietet das Tool auch die Generierung von Quellcode aus dem UML-Zustandsdiagramm an. Diese Modellierungstechnik spielt bei der Entwicklung von Embedded Systems eine besondere Rolle.\n\n\n"}
{"id": "1833267", "url": "https://de.wikipedia.org/wiki?curid=1833267", "title": "Sierra Wireless Voq", "text": "Sierra Wireless Voq\n\nDas Voq Professional Phone ist ein Smartphone des kanadischen Elektronikherstellers Sierra Wireless. Es ist ein Windows Powered Smartphone, das auf Basis des Betriebssystems Windows Mobile 2003 SE arbeitet.\n\nDas Voq Smartphone hat ein Gehäuse von 133 × 53 × 23 mm bei einem Gewicht von 145 Gramm. Die numerische Tastatur lässt sich seitlich wegklappen, so dass man eine Tastatur für die schnelle Eingabe von SMS erhält.\n\nDas TFT-Display hat eine Größe von 2,2 Zoll, eine Auflösung von 176 × 220 Pixeln bei 65.536 Farben. Das Smartphone hat keine Fotofunktionen, wodurch es auch für den Unternehmenseinsatz geeignet ist – mittlerweile erlauben manche Unternehmen aus Furcht vor Wirtschaftsspionage keine fototauglichen Handys mehr auf ihrem Gelände. Es bringt 40 polyphone Klingeltöne mit und kann beliebig um eigene Klingeltöne im Audioformat MP3 und WMA erweitert werden.\n\nDas Voq hat einen Intel XScale-PXA-262-Prozessor (200 MHz) mit einem internen Speicher von 48 MB ROM und 32 MB RAM. Der externe Speicher ist durch SD/MMC Memory Card erweiterbar.\n\nDas Voq Smartphone verfügt über Microsoft Outlook mit einer Kontaktdatenbank für acht Telefonnummern, zwei Faxnummern und drei E-Mail-Adressen je Kontakt, darüber hinaus über eine Kalenderfunktion und ein E-Mail-Programm. Die Kontaktdaten können über ActiveSync mit dem Computer abgeglichen werden.\n\nWeiterhin hat es den Windows Media Player 10.0 zur Wiedergabe von Musik und Videos sowie den Internet Explorer für den mobilen Zugang ins Internet und Intranet (über VPN-Client \"movian\"). Es kann Dateien in den Formaten Word, Excel, PowerPoint, PDF und weitere Formate darstellen.\n\nAls MP3-Player eignet es sich nur mit einem geeigneten Adapter für 2,5-mm-Klinkenstecker; der Klang ist gut und das Gerät dank des SD-Karteneinschubs sowie des hellen und kontrastreichen Displays gut für die Wiedergabe von Musik und Videos geeignet.\n\nDas Gerät verfügt über einen Lithium-Polymer-Akku mit einer Kapazität von 1050 mAh für eine Standbyzeit von 100 Stunden und eine Gesprächszeit von sechs Stunden.\n\nDas Gerät wird von Sierra Wireless selbst nicht mehr vertrieben. Es gibt die Möglichkeit, Software nachzuinstallieren, jedoch ist dies durch Microsofts Zertifizierungspolitik eingeschränkt.\n\n"}
{"id": "1834444", "url": "https://de.wikipedia.org/wiki?curid=1834444", "title": "No23Live", "text": "No23Live\n\nNo23Live ist eine Freeware-Software für das Audio-Streaming. Die Software verwendet das WMA-Format als Encoder und besitzt einen integrierten Streaming Server für die Benutzerverwaltung.\n\nNo23Live tastet die Aufnahmekanäle der Soundkarte ab. Das abgetastete Audiosignal wird in das WMA-Format übersetzt und als Live-Audiostream über das Netz gesendet. Der gesendete Audiostream kann vom Hörer über ein Abspielprogramm (Audioplayer) empfangen und wiedergegeben werden. Voraussetzung hierfür ist, dass das Abspielprogramm das WMA-Format unterstützt und auch mit Streaming zurechtkommt. Bis zu 50 Hörer können sich gleichzeitig mit No23Live verbinden, um den Audiostream zu empfangen. Zusätzlich kann der Audiostream auch an einen Windows-Media-Server gesendet werden.\n\nDarüber hinaus bietet das Programm die Möglichkeit, den Audiostream auf der eigenen Homepage zu veröffentlichen oder Hörer per E-Mail einzuladen. Alle erforderlichen Informationen (IP-Adresse, Portnummer usw.) werden automatisch ermittelt und können mit dem in der Software integrierten FTP-Client, auf den Webserver oder als vorgefertigte E-Mail in das Standard-E-Mail-Programm übertragen werden.\n\n\n\n"}
{"id": "1837276", "url": "https://de.wikipedia.org/wiki?curid=1837276", "title": "Windows Aero", "text": "Windows Aero\n\nWindows Aero ist eine grafische Benutzeroberfläche und ein Skin für das Betriebssystem Windows. Windows Aero ist im Lieferumfang der meisten Editionen von Windows Vista und Windows 7 enthalten und standardmäßig aktiviert. Bei Windows Server 2008 wird es ebenfalls mitgeliefert, ist dort aber nicht standardmäßig aktiviert. Das Wort \"Aero\" ist ein Backronym von \"Authentic, Energetic, Reflective, Open\".\n\nWindows Aero löst die vorige Benutzeroberfläche Luna ab und zeichnet sich durch halbdurchsichtige Fensterrahmen sowie durch Animationen beispielsweise beim Minimieren der Fenster aus. Aero bietet dem Benutzer frei skalierbare Anwendungsfenster mit Schattenwurf. Mit Hilfe von „Windows Flip 3D“, einem Element von Aero, das mit der Tastenkombination Windows + Tab aufgerufen wird, können Anwendungsfenster aller geöffneten Anwendungen beim schnellen Wechseln zwischen Programmen angezeigt werden. Die Hardware-beschleunigte Darstellung setzt eine kompatible Grafikkarte sowie kompatible Treiber voraus. Windows Aero unterteilt sich in Aero Basic, welches lediglich Designänderungen gegenüber Windows XP aufweist, und in Aero Glass, in dem die genannten Neuerungen enthalten sind.\nIn Windows 8.1 ist die Aero-Oberfläche noch enthalten, allerdings ohne \"Aero Glass\". Die Features \"Aero Shake\" und \"Aero Peek\" sind ebenfalls noch enthalten.\n\nDieser Modus bietet lediglich das neue Fensterdesign ohne Transparenzeffekt und ist zurzeit in Windows Vista Home Basic, Windows 7 Starter und Windows 7 Home Basic das Standard-Design. In Windows 7 Home Premium, Professional, Enterprise und Ultimate sowie Windows Vista Home Premium, Business, Enterprise und Ultimate ist es zusätzlich als Alternative zu Aero Glass integriert.\nVom Hersteller werden folgende Mindestvoraussetzungen angegeben:\n\n\nAero Basic läuft aber auch auf deutlich weniger leistungsfähigen Computern.\n\nAero Glass arbeitet mit 3D-Grafik, Animationen und visuellen Effekten (zum Beispiel Transparenz). Dafür müssen folgende Voraussetzungen erfüllt sein:\n\n\nDie Hardware erfüllt die Anforderungen, wenn bei der Bewertung ein Leistungsindex von mindestens 3,0 erreicht wird.\n\nUnterstützte Grafik-Chipsätze:\n\n\nMit der Veröffentlichung von Windows 8 wurden die Glass-Effekte weitgehend entfernt, jedoch ist Transparenz noch möglich. Mit Windows 10 wurden optionale Glaseffekte für das Startmenü, die Taskleiste und das Info-Center wieder eingeführt.\n"}
{"id": "1841044", "url": "https://de.wikipedia.org/wiki?curid=1841044", "title": "Tessy (Software)", "text": "Tessy (Software)\n\nTessy ist ein Werkzeug zum automatisierten Modultest von in C oder C++ geschriebener Software. Tessy ist besonders zum Test von Embedded Software geeignet, da Tessy viele von Cross-Compilern eingesetzte C-Dialekte für Embedded Systeme versteht und die Ausführung der Tests typischerweise auf dem Embedded System erfolgt. Tessy stammt aus dem Software-Forschungslabor der Daimler AG, heute Razorcat, in Berlin. Die Ursprünge reichen bis in die 1990er Jahre zurück.\n\nTessy bestimmt automatisch die Schnittstelle der zu testenden C-Funktion (der Unit bzw. dem Modul). Die Schnittstelle besteht im Wesentlichen aus der Menge der Eingabe- und der Menge der Ausgabevariablen dieser Funktion. Tessy generiert automatisch die Software für einen Test-Treiber, der es erlaubt, die zu testende Funktion ohne die anderen C-Funktionen der Applikation aufzurufen. Der Benutzer bestimmt die Testdaten, mit denen die zu prüfende Funktion versorgt werden soll und die erwarteten Ergebnisse. Funktionen, die von der zu prüfenden Funktion aufgerufen werden, können durch Stubs mit einem definierten Verhalten ersetzt werden. Solche Stubs können überprüfen, ob sie ihrerseits mit gültigen Parameter aufgerufen wurden und liefern typischerweise konstante Werte zurück, mit denen die zu testende Funktion arbeiten soll (sogenanntes Mocking). Test-Treiber und zu testende Funktion werden von Tessy übersetzt und gebunden, normalerweise mit dem Cross-Compiler für das betreffende Embedded System. Die Tests werden von Tessy direkt auf dem Embedded System durchgeführt, können aber auch auf einem PC ablaufen. Tatsächliche Testergebnisse werden automatisch mit den erwarteten Ergebnissen verglichen.\n\nTESSY kann Tests ohne Benutzerinteraktion wiederholen, was für Regressionstests wichtig ist. Zudem ermittelt TESSY die Testabdeckung (Coverage) automatisch.\n\nTestfallspezifikationen werden von TESSY nach der Klassifikationsbaummethode einlesen, denn es ist an das betreffende Werkzeug, den Classification Tree Editor (CTE) angebunden.\n\nTESSY erzeugt die Testdokumentation in verschiedenen Formaten, unter anderem Word, Excel, HTML. Aussehen und Umfang kann der Anwender weitgehend selbst festlegen.\n\nTESSY läuft unter Windows 2000 bis Windows 10.\n\n\n"}
{"id": "1847672", "url": "https://de.wikipedia.org/wiki?curid=1847672", "title": "Embedded-PC", "text": "Embedded-PC\n\nUnter einem Embedded-PC versteht man einen modular aufgebauten und kompakten Industrie-PC. Er ist ein eingebettetes System, dessen Rechnerarchitektur sich am Standard-PC orientiert.\n\nBei diesem Computer werden nur Komponenten in das System eingefügt, die auch für die entsprechende Anwendung benötigt werden – so kann ein Embedded-PC z. B. „headless“ betrieben werden, d. h. ohne Anzeige wie Monitor oder Display und Bediengeräte wie Maus und Tastatur; die entsprechende Schnittstelle kann dann entfallen. Wegen der geringen Leistungsaufnahme können diese PC meistens lüfterlos und wegen des geringen Speicherplatzbedarfs ohne Festplatte (dann z. B. mit CF-Karte) eingesetzt werden. Embedded-PC finden Einsatz in Produkten der Automobilindustrie, Verkehrstechnik, Produktions- und Fertigungstechnik, Telekommunikation und mehr. Immer leistungsfähigere Prozessoren ermöglichen den Einsatz von Embedded-PCs zur Steuerung komplexer Maschinen und Anlagen. Als dezentrale Maschinensteuerung kommen Systeme mit integrierter Sensor-Aktor-Verdrahtung zum Einsatz. Embedded-PCs werden auch in der Gebäudeautomatisierung eingesetzt.\n\nVorteile der Standard-PC-Architektur gegenüber anderen Architekturen ist die für viele Entwickler gewohnte Hardware- und Software-Umgebung und die Verfügbarkeit entsprechender PC-Software und Entwicklungsumgebungen.\n\nZumeist werden in eingebetteten Systemen sehr spezialisierte Betriebssysteme (VxWorks, Nucleus, OSEK, OS-9, spezielle Linux-Derivate, NetBSD usw.) eingesetzt.\nAllerdings finden auch spezielle Eingebettete Versionen von Standardbetriebssystemen wie Linux (Embedded Linux), NetBSD oder Windows (CE, XP Embedded, Automotive oder Embedded for PoS) Anwendung.\n\nZumeist besteht ein Embedded-PC aus folgenden Komponenten:\n\nEmbedded-PCs werden dort eingesetzt, wo die Eigenschaften und Rechenleistungen von Industrie-PCs erforderlich sind, andererseits aber deren preisliches Einstiegsniveau unter 1000 oder sogar unter 500 € liegen sollten. \nHäufig können sie auf kleinstem Raum – z. B. auf der Hutschiene – montiert werden. Trotz der Kompaktheit des Systems kommen häufig vergleichsweise leistungsstarke Prozessoren wie Intel Pentium M sowie Arbeitsspeicher 2 GiB zur Anwendung.\nZumeist bleiben die Embedded-PCs dauernd eingeschaltet, d. h. die Embedded-Betriebssysteme müssen nicht heruntergefahren werden.\n\nDer wachsende Markt für diese Geräte wird von der jährlich in Nürnberg stattfindenden Messe \"embeddedworld\" bedient.\n\n\n\n"}
{"id": "1847952", "url": "https://de.wikipedia.org/wiki?curid=1847952", "title": "Dr. Dobb’s Journal", "text": "Dr. Dobb’s Journal\n\nDr. Dobb’s Journal (DDJ) war eine bis Januar 2009 monatlich erscheinende US-amerikanische Computerzeitschrift für Softwareentwickler. Das kurz oft auch als „Dr. Dobb’s“ bezeichnete Heft wurde von CMP Media verlegt und erstmals im Januar 1976 herausgegeben. Die erste Ausgabe trug den Titel „Dr. Dobb’s Journal of Computer Calisthenics and Orthodontia“.\n\nAnfang 2009 gab Chefredakteur Jonathan Erickson die Einstellung der Printausgabe bekannt und verkündete, dass künftig nur noch eine abgespeckte Variante als Dr. Dobb’s Report im Magazin InformationWeek erscheinen werde. Ende 2014 wurde auch das Online-Angebot eingestellt. Die Webseite bleibt als Archiv online verfügbar.\n\nDer Name im Titel „Dr. Dobb’s“ ist ein Kunstwort, entstanden durch Kontraktion aus den Vornamen von Dennis Allison und Bob Albrecht, wobei der Namenserfinder, Rick Bakalinsky, fälschlich annahm, Dennis’ Vorname sei \"Don\".\n\nDDJ war die erste regelmäßig erscheinende Computerzeitschrift, die sich speziell mit Mikrocomputer-Software statt mit Hardware beschäftigte. Im Jahr 1985 wurde im DDJ das legendäre GNU Manifesto von Richard Stallman veröffentlicht.\n\n"}
{"id": "1850843", "url": "https://de.wikipedia.org/wiki?curid=1850843", "title": "Mehrplatzrechner", "text": "Mehrplatzrechner\n\nEin Mehrplatzrechner oder eine Multiterminalkonfiguration ist ein einzelner Computer, an dem mehrere Benutzer gleichzeitig arbeiten können. Die Konfiguration bestehen gewöhnlich aus einem Monitor, einer Tastatur und aus einer Maus für jeden einzelnen Benutzer, die gemeinsam an einen einzigen Rechner angeschlossen sind.\n\nDie ersten Mehrplatz-Systeme wurden bereits in den 1970er Jahren entwickelt. Mit der zunehmenden Rechenleistung der Prozessoren und ausreichenden Hauptspeichergröße können eine große Zahl an Programmen in einem Computer gleichzeitig verarbeitet werden, ohne den Computer zu überlasten. Jedoch ist mit der Standardkonfiguration nur ein Benutzer in der Lage, den Computer zu nutzen, meist wird das System gar nicht vollständig ausgelastet und der Rechner bleibt die meiste Zeit untätig. Mit einem \"Mehrplatzrechner/Multiterminal\" können sich mehrere Benutzer einen leistungsfähigen Computer teilen und so Kosten sparen.\n\nFür einen Mehrplatz-Rechner müssen für jeden Benutzer ein Bildschirm, eine Tastatur und eine Maus zur Verfügung gestellt werden. Werden gewöhnliche Grafikkarten verwendet, benötigt man ebenfalls für jeden Arbeitsplatz eine eigene. Es gibt allerdings auch speziell auf solche Systeme ausgelegte Grafikkarten, die dann mehrere Monitore gleichzeitig versorgen können.\n\nBei einem Betriebssystemen wie Linux wird die Interaktion mit dem Benutzer durch das X Window System ermöglicht. Es gibt eine Reihe von Varianten, wie ein Mehrplatz-Rechner/Multiterminal unter Linux realisiert werden kann:\n\n\n\n\n\n"}
{"id": "1850996", "url": "https://de.wikipedia.org/wiki?curid=1850996", "title": "Arcad", "text": "Arcad\n\nArcad ist ein CAAD-Programm für zweidimensionale und dreidimensionale Bauzeichnungen. Das Programm ist für Architekten, Bauingenieure und Stadtplaner ausgelegt. Dabei ist es dem Benutzer überlassen, ob er die Zeichnung traditionell 2D zeichnet oder in 3D modelliert und anschließend zum Bau benötigte 2D-Zeichnungen erstellen lässt.\n\nDas Programm ist in ANSI C unter Zuhilfenahme des OpenMotif GUI-Toolkits geschrieben und soll daher sehr schnell und unabhängig von der verwendeten Distribution laufen.\n\nAlle vom Systemhaus kommenden Programme verwenden dieselbe Datenbank, so dass die Programme sehr kollaborativ arbeiten sollen.\n\nNach eigenen Aussagen entwickelt das Unternehmen seit 1996 auf Linux und soll auf der Messe ACS in Wiesbaden das erste CAD-Programm und AVA-System für Linux vorgestellt haben. Danach folgte die Weiterentwicklung. 1998 kam eine Campus-Version und 2004 wurde Arcad 64-Bit-fähig.\n\nDas Unternehmen wurde 1983 in Haltern am See gegründet. \nNeben Arcad bietet das Unternehmen weitere Linux-Anwendungen für den professionellen Bereich. \nEin Auftragsbearbeitungs und Warenwirtschafts-System LXAuftrag, ein Finanzbuchhaltungs-System LXFibu, ein Lohn- und Gehaltsabrechnungssystem LXLohn, das AVA-System ARCHITEC für Architekten und eine E-Shop-Lösung.\n\n"}
{"id": "1851077", "url": "https://de.wikipedia.org/wiki?curid=1851077", "title": "Vectorworks", "text": "Vectorworks\n\nVectorworks ist ein CAD-System des Unternehmens Vectorworks, Inc. Es bietet ein Set von 2D-, 3D-, Präsentations- und Konstruktionswerkzeugen für alle Phasen des Planungsprozesses.\n\nAnwender können wie bei der traditionellen Arbeit am Zeichenbrett mit Geraden, Kreisbögen, Kreisen, Rechtecken usw. Ideen skizzieren, aber auch Elemente wie Wände, Fenster, Schränke, Pflanzen, Straßen und Scheinwerfer verwenden. Diese Objekte können mit Mehrfenstertechnik in 2D- und 3D-Ansichten angezeigt werden. 2D-Objekte lassen sich als \"planare Objekte\" auch in 3D-Ansichten zeichnen. 3D-Modelle können aus 2D-Zeichnungen erzeugt werden und umgekehrt, z. B. durch Legen von Schnitten.\n\nVectorworks verfügt über eine DXF/DWG- sowie eine IFC-Schnittstelle und kann eine Vielzahl von Dateiformaten importieren und exportieren. Dazu gehören u. a. SketchUp, 3DS, c4d, EPix, Shapefile/SHP, SAT, Parasolid X_T, PDF, EPS, JPG, TIF und BMP. Darüber hinaus unterstützt Vectorworks die Formate IGES, SAT, STEP und STL, mit deren Hilfe Vectorworks-Modelle z. B. an 3D-Drucker bzw. Rapid-Prototyping-Maschinen übertragen werden können. Mit der integrierten ODBC-Datenbankschnittstelle lassen sich in Vectorworks gezeichnete Objekte mit den Daten externer Datenbanken wie FileMaker, Access, MySQL, Excel u. a. verknüpfen. Das 3D-Modellieren erfolgt auf der Basis des Parasolid-Modellierkerns von Siemens PLM-Software. Der Bildschirmaufbau wird durch das Vectorworks Graphics Module beschleunigt, das über Multicore-Unterstützung und intelligente Objekte-Tessellierung verfügt. Für die Eventbranche wurde das Standardformat GDTF mitentwickelt. Die Daten können mit Hilfe des Dateiformats \"MVR\" weitergegeben werden. Die Versionen Vectorworks Architektur und Vectorworks Designer unterstützen Building Information Modeling (BIM).\n\nMit Grafikfunktionen, wie z. B. echten Liniendicken, Mustern, Rasterbildfüllungen, Schraffuren, Farbverläufen, Transparenzen, Mosaikfüllungen, Ansichtsbereichen (Viewports), Layoutebenen usw. können Kundenpräsentationen erzeugt werden. Die Skizzenstil-Technologie verleiht CAD-Zeichnungen das Aussehen von handskizzierten Illustrationen.\n\nFür fortgeschritteneres 3D-Rendering steht Renderworks zur Verfügung. Mit dem in Vectorworks integrierten Renderer lassen sich sowohl realistische Bilder erzeugen als auch Bilder, die wie von Hand skizziert aussehen (Aquarell, Bleistift u. a.). Zur Funktionalität von Renderworks gehören Global Illumination, Schattenstudien, sichtbares Licht und Flächenlichter, eine Bibliothek von weit über 1000 Texturen, 3D-Rasterbildobjekte, Umgebungsbilder, atmosphärische Effekte sowie die Unterstützung von HDRI und QuickTime VR. Renderworks basiert auf der CINEMA 4D Render Engine und erzeugt dadurch beim Export quasi ein generisches .c4d-Format.\n\nProjekt Sharing macht es möglich, dass mehrere Personen am gleichen Projekt zusammenarbeiten. Bürostandards wie Planköpfe, Stempelobjekte oder Symbolbibliotheken können zentral verwaltet werden.\nVectorworks verfügt außerdem über eine Programmiersprache namens VectorScript, mit der man selbst Funktionen programmieren oder aufzeichnen kann – vom einfachen Suchskript über eigene Befehle und Werkzeuge bis hin zu Intelligenten Objekten. VectorScript ähnelt syntaktisch Pascal. Außerdem können auch mit Python sowie Visual Scripting eigene Scripts erzeugt werden.\n\nZu den Leistungsmerkmalen von Vectorworks gehören darüber hinaus Strukturelemente wie Ebenen, Klassen, Referenzen, Gruppen, Symbole usw., eine assoziative Bemaßung, eine integrierte Datenbank und ein Kalkulationsblatt sowie Solid Modelling-Funktionen für Volumenmodelle.\n\n\n\nVectorworks hieß bis 1999 MiniCAD. Es wurde ursprünglich für den Apple Macintosh entwickelt, und zwar von \"Diehl Graphsoft Inc.\" Ab 2000 hieß die Firma \"Nemetschek North America\", ab 2008 \"Nemetschek Vectorworks\" und seit 2015 \"Vectorworks Inc.\"\n\n\n"}
{"id": "1854212", "url": "https://de.wikipedia.org/wiki?curid=1854212", "title": "Sky Chart", "text": "Sky Chart\n\nSky Charts oder Cartes du Ciel ist ein freies Astronomieprogramm. Man kann sich damit den Sternenhimmel so anzeigen lassen, wie er sich zu einer gegebenen Zeit, an einem gegebenen Ort und in einem gegebenen Raumwinkel darstellt. Es simuliert den Sternenhimmel für den Zeitraum von 200.000 v. Chr. bis 200.000 n. Chr., die Planetenpositionen können jedoch standardmäßig nur von 3.000 v. Chr. bis 3.000 n. Chr. angezeigt werden.\n\nEbenfalls besteht die Möglichkeit, verschiedene Sternkataloge zu laden als auch Teleskope mit Motorsteuerung anzuschließen und mithilfe des Programms zu positionieren.\n\nHauptansprechpartner ist der Schweizer \"Patrick Chevalley\". Das Programm entstand mit Unterstützung von \"Luca Crivelli\" and \"Greg Roberts\".\n\n"}
{"id": "1854469", "url": "https://de.wikipedia.org/wiki?curid=1854469", "title": "Artists Against 419", "text": "Artists Against 419\n\nArtists Against 419 (\"kurz:\" AA419) ist eine Internetgemeinde, die sich der Identifizierung und Schließung von Vorschussbetrug-Webseiten widmet. Die Zahl 419 im Namen erklärt sich aus dem Nigerianischen Strafrecht. Der Abschnitt Nummer 419 behandelt speziell den Betrug mit angeblichen Gebühren und überhöhten versprochenen Gewinnen. Neben der Bezeichnung „Nigerian Fraud“ ist daher nach Ansicht der \"Artists\" auch „419 Fraud“ eine übliche Bezeichnung für diese spezielle Form des Betruges. \n\nIm Oktober 2003 begannen die \"Artists\" bei falschen Banken durch \"hotlinking\" von deren Bilder-Seiten, die geringe monatliche Bandbreite zu erschöpfen. Im Laufe der Zeit haben sich die gefälschten Banken weiterentwickelt, und ebenso die \"Artists\". Am 30. November 2003 hosteten die \"Artists\" den ersten internationalen Flashmob. Es hat danach weitere Flashmobs gegeben, die dazu bestimmt waren, die Hoster darauf aufmerksam zu machen, dass die \"Artists\" es nicht hinnehmen werden, dass Hoster wissentlich kriminelle Webseiten hosten.\n\nAußerdem begannen die \"Artists\", eine Datenbank betrügerischer Webseiten zu erstellen, welche ihre Mitglieder gefunden hatten, damit potenzielle Betrugsopfer ihre Seite finden und somit gewarnt werden können, wenn sie nach den Seiten suchen, auf die die Betrüger sie leiten wollen. Die Datenbank enthält mittlerweile über 135.000 Websites (Stand: Februar 2019) und ist eine der größten Datenbanken betrügerischer Webseiten weltweit.\n\nMit einer speziellen Suchmethode wird nach den gefälschten Webseiten gesucht. Sobald eine Webseite als Fälschung identifiziert wird, wird sie in die Datenbank eingetragen und der Hoster wird kontaktiert und gebeten, die betrügerische Webseite abzuschalten. In den meisten Fällen werden gefälschte Seiten innerhalb von Stunden nach ihrer Erstellung deaktiviert. Jede Seite wird mit großer Sorgfalt geprüft, bevor sie in die Datenbank eingetragen wird. Die Vollzugsbehörden nutzen zunehmend diese Daten als Informationsquelle.\n\nDie \"Artists\" pflegen Kontakte zu Webhosting-Firmen, die bei ausreichender Beweislage die Webseiten schließen. Sollte eine Firma trotz erhärteter Beweislage keine Reaktionen zeigen, wird von ihnen ein Flashmob-Verfahren eingeleitet.\n\nIn diesem Falle besteht der Flashmob aus einer großen Anzahl von Personen, die die betrügerische Webseite besuchen und herunterladen. Ziel ist es, die Bandbreitenquote aufzubrauchen, sodass die Webseite nicht mehr erreichbar ist. Teilen sich mehrere Webseiten dieselbe Quote, so werden auch diese anderen Webseiten schlechter erreichbar. In manchen Fällen, insbesondere wenn kleine Webhosting-Firmen betroffen sind, kann es passieren, dass alle Webseiten des Hosters verlangsamt werden. Sobald aber der Hoster die kriminelle Webseite deaktiviert, kehrt automatisch wieder „Normalität“ ein, da die deaktivierte Seite mit „Fehler 404 nicht erreichbar“ antwortet (sehr kleine Datenmenge) und die viel größere Datenmenge der Webseite nicht mehr übertragen wird. \n\nDie \"Artists\" wollen keine unangekündigten Flashmobs durchführen. Das Verfahren soll nur als letztes Mittel eingesetzt werden.\n\n"}
{"id": "1856516", "url": "https://de.wikipedia.org/wiki?curid=1856516", "title": "Jagdfieber (2006)", "text": "Jagdfieber (2006)\n\nJagdfieber (Originaltitel: \"Open Season\") ist eine computeranimierte Filmkomödie aus dem Jahr 2006. Es ist der erste computeranimierte Spielfilm, der von \"Sony Pictures Animation\" produziert wurde.\n\n2009 erschien eine Fortsetzung unter dem Titel \"Jagdfieber 2\" und 2010 eine weitere unter dem Titel \"Jagdfieber 3\", die nicht in die Kinos kamen und direkt auf DVD veröffentlicht wurden. 2015 folgte \"\". \n\nDer Grizzlybär Boog führt ein fast menschliches Leben bei Wildhüterin Beth in der kleinen Stadt \"Timberline\". Regelmäßig tritt er als gezähmter Bär in ihren Shows auf und wohnt für sich allein in einer Garage. Er schläft auf weichen Kissen und hat als Kuscheltier einen Teddybären.\n\nEines Tages rettet Boog dem Hirsch Elliot, der von einem Wilderer gefangen wurde, das Leben. Daraufhin sucht Elliot eines Nachts Boog in seiner Garage auf um ihn zu „befreien“, da er glaubt, der Bär würde dort von den Menschen gefangen gehalten. Boog will jedoch seine Garage nicht verlassen. Elliot kann den Bären jedoch mit Süßigkeiten ins Freie locken. Um weitere Süßigkeiten zu beschaffen, brechen sie in einen Laden ein. Boog wird im zerstörten Laden vom Sheriff gefangen genommen und zu Beth zurückgebracht. Als es am nächsten Tag bei Boogs Auftritt vor Kindern zu einer wilden Prügelei zwischen dem Bären und dem Hirsch kommt, sieht Beth ein, dass der Bär wohl doch nicht in die Stadt gehört und muss ihn schweren Herzens zusammen mit dem Hirsch im Wald aussetzen. Zu deren Sicherheit geschieht dies außerhalb des offiziellen Jagdgebiets, da es nur noch drei Tage bis zum Beginn der Jagdsaison ist.\n\nAls Boog geschockt aus der Narkose erwacht, verspricht ihm Elliot, ihn zurück in die Stadt zu bringen, obwohl er sich eigentlich wünscht, dass Boog bei ihm bleibt. Auf ihrer Suche nach dem Weg in die Stadt lernen sie die Bewohner des Waldes kennen, und Boog muss erkennen, dass er alles andere als ein gefährlicher Grizzly – der größte Fleischfresser Nordamerikas – ist.\n\nZu allem Unglück zerstören Boog und Elliot aus Versehen einen großen Biberdamm. Die freiwerdenden Wassermassen spülen daraufhin die beiden und zahlreiche weitere Tiere hinunter in das Jagdgebiet, wo nun auch die Jagdsaison eröffnet wird. Die Tiere des Waldes müssen nun um ihr Leben fürchten. Gemeinsam gelingt es ihnen jedoch die Jäger aus dem Wald zu vertreiben. Als Beth in den Wald kommt, um Boog zurück in die Stadt zu holen, entscheidet sich Boog gegen die Stadt und für seine neuen Freunde. Den Wald sieht er nun als sein neues Zuhause an.\n\nDer Film wurde bei der Berliner Synchron synchronisiert. Michael Nowka schrieb das Dialogbuch und führte die Dialogregie.\n\nAuf Rotten Tomatoes wurde der Film bei 96 Rezensionen im Schnitt mit 47 % bewertet. Der Konsens ergab „eine klischeehafte Palette von müden Witzen“ und „computergenerierter Tier-Mumpitz den man bereits mehrfach gesehen hat“.\n\nSvenja Friedrich auf stern.de meinte, die Idee hätte funktionieren können „wenn der Film nicht Ewigkeiten brauchen würde, bis der Kampf im Wald beginnt. In der Zwischenzeit langweilen sich erwachsene Zuschauer bereits zu Tode“, ein weiteres Manko wäre, „dass der Zuschauer bereits bei Filmbeginn das Gefühl hat, die Story zu kennen“ und „dass der Film nach ungefähr 30 Minuten beginnt, sich selbst zu wiederholen“.\n\n\n"}
{"id": "1857557", "url": "https://de.wikipedia.org/wiki?curid=1857557", "title": "Computer easy", "text": "Computer easy\n\nDie Computer easy war eine deutsche Computerzeitschrift mit zweiwöchentlicher Erscheinungsweise, die sich speziell an PC-Einsteiger richtete, die das Betriebssystem Microsoft Windows einsetzen. Die Erstausgabe von \"Computer easy\" erschien am 14. Januar 1998 und die letzte Ausgabe am 5. April 2004.\n\nVerlegt wurde die Zeitschrift von der \"Vogel Computer Presse\" (heute Vogel Business Media). Chefredakteure waren ab April 2000 bis zur Einstellung im April 2004 Volker Everts und davor der Gründungschefredakteur Martin Vieten. Ähnlich wie später in der \"Computer Bild\" gab es in der Heftmitte von \"Computer easy\" heraustrennbare Workshops zum Sammeln.\n\nUnter dem Titel \"Computer easy\" erschienen auch nach Einstellung der Zeitschrift noch sporadisch Sonderhefte und Bücher.\n"}
{"id": "1861176", "url": "https://de.wikipedia.org/wiki?curid=1861176", "title": "Setun", "text": "Setun\n\nSetun () war ein auf balancierter ternärer Logik aufbauender Computer, welcher 1958 in der Sowjetunion entwickelt wurde. \n\nDer Setun-Computer war der weltweit einzige Rechner, der auf dem Prinzip der balancierten ternären Logik (−1, 0, 1) basierte. Er wurde für Lehrzwecke und wissenschaftliche Aufgaben (z. B. Agrochemie, Nuklearforschung) eingesetzt. 50 Exemplare des Setun wurden in den 1960er Jahren gebaut und kamen in allen Unionsrepubliken zum Einsatz. Der Computer erhielt seinen Namen nach dem Flüsschen Setun, das in der Nähe der Moskauer Lomonossow-Universität fließt.\n\nDer ternäre Computer Setun wurde von 1956 bis 1958 durch ein Team um den sowjetischen Funkingenieur Nikolai Brussenzow entwickelt. Die sich langsam vom Zweiten Weltkrieg erholende Wirtschaft und Wissenschaft des Landes sollte mit elektronischen Rechnern für Lehrzwecke und wissenschaftliche Anwendungen ausgerüstet werden. 1956 trafen sich einige Ingenieure und Studenten des von Sergei Sobolew geleiteten Computer-Forschungszentrums der Moskauer Lomonossow-Universität in einem Seminar, an dem neben Michail Schura-Bura, Konstantin Semendjajew und Jewgeni Schogolew auch der junge Brussenzow teilnahm. \n\nIn den darauf folgenden Jahren wurden 50 Computer in der Fabrik für Computersysteme in Kasan zum Stückpreis von 27.000 Rubel hergestellt. Obwohl es für den in der gesamten Sowjetunion an Universitäten und in der industriellen Produktion eingesetzten Computer (u. a. in Nowosibirsk, Kaliningrad, Jakutsk, Aschchabad, Magadan, Odessa, Irkutsk, Krasnojarsk, Duschanbe, Machatschkala) keinen offiziellen technischen Benutzer-Support gab, lief der Setun nach Aussagen von Nikolai Brussenzow meist fehlerfrei. Er und sein Team entwickelten 1970 das Nachfolgemodell \"Setun 70\". Jedoch favorisierte das Staatliche Planungskomitee Gosplan andere Projekte und die Entwicklung wurde schließlich eingestellt.\n\nAuch in den USA und Kanada wurde zu Ternär-Bauelementen geforscht. Allerdings zeigte sich spätestens in den beginnenden 1970er Jahren, dass die Entwicklung von ternären Bauelementen angesichts der bereits weit vorangeschrittenen binären Technologien zu teuer wurde. Die Rechenkapazitäten nahmen im Vergleich zu den beginnenden Sechzigern derart stark zu, dass ternäre Rechenoperationen problemlos auf binären Computern emuliert werden konnten.\n\nSetun ist sequentiell aufgebaut und besitzt einen Ferritkernspeicher mit drei Seiten zu je 54 Worten. Die Magnettrommeln arbeiten mit dem RAM als Cache zusammen. Der Inhalt des Index-Registers kann, abhängig vom Wert des Adressen-Modifizierungstrits (+, 0, -), zum Adressenteil der Instruktion addiert oder von ihr subtrahiert werden. Der Befehlssatz besteht aus nur 24 Befehlen, die u. a. folgende Funktionen ermöglichen: Mantissen-Normalisierung für Gleitkomma-Rechnung, Shift, kombinierte Multiplikation und Addition.\n\n\n"}
{"id": "1861648", "url": "https://de.wikipedia.org/wiki?curid=1861648", "title": "Ext4", "text": "Ext4\n\nDas ext4 \"(fourth extended filesystem)\" ist ein Journaling-Dateisystem, das für den Linux-Kernel als Nachfolger von ext3 entwickelt wurde.\n\next4 wurde am 10. Oktober 2006 von Andrew Morton vorgestellt. Ab der Version 2.6.19 war eine vorläufige Testversion offizieller Bestandteil des Linux-Kernels. Mit dem Erscheinen von Linux 2.6.28 am 24. Dezember 2008 verließ ext4 das Hauptentwicklungsstadium. In Linux 4.3 wurde der Code des nativen Treibers für Ext3 endgültig entfernt. Der Ext4-Treiber unterstützt zukünftig weiterhin Ext3.\n\n\"ext4\" benutzt 48 bit große Blocknummern (ext3 hatte 32 bit) und unterstützt so Partitionen oder Volumes, die bis zu 1 EiB groß sind (Volumes größer als 16 TiB erst ab e2fsprogs Version 1.42 vom 29. November 2011), im Gegensatz zu ext3, das nur 32 TiB zulässt (abhängig von der Größe einer Speicherseite in der jeweiligen Maschinenarchitektur, bei IA-32 zum Beispiel sind nur maximal 2 · 4 KiB = 16 TiB möglich). Auch kann die Adressierung von Dateien über \"Extents\" erfolgen, wobei Speichereinheiten zu einem zusammenhängenden Block zusammengefasst werden. Dies führt zu einer Reduzierung des Zusatzaufwands (RAM, E/A-Zugriffe und Transaktionen) und kann die Leistung im Betrieb steigern.\n\nSeit Veröffentlichung im Kernel 2.6.19 sind folgende Verbesserungen implementiert worden:\n\n\nAls weitere Verbesserungen gegenüber ext3/ext2 sind unter anderem noch in Planung oder bereits implementiert:\n\n\n\n\n\n\n\n\nBei bestehenden ext3-Partitionen können einige der ext4-Features ohne Neuformatierung aktiviert werden.\next2- und ext3-Partitionen können eingehängt werden, als wären sie ext4-Partitionen. Daraus ergeben sich durch Optimierung im ext4-Treiber bereits kleine Leistungsgewinne.\n\nSeit Kernel 4.1 unterstützt ext4 Verschlüsselung. Diese wurde zunächst von Google entwickelt und in ext4 direkt eingebaut, seit Kernel 4.6 ist die Verschlüsselung unter dem Namen fscrypt eine eigene Bibliothek im Linux-Kernel, welche über Hooks in Dateisystemen genutzt werden kann. Neben ext4 haben derzeit F2FS und UBIFS Unterstützung für fscrypt implementiert. Das Keyhandling wird über den Kernelkeyring gemanagt.\n\nMit e4crypt existiert eine Referenzimplementation für ein Userspace-Tool zum Anlegen von Schlüsseln und Aktivieren der Verschlüsselung für Verzeichnisse. Eine alternative Implementation sind die Tools fscryptctl und fscrypt.\n\nVoraussetzungen:\n\n\nEigenschaften:\n\n\nNachteile:\n\n\nZeitverzögerte Allokation von Dateiblöcken und Inodes erhöht das Risiko von Datenverlust bei Abstürzen oder Stromausfall. In Kernel Version 2.6.30 wurde dieses Problem gegenüber früheren Versionen entschärft.\n\n\n"}
{"id": "1863337", "url": "https://de.wikipedia.org/wiki?curid=1863337", "title": "BV4.1", "text": "BV4.1\n\nDie Anwendungssoftware BV4.1 ist ein auf Benutzerfreundlichkeit ausgerichtetes Werkzeug für Komponentenzerlegungen (siehe Methoden der Zeitreihenanalyse) und Saisonbereinigungen von monatlichen und vierteljährlichen ökonomischen Zeitreihen mit dem Berliner Verfahren, Version BV4.1. Sie wurde vom deutschen Statistischen Bundesamt entwickelt und steht für nicht-kommerzielle Anwendungen als Freeware zur Verfügung.\n\nDie Software BV4.1 besitzt folgende wesentlichen Leistungsmerkmale: \n\n"}
{"id": "1863727", "url": "https://de.wikipedia.org/wiki?curid=1863727", "title": "PfSense", "text": "PfSense\n\npfSense ist eine Firewall-Distribution auf der Basis des Betriebssystems FreeBSD und des Paketfilters \"pf\".\n\nUm pfSense in der Version 1.2.x auf einem Computer einzurichten, muss der Computer folgende Voraussetzungen erfüllen: Es werden ein Pentium oder ARM Prozessor mit mindestens 100 MHz sowie 128 MB Arbeitsspeicher und 1 GB Festplattenspeicher benötigt. Zum Einrichten wird ein CD-Laufwerk für die Installations-CD sowie ein USB-Steckplatz oder ein Diskettenlaufwerk zum Laden von Einstellungen benötigt.\n\nHier sind die Mindestsystemvoraussetzungen für pfSense genannt, in Kombination mit Add-Ons verändern sich diese Voraussetzungen.\n\nDie Distribution ist ein Fork vom mittlerweile eingestellten Projekt m0n0wall und wurde 2004 von Chris Buechler und Scott Ullrich ins Leben gerufen. m0n0wall ist eine Firewall-Distribution, damals auf Basis von FreeBSD-4 und ipfilter. m0n0wall zielt ab auf kleine Embedded-Systeme mit wenig Hardware-Ressourcen. Auf PCs läuft m0n0wall direkt von einer CD und speichert die Konfiguration in einer XML-Datei auf einer Floppy-Diskette. Alternativ kann m0n0wall auch mit einem CF-Kartenadapter von einer Flash-EEPROM CF-Karte laufen, was zuverlässiger als die CD/Floppy- oder Festplatten-Variante ist.\n\nm0n0wall wird komplett über ein Web-Interface gesteuert. Das FreeBSD-4-Basissystem ist nicht über eine Konsole zugänglich. Weiterhin unterstützt m0n0wall keinen Web-Proxy, keine Multiprozessor-Systeme und keine Lastverteilung.\n\nDas ist der Ansatz von pfSense.\n\npfSense erweitert die Fähigkeiten von m0n0wall und übernimmt die Stärken wie die einfache Konfiguration über ein PHP-Web-GUI, Speicherung aller Konfigurationsdaten in einer XML-Datei und FreeBSD-Basis.\n\n\n\nPfSense verwendet OpenSSL und war damit auch vom \"Heartbleed bug\" betroffen, dieser Fehler trat kurz nach dem Veröffentlichen der Version 2.1.1 auf, weshalb am 10. April 2014 das Update zu 2.1.2 bereitgestellt wurde.\n\nIm November 2017 stellte ein Schiedsgericht der Weltorganisation für geistiges Eigentum fest, dass Netgate die Domain opnsense.com in böser Absicht benutzt hatte, um OPNsense, eine konkurrierende Open-Source-Firewall, zu diskreditieren, und verpflichtete Netgate, die Domain an Deciso, den Entwickler von OPNsense, zu übertragen. Die Netgate-Partei versuchte, sich auf die Fair-Use-Klausel zu berufen und behauptete, dass der Domainname \"für eine Parodie-Website verwendet wurde\"; dies wurde mit der Begründung abgelehnt, dass die Meinungsfreiheit die Registrierung von Domainnamen nicht abdeckt.\n\nDer Name pfSense setzt sich zusammen aus dem Namen des verwendeten Paketfilters \"pf\" und dem englischen Begriff \"sense\", welcher hier verwendet wird im Sinne von \"making sense of pf\". Dies lässt sich sinngemäß übersetzen zu „pf einen Sinn geben“, „Sinnvolles mit pf machen“, „aus pf schlau werden“.\n\nBSD basiert:\nLinux basiert:\n\n"}
{"id": "1864278", "url": "https://de.wikipedia.org/wiki?curid=1864278", "title": "Umbrello", "text": "Umbrello\n\nUmbrello UML Modeller ist ein freies/Open-Source-Entwurfswerkzeug (CASE-Tool) zur Beschreibung und Modellierung von (Software-)Systemen und zur Code-Generierung.\n\nUmbrello nutzt die standardisierte grafische Notation Unified Modeling Language (UML). Grafisch erstellte Entwürfe, Software-Architekturen und -Modelle können in Programmcode für die gängigsten Programmiersprachen umgesetzt werden, und umgekehrt kann vorhandener Programmcode automatisch in einen grafischen Entwurf, eine Software-Architektur beziehungsweise ein Softwaremodell rückübertragen werden (Reverse Engineering). Das Reverse Engineering ist jedoch noch nicht vollständig implementiert: Der Code-Import ist zwar möglich, es wird jedoch nur ein Klassenbaum, aber im gegenwärtigen Release noch kein UML-Klassendiagramm erzeugt. In einer künftigen Ausbaustufe soll auch die Simulation von (Software-)Systemen umgesetzt werden.\n\nDurch standardisierte UML-Modellierung wird das Software-Architekturmodell anschaulicher und die Kommunikation zwischen Software-Entwicklern sowie zwischen Entwicklern und Auftraggebern erleichtert, wodurch das Risiko häufig auftretender und vermeidbarer Fehler im gesamten Entwicklungsprozess minimiert werden kann.\n\nUmbrello ist Teil des KDE-Projektes, entwickelt in C++ mit Qt, und läuft auf den Betriebssystemen Unix/Linux (ab KDE 4.x auch auf Windows). Seine Verwendung ist jedoch nicht auf KDE beschränkt; Umbrello arbeitet auch unter anderen Desktop-Umgebungen, sofern diese, wie zum Beispiel Gnome, zu den Standards von freedesktop.org konform sind.\n\nDas intern verwendete Dateiformat basiert auf XMI.\n\nUmbrello ermöglicht die Verteilung oder den Austausch von Software-Architekturmodellen durch Exportmöglichkeiten in das DocBook- und das XHTML-Format. Diese Eigenschaft unterstützt Entwicklergruppen, zum Beispiel wenn Teammitglieder keinen direkten Zugriff auf Umbrello haben, oder bietet die Möglichkeit, mit Umbrello erstellte Software-Architekturmodelle im Intranet beziehungsweise Internet zu publizieren.\n\n\n\n"}
{"id": "1865159", "url": "https://de.wikipedia.org/wiki?curid=1865159", "title": "Lotus Freelance Graphics", "text": "Lotus Freelance Graphics\n\nLotus Freelance Graphics ist ein Präsentationsprogramm der Firma Lotus Development Corporation (heute ein Unternehmen von IBM).\n\nDas Programm erlaubt dem Benutzer, Text, Bilder, Zeichnungen und Diagramme (wie Balken- und Kreisdiagramme) in eine Microsoft PowerPoint ähnliche Diavorführung einzubinden.\n\nFreelance Graphics war das Nachfolgeprodukt zu dem Präsentationsprogramm Freelance Plus unter DOS\n\nDie erste Version wurde Anfang 1990 für den OS/2 Präsentations-Manager herausgegeben. Es konnten bereits Daten aus Lotus 1-2-3 integriert werden. \nIm Jahr 1993 kam die Version 2.0 für OS/2 2.0 und Microsoft Windows auf den Markt.\n\nFreelance Graphics ist ein Teil der Lotus SmartSuite für Microsoft Windows. Die derzeit aktuelle Version ist 9.8 (Stand: Oktober 2006). \n\nDie mit Freelance erstellten Dateien erhalten die Endung .prz, ältere Versionen speichern mit der Dateiendung .pre . Vorlagendateien (so genannte SmartMaster) haben die Dateiendung .smc.\nDas Dateiformat selbst ist proprietär und kann nicht ohne weiteres von anderen Programmen gelesen werden. Mit Freelance Graphics kann man jedoch viele Fremdformate (z. B. Microsoft PowerPoint) lesen, bearbeiten und speichern. Es gibt jedoch einen Betrachter für Windows, mit dem die Dateien angezeigt werden können.\n\n\n\n\n\n"}
{"id": "1866986", "url": "https://de.wikipedia.org/wiki?curid=1866986", "title": "Processor Direct Slot", "text": "Processor Direct Slot\n\nDer Processor Direct Slot (PDS) bezeichnet einen Steckplatz der Firma Apple, der direkt an den Prozessorbus angebunden ist. Dieser Steckplatz hat schnellen Zugriff auf den Prozessor und den Hauptspeicher.\n\nApple hat in seinen Computern verschiedene PDS-Formate benutzt. Es gab Ethernetkarten, Grafikkarten, PC-Emulationskarten und Beschleunigerkarten. Im Allgemeinen funktionieren alle diese Karten jeweils nur in einem einzigen Rechnermodell oder einer kleinen Gruppe eng verwandter Modelle.\n\nRechner mit PDS waren u. a.\n\n"}
{"id": "1868213", "url": "https://de.wikipedia.org/wiki?curid=1868213", "title": "Olivetti Echos P75", "text": "Olivetti Echos P75\n\nDer Olivetti Echos P75 ist ein Personal Computer (PC) der italienischen Firma Olivetti.\n\nGebaut wurde er um 1994 und ist mittlerweile technisch veraltet. Ersatzteile gibt es nicht mehr, da die Firma Olivetti die Produktion von Personal-Computern eingestellt hat. In Internet-Auktionshäusern werden jedoch hin und wieder noch einige Exemplare angeboten, die meist Sammlern und Liebhabern als Ersatzteillager dienen.\n\n"}
{"id": "1869172", "url": "https://de.wikipedia.org/wiki?curid=1869172", "title": "CFEngine", "text": "CFEngine\n\nCfengine (Eigenschreibweise: CFEngine) ist ein Regel-basiertes Computer-Verwaltungssystem, welches von Mark Burgess am Oslo University College geschrieben wurde. Seine Hauptfunktion besteht darin, eine automatisierte, gruppenrichtlinien-spezifische Konfiguration und Wartung von Computern anzubieten.\n\nDas Projekt Cfengine wurde 1993 als Reaktion auf die Komplexität und schlechte Portierbarkeit von Shell-Skripten für die Konfiguration von Unix-Systemen ins Leben gerufen und wird noch heute weiterentwickelt. Das Ziel war es, oft gebrauchte Programmier-Paradigmen unnötig zu machen und durch eine deklarative, domain-spezifische Sprache zu ersetzen. Die Sprache sollte so einfach zu lesen sein, dass sie selbst-dokumentierend ist.\n\nDie Cfengine bietet eine Betriebssystem-unabhängige Schnittstelle zu unixähnlichen Konfigurationen. Es abstrahiert die Eigenheiten der verschiedenen Betriebssysteme und kann Instandhaltungsarbeiten auf verschiedenartigen Unix-ähnlichen Servern gleichzeitig durchführen. Die Cfengine kann auch auf Windows-Servern eingesetzt werden. In letzter Zeit wird sie mehr und mehr als eine Möglichkeit anerkannt, eine Vielzahl von Unix-Servern verschiedenartiger Betriebssystem wie Solaris, Linux, AIX und HP-UX zu verwalten.\n\nEine der Hauptinnovationen der Cfengine ist die Idee, dass Änderungen an der Computer-Konfiguration als atomare Aktionen ausgeführt werden sollen. Das bedeutet, dass Änderungen vom Agenten Fixpunkt-artig ausgeführt werden. Anstatt die einzelnen Schritte zu beschreiben, welche nötig sind um eine Änderung hervorzurufen, beschreibt Cfengine den Endzustand des Systems. Der eingesetzte Agent sorgt dafür, dass dieser erreicht wird, indem die notwendigen Schritte ausgeführt werden bis ein „Richtlinien-kompatibler Systemzustand“ eingetreten ist. Dadurch kann die Cfengine wieder und wieder ausgeführt werden und es wird unabhängig vom Anfangszustand des Systems das vorhergesehene Ergebnis eintreten.\n\n\n"}
{"id": "1870096", "url": "https://de.wikipedia.org/wiki?curid=1870096", "title": "Stencilbuffer", "text": "Stencilbuffer\n\nDer Stencilbuffer (engl. \"stencil\" – Schablone, \"buffer\" – Puffer) ist in der Computergrafik ein zusätzlich zum Color-Buffer und Z-Buffer vorhandener Teil des Framebuffers. Jedem Pixel ist ein Wert im Stencilbuffer zugeordnet. Die Aufgabe des Stencilbuffers ist es, die Übernahme von Fragmenten in den Framebuffer auf Regionen mit bestimmten Eigenschaften der Stencilwerte einzuschränken. Die zu erfüllende Eigenschaft wird durch die Stencilfunction eingestellt. In welcher Art der Stencilwert bei der Verarbeitung eines Fragments modifiziert wird, wird durch die Stenciloperation festgelegt, die abhängig vom Ausgang des Stencil- und des Z-Tests unterschiedlich eingestellt werden kann.\n\nIm einfachsten Fall wird durch den Stencilbuffer das Renderinggebiet begrenzt. Dies kann beispielsweise bei einer Auto- oder Flugsimulation zum Ausmaskieren des Cockpits genutzt werden, um die Teile der Szene, die sich hinter dem Cockpit befinden, nicht zu rendern. Ein anderes solches Einsatzgebiet ist die Vermeidung von Z-Fighting bei der Darstellung komplanarer Ebenen (Dreiecke). Mit Hilfe des Stencilbuffers lassen sich auch Spiegel darstellen, in dem die gespiegelte Szene in der originalen nur innerhalb des Spiegelrahmens gerendert wird.\n\nDie enge Verzahnung des Stencil- und des Z-Buffers in der Grafikpipeline und insbesondere die Möglichkeit, die Inkrementierung oder Dekrementierung als Stenciloperation einstellen zu können, erlaubt aber auch die Implementierung einer Reihe komplexerer Verfahren. Eines der wichtigsten ist der Schattenvolumen-Algorithmus zur Erzeugung von Schatten von Punktlichtquellen. Verfahren dieser Art erfordern es meist, die Szene oder Teile der Szene mehrfach zu rendern, um Zwischenergebnisse im Stencilbuffer bei der Erzeugung eines Bilds sofort verwenden zu können. Daher beanspruchen sie die Grafikhardware in der Regel stark.\n\nDen Stencilbuffer in der heutigen Form gibt es etwa seit Anfang der 1990er Jahre mit der Einführung der SGI Indigo von Silicon Graphics. Die erste Programmierschnittstelle, die den Stencilbuffer unterstützte, war das herstellereigene IRIS GL, gefolgt von OpenGL 1.0 im Jahre 1992. Direct3D enthält ab Version 6.0 Befehle zur Verwendung des Stencilbuffers.\n\nSeit 1998 fand der Stencilbuffer Einzug in für den Spielemarkt konzipierte Grafikhardware, vor allem mit Erscheinen der Riva TNT von Nvidia und der Rage 128 von ATI. In allen neueren derartigen Produkten wird er seitdem ebenfalls unterstützt. Technisch belegen bei diesen Produkten bis heute der Stencil- und Z-Buffer den gleichen Speicherbereich auf der Grafikhardware, mit einer Größe von 32 Bit pro Pixel. Der Z-Buffer hat dabei eine Tiefe von 24 Bit pro Pixel, für den Stencilbuffer fallen die restlichen 8 Bit pro Pixel ab.\n\n"}
{"id": "1873654", "url": "https://de.wikipedia.org/wiki?curid=1873654", "title": "Kexi", "text": "Kexi\n\nKexi ist eine freie integrierte Datenbankmanagementanwendung als Teil von Calligra, die die Lücke zwischen Tabellen (Calc) und professionellen Datenbanklösungen schließen soll. Das Programm ähnelt in Bedienung und Verhalten sehr stark Microsoft Access und liefert auch ohne professionelle Datenbank-Kenntnisse schnell ansehnliche Ergebnisse.\n\nDie Arbeit an Kexi wurde begonnen, als man einen Mangel an freien Software-Lösungen mit einem ähnlichen Funktionsumfang erkannte, wie ihn Microsoft Access, FoxPro, Oracle Forms oder FileMaker bieten. Kexi ist Bestandteil von KOffice, wobei seit 2003 viele Beiträge von OpenOffice Polska hinzukamen. OpenOffice Polska bietet auch eine Kexi-Demo für Windows-Systeme zum Download an, die bislang allerdings nur kostenpflichtig angeboten werden konnte. Zukünftig soll auch die Windows-Version kostenlos offeriert werden. Kexi läuft außerdem unter Linux und Unix, unter Mac OS X (mittels Fink) und unter Solaris.\nNach Version 1.6 von KOffice wurde Kexi aus dem Software-Paket entfernt. In Version 2.2 wurde es nach einer Überarbeitung der Benutzeroberfläche wieder in das Paket aufgenommen.\n\nMit Version 2.4 wird Kexi wieder aus KOffice entfernt und stattdessen mit Calligra Suite ausgeliefert.\n\nKexi kann auf unterschiedliche Datenbank-Server wie etwa MySQL oder PostgreSQL zugreifen. Wird SQLite verwendet, kann die erzeugte SQLite-Datenbank mit jedem anderen SQLite-Programm bearbeitet werden. Neben Tabellen und Abfragen sind auch Formulare zum Eingeben und Abfragen von Daten möglich. Außerdem sind einfache Berichte möglich. Kleine Scripts sind mittels Python oder Ruby möglich. Die Unterstützung für Makros ist in Vorbereitung. Da alle Datenbank-Objekte, also Tabellen, Abfragen und Formulare, in einer einzelnen Datenbank-Datei gespeichert werden, erleichtert das die Weitergabe und den Austausch bestehender Datenbanken.\n"}
{"id": "1875880", "url": "https://de.wikipedia.org/wiki?curid=1875880", "title": "NDISwrapper", "text": "NDISwrapper\n\nNDISwrapper ist ein Open-Source-Programm, welches die Nutzung von Windows-Treibern für drahtlose Netzwerkkarten primär unter GNU/Linux ermöglicht.\n\nDie Network Driver Interface Specification (NDIS) bezeichnet dabei die ursprünglich von Microsoft und 3Com standardisierte Treiber-Spezifikation, die es Hardware-Herstellern erleichtern soll, entsprechende Treiber für ihre Geräte zu schreiben. Existieren benötigte Treiber für bestimmte Kartentypen noch nicht für Linux- oder Unix-Systeme, fungiert der NDISwrapper wie ein Adapter zwischen Betriebssystem und Treiber. Er enthält neben dem Modul für den Linux/Unix-Kernel auch Programme zur Administration und Einrichtung der Treiber.\n\nNDISwrapper besteht aus einem Kernel-Modul und einem Kommandozeilen-Programm zur Administration. Um die Benutzung von NDISwrapper zu vereinfachen, wurden einige grafische Frontends entwickelt, die die Installation des Windows-Treibers vereinfachen sollen. Diese Programme stellen eine grafische Benutzeroberfläche zur Verfügung und verwenden NDISwrapper als Backend. Zu den grafischen Frontends zählen ndisgtk, das bei Zenwalk Linux und Wolvix in der Standard-Installation vorhanden ist, ndisconfig, das standardmäßig unter VectorLinux Verwendung findet und KNDISWrapper für die KDE-3.5.x-Oberfläche.\n\n"}
{"id": "1878684", "url": "https://de.wikipedia.org/wiki?curid=1878684", "title": "IBM PC Portable", "text": "IBM PC Portable\n\nDer IBM Portable Personal Computer war ein IBM PC XT in einem beigen, tragbaren Gehäuse mit integriertem, grafikfähigem 9-Zoll-Bildschirm (Kathodenstrahlröhre), in bernsteinfarbener, monochromer Ausführung. Die Tastatur bildete den Boden des Koffers und diente gleichzeitig zum Schutz von Bildschirm und Disketten-Laufwerk an der Front des PCs. Sie konnte zum Arbeiten wahlweise nur oben oder komplett ausgeklipst werden und wurde per Spiralkabel mit RJ-Stecker an der Gehäusefront anschlossen. Zum Einklappen der Tastatur musste das Kabel in einem dafür vorgesehenen Schlitz im oberen Teil verstaut werden. \n\nDer Portable wog ca. 15 kg und wurde gegen Aufpreis in einer blauen Tragetasche aus Leinen geliefert. Mit stoßsicherer 10-MB-Festplatte und 256-kB-Hauptspeicher – eine Aufrüstung auf 640 kB war gegen Aufpreis möglich – waren etwa 20.000 DM zu zahlen (nach heutiger Kaufkraft ca. Euro). Ein -Zoll-Diskettenlaufwerk (Floppy-Disk) gehörte zur Standardausstattung. Er war im Februar 1984 der erste tragbare PC von IBM in der Klasse der Portables, nachdem Compaq bereits ein Jahr zuvor seinen IBM-kompatiblen Portable erfolgreich auf den Markt gebracht hatte.\n\nEs konnten mehrere Steckplätze mit Erweiterungen bestückt werden, teilweise nur in kurzer Bauform.\n\nAls besonderer Komfort war über dem Diskettenlaufwerk ein etwa 1 cm hohes Steckfach für -Zoll-Disketten vorhanden. Ein solches Merkmal bot allerdings schon der erste tragbare Computer (Osborne 1).\n\nDer Portable verfügte über ein Netzteil, das wahlweise mit 110 oder 230 Volt, 50/60 Hz, betrieben werden konnte. Er bot somit gute Voraussetzungen für mobilen, internationalen Gebrauch. Batteriebetrieb war auf Grund des Strombedarfs noch undenkbar. Nach einiger Betriebsdauer wurde das Gehäuse mehr als nur handwarm. Dennoch war der PC für die damalige Zeit zuverlässig.\n\n\n"}
{"id": "1882257", "url": "https://de.wikipedia.org/wiki?curid=1882257", "title": "Trommelspeicher", "text": "Trommelspeicher\n\nDer Trommelspeicher (englisch: drum memory) war eine frühe Form der Datenspeicherung in Computersystemen, die in den 1950er und bis in die 1960er Jahre weit verbreitet war und heute als Vorläufer der Festplatte gesehen werden kann. Die Methode wurde 1932 in Österreich von Gustav Tauschek entwickelt. Am 1. Juli 1933 meldete er seine Erfindung als „Elektromagnetischer Speicher für Zahlen und andere Angaben, besonders für Buchführungseinrichtungen“ beim Deutschen Reichspatentamt an und erhielt darauf das Patent DRP 643803. In vielen frühen Computersystemen wurde der Hauptarbeitsspeicher durch ein solches Trommelsystem gebildet, auf dem Daten und Programme während der Berechnung gehalten wurden. Trommelspeicher wurden später und bis zur Einführung des Halbleiterspeichers durch Kernspeicher ersetzt, der schneller war und ohne bewegte Teile auskam.\n\nEin Trommelspeicher besteht aus einem rotierenden Metallzylinder, der an der Außenfläche mit einem ferromagnetischen Material beschichtet ist. Man kann sich die Funktion wie bei einer Festplatte vorstellen, nur dass die Daten auf einem Zylindermantel statt einer flachen Scheibe gespeichert sind.\n\nEin wesentlicher Unterschied zur Festplatte ist, dass beim Trommelspeicher üblicherweise für jede Spur ein eigener Schreib-Lesekopf existiert.\n\nZum Ende der Entwicklung wurden – beispielsweise beim TR 440 – als „Trommel“-Speicher auch Magnetplatten eingesetzt. Diese hatten einen Durchmesser von über einem Meter. Auch dabei hatte jede Spur (der Trommel bzw. der Platte) einen eigenen Schreib-/Lesekopf.\n\nDaher sind keine Kopfbewegungen und Suchzeiten erforderlich, um eine bestimmte Spur anzufahren. Die Zugriffszeit zu einem bestimmten Datensatz bei einer Trommel ist also kleiner, die Steuerung muss nur warten, bis die gewünschten Daten unter dem richtigen Lesekopf erscheinen. Die Leistung des Trommelspeichers wird demnach fast ausschließlich durch seine Rotationsgeschwindigkeit bestimmt, während bei einer Festplatte auch die Geschwindigkeit der Kopfpositionierung einfließt.\n\nDer Systemtakt wurde mitunter durch einen speziell dafür vorgesehenen Lesekopf generiert, dessen Spur ein fest magnetisiertes Muster enthielt. Hierdurch konnte der synchrone Datenzugriff bei der Befehlsausführung des Programms sichergestellt werden.\n\nWenn diese Systeme als Hauptspeicher eingesetzt wurden, war der Durchsatz das entscheidende Problem. Programmierer bemühten sich daher oft, Code und Daten kunstvoll optimiert auf der Trommel anzuordnen, um die Zeitspanne für den Zugriff auf die jeweils nächste Instruktion oder den nächsten Datensatz zu minimieren. Dazu wurden Ausführungszeiten genau bestimmt und die Daten dann so positioniert, dass der nächste Datensatz genau zum richtigen Zeitpunkt einen Lesekopf passierte. Dieses Prinzip wurde als Interleaving auch später noch bei Festplatten angewandt – dort aber als fester Faktor, um die Datenrate an die Verarbeitungsgeschwindigkeit des Rechners anzupassen.\nEin Rechner mit Trommelspeicher als Arbeitsspeicher wurde wegen der hohen Zugriffszeiten mithilfe eines Speicherbelegungsplans programmiert, der als Matrix aller auf der Trommel vorhandenen Speicherelemente angelegt war. Im Befehlscode war die Trommeladresse des nachfolgend auszuführenden Maschinenbefehls angegeben, um nach der über eine Tabelle der Befehlslaufzeiten ermittelten Ausführungszeit möglichst früh den nächsten Maschinenbefehl zu erreichen. Diese rechnernahe mühsame Programmierung ist mit der Entwicklung der Hardware bereits ca. 1965 durch die Nutzung höherer Programmiersprachen wie Algol 60 abgelöst worden.\n\nTypische mittlere Leistungswerte von Trommelspeichersystemen:\n\n"}
{"id": "1883407", "url": "https://de.wikipedia.org/wiki?curid=1883407", "title": "Deutsche Linux-Distribution", "text": "Deutsche Linux-Distribution\n\nDie Deutsche Linux-Distribution (DLD) war die erste deutsche Linux-Distribution.\n\nSie erschien erstmals im Jahr 1992 und wurde ab 1994 vom Unternehmen Delix Computer GmbH, die von Dirk Haaga, Nils Mache und Jens Ziemann gegründet worden war, aus Stuttgart produziert und vertrieben. Anfangs war sie kompatibel mit Slackware, diese Kompatibilität wurde aber aufgegeben, als man das Init-System vom BSD- auf den System-V-Stil änderte und RPM als Standard-Paketformat einführte. DLD zeichnete sich durch die Übersetzung nahezu aller Dokumentationen und Programme in die Deutsche Sprache aus.\n\nAnfang 1999 wurde die DLD-Version 6.0 Professional von IBM als Netfinity Server Proven zertifiziert.\n\nDie letzte Version der DLD war 6.1 im Jahr 1999. Nachdem Red Hat das Unternehmen Delix im selben Jahr übernommen hatte, wurde DLD eingestellt. Dirk Haaga leitete danach die Red Hat Deutschland GmbH bis zu seinem Unfalltod im Jahr 2006 als Geschäftsführer weiter.\n"}
{"id": "1886908", "url": "https://de.wikipedia.org/wiki?curid=1886908", "title": "Sharp MZ-800", "text": "Sharp MZ-800\n\nDer Sharp MZ-800 war ein Heimcomputer der japanischen Firma Sharp, der im Jahre 1985 auf den Markt kam. Das Gerät erschien in Japan unter der Bezeichnung Sharp MZ 1500.\n\nDer MZ-800 setzte das Konzept der MZ-Reihe fort und war der Nachfolger des MZ-700. Technisch basierte der Rechner auf einem Z80A Prozessor mit 3,55 MHz. Das Gerät war mit 64 KiB RAM ausgestattet, der Speicher konnte aber auf 128 KiB erweitert werden.\n\nNeu für die MZ Serie von Sharp war an dem MZ-800 (und dem MZ80B) die grafische Auflösung von 640 mal 200 Pixeln, was eine erhebliche Verbesserung gegenüber der MZ-700er-Serie bedeutete.\n\nDer MZ-800 ist abwärtskompatibel zum MZ-80 und MZ-700. Im Gegensatz zum MZ-80 (1979) verfügt der MZ-800 nicht über einen eingebauten Monitor und ist dementsprechend flacher. Er war in drei Varianten erhältlich: als Grundmodell (MZ-811), mit eingebauter Datasette (MZ-821) und mit einem zusätzlich integrierten Vierfarbplotter (MZ-831). Anstelle der Datasette konnte ein Quick-Disk-Laufwerk für eine 2,8-Zoll-Diskette mit sequentiellem Zugriff eingebaut werden. Außerdem konnte man ein externes 5,25\"-Floppy-Laufwerk anschließen. Für Spiele gab es einen Joystick.\n\nIm Gegensatz zu anderen Heimcomputern enthielt das ROM der Geräte aus der MZ-Serie keine Programmiersprache, sondern nur einen Boot-Monitor mit elementaren Eingabe-Ausgabe-Befehlen. Damit war es möglich, Daten von Kassette oder Diskette einzulesen, einzelne Speicherzellen auszulesen und ihren Inhalt in hexadezimaler Notation zu verändern sowie Daten wieder auf den Massenspeicher zu schreiben. Der Assembler-Quelltext des Monitors war im mitgelieferten Handbuch als Ausdruck enthalten. Sharp bezeichnete dieses Konzept als \"Clean Computer\". Anwendungen oder Programmiersprachen mussten nach dem Einschalten erst von Kassette oder von Diskette eingelesen werden. Mitgeliefert wurden das herstellereigene S-Basic (ein Interpreter) sowie einige Spiele. Es standen aber auch Compiler für Basic sowie für Pascal oder Fortran und zur Arbeit mit Z80-Assembler zur Verfügung. Unter CP/M konnten die damals verbreiteten Office-Anwendungen betrieben werden.\n\nIn Deutschland war der Rechner zu einem Verkaufspreis von 1198 DM zu erstehen.\n\n"}
{"id": "1890552", "url": "https://de.wikipedia.org/wiki?curid=1890552", "title": "SUPRENUM", "text": "SUPRENUM\n\nSUPRENUM (Superrechner für numerische Anwendungen) war ein deutsches Forschungsprojekt zur Entwicklung eines Parallelrechners im Zeitraum von 1985 bis 1990. Obwohl der Suprenum-1 für kurze Zeit das leistungsfähigste massiv parallele Rechnersystem der Welt war, wurde die Entwicklung einer zweiten Generation des Systems nicht mehr finanziert. \n\nDie SUPRENUM GmbH als Trägergesellschaft des Verbundprojekts bildete sich unter dem Einfluss von zwei Forschergruppen der Gesellschaft für Mathematik und Datenverarbeitung (GMD). Während die Gruppe um Ulrich Trottenberg in Sankt Augustin an parallelen numerischen Verfahren zur Lösung partieller Differentialgleichungen forschte, steuerte GMD First (Berlin) unter der Leitung von Wolfgang Giloi das notwendige Know-how im Bereich Hardware- und Betriebssystem-Design bei. \n\nAn der Hauptphase der Forschungs- und Entwicklungsarbeiten waren insgesamt 14 Partner\nbeteiligt, und zwar:\nNach dem Ende des SUPRENUM-Projekts entstand aus der SUPRENUM GmbH 1991 die Pallas GmbH, die schließlich 2003 ihren Firmenbereich \"High Performance Computing\" an die Firma Intel verkaufte.\n\nIm Gegensatz zum herkömmlichen Vektorrechner arbeitete der Suprenum-1 als massiv paralleler Rechner nach dem MIMD-Prinzip. Das System war insgesamt bis zu 256 Rechnerknoten skalierbar. Jeweils 16 Knoten bildeten einen Cluster und waren über ein lokales 4×4-Interconnect-Netzwerk mit 200 Mbit/s Bandbreite („horizontal buses“) verbunden. Zusätzlich waren die Cluster über vier vertikale Busse („global buses“) verbunden. Ein eigenes I/O-Subsystem stellte die Verbindung zur lokalen Disk des Clusters, dem „global bus“ und dem Host-Rechner, einer SUN-Workstation, her. Jeder Knoten verfügte über einen Prozessor vom Typ Motorola MC 68020, einen numerischen Koprozessor (Weitek 2264/65) und 8 MB lokalen Arbeitsspeicher.\n\nIm Rahmen des SUPRENUM-Projekts entstand unter Federführung von Wolfgang Schröder-Preikschat das Mikrokernel-Betriebssystem PEACE (Process Execution And Communication Environment), das nach den Prinzipien der Objektorientierung konzipiert und in der Programmiersprache C++ implementiert wurde. Die Kommunikationslatenz war mit einer Millisekunde relativ hoch für ein auf massiv parallele Architekturen spezialisiertes Betriebssystem. \n\nZur effektiven Nutzung des Parallelrechners für numerische Verfahren sollte ein spezieller Fortran-77-Compiler entwickelt werden, dessen Implementierung jedoch aufgrund des begrenzten Hauptspeichers der Knoten Schwierigkeiten bereitete. Allerdings war der Suprenum-1 auch unter Verwendung der PARMACS („Parallel Macros“) Kommunikations-Bibliothek programmierbar. Im Gegensatz zum oben erwähnten Fortran Compiler beruht dieses Programmiermodell auf explizitem Versenden von Daten („Message Passing“) und wurde später zum MPI-Standard weiterentwickelt.\n\nEin erfolgreicher Schwerpunkt des Projektes lag auf der Anwendungs-Software und der zugehörigen parallelen Algorithmik. Hierin unterschied sich das Projekt von vielen Parallelrechner-Entwicklungen weltweit.\n\nWegen der hohen Entwicklungskosten von mehr als 160 Millionen DM und des begrenzten Erfolgs bei der Vermarktung wurde die Hardware-Entwicklung des Projektes in der Öffentlichkeit kritisch bewertet. Das Bundesministerium für Forschung und Technologie (BMFT) zog sich deshalb aus der Finanzierung der eigentlich geplanten Hardware-Weiterentwicklung (zweite, kommerziellen Projektphase) zurück. \n\nIm Rückblick wird vor allem die fehlende Nachfrage aus der Industrie kritisiert. Als Forschungsprojekt war SUPRENUM dagegen sehr erfolgreich, insbesondere im Bereich der parallelen Anwendungs-Software. In den beteiligten Institutionen wurde substantielles Know-how aufgebaut, das im europäischen Folgeprojekt GENESIS weiterentwickelt werden konnte. PEACE diente als Betriebssystem für die nicht-kommerzielle MANNA-Architektur. SUPRENUM beeinflusste auch die Entwicklung anderer Parallelrechner wie die des \"Meiko CS-2\".\n\nin \"Parallel Computing\" (Special double issue: SUPRENUM and GENESIS) Volume 20, Issue 10-11 (November 1994) \n\n\n\n"}
{"id": "1892781", "url": "https://de.wikipedia.org/wiki?curid=1892781", "title": "Ryan (Film)", "text": "Ryan (Film)\n\nRyan ist ein kanadischer Computeranimationsfilm aus dem Jahr 2004. Das vierzehnminütige, dokumentarische Drama, bei dem Chris Landreth Regie führte, erzählt vom sozialen Abstieg des Trickfilmers Ryan Larkin. Produziert wurde der mehrfach preisgekrönte Film von Copper Heart Entertainment und dem National Film Board of Canada.\n\nDer Animationsfilmer Chris Landreth, um die vierzig, führt in einer Welt, in der sich die Schwächen der Menschen durch bunte Merkmale oder das bizarre Verschwinden von Körperteilen zeigt, ein Interview mit Ryan Larkin. Dieser erregte in den 1960er und 1970er Jahren durch seine ungewöhnlichen Zeichentrickkurzfilme Aufmerksamkeit und wurde für eines seiner Werke, \"En marchant\", sogar für den Oscar nominiert. Larkin wurde mit der Zeit drogen- und alkoholabhängig, bis er, verloren von seiner künstlerischen Inspiration, schließlich auf der Straße bettelte, um sich seinen Lebensunterhalt zu verdienen.\n\nDer Film feierte seine Premiere am 17. Mai 2004 im Kurzfilmwettbewerb der Internationalen Filmfestspiele von Cannes und daraufhin auf mehreren weiteren Festivals, unter anderem auf dem Valladolid International Film Festival.\n\nFast ausnahmslos alle Kritiker nahmen den Film positiv auf. Der renommierte US-amerikanische Filmkritiker Roger Ebert schrieb beispielsweise am 25. Februar 2005 in der Chicago Sun-Times, der Film würde tief in die Wahrheit des menschlichen Lebens hineinschneiden. Die Animationstechnik sei dramatisch, eindrucksvoll und originell. Der Regisseur Landreth sagte über die 3D-animierte Welt, die er in dem Film zeigt, sie spiegele eine Art psychologischen Realismus wider.\n\n\"Ryan\" gewann bei den Filmfestspielen von Cannes den Kodak-Kurzfilmpreis, den Canal+-Preis und den Preis der jungen Kritiker. Auf dem AFI Fest 2004 erhielt der Film eine \"Besondere Erwähnung\", auf dem Atlantic Film Festival den Preis als \"Bester kanadischer Kurzfilm\". Ebenso wurde er auf dem Columbus International Film & Video Festival, dem Leipzig DOK Festival, dem Melbourne International Animation Festival, dem Newport International Film Festival, dem Ottawa International Animation Festival, dem San Francisco International Film Festival, dem Sundance Film Festival, dem Tampere International Short Film Festival, dem Toronto Worldwide Short Film Festival, dem Uppsala International Short Film Festival, dem Victoria Independent Film & Video Festival und dem Valladolid International Film Festival ausgezeichnet.\n\nBei der Oscarverleihung 2005 gewann der Film in der Kategorie \"Bester animierter Kurzfilm\" und konnte sich damit unter anderem gegen Bill Plymptons \"Guard Dog\" durchsetzen. Bei den Annie Awards 2005 war der Film als \"Bester animierter Kurzfilm\" nominiert, bei den Genie Awards 2005 gewann er in der gleichen Kategorie. Im Rahmen des jährlich stattfindenden Ars Electronica Festivals in Linz wurde der Kurzfilm 2004 mit der Goldenen Nica – einem bedeutenden Preis im Bereich der elektronischen Kunst und Kultur – in der Kategorie Computer Animation/Visual Effects prämiert.\n\n"}
{"id": "1894198", "url": "https://de.wikipedia.org/wiki?curid=1894198", "title": "Kaffe", "text": "Kaffe\n\nKaffe ist die Reinraum-Implementierung einer Java Virtual Machine (JVM) von Tim Wilkinson, die als freie Software unter der GNU General Public License (GPL) veröffentlicht wird.\n\nKaffe ist eine schlanke, schnelle und leicht übertragbare (\"portable\") virtuelle Maschine. Verglichen mit Suns Referenzimplementierung der JVM ist Kaffe zwar deutlich kleiner, allerdings zu dieser wegen einiger fehlender Schlüsselfunktionen nicht ganz verträglich (\"kompatibel\"). Kaffe kann für viele Prozessorarchitekturen mittels Just-in-time-Kompilierung Maschinensprache übersetzen (\"kompilieren\"), mit dem ausgeführte Java-Programme ohne zeitaufwändige Bytecode-Interpretation vergleichsweise schnell und sparsam (\"effizient\") ausgeführt werden können.\n\nKaffe unterstützt zahlreiche Betriebssystem- und Prozessor-Plattformen, oder genauer dessen Befehlssatzarchitekturen, und wird daher auch als plattformübergreifend beschrieben. Auf vielen ist Kaffe damit die einzige verfügbare virtuelle Maschine für eine Java-Laufzeitumgebung.\n\nDer Name \"Kaffe\" stammt vermutlich daher, dass starker gebrühter Kaffee in den USA auch als Java – nach der Java-Bohne – bezeichnet wird. Kaffe ist die schwedische Bezeichnung für Kaffee, da der Entwickler Tim Wilkinson im Januar 1996 die Arbeit an dem Projekt in Schweden begann.\nAnfangs wurde Kaffe als Teil eines anderen Projektes entwickelt. Es wurde so beliebt, dass die Entwickler Tim Wilkinson und Peter Mehlitz die Firma Transvirtual Technologies, Inc. um Kaffe als ihr Vorzeigeprodukt aufbauten. Im Juli 1998 veröffentlichte Transvirtual Kaffe OpenVM unter der GPL. Seither wird es von einer weltweiten Entwicklergemeinde weiterentwickelt.\nNach Entstehung des GNU-Classpath-Projektes flossen Entwicklungen aus der bisherigen Klassenbibliothek von Kaffe in GNU Classpath, die Kaffe nun selber nutzt.\n\n\n"}
{"id": "1897146", "url": "https://de.wikipedia.org/wiki?curid=1897146", "title": "Sabayon Linux", "text": "Sabayon Linux\n\nSabayon Linux ist eine in Italien entwickelte Linux-Distribution. Sabayon Linux basiert auf der Distribution Gentoo und legt einen besonderen Wert auf Hardwareerkennung und grafische Effekte.\n\nEntstanden ist die Distribution im Oktober 2004 unter dem Namen „RR4“ beziehungsweise später zusätzlich „RR64“ für die 64 Bit-Version als fertiges Gentoo-System. Im August 2006 wurde es in \"Sabayon Linux 3.0\" umbenannt.\n\nSeit Sabayon 6 erscheint Sabayon als Rolling Release.\n\nIm Gegensatz zu den meisten Live-Distributionen handelt es sich bei Sabayon um eine DVD mit ca. 2 GB Umfang. Sabayon versucht eine ansprechende Multimedia-Umgebung out-of-the-box zu liefern. Dafür werden auf der DVD die meisten Treiber mitgeliefert.\n\nSabayon unterstützt KDE und Gnome gleichberechtigt als Standard, sie werden auf separaten Live-DVDs angeboten. Darüber hinaus werden auch Live-DVDs mit Xfce, Mate, LXDE und eine Live-CD mit Enlightenment angeboten, diese sind aber in einem experimentellen Status. Darüber hinaus gibt es noch die Versionen ServerBase und SpinBase (beide ohne X Window System). Eine weitere Besonderheit ist der Umgang mit proprietärer Software, die bei Sabayon in keiner Weise von freier Software getrennt wird. So werden die unfreien Grafikkartentreiber von ATI und Nvidia automatisch installiert. Auch Google Earth gehört, ebenso wie die rechtlich umstrittene Bibliothek libdvdcss, zum Standardumfang.\n\nSabayon Linux lässt sich als Live-System direkt von der DVD/CD starten. Vor der Installation kann ein Update des Installers durchgeführt werden. Als Paketverwaltungssystem verwendet Sabayon Linux equo mit dem hauptsächlich vorkompilierte Software durch Befehle in der Kommandozeile verwaltet werden kann. Ein paralleler Betrieb von equo und dem von Gentoo Linux her bekannten Portage ist möglich und für fortgeschrittene Nutzer vorgesehen.\n\n\n"}
{"id": "1900074", "url": "https://de.wikipedia.org/wiki?curid=1900074", "title": "Wordfast", "text": "Wordfast\n\nWordfast ist ein Hilfsprogramm für das Anfertigen von Übersetzungen (CAT).\n\nDas Bedienungskonzept in der Programmversion Wordfast Classic unterscheidet sich von den Konkurrenzprodukten (SDL Trados, Déjà Vu, MemoQ) dadurch, dass es als Makro-Sammlung für Microsoft Word konzipiert ist und keine eigene Programmoberfläche benötigt. Es kann daher auch direkt in anderen Anwendungsprogrammen benutzt werden, die Word als Editor zulassen, z. B. in Microsoft Outlook. Dabei können die gewohnten Formatierungsfunktionen und Tastaturkombinationen dieser Programme weiterhin benutzt werden.\n\nEntwickler des Programms ist der Franzose Yves Champollion, der nach eigener Aussage ein Nachfahre von Jean-François Champollion ist.\n\nDie Unterstützung des Übersetzers besteht darin, dass angefertigte Übersetzungen segmentweise (ein Segment ist in der Regel ein Satz) in einer Datenbank gespeichert werden und dass bei ähnlichen Übersetzungen in der Zukunft die neuen Formulierungen mit den abgelegten Einträgen abgeglichen werden. Das Programm ermittelt den Grad der Übereinstimmung und schlägt je nach den Voreinstellungen des Benutzers gleiche oder ähnliche Formulierungen zur Übernahme in die neue Übersetzung vor. Dieser Programmtyp wird daher auch als Translation Memory (dt.: \"Übersetzungsspeicher\") bezeichnet.\n\nIn diesen Ablauf können ferner Wortlisten, Glossare oder Terminologiedatenbanken eingebunden und durchsucht werden. \n\nFür Übersetzer in Entwicklungsländern wird ein Rabatt von 50 % gewährt.\n\nTechnische Hilfestellung wird nur im ersten Jahr der Lizenzierung per E-Mail angeboten. Weitere Unterstützung erhält der Nutzer über mehrere Yahoo!-Diskussionsgruppen (Hauptliste auf Englisch, weitere Listen auf Deutsch, Französisch, Spanisch, Finnisch usw.).\n\nNeben \"Wordfast Classic\" gibt es eine von Word unabhängige, eigenständige Programmversion Wordfast Pro, die auf der Programmiersprache Java beruht und daher neben OmegaT, Swordfish, CafeTran und Heartsome Translation Studio zu den Übersetzungstools gehört, die ohne weitere Hilfsmittel unter den Betriebssystemen Linux und Mac OS funktionieren. Anders als die Classic-Version zeigt \"Wordfast Pro\" den zu übersetzenden und den übersetzten Text in zwei Tabellenspalten nebeneinander an.\n\nDie Programmversionen \"Wordfast Pro\" und \"Wordfast Classic\" werden einzeln oder auch gemeinsam als \"Wordfast Studio\" verkauft. Beide Programme nutzen dasselbe Translation-Memory- und Glossarformat.\n\nLaut Ankündigung des Entwicklers soll zukünftig der Schwerpunkt auf der Pro-Version liegen und in einem weiteren Schritt die Classic-Version durch eine Oberfläche für OpenOffice und LibreOffice ersetzt werden.\n\n"}
{"id": "1911597", "url": "https://de.wikipedia.org/wiki?curid=1911597", "title": "BabyDevelop", "text": "BabyDevelop\n\nBabyDevelop ist eine freie IDE für GNU/Linux, andere Unix-artige Betriebssysteme und Windows.\nBabyDevelop ist lizenziert unter der GNU General Public License.\n\nBabyDevelop enthält keinen eigenen Compiler. Es muss stattdessen ein anderer (z. B. aus der GNU Compiler Collection) zum Erzeugen des ausführbaren Codes installiert sein. Für Qt-Bibliotheken wird zusätzlich der dort enthaltene Meta-Object-Compiler verwendet.\n\nBabyDevelop ist eine leichtgewichtige Entwicklungsumgebung.\nDies bedeutet, dass nur die notwendigsten Merkmale enthalten sind.\nDadurch ist es besonders geeignet für Anfänger in der Programmierung. Eine weitere angenehme Begleiterscheinung ist die Geschwindigkeit, mit der BabyDevelop arbeitet, sodass es auch auf weniger leistungsstarken Systemen eingesetzt werden kann.\nDurch in der Dokumentation enthaltene einfache Beispiele ist eine sehr schnelle Einarbeitung in die Qt-Widgets/C++/C möglich. Dadurch wird der Junior-Entwickler schnell in die Lage versetzt, eigene Programme und Ideen umzusetzen.\n\nDurch die Verwendung der Qt-Bibliotheken ist die IDE auf Linux und Windows lauffähig (bis Version 5 nur mit Cygwin).\nBabyDevelop benutzt den Qt-eigenen Texteditor QTextEdit und den aus den Qt-Beispielen bekannten CodeEditor zum Darstellen der Zeilennummern.\nBis zur Version 5 arbeitete BabyDevelop mit der Qt-Version 3, ab BabyDevelop 7 wird Qt 4.x vorausgesetzt.\n\nEigenschaften von BabyDevelop im Einzelnen:\n\nBabyDevelop kompiliert/linkt Quellcodes mit Shell-Scripten.\n\n\n"}
{"id": "1913136", "url": "https://de.wikipedia.org/wiki?curid=1913136", "title": "Injector Linux", "text": "Injector Linux\n\nInjector Linux ist eine freie „One-Disk“-Linux-Distribution, d. h., es ist klein genug um auf eine Diskette zu passen. Injector Linux wurde für verschiedene Arten von Datenrettungs- und Manipulationsvorgängen auf Festplatten entworfen. Es wird seit 2003 nicht mehr weiter entwickelt. Die Website wird aber weiterhin gewartet.\n\nDer größte Unterschied im Vergleich zu vielen anderen Linux-Distributionen dieser Art, ist die Fähigkeit eine Vielzahl von Dateisystemen einzubinden und mit, soweit möglich, vollen Schreibrechten zu versehen. So ist das System in der Lage 25 unterschiedliche Dateisysteme zu beschreiben. Dies sind unter anderem ReiserFS, ADFS, HFS, Be File System, ext3, FAT16, FAT32, ISO 9660, JFS, NTFS, HPFS, ext2, UDF.\n\nDas System basiert aus Platzgründen auf dem Linux-Kernel 2.4.23. Als weitere Software gibt es lediglich BusyBox 0.60 und einige Software zur Wartung von Festplatten (badblocks, fdisk, bzip2, lsattr, chattr, fdformat, strings und srm).\n\n\n"}
{"id": "1914103", "url": "https://de.wikipedia.org/wiki?curid=1914103", "title": "BBEdit", "text": "BBEdit\n\nBBEdit ist ein proprietärer Texteditor für macOS (vormals Mac OS X und OS X), der sich vor allem an Programmierer und Webdesigner richtet. Es wurde am 12. April 1992 als Programm für Macintosh System Software 6 vorgestellt und wurde seitdem kontinuierlich weiterentwickelt.\n\nDer in Bedford (Massachusetts) in den USA ansässige Hersteller Bare Bones Software bot zusätzlich zur kostenpflichtigen Variante eine kostenlose, funktional eingeschränkte Version an: Bis Version 6.1 war dies BBEdit Lite, später TextWrangler. Mit der Version 11.6 von BBEdit wurden diese eingeschränkten Varianten im Sommer 2016 eingestellt, statt dessen bietet nun die unlizenzierte Demoversion von BBEdit dauerhaft einen vergleichbaren Funktionsumfang.\n\nBBEdit beherrscht Syntaxhervorhebung für viele verschiedene Programmiersprachen. Weiter ist eine FTP- und SFTP-Unterstützung integriert, wie auch die Möglichkeit zum Vergleich verschiedener Datei-Versionen. Einige Entwicklungsumgebungen können BBEdit direkt als Quelltext-Editor verwenden.\n\nDer Funktionsumfang von BBEdit kann vom Nutzer durch Skripte erweitert werden. Außerdem ist es möglich, Syntaxhervorhebung für zusätzliche Programmiersprachen hinzuzufügen.\n\nBBEdit wird als „mächtiger Editor“ „mit vielen durchdachten und nützlichen Funktionen“ beschrieben. Die Zeitschrift c’t hebt 1997 die mächtige Suchen-und-Ersetzen-Funktion hervor. Die Technologie-Website Lifewire zählt die kostenlose BBEdit-Version zu den besten freien HTML-Editoren für den Mac. Das Mac-Magazin Macworld lobt 2012 die plattformunabhängige, leistungsfähige Textverarbeitungsfunktion von BBEdit.\n\nIm Folgenden findet sich ein auf die unterstützten Betriebssystemversionen von Mac OS und macOS bezogener Auszug aus der Versionsgeschichte von BBEdit.\n"}
{"id": "1917952", "url": "https://de.wikipedia.org/wiki?curid=1917952", "title": "Apple Integer Basic", "text": "Apple Integer Basic\n\nDas Apple Integer BASIC ist der BASIC-Interpreter des Apple I – dort von Cassette einzuladen – und des ursprünglichen Apple-II-Modells – dort im ROM fest eingebaut und mit dem Computer ab Werk ausgeliefert. Die Integer-BASIC-Sprache beruht in Syntax und Semantik auf HP-BASIC, dem vom Unternehmen Hewlett-Packard entwickelten BASIC-Dialekt der 1970er Jahre; der Integer-BASIC-Interpreter selbst ist allerdings eine ganz eigenständige Neuschöpfung.\n\nAls Apple-Mitgründer und Entwickler Steve Wozniak den Apple I konstruierte, hatten Kleincomputer weder Monitor noch Benutzeroberfläche; Konkurrenzgeräte wie der Altair 8800 brachten von Haus aus bestenfalls rudimentäre Ein- und Ausgaberoutinen mit, sie wurden in der Regel über Kippschalter Byte für Byte in Maschinensprache programmiert. Wozniak erfuhr im Homebrew Computer Club von dem BASIC-Interpreter, den Bill Gates für den Altair geschrieben hatte; dieser war aber für den Apple I nicht brauchbar, da das Altair-BASIC nur auf einem 8080-Prozessor lief und nicht auf dem 6502-Prozessor des Apple I. Woz wollte es Gates nun gleichtun und unbedingt der Erste sein, der ein BASIC für den 6502-Prozessor vorlegen konnte, obwohl er eigentlich eher in der Programmiersprache Fortran zuhause war. Als weiteren Anstoß gibt er das Buch \"101 BASIC Computer Games\" von David H. Ahl an.\n\nDa Wozniak eigentlich Hardware-Entwickler war und kaum Kenntnisse in Software-Entwicklung hatte, ging er intuitiv an das Projekt heran: er analysierte Handbücher für HP-BASIC und leitete darauf eine Syntax für seinen BASIC-Interpreter ab. Er entschied sich, die Sprache einfach zu halten: Integer BASIC konnte nur mit 16-Bit-Ganzzahlen umgehen, Gleitkomma-Arithmetik sparte er aus. Er benötigte etwa vier Monate Entwicklungszeit und kodierte den Interpreter zunächst in einem Notizbuch, um ihn dann Byte für Byte einzugeben. Bestandteil des Codes war auch ein kleines Monitorprogramm für Maschinensprache. Als Teil des Integer BASIC implementierte Wozniak außerdem eine kleine, aber vielseitige virtuelle Maschine namens \"Sweet 16\", die in wenigen hundert Bytes Maschinencode einen fiktiven 16-Bit-Prozessor mit 16 Registern emulierte. Viele Operationen des Interpreters ließen sich in diesem 16-bit-Pseudocode wesentlich kompakter formulieren als in nativem 6502-Code, so dass der Speicherbedarf insgesamt deutlich sank.\n\nWozniak bezeichnete die Entwicklung des Integer BASIC später als größte technische Herausforderung seines ganzen Berufslebens. Der gesamte Code passte mitsamt den ROM-Routinen für Bildschirmdarstellung, Tastaturansteuerung etc. in 8 KB Speicher.\n\nInteger BASIC war nicht kompatibel zum BASIC-Dialekt von Microsoft, der auf dem BASIC des Computerherstellers DEC beruhte. Wozniak entdeckte dies eigenen Aussagen zufolge erst, als er die Programme aus \"101 BASIC Computer Games\" auf den Apple übertragen wollte und scheiterte. Als erstes Programm passte er das Spiel Star Trek an seinen Computer an.\n\nFür den 1977 erschienenen Apple II erweiterte Wozniak das Integer-BASIC um einige Grafikbefehle zur Ansteuerung des neuen LoRes-Grafikmodus und der Paddles; dabei ging er wieder eher praktisch vor, er implementierte genau die Befehle, die er benötigte, um einen brauchbaren Breakout-Clone in BASIC schreiben zu können. Damals herrschte bei Apple noch die Meinung vor, der hochauflösende HiRes-Grafikmodus werde besser den Maschinensprache-Programmierern überlassen, da ein interpretiertes BASIC auf einem 1-MHz-Rechner prinzipiell zu langsam sei, um damit ansprechende HiRes-Programme zu schreiben. Erst allmählich setzte sich die Erkenntnis durch, dass viele Anwender eher Interesse an einer einfachen als an einer schnellen Grafikprogrammierung hatten.\n\nAls Ergänzung zu Integer BASIC für den Apple II bot Apple bald noch eine \"Programmer's Aid #1\" (Programmierhilfe Nr. 1) genannte Erweiterung an, die aus einem weiteren ROM-Chip bestand. Diese bot Unterstützung für Sound und Musik, für hochauflösende Graphik einschließlich einer simplen Vektorgraphik, und eine Reihe von Tools z. B. zum Testen der Speicherchips des Rechners, zum Zusammenfügen zweier Programme, zum nachträglichen Neunumerieren von Programmzeilen und so weiter. Allerdings waren alle diese Möglichkeiten über Maschinensprache-Subroutinen umgesetzt, konnten also nur über kryptische CALL-Befehle aufgerufen werden und integrierten sich somit nicht sehr gut in das bestehende BASIC. Weitere Chips dieser Art, mit anderen Schwerpunkten wie z. B. Business oder Wissenschaft, waren angedacht, erschienen aber nicht mehr.\n\nBereits Ende 1977 bot Apple zusätzlich zum eingebauten Integer-BASIC einen von Microsoft zugekauften BASIC-Interpreter an, weil eigene Versuche der weiteren Fortentwicklung nicht gefruchtet hatten: Wozniak war der einzige, der den Code des Integer-BASIC wirklich verstand, aber er wurde bei der Entwicklung des neuen Diskettenlaufwerks für den Apple noch dringender gebraucht. Das aus dem Microsoft BASIC abgeleitete und um einige Apple-spezifische Befehle ergänzte Applesoft BASIC war deutlich langsamer und weniger sparsam im Speicherverbrauch, bot aber die schmerzlich vermisste Gleitkomma-Arithmetik und Befehle zur Darstellung des hochauflösenden \"HiRes\"-Grafikmodus des Apple II mit 280 x 192 Pixeln – Integer-BASIC war ohne Umwege über Maschinensprache nur zur Ansteuerung des \"LoRes\"-Grafikmodus mit 40 x 48 Pixeln in der Lage.\n\nZunächst war Applesoft BASIC als Programmkassette zu erhalten, bald dann auch auf Diskette sowie als ROM-Steckkarte, wodurch kein kostbarer RAM-Speicher mehr dafür benötigt wurde. Viele Anwender gingen bald dazu über, die ROM-Chips aus dieser Steckkarte herauszunehmen und direkt in die Hauptplatine einzusetzen, anstelle der Integer-BASIC-Chips. Die größere Beliebtheit des Applesoft BASIC wurde schließlich von Apple anerkannt: Mit Applesoft BASIC auf der Hauptplatine (und größerem Speicher) verkaufte Apple den Rechner ab 1979 als Apple II+. Bei diesem und allen späteren Modellen der Apple-II-Serie kann jedoch Integer BASIC, inklusive der \"Programmierhilfe Nr. 1\", weiterhin bei Bedarf von Diskette nachgeladen werden.\n"}
{"id": "1920385", "url": "https://de.wikipedia.org/wiki?curid=1920385", "title": "Osborne 1", "text": "Osborne 1\n\nDer Osborne 1 war der erste kommerziell erhältliche tragbare Computer. Sein Erfinder war Adam Osborne.\n\nDer Computer wurde im April 1981 von der Firma Osborne Computer Corporation auf den Markt gebracht. Der Rechner wog 11 kg, weshalb er im Vergleich zu späteren Laptops im Englischen meist als \"luggable computer\", also als \"schleppbarer Computer\" (deutsches Wortspiel \"Schlepptop\") bezeichnet wird. Der Einführungsslogan lautete: „Unser Computer passt unter jeden Flugzeugsitz.“ Bei der Markteinführung kostete er in den USA 1795 US-$. In Deutschland lag der Preis Anfang 1983 bei knapp unter 6000 DM.\n\nIm Rechner arbeitete eine Zilog-Z80-CPU mit 4,0 MHz, die auf einen Speicher von 64 kB RAM zugreifen konnte. Zum Lieferumfang gehörte neben dem Betriebssystem CP/M 2.2 auch die Programmiersprache MBASIC. Im Design war er stark angelehnt an den Xerox NoteTaker von Xerox PARC, der 1976 nach Vorlage eines Konzeptes von Alan Kay entwickelt wurde, aber nie in Serie ging.\n\nIn dem zusammenklappbaren Computer waren eine Tastatur mit 69 Tasten (heutige Tastaturen haben etwa 100) und ein 5″-Bildschirm integriert, der 24 Zeilen à 52 Zeichen darstellen konnte.\n\nNachfolgemodell des Osborne 1 war der Osborne Executive, bevor der Hersteller schließlich im September 1983 in Konkurs ging.\n\n\nDer Osborne 1 wurde zusammen mit einem Paket an Anwendersoftware ausgeliefert, dessen Zusammenstellung variierte. So war das Programm dBASE II bei der ersten Rechnerversion nicht enthalten. Als Betriebssystem diente CP/M 2.2 der Firma Digital Research.\n\nDer Osborne 1 bzw. sein Nachfolger, der Osborne Executive, ist kurz in dem Film \"Das Philadelphia Experiment\" (1984) zu sehen. In derselben Szene sieht man auch einen Commodore 64.\n\n"}
{"id": "1930665", "url": "https://de.wikipedia.org/wiki?curid=1930665", "title": "Apple II Language Card", "text": "Apple II Language Card\n\nDie Apple II Language Card war eine populäre Erweiterungskarte für den ersten Heimcomputer Apple II, die in dessen ROM-Adressraum durch Bank Switching wahlweise RAM-Speicher einblenden konnte. Dadurch wurde ein Speicherausbau bis 64 KB ermöglicht. Die Karte wurde ursprünglich nur zusammen mit Erweiterungssprachen verkauft, zum Beispiel mit Apple Pascal und Apple FORTRAN. Nachbauten der Karte durch andere Unternehmen wurden aber bald auch ohne solche Sprachpakete erhältlich, und ab etwa 1982 setzten viele Apple-Programme eine solche Karte voraus.\n\nDer 6502-Mikroprozessor des Apple II hatte einen 16-Bit-Adressraum, konnte von Haus also nur 64 KB Speicher adressieren. Von diesem Adressraum nutzte der Apple II bis zu 48 KB für RAM-Speicher, dann schlossen sich 4 KB an, in denen I/O-Adressen für Memory Mapped I/O und die ROMs auf Erweiterungskarten untergebracht wurden. Die oberen 12 KB waren für das eingebaute ROM des Apple II reserviert (10 KB für den BASIC-Interpreter, 2 KB für das eigentliche Betriebssystem).\n\nDie Language Card blendete sich beim Zugriff auf bestimmte I/O-Register statt der 12 KB des ROMs in den Adressraum ein. Dabei konnten die ersten 4 KB mittels einer zweiten Ebene von Bank Switching zwischen zwei Speicherbänken umgeschaltet werden, sodass die Karte insgesamt 16 KB bot. Andere Hersteller nutzten dasselbe Prinzip, um weitere 4-KB-Blöcke in den Adressraum einzublenden und so auf deutlich mehr als 64 KB Gesamtspeicher zu kommen.\n\nDie Karte wurde standardmäßig stets in den Steckplatz 0 (ganz links) eingesetzt. Sie funktioniert prinzipiell auch in den anderen Steckplätzen, aber fast alle Programme, einschließlich der Betriebssysteme Apple DOS und Apple ProDOS, erwarten die Karte im Steckplatz 0.\n\nDie von Apple selbst angebotene Language Card enthielt zusätzlich einen ROM-Chip, der inhaltlich identisch mit dem sogenannten Autostart-ROM des Apple II+ war. Damit erhielt auch das Apple-II-Urmodell die Fähigkeit, beim Einschalten ohne Befehlseingabe selbsttätig ein Betriebssystem oder anderes Programm von einer Diskette zu starten. Die von anderen Unternehmen angebotenen Nachbauten der Language Card verzichteten aus urheberrechtlichen Gründen auf diesen ROM-Chip; auf dem inzwischen weit häufigeren Apple II+ brachte dieser ohnehin keinen Zusatznutzen.\n\nBeim weiter entwickelten Computermodell Apple IIe und allen späteren Modellen der Baureihe war eine Speichererweiterung nach Art der Language Card bereits eingebaut. Dafür entfiel der Steckplatz 0, so dass nur noch sieben Standard-Apple-Steckplätze (1–7) vorhanden waren.\n\n"}
{"id": "1930991", "url": "https://de.wikipedia.org/wiki?curid=1930991", "title": "Windows Genuine Advantage", "text": "Windows Genuine Advantage\n\nDie Windows-Echtheitsprüfung Windows Genuine Advantage (WGA), dt. etwa „Echtheitsvorteil“, ist ein Programm und Teil von Microsofts Maßnahmen zum Schutz von Softwarelizenzen unter Windows XP.\n\nDas Programm ist Teil von Microsofts wirtschaftlich begründeten und durch das Urheberrecht legitimierten Anstrengungen, Kunden und Partner vor Softwarefälschern zu schützen. Durch das Programm wird der Einsatz unlizenzierter Windows-Betriebssysteme erschwert, indem binnen 30 Tagen eine Produktaktivierung erfolgen muss oder eine Deaktivierung wesentlicher Funktionen erfolgt.\n\nWindows Genuine Advantage wurde für Windows XP im Juli 2005 obligatorisch eingeführt, um die Authentizität der verwendeten Kopie von Microsoft Windows zu bestätigen und Microsoft beim Einsatz gegen Softwarepiraterie zu unterstützen. Seit Windows Vista ist das Programm standardmäßig in der Release-Version des Betriebssystems implementiert.\n\nBei dem Betriebssystem Windows 7 wurde das Tool in Windows Activation Technologies (WAT) umbenannt.\n\nDas WGA-Programm setzt sich aus zwei Hauptkomponenten zusammen: der WGA-Gültigkeitsprüfung und \"Windows Genuine Advantage Notifications\". Mit der Gültigkeitsprüfung wird ermittelt, ob es sich bei der installierten Windows-XP-Kopie um lizenzierte Originalsoftware handelt. Die \"WGA-Notifications\" weisen Benutzer, bei denen die Gültigkeitsprüfung fehlgeschlagen ist, darauf hin, dass keine Originalsoftware von Windows verwendet wird. Anschließend wird der Benutzer auf Informationen über die Vorteile einer Originalkopie von Windows XP verwiesen.In Windows Vista fährt das WGA-Tool nach Ablauf der 30-Tages-Frist Windows zudem automatisch nach einer Stunde Betriebszeit herunter.\n\nDurch die Gültigkeitsprüfung werden zunächst Daten über die Hard- und Softwareumgebung des Computers gesammelt und in verschlüsselter Form via Internet an Microsoft gesendet. Dort wird mit einer Datenbank geprüft, ob jede Lizenznummer weltweit gleichzeitig nur für ein System verwendet wird. Ungültige oder mehrfach verwendete Lizenznummern werden als Schwarzkopien angesehen und führen schließlich zu Fehlermeldungen beziehungsweise zum Ausschluss von Support und von nicht-sicherheitsrelevanten Aktualisierungen () für die entsprechenden Microsoft-Programme. Sicherheitsupdates, d. h. \"kritische\" Patches, werden weiterhin zur Verfügung gestellt.\n\nDer Assistent zur Windows-Überprüfung führt dieselbe Gültigkeitsprüfung wie WGA aus, allerdings handelt es sich um ein eigenständiges Dienstprogramm (Tool), das unabhängig davon arbeitet, ob man von Microsoft Dateien herunterladen oder sein System auf den neuesten Stand bringen möchte.\n\nDie \"WGA-Notifications\"-Programmkomponente wurde anfangs als „kritisches Update“ KB905474 verteilt. Im Nachhinein hat Microsoft diese Prozedur bei Windows XP aber revidiert und den Installationsablauf insoweit geändert, als der Installation nun explizit zuzustimmen ist.\n\nWenn über WGA die Echtheit der Installation geprüft wird, werden folgende Daten gesammelt:\n\nNeben WGA existiert für Microsoft-Office-Produkte – zunächst für die 2007-Version – das spezielle \"Office-Genuine-Advantage\"-Programm (\"OGA\"). Der Download von nicht-kritischen Updates und Add-Ons war nur für Besitzer eines Originals möglich. Seit 2006 prüfte Microsoft die installierten Lizenzen während des Updatevorgangs und seit 2008 wurden Nutzern ungültiger Lizenzschlüssel Hinweise angezeigt. Im Dezember 2010 wurde OGA eingestellt.\n\nWenn ein rechtmäßiger Endanwender einem Betrüger aufgesessen ist und erst im Nachhinein erfährt, dass sein Lizenz-/Produktschlüssel ungültig und das erworbene Produkt somit eine illegale Schwarzkopie ist, besteht unter bestimmten Voraussetzungen die Möglichkeit, von Microsoft kostenlosen Ersatz zu bekommen.\n\nAutorisierte Kunden erhalten entweder eine \"elektronische Lizenz\", d. h., sie bekommen eine E-Mail-Bestätigung mit einem neuen 25-stelligen \"Product Key\" und einer Anleitung dazu…\n…oder – wie z. B. im Falle des \"Office Genuine Advantage Kits\" – eine CD mit einem neuen Schlüssel, womit die Office-Software neu installiert und erneut aktiviert werden muss.\n\n"}
{"id": "1936786", "url": "https://de.wikipedia.org/wiki?curid=1936786", "title": "Sentiment Detection", "text": "Sentiment Detection\n\nSentiment Detection (auch Sentimentanalyse, englisch für „Stimmungserkennung“) ist ein Untergebiet des Text Mining und bezeichnet die automatische Auswertung von Texten mit dem Ziel, eine geäußerte Haltung als positiv oder negativ zu erkennen.\n\nMenschen unterhalten sich in natürlichen Sprachen, Sprachen also, die Bedeutung und Information anders als formale Sprachen nicht eindeutig und nicht allein strukturell übermitteln und deren automatische Verarbeitung durch Computer dadurch erschwert wird. Die Computerlinguistik erforscht, wie man mit Computern trotzdem natürliche Sprache analysieren kann. Lange Zeit hoffte man dabei auf die Künstliche Intelligenz, die versucht, intelligente Systeme zu schaffen, doch da selbst moderne Computer von diesem Ziel noch weit entfernt sind, grenzte man die Ziele der Sprachverarbeitung stark ein und wandte sich einfacheren aber erfolgversprechenderen Methoden zu. Ein solches Ziel ist es, spezielles Wissen aus Texten herauszuarbeiten, z. B. das Thema oder – wie hier – die Einstellung des Autors zu diesem Thema. Das Gebiet, das sich mit der Lösung solcher Aufgaben beschäftigt, nennt sich Text Mining, in Anlehnung an Data-Mining, mit dem es die Grundideen gemeinsam hat. Die Methoden, mit denen die \"Sentiment Detection\" arbeitet, entstammen Gebieten wie Statistik, maschinellem Lernen und Natural language processing.\n\nDie Aufgabenstellung der \"Sentiment Detection\" wird durch statistische Methoden angegangen. Darüber hinaus kann man die Grammatik der untersuchten Äußerungen einbeziehen. Zur statistischen Analyse geht man von einer Grundmenge von Begriffen (oder N-Grammen) aus, mit denen man positive oder negative Tendenzen verbindet. Die Häufigkeiten positiver und negativer Begriffe im analysierten Text werden einander gegenübergestellt und bestimmen die vermutete Haltung.\n\nDarauf aufbauend lassen sich Algorithmen des maschinellen Lernens anwenden. Auf Grundlage von vorverarbeiteten Texten, zu denen die Haltungen bekannt sind, können solche Algorithmen auch für weitere Begriffe lernen, welcher Tendenz sie zuzuordnen sind.\n\nMit Hilfe von Techniken des Natural language processings kann Wissen über die natürliche Sprache in die Entscheidung einfließen. Wird beispielsweise die Grammatik der Texte analysiert, können maschinell erlernte Muster auf die Struktur angewendet werden.\n\n\nSofern nicht anders angegeben, entstammt der Artikelinhalt der Hauptquelle:\n"}
{"id": "1937686", "url": "https://de.wikipedia.org/wiki?curid=1937686", "title": "Computerwurm", "text": "Computerwurm\n\nEin Computerwurm (im Computerkontext kurz Wurm) ist ein Schadprogramm (Computerprogramm oder Skript) mit der Eigenschaft, sich selbst zu vervielfältigen, nachdem es einmal ausgeführt wurde. In Abgrenzung zum Computervirus verbreitet sich der Wurm, ohne fremde Dateien oder Bootsektoren mit seinem Code zu infizieren.\n\nWürmer verbreiten sich über Netzwerke oder über Wechselmedien wie USB-Sticks. Dafür benötigen sie gewöhnlich (aber nicht zwingend) ein Hilfsprogramm wie einen Netzwerkdienst oder eine Anwendungssoftware als Schnittstelle zum Netz; für Wechselmedien benötigen sie meist einen Dienst, der nach dem Anschluss des belasteten Mediums den automatischen Start des Wurms ermöglicht (wie Autorun, mitunter auch den aktiven Desktop von Windows).\n\nEin Hilfsprogramm könnte beispielsweise ein E-Mail-Programm sein, das der Wurm fernsteuert, um sich an alle dort eingetragenen E-Mail-Adressen zu verteilen. Je nach Art des Hilfsprogramms kann sich der Wurmcode auf den Zielsystemen manchmal sogar selbst ausführen, weshalb dann keine Interaktion mit dem Benutzer mehr notwendig ist, um sich von dort aus weiter zu verbreiten. Daher ist diese Methode im Vergleich zur Ausbreitungsgeschwindigkeit eines Virus sehr effizient. Auf Systemen, die dem Wurm keinen Zugriff auf das benötigte Hilfsprogramm ermöglichen, kann sich der Wurm allerdings nicht, oder zumindest nicht automatisiert, reproduzieren.\n\nDer Wurm zählt zur Familie unerwünschter bzw. schädlicher Programme, der sogenannten Malware, was Schutzmaßnahmen gegen Würmer notwendig macht. Neben der geheimen Verbreitung, die bereits ungefragt Ressourcen bindet, kann eine mögliche Schadfunktion des Wurms vom Anwender nichtkontrollierbare Veränderungen am System vornehmen. Es besteht die Gefahr, dass zahlreiche miteinander vernetzte Computer kompromittiert werden.\n\nEinem Virus und einem Wurm gemein ist die Eigenschaft, sich auf Computern zu verbreiten. Ein Virus tut dies, indem er sich in den Bootbereich eines Datenträgers einträgt (Bootsektorvirus) oder in andere Dateien einbettet (Dateivirus). Durch Interaktion des Benutzers, der ein infiziertes Wechselmedium an ein anderes System anschließt (und in diesem Zustand rebootet) oder eine infizierte Datei öffnet, gelangt der Virencode auch dort zur Ausführung, wodurch weitere Systeme mit dem Virus infiziert werden. Der Virus wird durch Mithilfe des Anwenders verbreitet.\n\nEin Wurm verbreitet sich auf eine andere Art, ohne Dateien oder Bootbereiche der Datenträger zu infizieren. Er nutzt gewöhnlich eine bestehende Infrastruktur, um sich automatisiert auf andere Systeme zu kopieren. Um bei dem Beispiel der Einleitung zu bleiben, könnte der Wurm sich selbst an alle von einem E-Mail-Programm verwalteten E-Mail-Adressen verschicken. Auf den Zielsystemen braucht es mitunter auch hier eine Interaktion mit dem Benutzer, der den E-Mail-Anhang öffnet und damit den darin erhaltenen Wurm ausführt. Einmal ausgeführt, verschickt sich der Wurm dann wiederum an alle E-Mail-Adressen, die das neue System verwaltet, und gelangt so auf weitere Systeme.\n\nAls Trojanisches Pferd, kurz Trojaner, wird ein Computerprogramm oder Skript bezeichnet, das sich als nützliche Anwendung tarnt, im Hintergrund aber ohne Wissen des Anwenders eine andere Funktion erfüllt. Das einfachste Beispiel dafür ist eine schädigende Datei, wie codice_1, die einen Dateinamen erhält, der auf eine andere Funktion schließen lässt, wie codice_2. Dabei ist es unerheblich, ob der „lustige Bildschirmschoner“ tatsächlich auch einen Bildschirmschoner anzeigt, während er die Daten zerstört, oder ob er einfach nur die Daten zerstört. Die Nutzung des irreführenden Dateinamens genügt völlig, um das Programm als Trojanisches Pferd zu klassifizieren.\n\nIn dem oben aufgezeigten Beispiel des Wurms, der als E-Mail-Anhang darauf aus ist, dass der Anwender ihn öffnet, nutzt der Wurm gerne die Verschleierungstechniken des Trojanischen Pferdes. Statt also einen Anhang mit dem Namen „ich bin ein Wurm“ zu verwenden, gibt er sich lieber als „wichtiges Dokument“ (z. B. eine \"Rechnung\", wobei es unerheblich ist, ob diese echt ist) aus, damit der Anwender den Wurm auch öffnet. Er bildet dann eine Mischform aus Wurm und Trojaner.\n\nEbenso hält niemand den Entwickler des Wurms davon ab, für die Verbreitung seines Programms einen zweiten Weg, den Weg des Virus, einzuschlagen. Der Wurm kann also zusätzlich auch Dateien des Systems, auf dem er ausgeführt wird, mit seinem Code infizieren. Ein solches Programm bildet dann eine Mischform aus Wurm und Virus.\n\nWürmer verbreiten sich über Netzwerke oder über Wechselmedien wie z. B. USB-Sticks.\n\nDa der Wurm selbst in Form eines ausführbaren Programms oder Skripts auftritt, ist er darauf angewiesen, auf dem Zielsystem ausgeführt zu werden. Entweder geschieht dies durch den Benutzer, der den Wurm „von Hand“ öffnet, oder er wird im Zusammenhang mit dem Empfang des Wurmcodes automatisch auf dem Zielsystem ausgeführt. Letzteres ist auch durch einen Fehler im Design des Hilfsprogramms, einen technischen Programmierfehler (wie Pufferüberlauf) oder eine andere Sicherheitslücke möglich. Da dem Hersteller bekannte Sicherheitslücken bei funktionierender Unterstützung über kurz oder lang geschlossen werden, kommt der Verbreitung des Wurms durch Bequemlichkeit, Unwissenheit und Fehlverhalten des Benutzers eine große Bedeutung zu, indem er die Software seines Systems nicht aktualisiert oder den Wurm selbst startet.\n\nFür den Start des Wurms „von Hand“ siehe das Beispiel zum .\n\nRobert T. Morris schrieb 1988 ein Programm, das unter anderem eine Remote Shell nutzt, um sich auf andere Systeme zu kopieren und dort auszuführen, mit dem Ziel, sich von dort aus auf weitere Systeme zu kopieren und dort auszuführen. Als sein Programm außer Kontrolle geriet, sah sich die Welt mit dem ersten Internetwurm konfrontiert. Sein Programm versuchte, sich der Entdeckung und Analyse auf den befallenen Systemen zu entziehen, enthielt aber keine explizite Schadroutine. Dessen permanent arbeitende Verbreitungsroutine legte dennoch zahlreiche Systeme lahm. Moderne Würmer nutzen mitunter noch immer solche oder ähnliche Automatisierungsmechanismen eines Programms, wie sie beispielsweise die \"Remote Shell\" zur Verfügung stellt, um ihren Code auf ein entferntes System zu kopieren und dort auszuführen.\n\nDer Morris-Wurm zeigte darüber hinaus einen Weg auf, wie man Programmierfehler ausnutzt, um einen solchen Mechanismus in Programmen zu erschaffen, die normalerweise eine derartige Automatisierung gar nicht vorsehen (\"Command-Execution-Exploit\" durch einen Fehler im Netzwerkdienst \"finger\" über einen buffer overflow in der Funktion \"gets()\"). Als weiteres Beispiel nutzt der Wurm \"Blaster\" einen Exploit in der RPC/DCOM-Schnittstelle von Windows 2000 und XP, um Computer über Netzwerke zu suchen und zu infizieren, auf denen die von dem Wurm genutzte Sicherheitslücke existiert.\n\nAlternativ dazu können Würmer auch Sicherheitslücken im Design einer Anwendung nutzen, wenn die Anwendung beispielsweise Funktionen vorsieht, die den Komfort der Anwendung erhöhen, dafür aber die üblichen Sicherheitseinschränkungen durchbrechen. Dazu gehört ein Programmcode, der als „Objekt“ in eine Webseite oder eine HTML-E-Mail eingebunden werden kann, und Ähnliches. Bei Letzterem wird der Wurmcode dann bereits beim Lesen der E-Mail gestartet, ohne einen Anhang öffnen zu müssen. Konkret kann die Verwendung von ActiveX-Objekten sowie die Implementierung von JScript und VBScript eine gewisse Benutzerfreundlichkeit ermöglichen, birgt aber die genannten Risiken. Letztlich führte dies dazu, bestimmte vom Entwickler eigentlich gewollte Funktionen wieder zu blockieren; der Anwender muss sie nun explizit in seiner Anwendung freischalten, wenn er sie trotzdem nutzen möchte. Demgegenüber gibt es die Methode, bestimmte Quellen mit Hilfe von digitalen Zertifikaten als vertrauenswürdig einzustufen und ihnen den Zugriff auf sonst blockierte Mechanismen zu erlauben. Bei all diesen Methoden, angefangen von der Softwareimplementierung der Blockade bis hin zum Regelwerk, kommt es hin und wieder zu Fehlern, die bei der Verbreitung von Würmern genutzt werden.\n\nKonkret gibt es beispielsweise eine Reihe von Würmern, die einen Fehler einer älteren Version des E-Mail-Programms Microsoft Outlook Express in der folgenden Form ausnutzen: Die Anlagen von HTML-E-Mails werden von Outlook Express üblicherweise \"inline\", also direkt in der Nachricht selbst, dargestellt. Alternativ kann der Quelltext der E-Mail auch eine Referenz enthalten, unter der die betreffende Datei online hinterlegt ist, und dann in einem Inlineframe dargestellt wird. Innerhalb eines HTML-Quelltextes können Dateiformate, die nicht dem Internetstandard entsprechen und deshalb normalerweise nicht direkt in eine HTML-Seite eingebunden werden können, als „Objekte“ definiert werden. Dazu wird dem System mitgeteilt, welcher Art das „Objekt“ ist und wie das System damit zu verfahren hat. Der HTML-Parser \"mshtml.dll\" müsste jetzt abfragen, ob diese Art von „Objekt“ bekannt ist und ausgeführt werden darf. Diese Abfrage ist der Schwachpunkt des Systems, da eine bestimmte fehlerhafte Abfrage zu einem Systemfehler und daraufhin zur Ausführung des „Objektes“ führt, obwohl das Gegenteil zu erwarten wäre. Allein das Betrachten des E-Mail-Textes startete also – ohne weiteres Zutun des Anwenders – die Schadsoftware. Dieser Fehler wurde durch eine Aktualisierung der Software behoben. Eine ähnliche Sicherheitslücke existierte auch im E-Mail-Programm „Eudora“.\n\nViele Würmer benutzen E-Mails, um sich zu verbreiten. Dabei wird entweder die ausführbare Datei oder ein Hyperlink zur ausführbaren Datei versendet. Die E-Mails können entweder durch Fernsteuerung von vorinstallierten Programmen wie Microsoft Outlook oder durch ein eigenes SMTP-Unterprogramm des Wurms verschickt werden. Die E-Mail-Adresse des Empfängers wird häufig in vorinstallierten Adressbüchern gefunden. Es können aber auch andere Dateien auf den Festplatten (wie in temporären Internetdateien) von dem Wurm genutzt oder für die initiale Verteilung E-Mail-Adressen aus speziellen Webseiten (etwa Online-Gästebücher) verwendet werden. Bekannte Vertreter dieser Art sind Loveletter, der sich im Mai 2000 explosionsartig per E-Mail verbreitet hat, oder Netsky.\n\nInstant-Messaging-Programme wie zum Beispiel WhatsApp, ICQ, MSN Messenger oder Skype sind durch ihre Web-Anbindung ebenfalls anfällig für Malware. Ein Wurm dieser Art verbreitet sich, indem an einen Messenger ein Link zu einer Webseite geschickt wird, die den Wurm enthält. Klickt der Benutzer auf den Link, wird der Wurm auf dessen Computer installiert und ausgeführt, da der Instant-Messenger zumeist keinen eigenen HTML-Parser enthält, sondern den Parser des Internet Explorers mitnutzt. Nun sendet der Wurm von diesem Computer den Link an alle eingetragenen Kontakte weiter.\n\nIRC-Clients sind Programme, mit denen jeder beliebige Benutzer mit anderen Benutzern virtuell in Echtzeit Textnachrichten im Internet Relay Chat austauschen kann. Die meisten IRC-Programme benutzen, um sich am IRC-Server anzumelden, ein spezielles Script, das beim Starten des Programms ausgeführt wird. Dieses Script beinhaltet Befehle, die das IRC-Programm ausführt. Diese Befehle sind zum Beispiel das Anmelden an einem Channel, das Schreiben von Meldungen, aber auch das Versenden von Dateien. Ein IRC-Wurm, der einen Computer infiziert hat, sucht nach IRC-Programmen, die er benutzen kann, um sich weiterzuverbreiten. Wenn er ein solches Programm gefunden hat, modifiziert er das Script, welches automatisch geladen wird. Beim nächsten Start des IRC-Programms wird der Wurm selbständig an alle Benutzer in einem Chatraum verschickt. Wenn ein Benutzer das Herunterladen akzeptiert und die geladene Datei öffnet, wiederholt sich das Ganze. Derzeit gibt es für wenigstens fünf IRC-Programme IRC-Würmer (mIRC, pIRCh, vIRC, dIRC und Xircon).\n\nPeer-to-Peer ist eine Netzwerkform, die ohne Server Computer im Netz verbindet, d. h. eine Direktverbindung zwischen den einzelnen Benutzern herstellt. Die meisten im Internet bestehenden Tauschbörsen wie Kazaa, Morpheus oder BitTorrent-Systeme nutzen Peer-to-Peer-Technik. Es gibt prinzipiell drei Möglichkeiten, wie sich ein Wurm in einer Tauschbörse verbreitet:\n\nDie erste Möglichkeit ist, dass sich der Wurm in den freigegebenen Ordner kopiert, von dem andere Benutzer Dateien herunterladen können. Für diese Art von Würmern ist die richtige Namensgebung wichtig, da mehr Benutzer eine Datei mit einem interessanten Namen herunterladen als eine Datei mit einem zufällig erstellten Namen. Darum gibt es Würmer, die ihre Namen im Internet auf speziellen Seiten suchen, um so glaubwürdig wie möglich zu sein. Diese Art der Verbreitung in Tauschbörsen ist einfach, aber nicht besonders effektiv, da in Tauschbörsen üblicherweise eher große Dateien getauscht werden und fast jedes Filesharing-Programm inzwischen wirksame Filter besitzt, um bestimmte verdächtige Dateiformate auszugrenzen.\n\nBei der zweiten Möglichkeit der Verbreitung bietet der Wurm über ein Peer-to-Peer-Protokoll bei jeder Suchabfrage den anderen Benutzern des P2P-Netzwerkes eine infizierte Datei als Suchergebnis (Hashset oder .torrent-File) an. Der Benutzer kopiert dann den Wurm als vermeintlich gesuchte Datei auf seinen Computer und infiziert ihn beim Öffnen. Diese Art der Verbreitung ist sehr effektiv, sofern die Dateigröße des Wurms annähernd so groß ist wie die gesuchte Datei, aber schwierig zu programmieren und deshalb kaum verbreitet.\n\nDie dritte Methode ist ein Angriff des Wurms auf eine Sicherheitslücke seiner Nachbarn im P2P-Netzwerk. Diese Methode kann in seiner Ausbreitungsgeschwindigkeit sehr effizient sein, wenn keine Aktion seitens des Benutzers (wie das Herunterladen einer Datei und deren Start auf dem Computer) benötigt wird. Der Wurm infiziert diese Systeme dann voll automatisiert. Sobald der Wurm zudem in der Lage ist, bei jedem infizierten Client eine Liste seiner Nachbarn im P2P-Netzwerk einzusehen, kann er diese gezielt ansprechen. Dadurch kann der Wurm einer Entdeckung vorbeugen, da er keine übergroße Anzahl an Verbindungen zu anderen Systemen im Internet aufzubauen braucht, was als anormales Verhalten angesehen wird und auffällig wäre. Ein P2P-Netzwerk basiert darauf, dass jeder Nutzer viele Verbindungen zu anderen Teilnehmern aufbaut, was die Erkennung des Wurms anhand des von ihm verursachten Datenverkehrs deutlich erschwert.\n\nWechseldatenträger sind austauschbare Datenträger für Computer, wie USB-Sticks. Diese Würmer kopieren sich selbständig auf die Datenträger, um sich von einem Computer zu einem anderen zu verbreiten. Im Unterschied zu den bisher erwähnten Arten benutzt diese Gruppe kein Netzwerk, um sich zu verbreiten. Dabei kann sich das Programm den automatischen Start des Datenträgers zunutze machen.\n\nDemgegenüber gibt es auch Würmer, die sich auf Disketten kopieren, ohne irgendeine Form des automatischen Starts zu benutzen. Sie sind die einzigen Würmer, die für ihre Verbreitung kein Hilfsprogramm benötigen, wobei sie darauf angewiesen sind, dass der Anwender sie selbst findet und „von Hand“ startet. Da Disketten nicht mehr weit verbreitet sind, haben solche Würmer heute jedoch keine Chance mehr, sich weit zu verbreiten. Grundlegend ist eine solche Art der Verbreitung aber auch mit aktuellen Medien, etwa eine beschreibbare CD, möglich. Das Kopieren des Schadcodes ist hier jedoch komplizierter.\n\nNeben USB-Memory-Sticks können auch andere USB-Kleingeräte zur Verbreitung von Würmern genutzt werden. Solche Angriffe sind nicht auf die Autostart-Fähigkeit eines USB-Speichers angewiesen, sondern bilden mit einem Kleinprozessor eine Tastatur nach. Von dieser gefälschten Tastatur aus schleust das angreifende Gerät Befehle in das System, die scheinbar vom echten Benutzer stammen. Auf diese Weise wird die Schadsoftware gestartet, die sich auf dem ebenfalls eingebauten USB-Massenspeicher befindet.\n\nFür diese Methode des Angriffs eignen sich alle Arten von USB-Kleingeräten, die man als scheinbares Werbegeschenk an das Opfer senden kann.\n\nWürmer für Mobiltelefone sind zuerst im Juni 2004 aufgetreten. Antivirenhersteller vermuten, dass in diesem Bereich immer mehr Viren und Würmer auftreten werden, ähnlich dem Verlauf im Computersektor.\n\nDie derzeitigen Würmer verbreiten sich meist über Bluetooth, eine kabellose Verbindung zwischen Mobiltelefonen, Drucker oder Scanner mit einer Reichweite von ungefähr zehn bis 100 Metern. Handywürmer greifen derzeit überwiegend das Betriebssystem Symbian OS an und versuchen, sich selbst mit Bluetooth an alle erreichbaren Bluetooth-Empfänger zu schicken. Seit dem Jahr 2005 ist es auch möglich, dass sich diese Würmer durch MMS verbreiten.\n\nAntivirenhersteller empfehlen ihren Kunden daher, Bluetooth standardmäßig zu deaktivieren.\n\nWeitere Verbreitungen sind über GPRS/UMTS sowie über WLAN möglich. Der erste bekannte iOS-Wurm, der nur auf iPhones mit Jailbreak gelang, welcher sich über das UMTS-Netz verbreitet hat (Australien), war der \"Ikee\". Sein Nachfolger hieß \"iPhone/Privacy.A\" und sucht seinen Weg über das WLAN.\n\nIn diesem Beispiel wird der Wurm als E-Mail-Anhang empfangen. Der Empfänger soll nun veranlasst werden, den Anhang zu öffnen und somit eine weitere Verbreitung des Wurms auslösen. Die im Folgenden verwendeten Methoden zielen daher auf den Benutzer des EDV-Systems und nicht auf das System selbst.\n\nDer Wurm muss sich vor den Augen des Benutzers tarnen, um unter den beschriebenen Voraussetzungen erfolgreich zu sein. Dies erfolgt unter zwei sich ergänzenden Konstellationen:\n\n\nDer erste Punkt zielt auf eine Technik, die unter dem Begriff „Social Engineering“ bekannt ist, die mentale Beeinflussung des Empfängers auf sozialer Ebene. Sie bezieht sich hier auf den Text der E-Mail, der auf den Benutzer einen besonderen Eindruck hinterlassen soll und ihn so zu Dingen veranlasst, die er normalerweise (womöglich) nicht täte, wie das Öffnen des Anhangs.\n\nDer zweite Punkt greift auf die Technik des „Trojanischen Pferdes“ zurück, die dafür benutzt wird, den E-Mail-Anhang selbst nicht als Wurm, sondern als „ungefährliche, nützliche Datei“ auszugeben.\n\nDas Interesse des Empfängers am Anhang wird geweckt, wenn der Inhalt der dazugehörigen E-Mail auf eine besondere Schockwirkung abzielt, indem beispielsweise mit Rechtsmitteln bis hin zur Strafverfolgung gedroht wird. Andere Begleittexte versuchen Neugier oder Begierden zu erwecken, indem hohe Geldbeträge versprochen oder vermeintlich private Bilddateien mit oder ohne pornographischen Inhalt angeboten werden.\n\nIn jedem Fall wird der Empfänger auf den Anhang der E-Mail verwiesen, welcher ausführliche Informationen enthalten soll. Das so geweckte Interesse am Dateianhang dämpft naturgemäß auch eventuelle Sicherheitsbedenken.\n\nEinige (vor allem ältere) E-Mail-Programme für das Betriebssystem Windows halten sich an die Standardeinstellung des Betriebssystems und blenden die Dateiendung bekannter ausführbarer Dateien aus. Dadurch kann ein Wurm als Datei beliebiger Art maskiert sein, sodass eine schädigende Datei „codice_3“ dem Benutzer namentlich nur als „codice_4“ angezeigt wird und somit auf den ersten Blick nicht von einer ungefährlichen MP3-Musikwiedergabedatei zu unterscheiden ist.\n\nDer Anwender könnte den wahren Dateityp jedoch erkennen, wenn das angezeigte Dateisymbol (Icon) dem Standardsymbol einer Anwendung entspricht. Ob allerdings dieses Standardsymbol oder das in der Anwendung eingebettete Icon angezeigt wird, hängt von dem verwendeten E-Mail-Programm ab. Besser ist es, die Einstellung des Programms dahingehend zu ändern, dass Endungen bekannter Dateitypen nicht mehr ausgeblendet werden, damit der gesamte Dateiname angezeigt wird.\n\nGrundsätzlich sollte man \"unverlangte\" Dateien aus externen Quellen nicht öffnen. E-Mail-Anhänge, die man öffnen möchte, sollten nicht einfach über die Option „öffnen“, sondern über die Option „öffnen mit“ geöffnet werden. Das bietet die Möglichkeit, ein Programm auszuwählen, das die entsprechende Datei wiedergeben soll. Eine Anwendung zum Abspielen von Musikdateien kann eine derartig getarnte ausführbare Datei nicht abspielen und reagiert mit einer Fehlermeldung, während die Option „öffnen“ die Datei einfach ausgeführt und den Wurm dadurch gestartet hätte.\n\nEine weitere Möglichkeit, ausführbaren Code unter einer „harmlosen“ Dateiendung zu verstecken, bieten Programme, die den Dateityp unabhängig von seiner Endung selbst analysieren und sie entsprechend ihrem tatsächlichen Typ behandeln. Als Beispiel ist es zwar theoretisch nicht möglich, in einer RTF-Datei ausführbaren Makrocode zu hinterlegen, da dieses Dateiformat keine Makros unterstützt. Jedoch wird eine Datei namens „codice_5“, die man in „codice_6“ umbenennt, von Office anhand des Dateiinhalts als DOC-Datei erkannt, woraufhin der darin hinterlegte Makrocode trotz der Dateiendung codice_7 ausgeführt wird.\n\nAuch hierfür lässt sich über die Option „öffnen mit“ aus den meisten E-Mail-Programmen heraus ein Programm auswählen, mit dem die Datei geöffnet wird. Um eine Ausführung des Wurms zu verhindern, ist es sinnvoll, statt der installierten Bearbeitungssoftware (Office) besser ein Programm auszuwählen, welches die Datei anzeigen und ausdrucken kann, ohne jedoch die Möglichkeit zu unterstützen, dabei auch Makrocode auszuführen. Der Softwarehersteller Microsoft bietet dafür kostenlose Windows-Anwendungen wie Word-Viewer, Excel-Viewer und PowerPoint-Viewer an.\n\nEin Command-Execution-Exploit nutzt Programmierfehler eines Programms aus, um seinen Code zur Ausführung zu bringen. Der Code kann jedoch nur dann gestartet werden, wenn die belastete Datei tatsächlich mit dem Programm geöffnet wird, für das der Exploit bestimmt ist.\n\nAbhängig von dem Programm, auf dessen Schwachstelle der Exploit basiert, kann sich der ausführbare Code in jedem Dateityp verbergen, also auch in Dateien, die normalerweise nicht ausführbar sind. So gibt es beispielsweise Möglichkeiten, ausführbaren Code in einer Grafikdatei zu hinterlegen.\n\nDa Programme vorgefertigte Mechanismen (gemeinsam benutzte Bibliotheken) des Betriebssystemherstellers nutzen können, um beispielsweise bestimmte Dateitypen anzuzeigen, sind Fehler in diesen Mechanismen auch für Anwendungen von Fremdherstellern relevant. Das gilt insbesondere für Sicherheitslücken, die für den Internet Explorer bekannt werden. Eine Sicherheits-Aktualisierung des Internet Explorers schließt dann auch gleichzeitig die Sicherheitslücke für diese Programme.\n\nDie Verwendung eines unverdächtigen, aber äußerst langen Dateinamens (etwa „codice_8“) soll über die Dateinamenerweiterung hinwegtäuschen. Sobald der Dateiname in einem relativ kleinen Fenster angezeigt wird, bleibt der letzte Teil des Dateinamens und somit die Erweiterung verborgen (angezeigt etwa als „codice_9“).\n\nDiese Taktik ist ausbaufähig, beispielsweise indem als Dateiname zunächst ein kurzer, unverdächtiger Name mit falscher Dateinamenerweiterung verwendet wird, an den eine Vielzahl von Leerzeichen vor der echten Erweiterung eingefügt sind (etwa „codice_10“). Hierbei kommen zwei Methoden der Verschleierung kombiniert zum Einsatz: Zum einen ist die Wahrscheinlichkeit groß, dass die tatsächliche Dateiendung aufgrund der Länge des Namens dem Benutzer nicht angezeigt wird und er durch die verwendeten Leerzeichen auch keinen Hinweis auf den erheblich längeren Dateinamen erhält. Wird (abhängig vom E-Mail-Programm) der Dateiname doch vollständig angezeigt, kann der Benutzer zum anderen den weit von dem scheinbar vollständigen Dateinamen entfernten Text \"„Checked by Antivirus.exe“\" auch lediglich als Hinweis deuten, ohne ihn in den direkten Zusammenhang mit dem Dateityp des Anhangs zu bringen.\n\nDa Anwendungen des Typs codice_11 als ausführbare Dateien relativ bekannt sind, wird mitunter auch auf weniger verbreitete Dateitypen (Dateiformate) zurückgegriffen, wie beispielsweise codice_12 oder codice_13. Die Dateiendung codice_14 ist zudem geeignet, einen Link auf eine Webseite vorzutäuschen (beispielsweise „codice_15“).\n\nDurch die Verwendung von Komprimierungsformaten, wie beispielsweise das ZIP-Format, wird der Dateityp des darin eingebetteten Wurms so lange verschleiert, bis er ausgepackt wird, was die Anwendung automatischer Schutzvorkehrungen grundsätzlich erschwert. Fehler in der Implementierung von Komprimierungsverfahren können eine Untersuchung der Datei auf Malware sogar verhindern. Zusätzlich kann die Datei verschlüsselt übertragen werden, was eine automatisierte Untersuchung einer solchen Datei zu einem Zeitpunkt, noch bevor der Benutzer sie öffnet, ausschließt.\n\nLaut einer Untersuchung von Sophos, einem Hersteller von Anti-Viren-Software, bestand im Jahr 2005 eine 50-prozentige Wahrscheinlichkeit für einen PC mit Windows XP ohne Softwareaktualisierung, im Internet innerhalb von zwölf Minuten mit schädlicher Software infiziert zu werden. Dies ist möglich, da bestimmte Würmer Schwächen und Fehler in Netzwerkdiensten ausnutzten, die auf einem PC ohne entsprechende Updates noch nicht geschlossen sind. Insbesondere durch die in späteren Windowsversionen standardmäßig aktivierte Desktop-Firewall und den vermehrten Einsatz von SoHo-Routern, die beide einen Fernzugriff auf Netzwerkdienste einschränken, hat sich diese Gefahr verringert.\n\nDer finanzielle Schaden, den Computerwürmer anrichten können, ist höher als bei Computerviren. Grund dafür ist der erhebliche Verbrauch an Netzwerkressourcen allein durch die Art, wie sich ein Wurm verbreitet, was zu einem Ausfall von Netzwerkteilnehmern wegen Überlastung führen kann. Wenn beispielsweise ein Server eines Unternehmens ausfällt, kann dies zu einem Arbeitsausfall führen.\n\nAnfang Mai 2004 erlitt eine Anzeigetafel des Flughafens Wien-Schwechat durch den Wurm „Sasser“ kurzfristig einen Totalausfall. SQL Slammer belastete stellenweise die Internet-Infrastruktur derart, dass vielerorts die Verbindungen komplett zusammenbrachen.\n\nEinen weiteren wirtschaftlichen Schaden können in Zukunft Handywürmer nach sich ziehen, die sich über MMS verbreiten. Wenn ein solcher Wurm dutzende kostenpflichtige MMS verschickt, ist mit einem hohen finanziellen Verlust zu rechnen.\n\nWeitere finanzielle Schäden können durch sogenannte Distributed-Denial-of-Service-Attacken entstehen. Wie am Beispiel W32.Blaster ersichtlich ist, können dadurch sogar große Unternehmen wie SCO oder Microsoft in Bedrängnis gebracht werden.\n\nIm November 2003 gründete Microsoft ein sogenanntes \"Anti-Virus-Reward-Programm\", um weltweit die Jagd auf Verantwortliche für die Verbreitung von Würmern und Viren zu unterstützen. Bei der Gründung erhielt die Initiative ein Startkapital von 5 Millionen US-Dollar, wovon bereits ein Teil der Summe für die Ergreifung und Verurteilung aktueller Wurmverbreiter zur Belohnung ausgesetzt wurde. Damit will Microsoft die zuständigen Ermittlungsbehörden bei der Fahndung nach den Verursachern unterstützen. Microsoft arbeitet mit Interpol, dem FBI, dem Secret Service und dem „Internet Fraud Complaint Center“ zusammen, denn \"„boshafte Würmer und Viren sind kriminelle Attacken auf jedermann, der das Internet benutzt“\".\n\nAuf dieser „Wanted“-Liste erschienen unter anderem die Autoren der Würmer W32.Blaster, Sasser, Netsky und \"Sobig\".\n\nIm Mai 2004 hatte dieses Programm seinen ersten Erfolg, als der Wurmautor von Sasser und Netsky verhaftet und verurteilt wurde. Der zu diesem Zeitpunkt 18-jährige Schüler aus Waffensen im Kreis Rotenburg/Wümme wurde von vormaligen Freunden wegen der ausgesetzten Belohnung angezeigt.\n\nIm Folgenden werden Teile des Artikels zusammengefasst, die sich auf den Schutz vor Würmern beziehen. Darüber hinaus werden gängige Softwarelösungen aus diesem Bereich behandelt.\n\nVor der psychologischen Beeinflussung des Benutzers (\"Social Engineering\"), beispielsweise durch den Text einer E-Mail, kann man sich technisch nicht schützen. Der Benutzer kann aber über die Risiken und Methoden von Schadsoftware aufgeklärt werden (siehe dazu das Beispiel zum \"„“\"). Aufklärung erhöht die Hemmschwelle und macht es einem Wurm schwerer, den Benutzer zum Öffnen einer belasteten Datei, wie des E-Mail-Anhangs oder Ähnlichem, zu überreden.\n\nEs ist ratsam, keine \"unverlangten\" Dateien aus E-Mail-Anhängen oder sonstigen anderen Quellen zu öffnen. Auch dann nicht, wenn sie von einem Absender stammen, der dem Empfänger bekannt ist. Denn auch bekannte Absender sind keine Gewährleistung für die Echtheit, da zum einen der Eintrag für den Absender gefälscht sein kann und zum anderen selbst bekannte Absender ebenfalls Opfer von Würmern werden können. Im Zweifelsfall sollte man beim Absender nachfragen.\n\nDateien, die man öffnen möchte, lassen sich zuvor dahingehend untersuchen, ob sie eine allgemein bekannte Schadsoftware enthalten (siehe den Abschnitt zum Virenscanner weiter unten).\n\nFür Dateien, die zu einer bestimmten Anwendung gehören (wie beispielsweise codice_16 als Musikdatei oder codice_17 als Grafikdatei) gilt, dass man sie nicht einfach über die Option „öffnen“, sondern über die Option „öffnen mit“ unter Auswahl des dazugehörenden Programms öffnen sollte (siehe dazu den Abschnitt \"„Doppelte Dateinamenserweiterung“\").\n\nSpeziell Office-Dokumente (darunter codice_18 und codice_7-Dateien) aus externen Quellen sollten nicht mit dem installierten Officeprogramm geöffnet werden, wenn man sie lediglich einsehen will. Denn das Officeprogramm birgt die für diesen Zweck unnötige Gefahr, dass dabei ein in dem Dokument hinterlegter Makrocode ausgeführt wird. Besser ist es, hierfür eine Anwendung zu verwenden, die solche Datei anzeigen und ausdrucken kann, ohne die Möglichkeit zu bieten, dabei Makrocode auszuführen. Der Abschnitt \"„Vermeintlich ungefährliche Dateitypen mit typfremdem Inhalt“\" geht darauf näher ein mit Hinweis auf eine kostenlose Alternative.\n\nWer sichergehen will, dass kein Schadcode bereits beim Lesen der E-Mail zur Ausführung gelangt (siehe \"„Automatische Ausführung“\"), kann sein E-Mail-Programm dahingehend konfigurieren, dass es keinen HTML-Code darstellt, sondern nur Text anzeigt.\n\nEin Virenscanner spürt allgemein bekannte Viren, Würmer und Trojanische Pferde auf und versucht, diese zu blockieren und zu beseitigen.\n\nWird eine Schadsoftware von dem Virenscanner erkannt, noch bevor die belastete Datei erstmals auf dem eigenen Computersystem ausgeführt wird, ist der Schutzmechanismus voll wirkungsvoll. Bevor eine auf dem Computer neu hinzugekommene Datei ausgeführt/in einer Anwendungssoftware eingelesen wird, die aus einer externen Quelle stammt (beispielsweise von einem Wechselmedium, von einer Webseite oder aus einer E-Mail), ist es daher ratsam, sie einer Überprüfung durch eine aktualisierte Antivirensoftware zu unterziehen.\n\nUm darüber hinaus weitere Infektionswege auszuschließen, gilt gleiches auch für Dateien, die auf einem gemeinsam genutzten Netzlaufwerk liegen, wenn eine zwischenzeitliche Infektion einer solchen Datei durch eines der anderen Systeme nicht ausgeschlossen werden kann (Mischformen zwischen Wurm und Virus).\n\nSpeziell zur Abwehr von Computerwürmern, die sich nicht Datei-basiert, sondern über Sicherheitslücken verbreiten, sind verhaltenserkennende Komponenten der Antivirensoftware zwingend notwendig, die sich entsprechend in das Betriebssystem einbetten.\n\nEin Virenscanner erkennt mit der Suchmethode „Signaturvergleich“ ausschließlich Schadsoftware, die ihm bekannt ist; ihm (noch) nicht bekannte Schadsoftware kann er so nicht erkennen. Er kann daher auf diese Weise nur feststellen, dass eine Datei, ein Datenträger oder gar das Computersystem frei von \"ihm bekannter\" Schadsoftware ist.\nDer Programmierer eines Computerwurms versucht, den Wurm möglichst versteckt zu halten oder eine bekannte Variante so stark zu verändern, dass sie nicht mehr erkannt wird; der Virenscanner-Hersteller versucht, die Signaturdatenbank möglichst aktuell zu halten - ein „Wettlauf“.\n\nAufgrund dieses prinzipiellen „Hinterherlaufens“ der Antivirensoftware enthält diese auch Komponenten, die laufende Prozesse im Computersystem auf verdächtige Aktivitäten hin überwachen, um eine Schadsoftware selbst dann zu erkennen, wenn sie dem Virenscanner nicht bekannt ist. Auch hier besteht ein Wettlauf mit der Schadsoftware - zwar nicht bzgl. der Bekanntheit der Schadsoftware selbst, dafür bzgl. der verwendeten Methoden und Vorgehensweisen der Schadprogramme.\n\nEinmal ausgeführten Schadprogrammen kann es gelingen, die Antivirensoftware zu deaktivieren oder das System derart zu manipulieren, dass die Schadprogramme vom Virenscanner nicht mehr entdeckt werden (siehe Rootkit). Bzgl. Datei-basierter Schadsoftware lässt sich das gesamte Computersystem besser über ein separates Bootmedium auf einen möglichen Befall einer Schadsoftware hin untersuchen, wie sie etwa auf bootfähigen Live-CDs (beispielsweise Desinfec’t, ehemals \"Knoppicillin\") zum Einsatz kommen. Hierbei wird verhindert, dass die eigene Softwareumgebung des Scanners entsprechend belastet ist.\n\nEine bereits ausgeführte (also auf dem System installierte) Schadsoftware lässt sich nur bedingt zuverlässig durch eine Antivirensoftware aus dem System entfernen. Denn der Schädling wird meist anhand einer Signatur erkannt, die manchmal keine genaue Aussage über die Variante des Schädlings und seiner Schadroutine trifft. Manche Schädlinge können auch Komponenten nachladen, meist über das Internet. Bei ihnen ist dann unbekannt, welche andere Schadsoftware sie ggf. nachgeladen haben und welche Änderungen diese am System vorgenommen hat. Diese Änderungen bleiben dann nach der Entfernung des Schädlings erhalten. Im günstigsten Fall kann die AV-Software die Schadsoftware jedoch komplett entfernen und die getätigten Änderungen am System korrigieren. Unter „Alternative Lösungen“ wird ein zuverlässiger Weg gezeigt, wie sich der Schädling ganz entfernen lässt.\n\nBei einem Virenscanner handelt es sich um eine komplexe Software, die sich mitunter sehr tief in das Computersystem einbettet, um bestimmte Abläufe kontrollieren zu können. Je komplexer eine Software ist, desto eher enthält sie Fehler, die sich auf die Performance, Stabilität und Sicherheit des Computersystems auswirken können.\n\nSpeziell zur Abwehr von Computerwürmern, die sich nicht Datei-basiert, sondern über Sicherheitslücken verbreiten, sind jedoch verhaltenserkennende Komponenten der Antivirensoftware zwingend notwendig, die sich in das eigene System einbetten.\n\nVirenscanner bieten keinen absolut zuverlässigen Schutz vor Schadsoftware, werden jedoch mitunter vollmundig entsprechend beworben. Benutzer könnten nachlässig werden und dann unbedarft handeln.\n\n\"Siehe auch: Überprüfbarkeit des Quelltextes\"\n\nDie Bereinigung des Systems über die Einspielung des letzten „sauberen“ Abbildes der Festplatte (Image) ist ein zuverlässiger Weg, um eine Schadsoftware recht sicher aus dem Computersystem zu entfernen. Man installiert also das Betriebssystem, richtet seine Software ein, passt das System derart an, dass alle persönlichen Dateien auf ein anderes Laufwerk abgelegt werden (sie dürfen also nicht auf demselben Laufwerk liegen, auf dem das Betriebssystem installiert wurde). Dann legt man eine Kopie des Laufwerks (genauer der \"Systempartition\") an, auf dem das Betriebssystem installiert wurde, und speichert es in eine Imagedatei. Wird das System später mit einer Schadsoftware infiziert, kann man den gespeicherten Softwarestand mithilfe der Imagedatei wiederherstellen und entfernt so üblicherweise die Schadsoftware und alle zwischenzeitlichen Änderungen aus seinem System.\n\nProbleme:\n\n\"Siehe auch:\" Die Systempartition schreibschützen\n\nErst ein \"Netzwerkdienst\" oder eine gestartete Anwendung mit entsprechender Funktionalität schafft die Möglichkeit, um über das Netzwerk auf Ressourcen des Computers (wie z. B. Dateien und Drucker) zugreifen zu können. Hinzu kommt, dass eine Sicherheitslücke in einem Netzwerkdienst die Basis dafür liefern kann, um über die normalen Zugriffsfunktionen hinaus Aktionen auf dem Computer auszuführen.\n\nAls \"Personal Firewall\" oder \"Desktop-Firewall\" wird eine lokal auf dem Computer installierte Firewall-Software bezeichnet. Zu ihrer Aufgabe gehört es, bösartige und ungewollte Zugriffe von außen auf Netzwerkdienste des Computers zu unterbinden. Abhängig vom Produkt kann sie zudem versuchen, Anwendungen davon abzuhalten, ohne das Einverständnis des Anwenders mit der Außenwelt zu kommunizieren.\n\nWürmer, die einen Sicherheitsfehler in einem Netzwerkdienst ausnutzen, um sich zu verbreiten, können den Computer nur dann infizieren, wenn der entsprechende Netzwerkdienst für den Wurm erreichbar ist. Hier kann eine Personal Firewall den Fernzugriff auf den Netzwerkdienst einschränken und somit eine Infektion erschweren oder sogar verhindern.\n\nBenötigt wird eine solche Filterung jedoch nur, wenn ein erforderlicher Netzwerkdienst auf dem Computer betrieben wird und der Zugriff darauf auf einige wenige Computer beschränkt werden soll. Manchmal soll auch lediglich das lokale System (localhost, die sogenannte Loopback-Schnittstelle 127.0.0.1) den Dienst nutzen können, ohne dass sich die Software dahingehend konfigurieren lässt. In allen anderen Fällen ist die Deaktivierung der Netzwerkdienste einer Blockade durch eine Personal Firewall vorzuziehen.\n\nDarüber hinaus können die Regeln der Personal Firewall im günstigsten Fall unterbinden, dass ein heimlich reaktivierter oder installierter Dienst ungehindert vom Netzwerk aus ansprechbar ist, falls trotz aller Vorsicht eine Schadsoftware beispielsweise per E-Mail-Anhang auf dem System aktiviert wird. Ein solcher Erfolg der Firewall-Software ist allerdings stark von dem Geschick der jeweiligen Schadsoftware abhängig (in Fachartikeln aus Microsofts \"TechNet Magazine\" und der c’t wird davor gewarnt, dass die Personal Firewall unerwünschte Netzwerkzugriffe nur unterbinden kann, wenn sich die Schadsoftware keine große Mühe gibt, ihre Aktivitäten zu verbergen). Wenn man die (mögliche) Meldung der Firewall-Software nutzt, um reaktivierte Dienste nebst Schadsoftware gleich wieder zu entfernen, kann der Einsatz der Personal Firewall doch lohnend gewesen sein.\n\nPersonal Firewalls oder andere Programme zur Netzwerküberwachung bieten keinen Schutz vor der Installation einer Schadsoftware, die darauf basiert, dass der Anwender eine belastete Datei öffnet. Sie können unter Umständen aber auf unautorisierte Netzwerkkommunikation und dadurch auf den Wurm aufmerksam machen. Einige Personal-Firewall-Produkte bieten als zusätzliche Maßnahme auch eine Überwachung der Autostarteinträge des Systems an, was dem Anwender unter Umständen einen Hinweis auf eine Installation des Wurms liefert, wenngleich auch die Firewall-Software von zahlreichen Schadprogrammen deaktiviert und überlistet werden kann.\n\nEs gibt Situationen, die zum Absturz oder sogar zur dauerhaften Deaktivierung der Firewall-Software führen können, wodurch ein uneingeschränkter Zugriff auf die zuvor gefilterten Netzwerkdienste möglich wird, ohne dass der Anwender dies bemerkt.\n\nEs ist zudem ein Problem des Konzepts, dass sich die Firewall-Software zwischen die normale Netzwerkimplementierung des Betriebssystems und die Außenwelt stellt, wodurch zwar nicht mehr die ursprüngliche Netzwerkimplementierung, dafür aber die wesentlich komplexere Firewall-Software direkt angreifbar wird. Die Erfahrung zeigt, dass eine Software desto mehr Fehler und Angriffspunkte enthält, je komplexer sie ist. Da ihre Komponenten (zumindest teilweise) mit erweiterten Rechten laufen und in der Regel sogar Kernelkomponenten installiert werden, wirken sich Programmier- und Designfehler hier besonders verheerend auf die Leistung, Sicherheit und Stabilität des Systems aus. Auf diese Weise können Angriffs- und Spionagemöglichkeiten geschaffen werden, die es ohne die installierte Firewall-Software nicht gibt. So können Personal Firewalls selbst Sicherheitslücken enthalten, die einem Wurm erst Ansätze für einen Fernzugriff bieten.\n\nWährend eine externe Firewall lediglich eine Auswirkung auf den Netzwerk-Datendurchsatz bei der Kommunikation mit dem externen Netz (Internet) hat, beeinflusst eine Personal Firewall die gesamte Netzwerkperformance negativ und verlangsamt zudem die allgemeine Arbeitsgeschwindigkeit des PCs, auf dem sie installiert wurde.\n\nDie Deaktivierung aller nicht benötigten Netzwerkdienste bietet den besten Schutz gegen ungewollte Fernzugriffe.\n\nUm einen Zugriff auf verbleibende Netzwerkdienste aus dem Internet heraus zu verhindern, sollten sie nicht an den Netzwerkadapter gebunden sein, der an dem Internet angeschlossen ist. Diese Aufgabe ist für einen Laien nicht ganz trivial, weshalb sich der Einsatz eines vermittelnden Gerätes, wie beispielsweise eines DSL-Routers, anbietet. Dieses Gerät sorgt automatisch dafür, dass kein Netzwerkdienst aus dem internen (privaten) Netz direkt aus dem Internet heraus zugreifbar ist.\n\nStatt des eigenen Computers wird in diesem Fall also der DSL-Router an das Internet angeschlossen, wobei die eigenen PCs wiederum mit diesem Gerät vernetzt werden. Das Gerät bildet die einzige Schnittstelle zwischen dem externen Netz (Internet) und dem eigenen (privaten) internen Netz. Die privaten PCs übermitteln ihre Anfragen an das Internet nun an den DSL-Router, welcher stellvertretend für die PCs auf das Internet zugreift. Das Zielsystem sieht daher als Absender nur den DSL-Router, der wiederum die Antwortpakete des Zielsystems an den entsprechenden PC im internen Netz weiterleitet.\n\nMögliche Angriffe aus dem Internet sind nun an den dafür prädestinierten DSL-Router gerichtet und treffen nicht direkt den internen PC. Jemand aus dem Internet, der auf der Netzwerkadresse des DSL-Routers nach einem Netzwerkdienst (wie z. B. die Datei- und Druckerfreigabe) sucht, wird nicht fündig, da der Dienst auf dem PC und nicht auf dem DSL-Router läuft. Auf diesem Level ist der DSL-Router also nicht angreifbar, und die Netzwerkdienste der internen PCs sind aus dem Internet heraus nicht erreichbar.\n\nAuch eine Schadsoftware, die womöglich auf dem PC heimlich einen Netzwerkdienst installiert, kann an diesem Zustand nichts ändern. Der Netzwerkdienst ist nur aus dem privaten Netz heraus ansprechbar, nicht jedoch aus dem Internet heraus (die Schadsoftware kann schließlich keinen Dienst auf dem DSL-Router installieren, sondern nur auf dem PC).\n\nAllerdings hat dieser Mechanismus auch seine Grenzen: Damit ein DSL-Router ohne permanenten manuellen Konfigurationsaufwand funktioniert, muss er in der Lage sein, dynamische Regeln zu erstellen. Diese Regeln erlauben automatisch alle Kommunikationsverbindungen, die von dem internen Netz (also von den privaten PCs) angefordert wurden. Wenn also die Schadsoftware lediglich einen Netzwerkdienst installiert, der auf eine externe Verbindung wartet, so funktioniert der Schutzmechanismus recht gut. Baut sie jedoch selbst eine Verbindung zum Internet auf, so wird der DSL-Router die Verbindung zulassen, da sie vom internen Netz heraus angefordert wurde. Ein solch konfiguriertes Gerät kann also lediglich externe Verbindungsanfragen effektiv unterbinden. Hier bietet eine Personal Firewall mitunter mehr Möglichkeiten, ist dafür aber auch leichter zu umgehen und beinhaltet die oben genannten Risiken. Eine Personal Firewall ist also kein ebenbürtiger Ersatz für solche Geräte, sie kann aber unter bestimmten Bedingungen als eine entsprechende Ergänzung dienen.\n\nAuch für Betriebssysteme, die über keine eigene Rechteverwaltung verfügen, gibt es die Möglichkeit, den Systemzugriff einer Anwendung über eine \"Sandbox\" einzuschränken. Ein Programm, das aus dieser Sandbox heraus gestartet wird, kann dann zum Beispiel nicht mehr in wichtige Systemverzeichnisse hineinschreiben, zumindest solange es dem Programm nicht gelingt, aus der Sandbox auszubrechen.\n\nBetriebssysteme wie Mac OS, Linux, Windows (ab NT, XP – jedoch nicht die \"Home\"-Version – und Nachfolgende) bieten von Haus aus eine Umgebung, die eine Zugriffsberechtigung auf sensible Bereiche abhängig von der Benutzerkennung und den dazugehörenden Gruppen verwaltet. Arbeitet also ein Benutzer unter einer Kennung, die nicht über die Zugriffsberechtigung verfügt, Änderungen in wichtigen Systembereichen vorzunehmen, dann hat dies eine ähnliche Auswirkung wie bei der Verwendung einer Sandbox: Eine Schadsoftware, die beispielsweise über einen E-Mail-Anhang geöffnet wird, ist dann in seiner Aktionsfreiheit eingeschränkt, was eine Verbreitung eines Wurms verhindern kann.\n\nArbeiten Benutzer jedoch mit Administratorrechten, setzen sie damit viele Sicherheitsschranken des Betriebssystems außer Kraft. Ein versehentlich oder automatisch gestartetes Wurmprogramm (das Gleiche gilt für Viren) kann sich ungehindert die Kontrolle über viele Systemfunktionen aneignen. Sinnvoller ist der Gebrauch von zwei unterschiedlich konfigurierten Benutzerkonten, eines für die routinemäßige Arbeit mit stark eingeschränkten Benutzerrechten (insbesondere mit eingeschränkten Rechten zur Softwareinstallation), das andere Konto mit Administratorrechten allein für Installations- und Konfigurationsarbeiten.\n\nFür alle Betriebssysteme gilt, dass das Arbeiten mit eingeschränkten Benutzerrechten die Verbreitung von Computerwürmern zwar einschränken, jedoch nicht in jedem Fall verhindern kann. Grund dafür ist, dass jeder Benutzer zum Beispiel in der Lage sein soll, E-Mails zu verschicken, und eine Schadsoftware unter der Kennung des Benutzers dieselben Rechte besitzt und dies daher auch tun kann.\n\nFrühe Betriebssysteme konnten auch von einer schreibgeschützten Diskette gestartet werden, dagegen mussten nachfolgende Versionen bald auf ein beschreibbares Medium, die Festplatte, installiert werden. Unter anderen war Windows 95 eines dieser Systeme, da es nach dem Start des Betriebssystems permanent versuchte, in eine Registry hineinzuschreiben, was bei einem schreibgeschützten Medium nicht möglich wäre.\n\nDennoch gab es auch für solche Systeme Konzepte, um Veränderungen am Systemlaufwerk zu unterbinden. Das geht jedoch nur über einen Umweg. Der Umweg sah vor, dass das Computersystem von einem schreibgeschützten Medium, wie einem CD-ROM-Laufwerk, bootet. Die Software auf der CD-ROM legt nun eine RAM-Disk an, kopiert sämtliche für den Betrieb notwendigen Dateien dort hinein und startet das Betriebssystem von dort. Die Ramdisk existiert lediglich im Arbeitsspeicher, verhält sich aber wie ein normales Laufwerk. Die Anwendungen können dort hineinschreiben. Auch einer Schadsoftware ist es möglich, sich dort zu installieren. Wird der Computer allerdings neu gestartet, so verschwindet diese Ramdisk und mit ihr sämtliche zwischenzeitlich vorgenommene Anpassungen. Die neue Ramdisk erhält wieder alle ursprünglichen Dateien und Einstellungen von der CD-ROM. Das System wird so bei jedem Start des Computers automatisch auf den vorherigen Stand zurückgesetzt. Einer Schadsoftware, wie beispielsweise einem Wurm, fehlt die Möglichkeit, sich in dieses System dauerhaft einzubetten.\n\nSogenannte „Live-Systeme“, die sich von einem schreibgeschützten Medium booten lassen, funktionieren ähnlich dem zuvor beschriebenen Konzept auch für zahlreiche andere Betriebssysteme.\n\nMögliche Dateien des Benutzers müssen naturgemäß auf einem anderen Laufwerk abgelegt werden als auf dem Systemlaufwerk, damit sie nicht ebenfalls zurückgesetzt werden. Schreibt sich eine Schadsoftware auch in diese Dateien (beispielsweise als Makrocode in Office-Dokumente), so wird das System zwar bei jedem Neustart zurückgesetzt, infiziert sich jedoch jedes Mal neu, sobald der Benutzer eine belastete Datei öffnet.\n\nWeiterhin hat dieses Konzept den Nebeneffekt, dass man für jede noch so kleine Anpassung am System das Bootmedium neu erstellen muss. Dagegen bieten Virtuelle Betriebsumgebungen ebenfalls Möglichkeiten an, das (virtualisierte) Betriebssystem bei jedem Neustart zurückzusetzen, können darüber hinaus aber veranlasst werden, bestimmte Anpassungen des Systems gezielt zu übernehmen. Ebenso gibt es beispielsweise für Windows XP alternative Konzepte jenseits des Live-Systems, um das Betriebssystem bei jedem Neustart auf einen definierten Stand zurückzusetzen. Mithilfe eines EWF-Filtertreibers ist hier eine Anpassung der Betriebssystemumgebung möglich. Stellt man beispielsweise während der Arbeit am PC fest, dass eine Software-Aktualisierung verfügbar ist, startet man das System neu und macht damit alle bis dahin unkontrollierten Anpassungen am System rückgängig. Nach dem Neustart deaktiviert man über ein Menü den Schreibschutz, installiert die Aktualisierungen, startet das System abermals neu, gibt dem System ein paar Minuten Zeit, um den Vorgang abzuschließen, und schaltet dann den Schreibschutz wieder ein. Danach ist der PC wieder für die normale Arbeit bereit. Sämtliche Änderungen an diesem System werden somit kontrolliert vorgenommen.\n\nDie Sicherheitsforscher Susan Young und Dave Aitel stellten 2005 mit Nematoden eine weitere Methode vor um Würmer zu bekämpfen. Ein Nematode verwendet dieselben Sicherheitslücken wie der zu bekämpfende Wurm, um auf die infizierten Systeme zu gelangen. Danach wird der Wurm deaktiviert oder gelöscht.\n\nDer Name leitet sich davon ab, dass Nematoden Schnecken und andere Schädlinge bekämpfen können.\n\nIm Jahre 2016 wurde ein Nematode zur Bekämpfung des Botnetzes Mirai vorgeschlagen, welcher einen großen Teil der Internetinfrastruktur lahmgelegt hat. Der Einsatz von Nematoden stellt rechtlich in vielen Ländern wie den USA, dem Vereinigten Königreich und Deutschland ein Eindringen in fremde Computersysteme dar und ist gesetzlich verboten.\n\nAnwendungen sind anfälliger für Fehler, je komplexer sie sind. Bei komplexen Programmen geht man sogar davon aus, dass sie Fehler enthalten. Bestimmte Fehler lassen sich dazu benutzen, über die normale Funktion der Anwendung hinaus beliebige Befehle in Form von fremdem Programmcode zur Ausführung zu bringen. Beispielsweise könnten geschickt aufgebaute Daten einer .mp3-Datei plötzlich einen fehlerhaften MP3-Player dazu veranlassen, Dinge zu tun, die er normalerweise nicht tun würde. Das kann auch Wurm- oder Viren-Code, das Löschen wichtiger Daten oder andere Schadfunktionen beinhalten. Der fremde Code kann jedoch nur gestartet werden, wenn die belastete Datei tatsächlich mit dem Programm geöffnet wird, für das die Datei bestimmt ist. Bei einem anderen MP3-Player bliebe diese „Erweiterung“ der .mp3-Datei also wirkungslos (\"siehe auch „Nicht ausführbare Dateitypen, die über einen Exploit doch ausführbar werden“\").\n\nViele Würmer nutzen Sicherheitslücken veralteter Softwareversionen bestimmter Programme aus, um sich zu verbreiten. Für einen wirkungsvollen Schutz gegen solche Sicherheitslücken wird dem Benutzer viel Aufmerksamkeit abverlangt: Die Software des eigenen Systems, angefangen vom Betriebssystem bis hin zum E-Mail-Programm, sollte auf dem aktuellen Stand gehalten werden. Außerdem gilt es sich zu informieren, ob die verwendete Konfiguration der Anwendungen und des Betriebssystems sicherheitskritisch ist und wie man diese Lücken schließen kann. Windows beispielsweise startet schon beim Systemstart in der Standardeinstellung eine Vielzahl von im Einzelfall zumeist unnötigen Netzwerkdiensten. Mehrere Würmer nutzten bereits Sicherheitslücken in diesen Diensten aus. Werden unnötige Netzwerkdienste deaktiviert, so fallen diese Infektionswege weg (\"siehe auch „Alternative Lösungen, um einen Fernzugriff des Wurms auf Netzwerkdienste zu unterbinden“\").\n\nBei Softwareprodukten ist eine freie Einsicht in deren Quellcode ein Aspekt der Computersicherheit. Dabei gilt es unter anderem die Gefahr zu minimieren, dass ein Produkt Funktionalitäten enthalten kann, von denen der Anwender nichts wissen soll. So gibt es beispielsweise einige Closed-Source-Produkte aus dem Bereich der Personal Firewalls, die selbst heimlich Daten zum Hersteller schicken, also genau das tun, was einige Anwender mit dem Produkt eigentlich zu verhindern suchen.\n\nQuelloffene Software lässt sich von der Öffentlichkeit dahingehend überprüfen und darüber hinaus mit rechtlich unbedenklichen Mitteln auf Schwachstellen untersuchen, die auf diese Weise schneller geschlossen werden können. \n\nQuelloffene Software kann zwar durch jeden mit entsprechender Sachkunde selbst auf heimliche Funktionalitäten und Schwachstellen hin untersucht werden, das bedeutet jedoch nicht, dass die bloße Verfügbarkeit des Quelltextes eine Garantie dafür ist, dass dieser von den Computernutzern hinreichend überprüft wurde. Über einen langen Zeitraum bestehende Sicherheitslücken in quelloffener Software weisen auf diesen Umstand hin. Zudem ist selbst eine geschickt verbaute Hintertür auch mit fundierten Fachkenntnissen mitunter schwer zu erkennen. Der Zeitaufwand für eine Analyse ist bei komplexen Programmen oft beträchtlich. Demgegenüber ist hier aber wenigstens eine Überprüfung des Quelltextes möglich.\n\nOb das von einer externen Quelle bezogene ausführbare Programm tatsächlich mit dem veröffentlichten Quellcode erstellt wurde, ist für den Anwender oft schwer zu erkennen. Auch hierfür gilt, dass mit entsprechender Sachkunde hier wenigstens eine Überprüfung möglich ist.\n\n1975 wird das Konzept eines Computerwurms oder Netzwerkwurms im Science-Fiction-Buch \"The Shockwave Rider\" (dt. \"Der Schockwellenreiter\") von John Brunner erwähnt.\n\n1987 wird das VNET vom XMAS EXEC kurzfristig völlig lahmgelegt.\n\n1988, genauer am 2. November, wird von Robert Morris der erste Computerwurm für das Internet programmiert und freigesetzt. Der sogenannte \"Morris-Wurm\" verbreitet sich unter Ausnutzung von einigen Unix-Diensten, wie z. B. sendmail, finger oder rexec sowie der r-Protokolle. Zwar hat der Wurm keine direkte Schadensroutine, trotzdem legt er wegen seiner aggressiven Weiterverbreitung ca. 6000 Rechner lahm – das entspricht zu dieser Zeit ungefähr 10 % des weltweiten Netzes.\n\nDie Entwicklung von Computerwürmern bleibt bis Mitte der 1990er Jahre beinahe stehen. Grund dafür ist, dass das Internet noch nicht die Ausdehnung besitzt, die es heute hat. Bis dahin können sich Computerviren schneller verbreiten.\n\nIn diesem Zeitraum nehmen Computerwürmer in ihrer Bedeutung unter der Schadsoftware zu.\n\n1997 verbreitet sich der erste E-Mail-Wurm, bekannt unter dem Namen \"ShareFun\". Er wurde in der Makrosprache WordBasic für Microsoft Word 6/7 geschrieben. Im selben Jahr wird der erste Wurm entdeckt, der sich über IRC verbreiten kann. Er benutzt dafür die codice_20-Datei des Programms mIRC. \"Homer\", ein Wurm, der als Erster für seine Verbreitung das Transferprotokoll FTP benutzt, tritt in Erscheinung. Ab diesem Zeitpunkt wurde klar, dass auch Netzwerkprotokolle von Würmern ausgenutzt werden können.\n\n1999 verbreitet sich über Outlook der E-Mail-Wurm \"Melissa\" weltweit und sorgt für große Aufmerksamkeit der Medien. Komplexe Würmer treten in Erscheinung, wie \"Toadie\" (der sowohl DOS- als auch Windows-Dateien infiziert und sich über IRC und E-Mail verbreitet) und \"W32.Babylonia\" (der sich als erste Malware selbst aktualisieren kann).\n\n2000 geriet ein Wurm besonders ins öffentliche Bewusstsein: Mit seinem massiven Auftreten inspiriert der \"I-love-you\"-E-Mail-Wurm viele Nachahmer.\n\n2001 erscheinen erste Würmer mit einer eigenen SMTP-Engine. Ab diesem Zeitpunkt sind Würmer nicht mehr auf Microsoft Outlook (Express) angewiesen. Zudem werden die ersten Würmer entdeckt, die sich via ICQ oder Peer-to-Peer-Netzwerken verbreiten können. Der Wurm \"Code Red\" erreicht eine große Verbreitung, indem er ein Sicherheitsloch in Microsofts Internet Information Services ausnutzt. Durch das Ausnutzen von Schwachstellen in Netzwerkdiensten können nun auch die ersten dateilosen Würmer in Erscheinung treten. Sie verbreiten sich durch Sicherheitslücken und bleiben nur im RAM, nisten sich also nicht auf die Festplatte ein.\n\n2002 wird mit dem Wurm \"Slapper\" die bis zurzeit am weitesten verbreitete Malware für das Betriebssystem Linux geschrieben.\n\n2003 verbreitet sich der Wurm \"SQL Slammer\" zügig durch das Ausnutzen einer Sicherheitslücke im Microsoft SQL Server. Bis dahin wurden Privat-Anwender von dieser Art von Würmern verschont. Das ändert sich im August 2003, als der Wurm \"W32.Blaster\" eine Sicherheitslücke im Microsoft-Windows-Betriebssystem ausnutzt.\n\n2004 nutzt der Wurm \"Sasser\" ebenfalls eine Sicherheitslücke im Windows-Betriebssystem und greift damit die Computer von Privatanwendern an. Der Wurm Mydoom wird das erste Mal gesichtet. Die schnelle Verbreitung des Wurms führt für ein paar Stunden zu einer durchschnittlich 10-prozentigen Verlangsamung des Internetverkehrs und einer durchschnittlich erhöhten Ladezeit der Webseiten von 50 Prozent. \"SymbOS.Caribe\" ist der erste Handywurm, der sich mit der Bluetooth-Netzwerktechnik auf Smartphones mit dem Betriebssystem Symbian OS weiterverbreitet. Er wurde von einem Mitglied der Virenschreibergruppe 29A entwickelt, und sein Quellcode wird veröffentlicht. Daher werden in den darauf folgenden Monaten mehrere Varianten des Wurms entdeckt. Vor allem bei großen Veranstaltungen gibt es immer wieder Masseninfektionen durch Bluetooth-Würmer.\n\n2005 erscheint mit \"SymbOS.Commwarrior\" der erste Wurm, der sich selbst als MMS verschicken kann. Die Verbreitung von Handywürmern wird mittlerweile von mehreren Antivirenprogramm-Herstellern gemeldet.\n\n2006, genauer am 13. Februar, wird der erste Wurm für Apples Mac-OS-X-Betriebssystem über ein Forum einer US-amerikanischen Gerüchteseite veröffentlicht. Bisher ist sich die Applegemeinde noch nicht sicher, ob es sich bei diesem Wurm tatsächlich um einen Wurm (Art der Verbreitung) oder einen Virus (Infizierung von ausführbarem Programmcode und verstecken darin) handelt. Auch die Benennung des Wurmes ist nicht eindeutig. Das Unternehmen Sophos nennt ihn OSX/Leap-A, Andrew Welch (verfasste die erste technische Beschreibung der „Schadensroutinen“) nennt ihn OSX/Oomp-A (nach der Überprüfungsroutine, die den Wurm vor der Reinfektion schützen soll). Im März wird von einer niederländischen Forschergruppe rund um den Universitätsprofessor Andrew Tanenbaum der erste Computerwurm für RFID-Funkchips veröffentlicht. Durch eine SQL-Injection im Datenbankprogramm Oracle kann sich das 127 Byte große Programm selbständig verbreiten.\n\n2008 hat das United States Strategic Command in einer Direktive den Einsatz von persönlichen USB-Sticks und weiterer tragbarer Speichermedien im eigenen Computernetzwerk verboten, um es vor Computerwurm-Angriffen zu schützen. Grund hierfür ist die Verbreitung des Wurms \"Agent.btz\".\n\n2010 wurde der \"Stuxnet\" (auch LNK-) Wurm entdeckt, der gleich vier Zero-Day-Exploits für Windows ausnutzt, um Kontrolle über WinCC, eine SCADA-Software von Siemens, zu übernehmen. Zudem sticht dieser Wurm durch eine ungewohnt hohe Komplexität heraus, die sich auch in der Dateigröße niederschlägt und einen staatlichen Ursprung wahrscheinlich macht.\n\n\n\n"}
{"id": "1946174", "url": "https://de.wikipedia.org/wiki?curid=1946174", "title": "Schneider Euro PC", "text": "Schneider Euro PC\n\nDer Schneider Euro PC war ein MS-DOS-basierter Heimcomputer der Schneider Computer Division und wurde ab 1988 vermarktet. Der Markenname war eingetragen auf die Schneider Rundfunkwerke Türkheim AG.\n\nEr wurde nach den Erfolgen der Schneider-CPC-Serie herausgegeben, um auch im aufkommenden Markt für Heim-PCs ein preiswertes Komplettsystem anzubieten. Wurde die CPC-Serie in Lizenz des englischen Herstellers Amstrad verkauft, war der Schneider Euro PC eine Eigenproduktion. Der Euro PC verwendete einen Siemens-8088-Prozessor (dessen Takt im BIOS oder im Betrieb per Tastenkombination auf 4,77, 7,15 oder 9,54 MHz eingestellt werden konnte), verfügte über 512 KB RAM (erweiterbar durch eine Steckkarte auf 640 KB) und wurde mit MS-DOS 3.3 und Microsoft Works 1.0 ausgeliefert. \n\nWie schon beim CPC und vielen anderen Heimcomputern seiner Zeit war beim Euro PC die Rechnerplatine ins Tastaturgehäuse eingebaut. Für das System waren ein Bernstein-Monochrom-Monitor mit 12 Zoll Bildschirmdiagonale (MM12) und ein Farbmonitor mit 14 Zoll Bildschirmdiagonale (CM14) erhältlich. Der Euro PC besaß einen Grafikchip, der – passend zum gewählten Monitor – zwischen Hercules monochrom mit einer relativ hohen Auflösung von 720 × 348 Bildpunkten und CGA umschaltbar war. Mit damals üblichen CGA-Emulatoren konnten häufig Spiele, die für CGA-Adapter ausgelegt waren, dennoch im Hercules-Modus betrieben werden.\n\nFür einen PC ungewöhnlich war das externe Netzteil. Als Massenspeicher war ein 3½-Zoll-Diskettenlaufwerk (720 KB) eingebaut. Als Zubehör gab es ein externes 3½-Zoll-Diskettenlaufwerk mit ebenfalls 720 KB (FD720), ein 5¼-Zoll-Diskettenlaufwerk mit 360 KB (FD360) Kapazität sowie eine 20-MB-Festplatte (XT Attachment, ähnlich IDE/ATA). Diese konnte durch kein anderes Modell ersetzt werden, da die Laufwerkgeometrie im BIOS fest einprogrammiert war. Allerdings war es möglich, mit einem entsprechenden Controller im Erweiterungssteckplatz auch andere Festplatten zu betreiben.\n\nDas Gerät wurde ab 1988 u. a. über große Versandhäuser zu einem Preis von 1.800 DM (nach anderen Quellen 1.600 DM) vertrieben. \n\nDer breite und hart umkämpfte PC-Markt ließ eigentlich wenig Raum für weitere Geräte in diesem Sektor, aber das Modell verkaufte sich durch seinen sehr günstigen Preis und das schlanke, heimcomputerartige Erscheinungsbild dennoch in beachtlichen Stückzahlen.\n\nNeben dem Euro PC gab es auch noch den \"Euro PC II\", der auf 768 KB RAM und um einen mathematischen 8087-Koprozessor erweitert werden konnte, den \"Euro XT\", den \"Euro AT\", der einen Intel-80286-Prozessor (hergestellt von Siemens), 1 MB RAM und eine EGA-Grafik mit 640 × 480 Pixeln Auflösung besaß, und den \"Euro SX\".\n\nSchneider Euro PC und Euro PC II können durch eine 8-Bit-ISA-Karte halber Baulänge erweitert werden. Auf diese Weise kann z. B. eine VGA-Karte nachgerüstet werden. Hierfür sind auch verschiedene 16-Bit-ISA-Karten geeignet, die sich je nach Typ auch in 8-Bit-Slots betreiben lassen (z. B. VGA-Karte Trident TVGA9000i). \n"}
{"id": "1947429", "url": "https://de.wikipedia.org/wiki?curid=1947429", "title": "Supplikant (Computer)", "text": "Supplikant (Computer)\n\nDer WPA-Supplicant (: Bittsteller) [Unix-Bezeichnung: wpa_supplicant] ist eine Software für Linux, BSD, AROS und Windows, welche die im WPA-Standard definierte Rolle des Supplicanten wahrnimmt.\n\nBei WPA werden die zur Verschlüsselung verwendeten Schlüssel regelmäßig automatisch ausgetauscht. WPA verwendet Schlüssel im alten WEP-Format, die durch das regelmäßige automatische Austauschen sicher gemacht werden. WEP-Schlüssel sind knackbar, sobald eine Mindestmenge darüber ausgetauschter Daten mitgehört wurde, der regelmäßige Schlüsseltausch sorgt dafür, dass die Schlüssel vor dem Erreichen dieser Datenmenge durch neue ersetzt werden.\n\nDer Supplicant ist für den Client-Teil des Schlüsselaustausches zuständig. Der Wireless Access Point verlangt in regelmäßigen Abständen vom Supplicanten, dass dieser sich authentisiert. Gelingt dies dem Supplicanten, so erhält er vom Access Point einen neuen Schlüssel, der von nun an für die Datenübertragung mit dem Access-Point zu verwenden ist – bis der Access Point den Schlüssel mit Hilfe des Supplicanten erneut austauscht. Der Supplicant rekonfiguriert also regelmäßig den Schlüssel einer WLAN-Karte über deren Gerätetreiber.\n\nZur Authentifizierung existieren eine ganze Reihe von Protokollen, die der WPA-Supplicant auch beherrscht, wenn sie von der Hardware sowohl auf der Client-Seite als auch auf dem Access-Point unterstützt werden. Der wpa_supplicant unterstützt WEP-, WPA-, WPA2-verschlüsselte und unverschlüsselte WLANs.\n\n"}
{"id": "1949472", "url": "https://de.wikipedia.org/wiki?curid=1949472", "title": "SpywareBlaster", "text": "SpywareBlaster\n\nSpywareBlaster ist ein Anti-Spyware-Programm zum Blockieren von böswilligen ActiveX-Objekten, verfolgenden Cookies und schlechten Seiten im Internet.\n\nDie Software funktioniert, im Gegensatz zu anderen Anti-Spyware-Programmen, ohne im Hintergrund zu laufen oder den Computer zu scannen. Die schadhaften Websites, Cookies und ActiveX-Objekte trägt das Programm in die schwarze Liste des Internet Explorers ein. Das Programm unterstützt auch Mozilla Firefox, hier werden aber nur Cookies blockiert, wobei das Programm in der aktuellen Version über 8000 Einträge enthält, die ansonsten händisch eingetragen werden müssten. Die Definitionsdatei wird in regelmäßigen Abständen aktualisiert und kann mit einem manuellen Update in die Datenbank integriert werden.\n\n\n"}
{"id": "1959678", "url": "https://de.wikipedia.org/wiki?curid=1959678", "title": "Hochdurchsatz-Screening", "text": "Hochdurchsatz-Screening\n\nHigh-Throughput-Screening (HTS), auch Hochdurchsatz-Screening genannt, ist eine vor allem in der Pharmaforschung angewendete, automatisierte Methode, bei der im Hochdurchsatz an Zehntausenden bis Millionen von Substanzen biochemische, genetische oder pharmakologische Tests durchgeführt werden. Werden mehr als 100.000 Stoffe pro Tag untersucht, spricht man auch vom \"Ultra\"-High-Throughput-Screening (uHTS). Mittels des High-Throughput-Screening wird insbesondere nach neuen, biologisch aktiven Substanzen gesucht, aus denen Leitstrukturen abgeleitet werden, um neue Arzneistoffe zu entwickeln.\n\nBeim High-Throughput-Screening werden umfangreiche Molekülbibliotheken durchsucht, wobei die Suche hohe Anforderungen an die Automatisierung, die Testverfahren und die Auswertung stellt.\n\nBeim High-Throughput-Screening zur Entdeckung neuer pharmakologisch aktiver Substanzen finden Target-basierte oder Phänotyp-basierte Testverfahren (Assays) Anwendung. \n\nBei Target-basierten Screenings wird die Interaktion der Testsubstanzen mit bestimmten definierten Zielstrukturen (Targets) untersucht. Targets können zum Beispiel Proteine sein, die mit einer Krankheit oder einem physiologischen Prozess in Verbindung stehen. Target-basierte Screenings repräsentieren in der pharmazeutischen Industrie die häufigste Form des Screenings von niedermolekularen Substanzen, um deren biologische Aktivität zu bestimmen. Sie werden in der Regel in Mikrotiterplatten mit gereinigten oder ungereinigten Proteinen oder indirekt mit Zellen, die das Target-Protein bilden, durchgeführt. Die Interaktion einer Testsubstanz mit dem Target kann direkt in Bindungsassays (in der Regel über die Verdrängung eines markierten Referenzliganden vom Target) oder indirekt über die Beeinflussung der vom Targetprotein aktivierten Signalwege (z. B. Aktivierung von Second Messengern, Protein-Protein-Interaktionen, Protein-Phosphorylierungen und Genaktivierungen) und enzymatischen Reaktionen bestimmt werden. Dazu werden insbesondere biochemische Methoden eingesetzt, bei denen ein Signal als eine Änderung der Farbintensität, der Fluoreszenz oder der Lumineszenz gemessen wird. Aus dem Signal-Rausch-Verhältnis folgt: Je stärker die Änderung der im Test ausgewerteten Signalintensität, desto besser geeignet sind die Testverfahren. Auf Lumineszenz basierende Verfahren verursachen eine vielfache Signalveränderung und sind daher oft besser geeignet als fotometrischen und fluorimetrischen Methoden. Eigenfarbe oder Eigenfluoreszenz von Testsubstanzen verschlechtern das Signal-Rausch-Verhältnis der fotometrischen und fluorimetrischen Messung. Auch szintimetrische Testmethoden, wie beispielsweise Radioligand-Bindungsstudien, sind hochsensitiv. Das Anfallen radioaktiver Abfälle ist jedoch ein zentrales Problem bei der Durchführung von szintimetrischen Testungen. Weitere Eigenschaften der Testsubstanzen, wie beispielsweise Löslichkeit und Stabilität, spielen eine entscheidende Rolle und müssen bei der Versuchsplanung berücksichtigt werden.\n\nBeim Phänotyp-basierten Screening werden die Effekte von Testsubstanzen auf lebende Zellen oder Gewebe untersucht, also die Auswirkungen der Applikation der Testsubstanz auf den Phänotyp der Zelle oder des Gewebes. Der Effekt einer Testsubstanz wird anhand einer phänotypischen Änderung, z. B. der Änderung der Zellform, des Zellwachstums oder der Zellfunktion, beurteilt. Hierbei ist es nicht erforderlich, das molekulare Target im Voraus zu kennen, oft dient das Screeningverfahren aber der Identifikation des molekularen Targets. Um das Ergebnis des Screenings nicht zu verfälschen, müssen meist eine Vielzahl an Parametern kontrolliert werden. Mit Phänotyp-basierten Screenings werden insbesondere Molekülbibliotheken durchgemustert, die höhermolekularen Verbindungen enthalten, wie beispielsweise Proteine, DNA und siRNA. Neben Zellen und Gewebe werden auch ganze Organismen, wie beispielsweise Fischembryonen, als Modellsysteme eingesetzt. Ein Phänotyp-basiertes Screening wird oft mit Hilfe von automatisierter Mikroskopie (High Content Screening) durchgeführt. Oft ist ein High Content Screening gegenüber einem Target-basierten Screening durch den geringeren Durchsatz limitiert.\n\nDa die Durchmusterung einer kompletten Molekülbibliothek in einem High-Throughput-Screening oft mehrere Tage bis Wochen dauert, ist ein gleichbleibend zuverlässiges Arbeiten des Testverfahrens eine kritische Voraussetzung. Insbesondere bei Verwendung von Zellen muss mit einer Veränderung mit zunehmender Kultivierungszeit gerechnet werden.\n\nZur Beurteilung der Robustheit der Daten eines High-Throughput-Screenings werden Kontrollsubstanzen untersucht. Im einfachsten Fall umfassen diese einerseits Vehikel oder eine bekanntermaßen inaktive Substanz (Negativkontrolle) und andererseits eine Substanz, die zu einer maximalen Aktivierung oder Inhibition des Test führt (Positivkontrolle). Mit Hilfe des Z'-Faktors\n\nformula_1,\n\nwobei σ und σ die Standardabweichungen der Positiv- bzw. Negativkontrolle sowie µ und µ die Mittelwerte der Positiv- bzw. Negativkontrolle darstellen, lässt sich das Messfenster des High-Throughput-Screenings beurteilen. Assays mit Z'-Faktoren von mindestens 0,5 gelten als optimal. Auch High-Throughput-Screenings bei einem Z'-Faktor von 0 – 0,5 können noch zur Unterscheidung von aktiven und inaktiven Verbindungen geeignet sein.\n\nHigh-Throughput-Screenings sind aufwändig und werden heute nur noch mit voll- oder zumindest teilautomatisierten Laborautomationssystemen durchgeführt. Es werden Roboter oder Automaten für das Liquid-Handling, die Datenaufnahme (Reader, Kameras) und gegebenenfalls die Zellkultur eingesetzt. Das Testvolumen wird reduziert und es werden Mikrotiterplatten mit 384, 1536 oder 3456 Näpfchen eingesetzt, um noch mehr Proben gleichzeitig zu testen und Kosten und Zeit zu sparen.\n\nDie als Ergebnis des High-Throughput-Screening anfallenden Daten werden statistisch analysiert. Substanzen, die Messwerte jenseits eines bestimmten Schwellenwerts liefern, werden als Treffer („Hits“) eingestuft. Dennoch muss das Auftreten falsch positiver und falsch negativer Ergebnisse berücksichtigt werden. Um die Menge falsch positiver Hits zu reduzieren, wird meist ein zweites, deutlich kleineres Screening durchgeführt, das sich auf die Hits des ersten Screenings beschränkt.\n\nDie aus den Screenings gewonnenen Daten werden auch mit Hilfe von chemoinformatischen Methoden analysiert. Dazu werden die Hits anhand ihrer molekularen Eigenschaften gefiltert. Auf diese Weise können Substanzen, die beispielsweise auf Grund reaktiver Gruppen (z. B. Aldehyde, Michael-Akzeptoren und Nitrogruppen) oder einer Nichterfüllung Lipinskis Rule of Five als ungeeignet für die weitere Entwicklung angesehen werden, von der Kandidatenliste der Leitstrukturen entfernt werden. Schließlich wählt man die vielversprechendsten Hits für die Entwicklung einer Leitstruktur aus.\n\nNur wenige in einem High-Throughput-Screening identifizierte Hits haben die Qualität, als Leitstruktur klassifiziert zu werden. Ein Hit ist somit nicht automatisch eine Leitstruktur und schon gar kein Arzneistoff. Da High-Throughput-Screenings in der Regel bei einer einzigen Testkonzentration mit Hilfe eines einzigen Assays durchgeführt werden, sind quantitative Aussagen über die Wirkstärke (Potenz) und Selektivität der Testsubstanzen nicht möglich. Viele für die Wirksamkeit und therapeutische Sicherheit einer Substanz notwendige pharmakologische Parameter, wie die Zellmembran- und Gewebepermeabilität sowie die Aufnahme, Verteilung, Metabolisierung, Ausscheidung (ADME) und Toxikologie werden in High-Throughput-Assays nicht oder nur unzureichend berücksichtigt. Die Weiterentwicklung von einem Hit bis hin zu einem Arzneistoff und dessen Zulassung dauert in der Regel etwa 10 bis 12 Jahre.\n\n"}
{"id": "1959749", "url": "https://de.wikipedia.org/wiki?curid=1959749", "title": "Image Growing", "text": "Image Growing\n\nImage Growing (englisch „Bildanbau“), gemeinhin auch „Textursynthese nach Efros und Leung“ genannt, ist ein nichtparametrischer Textursynthesealgorithmus. Die Technik wurde 1999 von Alexei A. Efros und Thomas K. Leung vorgestellt.\n\nZiel der nichtparametrischen Textursynthese ist es, aus einem Vorlagebild automatisch neue Bilder zu erzeugen, die der Vorlage zwar möglichst ähnlich sehen, aber nicht identisch mit ihr sind. Image Growing lässt aus einer Rastergrafik Pixel für Pixel ein neues, ähnliches digitales Bild „wachsen“.\n\nEs gibt zwei Varianten dieser Technik, die sich nur unwesentlich unterscheiden. Beim eigentlichen Image Growing ist in einem größtenteils leeren Bild ein kleines Stück der Vorlage als \"Saat\" untergebracht. Anschließend lässt der Algorithmus Pixel für Pixel um die Saat herum die Textur „wachsen“. Sind alle leeren Bildbereiche vollständig gefüllt, so ist die Synthese beendet; die Textur kann „geerntet“ werden. In der Variante \"Hole Filling\" ist die Ausgangssituation gerade andersherum: Ein größtenteils ausgefülltes Bild enthält einige \"Löcher\", leere Stellen, die vom Algorithmus gefüllt werden. Die Funktionsweise ist in beiden Fällen dieselbe.\n\nUm einen Pixel zu setzen sucht Image Growing in der Vorlage nach Pixeln, die eine ähnliche Umgebung aufweisen und fasst diese zu einer \"Kandidatenliste\" zusammen. Der neue Pixel übernimmt den Farbwert eines zufällig aus dieser Kandidatenliste ausgewählten Pixels.\n\nDer Algorithmus erhält in seiner Grundform drei Eingaben:\nformula_1\nGauß-ähnliche 3x3-Umgebung.\nNeben diesen Hauptargumenten benötigt der Algorithmus einen weiteren Parameter, der entweder als Benutzereingabe abgefragt oder fest im Algorithmus vorgegeben werden kann:\n\n\nDie Ausgabe des Algorithmus besteht aus dem synthetisierten Bild, das sich in der veränderten \"vorbereiteten Ausgabe\" befindet.\n\nEine Textur in der Textursynthese ist immer ein \"stationäres\" Bild, d. h. alle Teile des Bildes sehen sich ähnlich; betrachtet man verschiedene Bereiche einer solchen Textur durch ein kleines Sichtfenster, so hat man den Eindruck, immer dasselbe zu sehen. Diese besondere Eigenschaft macht sich die Textursynthese nach Efros und Leung zunutze, indem sie Textur als \"Markow-Netzwerk\" modelliert. Ein Markow-Netzwerk besteht aus miteinander verbundenen Objekten, sogenannten \"Knoten\", die verschiedene Zustände einnehmen können. In einem solchen Markow-Netzwerk gilt die sogenannte \"Markow-Eigenschaft\": Der Zustand jedes Knotens ist von den Zuständen der ihn in einem \"örtlich begrenzten\" Umfeld umgebenden Pixel abhängig.\n\nIn einer Textur stellt jeder Pixel einen Knoten in einem Markow-Netzwerk dar, wobei jeder Pixel mit seinen acht Nachbarpixeln verbunden ist. Das örtlich begrenzte Umfeld ist durch die Umgebungsmaske vorgegeben; diese gibt nicht nur an, wie groß das Umfeld ist, sondern auch, wie ein Pixel durch seine Nachbarn beeinflusst wird. Die Markow-Eigenschaft ist dabei eng mit der Stationärität verwandt; versucht man, ein nichtstationäres Bild in ähnlicher Weise zu modellieren, so stellt man fest, dass der Zustand eines Pixels von allen anderen Pixeln abhängt.\n\nImage Growing erzeugt qualitativ hochwertige Bilder, wenn die Parameter richtig gewählt werden. In der Regel gilt: Je größer die Filtermaske, desto besser die Ergebnisse. Die Größe sollte so gewählt sein, dass die Filtermaske die größte in der Vorlage vorkommende Struktur abdeckt.\n\nA. A. Efros und T. K. Leung bemerkten einen wichtigen Schwachpunkt bereits selbst: Manchmal versteift sich der Algorithmus bei seiner Suche nach Kandidaten auf einen kleinen Teilbereich der Vorlage und produziert ab da unbefriedigende Ergebnisse. Größere Strukturen zerfallen dann nach und nach zu Bildrauschen oder Vorlagenteile werden identisch kopiert.\n\nNach dem klassischen Modell der Registermaschine haben folgende Parameter Einfluss auf die Laufzeit des Algorithmus:\n\nDie Laufzeit wird asymptotisch nach oben abgeschätzt durch O(m·n·b). Dabei wird die wiederholte Suche nach noch leeren Pixeln großzügig vernachlässigt, da sie je nach Verfahren und Fortschritt sehr unterschiedlich ausfallen kann. Da für gewöhnlich m » n und b > 1 gilt, ist diese Laufzeit deutlich schlechter als O(n). Der Algorithmus ist damit selbst auf schnellen Rechnern sehr langsam.\n\nDer Speicherbedarf des Algorithmus ist vergleichsweise gering. Er variiert mit der Zeit mit der Größe der Menge der zu setzenden Pixel und der Größe der Kandidatenliste, für diese lassen sich jedoch die Bildergrößen als obere Schranken einsetzen.\n\nIm Originalansatz wird das Bild bei jedem Durchlauf vollständig durchsucht, um diejenigen leeren Pixel herauszusuchen, die im kommenden Durchlauf gesetzt werden. Diese erschöpfende Suche ist alles andere als optimal und kann beschleunigt werden.\n\nEin einfacher Ansatz ist es, Größe, Form und Positionierung der Saat fest vorzuschreiben. Dadurch ist es möglich, in jedem Schritt die nächsten leeren Pixel vorauszusagen, ohne sie überhaupt betrachten zu müssen. Dieser Ansatz ist insbesondere beim Hole Filling nicht praktikabel, wo Position, Größe und Form der leeren Bereiche nicht vorbestimmt werden können. Auch ist bei der Positionierung der Saat in der Bildmitte ein leichter Qualitätsgewinn zu beobachten.\n\nKompliziertere Ansätze verwenden zusätzliche Datenstrukturen, die im Voraus erzeugt werden, und schnelleres Suchen nach leeren Pixeln ermöglichen. So wäre beispielsweise ein Graph denkbar, in dem jeder Pixel auf diejenigen Pixel verweist, die gesetzt werden können, sobald der Pixel selbst gesetzt wurde.\n\nAuch der Aufbau der Kandidatenliste kann durch Einbeziehung zusätzlicher Suchstrukturen beschleunigt werden. So schlägt beispielsweise die Textursynthese mit Binärbaum-gestützter Vektorquantisierung einen speziellen Binärbaum vor, in dem die Pixel inklusive ihrer Umgebungen geschickt angeordnet werden.\n"}
{"id": "1960040", "url": "https://de.wikipedia.org/wiki?curid=1960040", "title": "Linguatec", "text": "Linguatec\n\nDie Linguatec Sprachtechnologien GmbH ist ein Sprachtechnologieanbieter, der auf die Bereiche Maschinelle Übersetzung, Sprachsynthese und Spracherkennung spezialisiert ist. \nLinguatec wurde 1996 in München gegründet und hat ihren Firmensitz in Pasing.\nBekannt wurden sie vor allem durch ihr kostenloses Online-Angebot, zum Beispiel werden das Wörterbuch LinguaDict oder der Volltextübersetzer PT Online von Linguatec betrieben.\n\n\n\n\n\n\n\n\n"}
{"id": "1960274", "url": "https://de.wikipedia.org/wiki?curid=1960274", "title": "PSPad", "text": "PSPad\n\nPSPad ist ein Text- und Quelltexteditor für Windows. Die Software ist Freeware.\n\nJan Fiala veröffentlichte die Software erstmals 2001 und entwickelt sie ständig weiter.\n\nDie Software lässt sich ohne Installation auf einem Windowssystem verwenden. Das macht den Einsatz auf mobilen Speichermedien als portable Software möglich.\n\nDie wichtigsten Funktionen von PSPad sind:\n\n"}
{"id": "1960782", "url": "https://de.wikipedia.org/wiki?curid=1960782", "title": "Corel Ventura", "text": "Corel Ventura\n\nCorel Ventura ist das älteste DTP-Programm für PCs mit einer bewegten Geschichte.\n1985 gründete John Meyer nach seinem Ausstieg aus Digital Research Inc. die Firma Ventura Software, um ein DTP-Programm unter der grafischen Oberfläche GEM zu entwickeln.\n1986 wurde die Version 1 fertig und wurde von Xerox vertrieben. 1987 überholte \"Ventura Publisher\" den damaligen Marktführer PageMaker und war das meistgenutzte DTP-Programm seinerzeit. Bis 1989 existierten bereits 200.000 Kopien (Anm.: wahrscheinlich in Bezug auf den amerikanischen Markt), als Xerox Ventura Software aufkaufte, um 1990 sowohl eine GEM-, als auch eine Windows- und OS/2-Version zu veröffentlichen.\nDoch die legendäre Geschwindigkeit der GEM-Versionen konnte die Windows-Version nicht leisten. Zudem war sie sehr fehlerhaft und daher kaum ernsthaft benutzbar.\nObwohl die Version 4 darauf deutlich besser war, konnten die verlorenen Marktanteile nie wieder aufgeholt werden.\n\n1993 übernahm Corel das Programm als \"Corel Ventura\" und implementierte für die Version 5 einige Elemente aus seinem Grafik-Programm CorelDraw 5.\n1996 kam Ventura in einer vollkommen neu programmierten Version 7 auf den Markt. Die bis dahin vorherrschende textorientierte Bearbeitung wurde um die objektorientierte Bearbeitung ergänzt. Obwohl diese Version dem damaligen Marktführer QuarkXPress ebenbürtig war, konnten außerhalb des englischsprachigen Raumes keine wesentlichen Marktanteile gewonnen werden, da die Oberfläche nur auf Englisch zu Verfügung stand (Rechtschreibprüfungen und Trennalgorithmen gab es jedoch in vielen Sprachen).\n\nDer Vorsprung von PageMaker und QuarkXPress war 1998 zumindest im deutschsprachigen Raum schon so groß, dass die Version 8, nun auch auf deutsch und mit vielen weiteren Verbesserungen, nicht sehr zur Kenntnis genommen wurde. Daran hat auch die bis heute aktuelle Version 10 (9 wurde übersprungen) nichts ändern können. Diese besitzt eine direkte PDF-Ausgabe, XML-Unterstützung, Datenbankanbindungen und eine enorm flexible Script-Programmierung.\n\nFachleute sind sich einig darüber, dass eklatantes Missmanagement dazu geführt hat, dass aus dem einstigen Marktführer eine Randerscheinung geworden ist. Mittlerweile findet keinerlei Marketing mehr für das Programm statt und die Realisierung einer künftigen Version 11 scheint ausgeschlossen.\n\nDennoch gibt es eine eingeschworene und sehr internationale Fangemeinde um Ventura, die sich aus Verlagen, Grafikern und EDV-Leuten zusammensetzt. Diese Fachleute beurteilen Ventura in vielen Punkten den etablierten DTP-Programmen immer noch als überlegen, obwohl ihm viele der modernen Layouttechniken, wie beispielsweise transparente Objektschatten, fehlen.\n\nSeine legendäre Arbeitsweise liegt in der Geschichte des Venturas begründet. Ventura setzte von Beginn an auf hohe typographische Präzision und effizientes Arbeiten durch Anwendung von leistungsfähigen Formaten (Stilen). Der Text konnte sowohl auf kapitelweise frei definierten Seiten als auch in verketteten und frei verschiebbaren Rahmen platziert werden.\n\nDiese Arbeitsweise erweist sich bei umfangreichen Dokumenten als enorm zeitsparend, da ein Absatz mit nur einem Klick zu einer Kapiteleingangsseite werden kann. Auch nachträgliche Änderungen müssen nur einmalig im Stil vorgenommen werden und wirken sich dann umgehend auf das gesamte Dokument aus.\n\nSchrittweise wurden weitere Layoutfunktionen, wie Seiten- und Tabellenstile usw., eingeführt. Somit ist es mit Ventura möglich, komplexe Layouts mit gedrehten und verketteten Rahmen zu erstellen und gleichzeitig die enormen Möglichkeiten der Ventura-Stile zu nutzen.\n\nNeben den normalen Layoutarbeiten ermöglichen diese Stile auch äußerst vielseitige Gestaltungsmöglichkeiten von datenbankbasierenden Dokumenten, das sogenannte Database Publishing. In Kombination mit verankerten Bildrahmen, stilbasierenden Spaltenwechseln, Tabellen, automatischen Nummerierungen, Indexen und Verzeichnissen können Telefonbücher, Jahresberichte, Kataloge in kürzester Zeit halb- oder vollautomatisch erstellt werden, während bei anderen DTP-Programmen deutlich mehr Handarbeit notwendig ist.\n\n"}
{"id": "1962180", "url": "https://de.wikipedia.org/wiki?curid=1962180", "title": "Recognizer", "text": "Recognizer\n\nEin Recognizer (engl. \"to recognize\": „erkennen“), auch Erkenner, ist in der Informatik ein bestimmtes abstraktes Maschinenmodell, ein sogenannter Automat. Dieser Automat stellt auf Grundlage einer formalen Grammatik fest, ob ein konkretes Wort Element einer formalen Sprache ist oder nicht. Die Sprache wird dabei durch die zugrundegelegte formale Grammatik definiert bzw. erzeugt. Der \"Recognizer\" entscheidet nur, ob ein Eingabetext hinsichtlich der Vorgaben „richtig“ oder „falsch“ ist; das unterscheidet ihn von einem Parser, der zusätzlich die analysierte grammatikalische Struktur beschreiben und ausgeben kann. Ein typisches Beispiel für einen \"Recognizer\" in der Automatentheorie ist der Kellerautomat.\n\nIn der Programmiersprache Prolog können sogenannte \"Definite Clause Grammars\" (DCG) dazu verwendet werden, um manche kontextfreien Grammatiken zu erstellen und zu verarbeiten. Angewandt auf die maschinelle Sprachverarbeitung zeigt das folgende Beispiel einer DCG eine sehr einfache Grammatik, mit der eine kleine Menge deutscher Sätze analysiert werden kann. Die Grammatikregeln legen fest, dass sich ein Satz aus einer Nominal- (NP) und einer Verbalphrase zusammensetzt, die NP wiederum besteht aus einem Artikel und einem Nomen, wobei beide in Numerus und Genus übereinstimmen müssen. Im Lexikon werden die lexikalischen Einheiten als Terminalsymbole definiert. Die Prolog-Abfrage \"recognize('Liste von Wörtern')\" setzt den \"Recognizer\" in Gang, der entscheidet, ob eine Folge von Wörtern auf Grundlage der modellierten DCG grammatisch ist oder nicht.\n\nDie Anfrage an den \"Recognizer\" ist erfolgreich (der Beispielsatz ist grammatisch):\n\nDie Anfrage an den \"Recognizer\" ist nicht erfolgreich (der Beispielsatz ist ungrammatisch):\n\n"}
{"id": "1962714", "url": "https://de.wikipedia.org/wiki?curid=1962714", "title": "Performance Data Computer", "text": "Performance Data Computer\n\nPerformance Data Computer (kurz: \"PDC\") ist ein bordeigenes Computersystem in Flugzeugen. PDC war Vorläufer des Flight Management System und sollte nach Eingabe verschiedener Variablen wie z. B. Flugzeuggewicht, Wind, Temperatur ein möglichst wirtschaftliches Betreiben des Flugzeuges ermöglichen. Dazu errechnete der Computer unter anderem die optimalen Flughöhen und Geschwindigkeiten, welche der Crew als Entscheidungshilfe für die Flugdurchführung halfen. Es bestand die Möglichkeit, den PDC direkt auf den Autopiloten zu schalten. \n"}
{"id": "1963068", "url": "https://de.wikipedia.org/wiki?curid=1963068", "title": "Notepad2", "text": "Notepad2\n\nNotepad2 ist ein Open-Source-Texteditor für Microsoft Windows, veröffentlicht unter einer BSD-Softwarelizenz. Er wurde von Florian Balmer entwickelt und basiert auf der Scintilla-Komponente für Textverarbeitung.\n\nEs unterstützt Syntaxhervorhebung bei den folgenden Sprachen:\nAußerdem unterstützt Notepad2 Suchen und Ersetzen mit regulären Ausdrücken, Umwandeln zwischen den Kodierungen ASCII, UTF-8 und UTF-16/Unicode, vielfaches Rückgängig/Wiederholen und automatisches Einrücken. Der Editor kommt mit den verschiedenen Zeilenumbrüchen von DOS (CR/LF), Unix (LF) und Mac (CR) zurecht. Neben der 32-Bit-Version gibt es auch eine Version, die speziell für den Einsatz auf 64-Bit-Systemen ausgelegt ist.\n\nDurch die Quelloffenheit existieren viele Modifikationen, die von anderen Entwicklern betreut werden. Es gibt zum Beispiel Versionen, die zusätzliche Funktionen zur Verschlüsselung oder Code-Faltung bieten.\n\n"}
{"id": "1963202", "url": "https://de.wikipedia.org/wiki?curid=1963202", "title": "Registrierungsdatei", "text": "Registrierungsdatei\n\nEine Registrierungsdatei ist eine Datei, die Informationen aus einer Registrierungsdatenbank (zum Beispiel der Windows-Registrierungsdatenbank) enthält. Registrierungsdateien können auf mit Microsoft Windows oder ReactOS betriebenen Computersystemen dazu verwendet werden, Informationen aus der Registrierungsdatenbank zu exportieren und weiterzugeben bzw. sie in selbige wieder zu importieren. Diese Dateien enden auf .reg und lassen sich in der Standardkonfiguration von Windows durch einen Doppelklick der Registrierungsdatenbank hinzufügen. Im Zusammenhang mit Wine versteht man unter den Registrierungsdateien spezielle Textdateien, die im Unterverzeichnis \".wine\" innerhalb eines Benutzerprofils auf einem Linux-System liegen können. Sie werden auch als interne Registrierungsdateien bezeichnet, da sie ein anderes Format haben als die Registrierungsdateien, die über die Exportfunktion des bei Wine mitgelieferten Programms regedit erzeugt wurden. In den Registrierungsdateien von Wine sind sowohl Konfigurationsdaten von Wine selbst als auch Daten, die von Drittanbietersoftware abgelegt wurden, gespeichert. Im Gegensatz zu Windows ist unter Wine die gesamte Registrierungsdatenbank an das Benutzerprofil gebunden (auch HKEY_LOCAL_MACHINE), sodass es keine globalen Registrierungsinformationen gibt.\n\nDie Registrierungsdatenbank ist unter den Betriebssystemen Microsoft Windows und ReactOS das zentrale Element zur Steuerung der Verhaltensweise des Systems oder von Systemdiensten. Änderungen, die durch das Ausführen von Registrierungsdateien erfolgen, können also tiefgreifende Änderungen im System verursachen, automatisch Schadprogramme starten oder den Computer sogar dadurch unbrauchbar machen, dass das Betriebssystem nicht mehr korrekt startet.\n\nWurde die Registrierungsdatei mittels der Exportfunktion des Dienstprogrammes Regedit unter Microsoft Windows erstellt, so steht in der ersten Zeile immer \"Windows Registry Editor Version \"Versionsnummer\"\". Bei internen Registrierungsdateien, die von Wine erstellt wurden, befindet sich an derselben Stelle folgender Dateikopf: \"WINE REGISTRY Version \"Versionsnummer\"\". In der nächsten Zeile befindet sich, sofern die Dateien automatisch von Wine angelegt wurden, ein mit \";;\" eingeleiteter Kommentar, der angibt, auf welchen Schlüssel sich die Datei bezieht, zum Beispiel: \";; All keys relative to \\\\Machine\" in der Datei \"~/.wine/system.reg\".\n\nDann folgt eine Leerzeile.\n\nDanach folgt eine Zeile, die in eckigen Klammern den Pfad angibt, der den Ort in der Registrierungsdatenbank bezeichnet, an den die darauf folgenden Informationen gespeichert werden sollen. Es folgen – jeweils eingeschlossen in Anführungszeichen – Paare aus Schlüsseln und Werten, die gespeichert werden. Schlüssel und Wert werden durch ein Gleichheitszeichen getrennt.\n\nDurch voranstellen eines \"-\" vor den Pfad in den eckigen Klammern wird beim importieren der .reg-Datei in die Registrierungsdatenbank der gesamte darunter liegende Baum gelöscht. Beispiel: [-HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Applets\\Regedit] (löscht die Historie des Windows Registrierungs-Editors)\n\n WINE REGISTRY Version 2\n ;; All keys relative to \\\\Machine\n\n REGEDIT4\n\n Windows Registry Editor Version 5.00\n\nDiese Registrierungsdatei hat, wenn sie in die Registrierungsdatenbank eingetragen wird, den Effekt, dass beim Start der Kompatibilitätsschicht Wine oder des Betriebssystems Microsoft Windows automatisch der mit Wine bzw. Windows mitgelieferte Taschenrechner ausgeführt wird.\n"}
{"id": "1968551", "url": "https://de.wikipedia.org/wiki?curid=1968551", "title": "SimpLiCo", "text": "SimpLiCo\n\nSimpLiCo war ein von dem PC-Hersteller Fujitsu Siemens im Jahr 2006 angebotenes PC-System, das speziell für die Nutzung durch Senioren gedacht war. Im Kaufpreis inbegriffen war der Aufbau sowie eine Einweisung in die Bedienung. Das Betriebssystem basierte auf Linux.\n\nDas System war dabei auf eine Nutzung ohne jegliche Vorkenntnisse ausgelegt – die einzelnen Anwendungen tragen statt eines Namens eine Beschreibung, die einzelnen \"Themenbereiche\" wie Büro oder Hobby tragen farbliche Markierungen, welche über spezielle Tasten auf der Tastatur angesprochen werden können. Die Benutzeroberfläche erinnert dabei eher an ein Smartphone. Die Tastatur selbst hat darüber hinaus extra große Buchstaben.\n\nAm Markt war das System ein Flop, was nach Schätzungen der c’t unter anderem an dem aufgrund unnötig leistungsstarker Hardware (unter anderem ein Intel-Pentium-D-Prozessor) zu hohen Preis von fast 1000 € und der fehlenden Erweiterbarkeit des Systems lag.\n"}
{"id": "1970345", "url": "https://de.wikipedia.org/wiki?curid=1970345", "title": "QuickDraw GX", "text": "QuickDraw GX\n\nQuickDraw GX war als Ablösung für die QuickDraw (QD) 2D-Grafik-Engine und den Printing Manager des Mac OS „Classic“ vorgesehen.\n\nObwohl GX auf denselben grundlegenden Geometrien und Metriken wie die originale QuickDraw-Engine basierte, wurde die zugrundeliegende Plattform als auflösungsunabhängiges, objektorientiertes und gepuffertes System neu spezifiziert und implementiert, welches das Ausführen üblicher Aufgaben für Programmierer sehr vereinfachte. Zusätzlich dazu wurden GX diverse Befehle zum Darstellen von Bezier-Kurven (welche Quickdraw fehlten) hinzugefügt sowie TrueType als grundlegendes Fontsystem eingeführt.\n\nObwohl GX zweifellos viele der Probleme von QuickDraw löste, hatten die meisten Anwender von QuickDraw zum Zeitpunkt des Erscheinens von GX ihre eigenen, proprietären Lösungen dafür entwickelt. GX krankte außerdem an einer Anzahl von Inkompatibilitäten im Zusammenspiel mit existierenden Programmen, insbesondere mit solchen, welche ihre eigenen Erweiterungen zum Umgehen der Unzulänglichkeiten von QuickDraw mitbrachten. Dies, sowie der Widerstand einiger namhafter Anwendungsanbieter, insbesondere des PostScript-Entwicklers Adobe, als auch die mangelhafte Vermittlung der Vorteile und Gründe für GX seitens Apple hatten zur Folge, dass diese Technik ein Schattendasein führte. Nachdem GX infolge des Aufkaufs von NeXT eingestampft wurde und Quartz die Rolle der bevorzugten Grafik-Engine übernahm, finden sich dennoch viele der Features von GX in abgewandelter Form in der heutigen Grafikschicht von macOS wieder.\n"}
{"id": "1973687", "url": "https://de.wikipedia.org/wiki?curid=1973687", "title": "Line Integral Convolution", "text": "Line Integral Convolution\n\nDie Line Integral Convolution (Abkürzung: LIC, zu deutsch: Linienintegralfaltung) ist eine Methode zur wissenschaftlichen Visualisierung von Vektorfeldern (z. B. Strömungsfeldern). Sie stellt ein globales Verfahren zur Verfügung, um alle interessanten Bereiche des Vektorfeldes darzustellen. \n\nDas Verfahren wurde zunächst für stationäre 2D-Felder entwickelt. Um eine LIC-Darstellung für solch ein Feld zu erhalten, wird ein zweidimensionales weißes Rauschen entlang der Linien des Strömungsfeldes mit einem Kern mit lokalem Träger gefaltet (im einfachsten Fall: lokal gemittelt). Die Pixelwerte entlang der Feldlinien sind dadurch stark korreliert, orthogonal dazu hingegen – durch das Rauschen – fast unkorreliert. Dadurch heben sich die Feldlinien optisch vom Hintergrund ab und werden sichtbar. Die Darstellungsmethode erinnert in der Vorgehensweise und im Ergebnis an die Sichtbarmachung von Magnetfeldlinien mit Hilfe zufällig verteilter Eisenfeilspäne.\n\nErweiterungen des Verfahrens auf zeitabhängige 2D-Felder sowie auf 3D-Felder wurden auch vorgeschlagen.\n\n\n"}
{"id": "1975981", "url": "https://de.wikipedia.org/wiki?curid=1975981", "title": "Winpooch", "text": "Winpooch\n\nWinpooch bzw. Winpooch Watchdog ist eine freie Sicherheitssoftware für die 32-Bit-Varianten von Windows 2000, Windows XP und Windows Server 2003. Das in C geschriebene Projekt wird unter der GPL veröffentlicht und soll eine Alternative zu der kommerziellen Software \"ProcessGuard\", sowie ein freies Windows-Gegenstück zu AppArmor (aus der Linuxwelt) sein.\n\nAutor Benoit Blanchon hat die Weiterentwicklung von \"Winpooch\" am 13. Juni 2008 beendet, da diese seine Freizeit zu sehr in Anspruch nähme. Er bietet anderen Programmierern an, das Projekt zu übernehmen.\n\n\"Winpooch\" ist dafür gedacht, das Einnisten sämtlicher Formen von Malware zu verhindern, ohne dass dazu Signaturen benötigt werden. Realisiert wird dieser Schutz durch „API Hooking“, eine ständige Überwachung der Programmierschnittstelle von Windows. Der Benutzer kann Programmen Rechte erteilen oder entziehen, wie das Aufbauen von Netzwerkverbindungen, das Starten/Beenden von anderen Programmen, das Schreiben/Lesen in Verzeichnissen der Festplatte, sowie Eingriffe in die Windows-Registrierungsdatenbank. Mit Hilfe von Wildcards können diese Restriktionen auch auf bisher unbekannte Programme angewandt werden, wovon dann auch Malware betroffen wäre. Kommt es zu einem vordefinierten Szenario, wird der Benutzer wahlweise aufgefordert zu entscheiden was geschehen soll, oder der Vorgang wird automatisch aufgehalten, akzeptiert oder simuliert (wobei \"Winpooch\" versucht, dem jeweiligen Prozess vorzutäuschen, dass die von ihm gewünschte Aktion ausgeführt worden wäre).\n\nStandardmäßig ist es jedem Programm verboten, in sensiblen Bereichen von Windows Änderungen vorzunehmen. Ferner ist \"Winpooch\" in der Lage, ausführbare Dateien vorher mit dem beiliegenden Antivirus ClamAV zu überprüfen.\n\nEine bislang fehlende Dokumentation, wie auch eine Reihe heftiger Programmfehler ab der frühen, öffentlichen Testphase der 0.6er-Reihe führten dazu, dass \"Winpooch\" bei einigen Benutzern in Misskredit fiel. Da die Software bei falscher bzw. vernachlässigter Konfiguration Abstürze oder ungewollte Einschränkungen verursachen kann, wird ihr Einsatz stellenweise als riskant tituliert. Im Extremfall könnte sich der Benutzer selbst sämtliche Kontrolle entziehen (auch wenn er Administrator ist), so dass er nicht einmal mehr Windows herunterfahren könnte. Beim dadurch nötig werdenden Hardware-Reset würde Datenverlust drohen.\n\n"}
{"id": "1980062", "url": "https://de.wikipedia.org/wiki?curid=1980062", "title": "Root-Konto", "text": "Root-Konto\n\nDas Root-Konto oder \"Superuser\"-Konto ist das Benutzerkonto, das bei der Installation eines Betriebssystems angelegt werden muss und mit weitreichendsten Zugriffsrechten ausgestattet ist.\n\nDieses Konto ist nicht für die alltägliche Verwendung des Systems gedacht, sondern nur für besondere Verwaltungsaufgaben, weil es mit umfassenden Risiken verbunden ist.\n\nAuf unixoiden Systemen wird jedes Benutzerkonto mit einer Zahl assoziiert: der sogenannten „UID“ (\"User ID\"). Das erste Benutzerkonto auf jedem System hat die UID \"0\" und besitzt auf historischen Unix-Systemen alle Rechte über die Ressourcen des Systems. Da dieses Konto für die Installation des Rechners notwendig ist und daher alle Dateien und Verzeichnisse aus diesem Benutzerkonto hervorgehen, kann man hier von einer „Wurzel“ (engl. \"root\") sprechen. Nach dem Beenden der Installation kann man dieses Konto zur Verwaltung (Administration) des Systems verwenden. Um als \"root\" zu arbeiten, kann man sich entweder entsprechend einloggen oder auf der Unix-Shell mit dem Befehl \"su\" die Identität wechseln.\n\nModerne Unix-Systeme wie z. B. Solaris implementieren feingranulare Rechtesysteme. Auf solchen Systemen bedeutet die Erlangung der UID \"0\" nicht zwangsläufig auch die Erlangung sämtlicher Rechte.\n\nDer Benutzer mit den Root-Rechten hat als einziger Benutzer auf einem Unix-Computer uneingeschränkte Rechte, was sich insbesondere bei Dateiverwaltung (Dateirechte etc.) und Benutzung von Systemressourcen (Arbeitsspeicher, Geräte) auszeichnet. Eine besondere Position wird dem \"root\" auch bei der Verwaltung des Kernels sowie der Prozesskontrolle eingeräumt: So kann der Root sämtliche Prozesse nach Belieben verändern und damit beispielsweise den Computer neu starten. Bei einem Kernel, der dynamisch ladbare Module unterstützt, kann Root indirekt mit dem Kernelspace auf nächster Ebene agieren.\n\nSollte ein böswilliger Cracker das Passwort des Benutzers Root herausfinden, so ist dieser vollständig kompromittiert. Um im Anschluss an einen erfolgreichen Angriff die eigene Anwesenheit vor dem Systemadministrator zu verbergen, nutzen Angreifer sogenannte Rootkits.\n\nÜblicherweise unterscheidet sich die Eingabeaufforderung des Benutzers Root von der anderer Benutzer durch eine abschließende Raute (#) statt eines Dollarzeichens ($). Systemadministratoren sprechen in diesem Falle von einem Rootprompt.\n\nBei der Installation von macOS wird ein Konto für den Systemadministrator mit Namen \"root\" angelegt und eines für den \"Admin\" mit wählbarem Namen. Bei macOS Server erhalten beide Konten dasselbe Passwort, während beim normalen macOS das Konto \"root\" kein Passwort erhält und gesperrt wird. Dem \"Admin\" ist nicht nur einiges verwehrt, was für \"root\" möglich ist, sondern auch umgekehrt.\n\nBei der Installation von Debian kann ebenfalls eine direkte Verwendung des Root-Kontos unterbunden werden. Unter dem auf Debian basierenden Ubuntu gibt es bei der normalen Installation nicht einmal die Möglichkeit, anders zu verfahren. Aus Sicherheitsgründen hat die Benutzergruppe \"admin\" dort aber keine weitergehenden Berechtigungen, als \"sudo\" auszuführen. So können sich ihre Mitglieder zeitweilig die Rechte des Superusers verschaffen. In der Regel wird \"sudo\" automatisch aufgerufen, sobald die Rechte des Superusers erforderlich sind.\nEs ist allerdings mittels des Befehls \"sudo passwd\" jederzeit möglich, den Root-Account dauerhaft freizuschalten, indem man ihm ein gültiges Kennwort zuweist.\n\n\"toor\" ist das rückwärts geschriebene Wort für \"root\" und stellt einen alternativen Root-Account dar, speziell auf BSD-Derivaten. Das Konto hat ebenfalls die UID 0, unterscheidet sich aber durch eine andere Konfiguration, vor allem durch eine andere Shell vom Root-Konto.\n\nÜblicherweise hat ein Konto (normalerweise root) eine umfangreiche Shell (wie bash oder zsh), während der jeweils andere Account (normalerweise toor) nur eine minimale Shell hat. Der Sinn dahinter ist, ein Konto mit Systemadministrationsfähigkeiten bereitzuhalten, selbst wenn die Standard-Shell des einen Kontos nicht mehr gestartet werden kann (wenn zum Beispiel die Partition, auf der die Shell liegt, nicht gemountet werden kann). \"toor\" ist außerdem das Passwort für den root-Account bei den bekannten BackTrack Distributionen und nun auch bei Kali Linux.\n\nWährend MS-DOS und das ursprüngliche Windows bis zur Millennium Edition nur ein einziges Benutzerkonto zuließ, das zwangsläufig alle Berechtigungen hatte, unterstützt Windows seit NT mehrere Benutzerkonten mit unterschiedlichen Berechtigungen. Das Root-Konto hat hier den Benutzernamen \"Administrator\". Allerdings existiert ein weiteres Benutzerkonto mit höheren Berechtigungen als denen des Administrators. Dieses heißt \"SYSTEM\", wird jedoch normalerweise nicht zur Administration des Computers benutzt.\nDas Benutzerkonto mit dem Namen \"Administrator\" ist auf dem Anmeldebildschirm in Windows XP standardmäßig nicht sichtbar, kann aber dennoch verwendet werden, indem der klassische Anmeldedialog, entweder über die Einstellungen oder durch zweimaliges Drücken von Strg+Alt+Entf, auf dem Anmeldebildschirm aufgerufen wird.\nUnter Windows Server 2008 R2 existiert ebenfalls ein Benutzeraccount mit dem Namen \"Administrator\", der schon beim ersten Start des Systems nach der Installation eingerichtet werden muss und genauso wie bei der aktuellen Version \"Windows Server 2012 Standard/Datencenter\" die höchsten Privilegien besitzt.\n\n\n"}
{"id": "1988624", "url": "https://de.wikipedia.org/wiki?curid=1988624", "title": "Staog", "text": "Staog\n\nStaog (auch bekannt als Linux/Staog) war der erste Computervirus, der für das Betriebssystem Linux geschrieben wurde. Es wurde im Herbst 1996 entdeckt. Staog nutzte drei bekannte Sicherheitslücken, diese wurden kurze Zeit später geschlossen, seitdem ist der Virus nicht mehr in freier Wildbahn (\"in-the-wild\") zu finden.\n\nStaog infizierte Linux-Systeme, indem es Sicherheitslücken im Linux-Kernel ausnutzte. In einem Linux-System ist der Zugriff eines Benutzers auf bestimmte Bereiche (Dateien, Verzeichnisse, Peripheriegeräte) des Systems beschränkt und nur der administrative Benutzer \"Root\" besitzt unbeschränkte Rechte (z. B. zum Löschen oder Ändern von Systemdateien). Der Virus konnte sich durch Ausnutzung der Sicherheitslücken diese Rechte verschaffen, deshalb konnte der Virus sich „resident“ im System einrichten und danach weitere ausführbare Dateien (Programme, Skripte) infizieren.\n\nDa die Verbreitung jedoch auf fundamentale Programmfehler aufbaute, die durch Softwareaktualisierungen behoben wurden, sind nun die meisten Linux-Systeme immun gegen Staog. Dies, sowie die Tatsache, dass er sich per „Schrotschuss-Verfahren“ weiter verbreitete, sorgte dafür, dass er ziemlich bald ausstarb.\n\nStaog wurde von der australischen Cracker-Gruppe \"VLAD\" in Assembler geschrieben.\n\n"}
{"id": "1989578", "url": "https://de.wikipedia.org/wiki?curid=1989578", "title": "Bliss (Computervirus)", "text": "Bliss (Computervirus)\n\nBliss ( für „Glückseligkeit“) ist ein Computervirus, der GNU/Linux-Betriebssysteme befallen kann. Am 5. Februar 1997 veröffentlichte sein Autor den Quelltext.\n\nWenn Bliss ausgeführt wird, hängt er sich selbst an ausführbare Dateien (Programme, Skripte), auf die gewöhnliche Benutzer keinen Zugriff haben. Diese ausführbaren Dateien können anschließend nicht mehr ausgeführt werden. Daher wird Bliss sehr rasch bemerkt.\n\nBliss schreibt eine saubere Log-Datei über alle seine Aktionen, \"/tmp/.bliss\" (der Punkt am Anfang des Dateinamens kennzeichnet in Linux versteckte Dateien, die also im gewöhnlichen Anzeige-Modus nicht zu sehen sind). Außerdem gibt es einen Kommandozeilen-Parameter \"--bliss-uninfect-files-please\" (etwa „Bliss, bitte desinfiziere die Dateien“), der tatsächlich dazu führt, dass die Infektionen rückgängig gemacht werden.\n\nAll diese Eigenschaften deuten darauf hin, dass Bliss möglicherweise nur geschrieben wurde, um zu beweisen, dass Linux mit Computerviren infiziert werden kann (Proof of Concept). Auch vermehrt sich dieser Virus nicht sehr effektiv, weil das System der Benutzerrechte in Linux eine Verbreitung sehr erschwert. Bliss hat sich nie ausbreiten können und blieb damit eine Kuriosität aus der Forschung.\n\nAls die Entdeckung von Bliss öffentlich bekannt wurde, gaben einige Hersteller von Antivirensoftware Pressemitteilungen heraus; sie behaupteten, dass nun, da tatsächlich ein Linux-Virus existiere, auch Linux-Benutzer unbedingt Antivirensoftware kaufen sollten, um sich zu schützen. Üblicherweise verwenden Linux-Benutzer nämlich keine Antivirensoftware, höchstens auf Servern, die als Datei- oder E-Mail-Server für Windows-Computer dienen und daher alle Daten nach Windows-Viren durchsuchen.\n\n\n"}
{"id": "1995396", "url": "https://de.wikipedia.org/wiki?curid=1995396", "title": "Station Rose", "text": "Station Rose\n\nStation Rose (kurz STR) ist ein Künstlerduo und wurde 1988 von Elisa Rose (Medienkünstlerin, geb. 1959 in Linz) & Gary Danner (Musiker, Medienkünstler, geb. 1959 in Linz) in Wien als öffentliches Multimedialabor gegründet, nachdem beide die Universität für Angewandte Kunst in Wien mit Diplom (Magisterium) absolviert hatten.\n\nDas Werk von „Station Rose“ lässt sich in die Kategorien Medienkunst, Performancekunst, digitale Kunst, Videokunst, Computerkunst, Netzkunst und Elektronische Musik einordnen.\n\nVon der Gründung der Station an reichte das Spektrum der STR-Aktivitäten von CD-, Vinyl-, DVD- und CD-ROM-Produktionen, über Kunstproduktion und Forschung zum Thema Virtuelle Realitäten und dem Kuratieren von Symposien bis zu Vorlesungen und Performances, Ausstellungen in Galerien, Museen, an Universitäten und im Underground.\n\n1988/89 betrieb STR für 8 Monate multimediale Feldforschung (Post-graduate-Stipendium) mit Computer, Scanner & Sampler in Cairo/Ägypten („Station im Aussendienst“).\n\nStation Rose veranstaltete 1989 die ersten Technoevents in Wien („Gunafa Clubbing“), übersiedelte 1991 nach Frankfurt am Main, und ging gleichzeitig online.\n\nBei ihren Gunafa Clubbings verwendeten sie ab 1992 das Internet als Element ihrer audiovisuellen Liveperformances. Die Echtzeitkommunikation zwischen global zugeschalteten Usern wurde dabei auf die Wände des Frankfurter Technoclubs „XS“ projiziert. Dazu wurden Sounds & Visuals in Echtzeit am Computer gespielt.\n\n1995 erhielt STR den Prix Ars Electronica (honorable mention). Im gleichen Jahr prägten sie den Begriff „Digital Bohemian“. 1996-1998 hatten sie einen Künstlervertrag mit Sony Music.\n1996–1998 waren sie Teil des Virtual Community Projektes „Electric Minds“ von Howard Rheingold.\n1998 erschien das von ihnen gestaltete Buch „1st Decade“. Seit 1999 webcasten STR auf www.stationrose.com\n\n2002–2004 teilten sich Rose und Danner eine Professur an der University of Applied Sciences Darmstadt (Media Production). Von 2002 bis 2006 wurde die einstündige Sendung „Station Rose - Best of Webcasting“ wöchentlich im hr-fernsehen/ARD Digital ausgestrahlt (gesamt ca. 31 Stunden audiovisuelle Kompositionen). Dazu erschienen 2005 die CD und DVD „Best of Webcasting“.\n\nAls eine der ersten Künstlergruppen weltweit lotete Station Rose die Möglichkeiten der interaktiven Medien und des Internets aus. Audiovisuelle Performances in Kunstgalerien und Universitäten stehen gleichberechtigt neben Aktionen auf Medienfestivals und Events im Clubbereich/Underground im Werkverzeichnis der Gruppe. Webcasting und Live-Streaming spielen dabei eine hervorgehobene Rolle.\n\n\n\n\nVertrieb: Sony.\n\n\n\n\n\n\n"}
{"id": "1999670", "url": "https://de.wikipedia.org/wiki?curid=1999670", "title": "Transmission (BitTorrent)", "text": "Transmission (BitTorrent)\n\nTransmission (englisch für „Übertragung“) ist ein freier, ressourcenschonender BitTorrent-Client. Er hat eine einfache Benutzeroberfläche und eine plattformunabhängige Implementierung des BitTorrent-Protokolls.\n\nTransmission ist in C geschrieben und als freie Software auch im Quelltext veröffentlicht. Dabei stehen einige Teile unter der MIT-Lizenz, andere unter der GNU GPL Version 2. Sie ist unter Windows, auf vielen unixoiden Betriebssystemen (unter anderem macOS, Linux und BSD), BeOS/ZETA (mit nativer Oberfläche), Mobiltelefon-Systemen (Android, iOS, Maemo), Embedded Systemen (z. B.: NAS Geräte, externe Festplattensysteme, Router) lauffähig.\n\nTransmission unterstützt weitgehend alle wesentlichen, verbreiteten Funktionen eines BitTorrent-Clients, unter anderem DHT, PEX, automatisches Port-Mapping (per UPnP und NAT-PMP), Protokollverschleierung, Auffindung lokaler Gegenstellen (siehe BitTorrent#Offizielle Protokollerweiterungen). Transmission kann Torrent-Dateien erstellen und bietet gute Verwaltungsfunktionen, unter anderem Bandbreitenbeschränkung, selektives Herunterladen mit Priorisierung, Sortieren und Filtern, …\nWeiterhin können IP-Adressen nach einer Bannliste ausgeschlossen werden. Sich schadhaft verhaltende Gegenstellen werden automatisch ausgeschlossen.\nDurch das Speichern von Peers können Übertragungen bei erneutem Programmstart schneller wieder aufgenommen werden („fast resume“). Es wird ein einziger „Listening Port“ für alle Übertragungen genutzt.\n\nTransmission ist getrennt in Front-End und Back-End aufgebaut.\nFür das Backend ist die Programm-Funktionalität in einer Programmbibliothek namens libTransmission umgesetzt, auf deren Basis ein Daemon existiert. Als Frontend dienen mehrere graphische Benutzeroberflächen auf Basis verschiedener GUI-Toolkits, verschiedene Weboberflächen zur Fernsteuerung per Webbrowser über HTTP(S), eine Kommandozeilen-Schnittstelle und anderes.\n\nUrsprünglich auf Gnome ausgerichtet bietet er nun für mehrere Umgebungen native Unterstützung mit entsprechenden eigenen Oberflächen auf Basis der jeweiligen GUI-Toolkits und Integration in die jeweilige Umgebung. So gibt es neben der ursprünglichen GTK+-Oberfläche unter anderem auch eine Qt-Oberfläche und eine macOS-Version mit Cocoa-Oberfläche, Integration mit dem Dock, Growl und Sparkle, Unterstützung für Quicklook und anderem.\nEine offizielle Windows-Version steht bisher nicht zur Verfügung, es gibt jedoch ein \"Projekt auf SourceForge\", welches sich der Thematik angenommen hat und aktuelle Builds anbietet. Weiterhin gibt es von Drittentwicklern die Windows-Oberflächen \"Transmission Remote Dot Net\" und \"transmission-remote-gui\".\nFür Mobiltelefone gibt es Ports für Apple iOS, Android (Transdroid) und Maemo.\n\nMit Ubuntu 8.04 von April 2008 wurde er wegen seines geringen Ressourcenbedarfs als Standard-Client dieses Linux-Betriebssystems gewählt und war als solcher erstmals in Version 1.06 enthalten. Er ersetzt dort den GNOME BitTorrent Downloader (GNOME-BT).\nAb Version 1.3 vom 6. August 2008 ist die ehemals separate Web-Schnittstelle \"Clutch\" in das Programm integriert.\nSeit der am 5. Juni 2009 veröffentlichten Version 1.70 wird (für öffentliche Torrents) auch dezentrales Tracken mit verteilten Hashtabellen (engl. Distributed Hash Table, DHT) unterstützt. Dies war ein langersehntes Merkmal, dessen Fehlen zuvor viele von der Nutzung dieses Clients abgehalten hatte. Darauf aufbauend kommt in Version 1.80 die Unterstützung für Magnet-Links, was seit dem Abschalten des Pirate-Bay-Tracker-Komplexes und dem Umstieg der Pirate-Bay-Seite von Torrent-Dateien auf Magnet-Links sehr wichtig geworden ist.\nVersion 2.0 vom Juni 2010 bringt die Fähigkeit zum Auffinden lokaler Gegenstellen.\n\nSein großer Funktionsumfang und die Vorinstallation als Standard-Client auf vielen Betriebssystemen und Geräten macht Transmission recht populär. Aufgrund seiner Schlankheit und Einfachheit in der Bedienung ist er bei vielen Betriebssystemen als Standard-Software beigepackt (unter anderem wichtige wie Ubuntu, Fedora, Mandriva Linux, openSUSE).\nWegen seiner Architektur, dem geringen Speicherverbrauch und der Einfachheit werden auch die BitTorrent-Dienste großer Websites wie ImageShack mit Transmission realisiert.\nEinige Geräte wie WLAN-Router und BitTorrent-fähige NAS-Systeme werden mit Transmission ausgeliefert (beispielsweise Fonera-Router).\n\n\n"}
{"id": "2000141", "url": "https://de.wikipedia.org/wiki?curid=2000141", "title": "FreeX", "text": "FreeX\n\nfreeX war eine deutschsprachige Computerzeitschrift mit Fokus auf dem praktischen Einsatz von freien Unix-Systemen (Linux, div. BSD- und Unix-Derivate). Herausgegeben wurde \"freeX\" vom C&L Verlag in Böblingen.\n\nJeder Ausgabe lag eine CD-ROM (seit Ausgabe 1/2007 eine DVD-ROM) mit einem oder mehreren Unix-Betriebssystemen – teils zum Installieren, teils als Live-System – sowie Anwendungsprogrammen bei. Die 1998 gegründete Zeitschrift erschien seit 1999 zweimonatlich, jeweils zu Beginn gerader Monate.\n\n\"FreeX\" wurde im Oktober 2012 eingestellt und in das \"Admin-Magazin\" eingegliedert, das wiederum im April 2014 in \"IT-Administrator\" eingegliedert wurde. Der Einsatz freier Software geriet jedes Mal weiter aus dem Mittelpunkt. Mittlerweile scheinen „Produkte im Test“ bzw. „Praxis-Workshops“ zu vorwiegend kommerziellen Erzeugnissen den Fokus zu bilden.\n"}
{"id": "2001902", "url": "https://de.wikipedia.org/wiki?curid=2001902", "title": "Happy Feet (2006)", "text": "Happy Feet (2006)\n\nHappy Feet ( [ˈhæpi fi:t] für \"Glückliche Füße\") ist ein australisch-US-amerikanischer Computeranimationsfilm von George Miller aus dem Jahr 2006. Millers erster Animationsfilm war gleichzeitig der erste von der in Sydney beheimateten Spezialeffekt-Firma Animal Logic realisierte Trickfilm. Der Film spielte an den weltweiten Kinokassen über 380 Millionen Dollar ein und verdrängte damit \"Crocodile Dundee\" als weltweit erfolgreichster australischer Film.\n\nDer Film erzählt die Geschichte des Kaiserpinguins Mumble. Da seinem Vater Memphis das Ei aus den Beinen rutscht und somit einige Zeit der Kälte ausgesetzt ist, kann Mumble nicht singen. Er kann aber steppen und gilt dadurch bei den anderen Pinguinen als Außenseiter, das Weibchen Gloria bringt ihm jedoch Sympathien entgegen.\n\nMumble lernt mit Adeliepinguinen eine andere Pinguinart kennen, deren Angehörige seine Tanzkünste schätzen. Bei ihnen lebt auch der Felsenpinguin Lovelace.\n\nMit diesen begibt er sich auf die Suche nach Menschen, die als „Aliens“ bezeichnet werden. Gemeinsam mit dem Adeliepinguin Ramon und seinen Kollegen sucht er die Antwort auf die Frage, warum die Bestände der Fische geringer wurden. Er wird an einen Strand gespült. Als er aufwacht, befindet er sich mit anderen Pinguinen in einem Zoo. Als er vor einem Mädchen hinter der Glaswand zu tanzen anfängt, erregt er die Aufmerksamkeit der übrigen Besucher.\nEr kehrt zu den Kaiserpinguinen mit einem Sender am Rücken zurück, der die Menschen zu ihm führt. Die Aufnahme des tanzenden Mumble inmitten der tanzenden Pinguinkolonie, die weltweit ausgestrahlt wird, bewegt die Menschen dazu, die Überfischung einzustellen. Mumble und Gloria werden ein Paar.\n\n\nJames Berardinelli lobte auf \"ReelViews\" die „realistisch“ wirkenden Zeichnungen der Pinguine sowie die „Spontanität“ und den „Humor“ von Robin Williams. Er schrieb, dass der Film die „Zutaten“ für einen „großartigen Film“ habe, aber vor dem Ende den richtigen Weg verlasse. Berardinelli könne zwar den Film empfehlen, aber nicht so „enthusiastisch“ wie er es sich wünschen würde.\n\nDer Film gewann bei der Oscarverleihung 2007 den Oscar in der Kategorie \"Bester animierter Spielfilm\". Er gewann im Jahr 2007 für den Filmsong \"The Song of the Heart\" (geschrieben und interpretiert von Prince) den Golden Globe Award.\n\nDie Filmanimation wurde in Australien durchgeführt. Die Produktionskosten betrugen schätzungsweise 85 Millionen US-Dollar. Der Film startete in den Kinos der USA am 17. November 2006 und spielte am Startwochenende ca. 41,5 Millionen US-Dollar ein. Der deutsche Kinostart erfolgte am 30. November 2006. Für die deutsche Fassung konnten unter anderem Ben Becker (Stimme von Lovelace) und Rick Kavanian (Stimme von Ramón) gewonnen werden.\n\nIm Januar 2010 wurde bekanntgegeben, dass eine Fortsetzung für den Film gedreht wird. Matt Damon, P!nk und Brad Pitt haben dafür der englischsprachigen Version ihre Stimmen geliehen. Happy Feet 2 kam am 1. Dezember 2011 in die deutschen Kinos.\n\n"}
{"id": "2002645", "url": "https://de.wikipedia.org/wiki?curid=2002645", "title": "Visual Computing", "text": "Visual Computing\n\nVisual Computing ist ein Oberbegriff für alle Informatikdisziplinen, die sich mit Bildinformationen und 3D-Modellen beschäftigen.\n\nDazu zählen Computergrafik, Bildverarbeitung, Visualisierung, Computer Vision, Virtual Reality und Augmented Reality, Videobearbeitung, aber auch Aspekte von Mustererkennung, der Mensch-Computer-Interaktion, des maschinellen Lernens und digitaler Bibliotheken. Dabei geht es um die Erfassung, Verarbeitung, Analyse und Darstellung visueller Informationen (hauptsächlich Bilder und Videos).\n\nAnwendungsbereiche sind z. B. industrielle Qualitätskontrolle, medizinische Bildverarbeitung und -visualisierung, Vermessung, Robotik, multimediale Systeme, Virtual Heritage, Visuelle Effekte in Film und Fernsehen, und Computerspiele.\n\nAn mehreren deutschsprachigen Universitäten werden eigene Studiengänge aus Visual Computing angeboten.\n\nVisual Computing ist noch ein relativ junger Begriff, der erst ab 2005 seine heutige Bedeutung erlangte, als die in der Informationstechnologie etablierten Disziplinen Computergrafik, Bildverarbeitung, Computer Vision u. ä. in ihrer Methodik und ihren Anwendungen immer näher zusammenrückten und ein Oberbegriff dafür benötigt wurde. Viele der verwendeten mathematischen und algorithmischen Methoden sind bei allen Bereichen, die Bilder verwenden, die gleichen: Bildformate, Filtermethoden, Farbmodelle, Bildmetriken und andere. Auch die Programmiermethoden auf Graphik-Hardware, die Verarbeitung großer Datenmengen, die Lehrbücher und die Kongresse, die wissenschaftlichen Communities dieser Disziplinen und die Arbeitsgruppen in Firmen vermischen sich immer mehr.\n\nDazu kommt, dass Anwendungen immer öfter Techniken aus mehreren dieser Disziplinen gleichzeitig benötigen. Um detailgenaue Modelle komplexer Gegenstände zu generieren benötigt man Bilderkennung, 3D-Sensoren und Rekonstruktionsverfahren. Um diese Modelle glaubwürdig darzustellen benötigt man realistische Renderingverfahren mit komplexer Beleuchtungssimulation. Echtzeitgrafik ist die Basis für brauchbare Virtual- und Augmented-Reality-Software. Eine gute Segmentierung der Organe ist bei der 3D-Darstellung von medizinischen Scans die Basis für interaktive Manipulationen. Robotersteuerung benötigt eine Erkennung der Objekte genauso wie eine Modellierung der Umwelt. Und eine ergonomische grafische Schnittstelle mit den verwendeten Geräten ist ebenfalls notwendig.\n\nWiewohl viele Aufgabenstellungen der Teildisziplinen in der wissenschaftlichen Welt (also meist unter „Laborbedingungen“) als gelöst gelten, besteht eine wesentliche Aufgabe der Gesamtdisziplin Visual Computing in der Integration der Teillösungen zu verwendbaren Produkten – das beinhaltet auch die Behandlung vieler praktischer Probleme, vom Umgang mit Hardwarevielfalt über die Verwendung echter (meist fehlerhafter oder umfangreicher) Daten bis zur Bedienung durch ungeschulte Benutzer.\n\nZumindest die folgenden Bereiche gehören zu Visual Computing. Ausführliche Beschreibungen jedes dieser Gebiete finden sich auf den jeweiligen Spezialseiten für die Begriffe.\n\nComputergrafik ist ein Oberbegriff für alle Techniken, die Bildinformation als Ergebnis eines Berechnungsprozesses erzeugen. Mit Bildsynthese (Rendering) werden aus Beschreibungen von Objekten Bilder generiert, die ja nach Anwendung meist einen Kompromiss aus Qualität und Rechenzeit darstellen. Computeranimation nennt man Computergrafik, wenn die Bilder zum Zweck der Erstellung eines Filmes erzeugt werden.\n\nTechniken, die aus vorhandenen Bildern Information über den Inhalt extrahieren können, fallen unter den Begriff Bilderkennung. Unter Computer Vision versteht man die Fähigkeit des Computers (oder eines Roboters), die Umgebung zu erkennen und korrekt zu interpretieren.\n\nDer Begriff Visualisierung wird meist verwendet, wenn Daten, die aus irgendeinem Grund einer direkten Darstellung nicht zugänglich sind, möglichst anschaulich dargestellt werden. Insbesondere gilt das für Volumendaten und Daten, die keine unmittelbare geometrische Dimension haben. Mit Interaktiver Visueller Analyse kann man durch interaktive Veränderung der Darstellung unübersichtliche Datenmengen effizient untersuchen.\n\nDie Repräsentation von darstellbaren Objekten im Rechner erfordert spezielle Methoden und Datenstrukturen, die unter dem Begriff Geometrische Modellierung geläufig sind. Neben beschreibenden und interaktiven geometrischen Techniken werden immer mehr auch Sensordaten zur Rekonstruktion der geometrischen Modelle verwendet. In neuerer Zeit werden auch Algorithmen zur effizienten Ansteuerung von 3D-Druckern zu Visual Computing gezählt.\n\nIm Gegensatz zur Bilderkennung dient Bildverarbeitung dazu, aus Bildern bessere Bilder zu berechnen. „Besser“ kann dabei je nach Anwendung sehr unterschiedliche Bedeutungen haben. Zu unterscheiden ist davon die Bildbearbeitung, die sich mit interaktiven Methoden zur manuellen Veränderung von Bildern beschäftigt.\n\nVirtual Reality heißen alle Techniken, die dem Benutzer suggerieren, sich in einer fiktiven Umgebung zu befinden. Dazu braucht man neben guten Datenbrillen vor allem exaktes Tracking und hochqualitative Echtzeitgrafik. Bei Augmented Reality sieht man zusätzlich auch die reale Umgebung, wodurch die Anforderungen an die Genauigkeit der visuellen Darstellung und Lokalisierung erheblich steigen.\n\nDas Mensch-Computer-Interaktion (oder ) genannte Gebiet beschäftigt sich mit der benutzergerechten Gestaltung von interaktiven Systemen, wobei den grafischen Komponenten eine besondere Bedeutung zukommt, weil der visuelle Kanal des Menschen die höchste Bandbreite zur Aufnahme von Informationen hat.\n"}
{"id": "2002668", "url": "https://de.wikipedia.org/wiki?curid=2002668", "title": "QGIS", "text": "QGIS\n\nQGIS (ehemals Quantum-GIS) ist ein freies Geoinformationssystem zum Betrachten, Bearbeiten und Erfassen von räumlichen Daten.\n\nQGIS ist ein Geoinformationssystem zum Betrachten, Bearbeiten und Erfassen von räumlichen Daten und ist GNU General Public License lizenziert. Wesentliche Merkmale der Applikation sind die breite Unterstützung gängiger Vektordaten und Rasterdaten wie Shapefile oder GeoTIFF, aber auch räumlicher Datenbanken wie PostGIS und SpatiaLite, ausgereifte Digitalisier-Werkzeuge zum Erfassen von Vektordaten sowie eine Druckzusammenstellung zum einfachen Erstellen von Kartenausdrucken.\n\nDie QGIS-Architektur baut stark auf Erweiterungen auf, nennenswert sind die \"fTools\"-Werkzeuge für allgemeine vektorbasierte Aufgaben oder die GRASS-Erweiterung für anspruchsvolle räumliche Analysen. Eine GPS-Erweiterung erlaubt es, GPX-Dateien zu lesen oder direkt auf ein GPS-Gerät zuzugreifen. Andere Erweiterungen erlauben das Einbinden von WMS- und WFS-Diensten.\n\nWesentliche Teile der grafischen Benutzeroberfläche sind in über 30 verschiedene Sprachen übersetzt.\n\nDie Grundlage von QGIS und seinen Erweiterungen bildet die plattformunabhängige Qt-Bibliothek, welche das Entwickeln von Applikationen mit grafischen Benutzeroberflächen im Stil des Wirtsbetriebssystems ermöglicht (QWindowsVistaStyle, QWindowsXPStyle, QMacStyle).\n\nQGIS bietet eine Programmierschnittstelle, welche das Verwenden von vorhandenen QGIS-Funktionalitäten in eigenen Programmen oder das Schreiben von Erweiterungen für QGIS erlaubt. Erweiterungen können sowohl in C++ als auch in Python (PyQt) entwickelt werden. Die Programmierschnittstelle unterteilt sich in vier Module:\n\nAufgrund des relativ geringen Speicherbedarfs und des damit einhergehenden geringen Anspruchs an die Hardware, eignet sich QGIS auch für den Einsatz auf älterer Hardware bzw. kann parallel zu anderen Anwendungen laufen.\n\nQGIS läuft auf macOS, Linux, Unix und Windows XP oder höher. Als Mobile App ist es für Android in einer Vorabversion verfügbar.\n\nAktueller Entwicklerplan\n\nSeit 2009 finden mehrtägige Entwickler-Treffen statt, in den ersten drei Jahren noch unter dem Namen \"QGIS Hackfest.\" Diese wurden in Hannover, Wien, Pisa, Breslau, Lissabon, Zürich, Lyon, Essen, Nødebo und Las Palmas de Gran Canaria durchgeführt.\n\nSeit 2010 finden QGIS-Anwendertreffen mit Vorträgen und Workshops statt. Die \"QGIS Anwendergruppe Deutschland e. V.\" ist seit 2015 beim Amtsgericht Köln registriert. Die \"QGIS Anwendergruppe Schweiz\" als ein Verein nach Art. 60 – 79 ZGB gibt es seit ihrer Gründungsgeneralversammlung in Solothurn am 8. Februar 2012.\n\n"}
{"id": "2011236", "url": "https://de.wikipedia.org/wiki?curid=2011236", "title": "Digita", "text": "Digita\n\ndigita ist ein deutscher Bildungsmedien-Preis. Er wird jährlich auf der Bildungsmesse didacta verliehen. Der Preis zeichnet digitale Lehr- und Lernangebote aus, die im deutschsprachigen Raum angeboten werden, inhaltlich und formal als hervorragend gelten können und die digitalen Medien beispielgebend nutzen.\n\nTräger und Ausrichter des digita ist das IBI – Institut für Bildung in der Informationsgesellschaft an der TU Berlin.\n\nDer Preis hat neun Kategorien:\n\nIn einer Vorauswahl werden zu allen Produkten mindestens zwei Gutachten erstellt, die unter anderem die Erfüllung der Anforderungen des Kriterienkatalogs überprüfen. Bei Uneinigkeit der Gutachter wird ein drittes Gutachten erstellt.\n\nDie Jury des digita entscheidet in eigenem Ermessen über die Nominierung der Produkte und wählt aus den nominierten Produkten einen Sieger pro Kategorie oder Sparte.\n\nDie Jury besteht aus Mitgliedern der Träger und Fachleuten aus Bildungsadministration, Wissenschaft und Wirtschaft, die von den Trägern berufen werden.\n\nDer Deutsche Bildungsmedien-Preis digita steht unter jährlich wechselnder Schirmherrschaft durch Vertreter der Bildungspolitik – in der Regel Bildungs- oder Kultusminister des Bundeslandes, in dem die Bildungsmesse didacta (Ort der Preisverleihung) stattfindet.\n\nVon 1995 bis zur Wettbewerbsrunde 2007 firmierte der digita unter dem Namen „Deutscher Bildungssoftware-Preis“. Die Umbenennung wurde von den Veranstaltern damit begründet, dass zunehmend sog. Hybridangebote bzw. Lernsysteme mit einer Kombination aus herkömmlichen Medien und Bildungssoftware zum Wettbewerb eingereicht wurden, denen der Begriff „Bildungssoftware“ nicht mehr gerecht wurde.\n\n"}
{"id": "2014124", "url": "https://de.wikipedia.org/wiki?curid=2014124", "title": "Automatisierter Handel", "text": "Automatisierter Handel\n\nAutomatisierter oder algorithmischer Handel (auch \"Algorithmic Trading\", \"Algo Trading\", \"Black Box\", \"High Frequency Trading\", \"Flash Trading\" oder \"Grey Box Trading\") bezeichnet umgangssprachlich allgemein den automatischen Handel von Wertpapieren durch Computerprogramme.\n\nNach dem Wertpapierhandelsgesetz ( Abs. 2 WpHG) wird der \"algorithmische Handel\" beschrieben als Handel mit Finanzinstrumenten, bei denen ein Computeralgorithmus über die Ausführung und die Parameter des Auftrags automatisch entscheidet. Ausgenommen sind davon Systeme, die Aufträge nur bestätigen oder an andere Handelsplätze weiterleiten.\n\nBis dato hat sich keine eindeutige Definition in der Literatur der Wirtschaftsinformatik und der Wirtschaftswissenschaft durchgesetzt. Viele Autoren verstehen darunter Computerprogramme, die dazu genutzt werden, bestehende Kauf- und Verkaufsaufträge (Orders) auf elektronischem Wege an die Börse zu leiten. Die andere Gruppe von Autoren versteht darunter Computerprogramme, die selbständig Kauf- und Verkaufsentscheidungen treffen. In diesem Kontext kann man Algorithmic Trading bei Buy-side- und Sell-side-Finanzinstituten unterscheiden.\n\nZur Entwicklung des automatisierten Handels: Börsen berichten von einem Anteil bis zu 50 Prozent am Umsatz. An der Eurex hat sich der automatisierte Handel von 2004 bis 2006 vervierfacht. Der traditionelle Handel ist dagegen nur leicht gewachsen. Die EUREX nimmt an, dass momentan ca. 20–30 % des gesamten Umsatzes durch automatisierten Handel entsteht. Innerhalb der EUREX rechnet man mit einer Wachstumsrate von etwa 20 % pro Jahr. Laut einer Studie der AITE Group waren 2006 etwa ein Drittel aller Wertpapierhandel von automatischen Computerprogrammen und Algorithmen gesteuert. AITE schätzt, dass dieser Anteil bis 2010 etwa 50 % erreichen könnte. Wie Gomolka darstellt, sind diese Zahlen zum Börsenumsatz jedoch kritisch zu werten. Denn die Börsen sehen nur diejenigen Orders, die von Maschinen an die Börse übermittelt und in den elektronischen Orderbüchern aufgefangen werden (siehe Transaktionsunterstützung). Welcher Anteil des Börsenumsatzes von Maschinen generiert wird (siehe Entscheidungsunterstützung) und welcher Anteil durch menschliche Händler in die Ordersysteme eingegeben wird, kann von den Börsen nicht gemessen werden.\n\nAnfang Juli 2009 wurde ein ehemaliger Mitarbeiter des amerikanischen Finanzdienstleisters Goldman Sachs vom FBI verhaftet, da er Teile der Software gestohlen haben soll, die von dem Unternehmen zum automatisierten Handel genutzt wird. Die Software sei laut Staatsanwaltschaft zudem geeignet, „um Märkte auf unfaire Weise zu manipulieren“. Er wurde jedoch inzwischen freigesprochen, da er nach US Recht keinen physikalischen Gegenstand gestohlen hatte. Zum größten Teil waren die Programme, die er mitnahm, nur von ihm selbst verbesserte Open Source Programme.\n\nJe nach Automatisierungsgrad kann der Computer selbständig über bestimmte Aspekte der Order entscheiden (Timing, Preis, Volumen oder Zeitpunkt der Orderaufgabe). Im sogenannten „Sell Side Algo-Trading“ (z. B. Brokerages) werden große Orders in mehrere kleinere Handel aufgeteilt. Damit können Market Impact, Opportunitätskosten und Risiken gesteuert werden.\nDer Algorithmus legt das Aufsplitten und den Zeitpunkt (Timing) der Orders anhand vordefinierter Parameter fest. Diese Parameter nutzen üblicherweise sowohl historische als auch aktuelle Marktdaten. Algorithmischer Handel wird von Brokern zum einen für den Eigenhandel verwendet, zum anderen aber auch den Kunden der Broker als Dienstleistung angeboten (Aufgrund der Komplexität und Ressourcenlage haben institutionelle Investoren einen gewissen Drang, auf Lösungen von Brokern zuzugreifen). Der Vorteil automatisierten Handels ist die hohe Geschwindigkeit, in der sie Geschäfte platzieren können, und die im Vergleich zum Menschen höhere Menge an relevanten Informationen, die sie beobachten und verarbeiten. Damit gehen auch geringere Transaktionskosten einher. Voraussetzung für algorithmischen Handel ist, dass bereits eine Order bzw. eine Handelsstrategie vorliegt. Hier geht es im Gegensatz zu automatischem Handel bzw. Quote-Maschinen darum, eine Order intelligent auf verschiedenen Märkten zu verteilen. Es geht nicht darum, anhand von Parametern automatisch Angebote in den Markt zu schießen.\n\nAutomatisierter Handel wird von Hedgefonds, Pensionsfonds, Investmentfonds, Banken und anderen institutionellen Anlegern genutzt, um Orders automatisch zu generieren und/oder auszuführen. Hier generieren Computer selbständig Kauf- und Verkaufssignale, die in Orders auf dem Finanzplatz umgesetzt werden, bevor Menschen überhaupt eingreifen können. Algorithmic Trading kann mit jeder Investment-Strategie benutzt werden: Market Making, Inter-Market Spreading, Arbitrage, Trendfolgemodelle oder Spekulationen. Die konkrete Anwendung von Computermodellen bei der Investmententscheidung und Durchführung ist unterschiedlich. So können Computer entweder nur unterstützend für die Investment-Analyse eingesetzt werden (Quant Fonds) oder die Orders sowohl automatisch generiert als auch an die Finanzplätze weitergeleitet werden (Autopilot).\nDie Schwierigkeit bei Algorithmic Trading liegt in der Aggregation und Analyse historischer Marktdaten sowie der Aggregation von Real-time-Kursen, um den Handel zu ermöglichen. Ebenso ist das Aufstellen und Testen mathematischer Modelle nicht trivial.\n\nIn der Literatur wird Algorithmic Trading oft mit Hochfrequenzhandel gleichgesetzt, bei dem Wertpapiere in Sekundenbruchteilen ge- und wieder verkauft werden. Einer Studie von FINalternatives zufolge kategorisieren Fondsmanager den Bereich des Algorithmic Trading aber höchst unterschiedlich. So verstehen über 60 % der Befragten unter Hochfrequenzhandel Transaktionen im Zeitraum von 1 s bis 10 Minuten. Ca. 15 % der Befragten verstehen darunter Transaktionen im Zeitraum von 1–5 Tagen. Aldridge (2009) kategorisiert Algorithmic Trading ausschließlich als Hochfrequenzhandel. Gomolka (2011) hingegen fasst unter dem Algorithmic Trading sowohl das High-Frequency Trading (in Sekundenbruchteilen) also auch das Systematic Trading (längerfristig über mehrere Tage) zusammen. Er betont, dass Computerprogramme nicht nur kurzfristig (z. B. zum Flash Trading) eingesetzt werden, sondern auch langfristig im Ablauf mehrerer Minuten, Stunden oder Tage selbständig handeln können.\n\nIm Gegensatz zur Computerbörse, bei der Computer nur als Kommunikationsplattform für die Verknüpfung von passenden Kauf- und Verkaufsangeboten dienen, platziert das System selbständig solche Angebote und sucht sich Handelspartner. Sie werden mitverantwortlich gemacht für den Börsenkrach am 19. Oktober 1987, den Schwarzen Montag. Ihre „Wenn-dann“-Algorithmen sollen dafür gesorgt haben, dass immer mehr Aktienpakete abgestoßen wurden, nachdem die Kurse zu fallen begonnen hatten, was letztlich zu panikartigen Verkäufen geführt habe. Am 6. Mai 2010 fiel der Dow Jones innerhalb von acht Minuten um über 1000 Punkte. Ausgelöst wurde dieser Crash jedoch ursprünglich nicht durch High Frequency Programme, sondern eine Sell-Order des Handelshauses Waddell & Reed, das 75,000 S&P500 E-Mini Future Kontrakte innerhalb 20 Minuten per Market Order in den Markt gab. Dieser Flash Crash veranlasste die SEC zu einer Verschärfung ihrer Circuit-Breaker-Regeln, wonach zukünftig Kurseinbrüche von über 10 % bei einer Aktie zu einem automatischen Aussetzen des Handels führen sollen.\n\n"}
{"id": "2015530", "url": "https://de.wikipedia.org/wiki?curid=2015530", "title": "Marble (Computerprogramm)", "text": "Marble (Computerprogramm)\n\nMarble ist ein freies Programm zum Anzeigen von geographischen Karten. Es wurde für die KDE Software Compilation 4 entwickelt, basiert auf Qt4 und ist Teil des KDE-Bildungsprojektes. Es läuft auf allen gängigen Betriebssystemen, wie zum Beispiel Linux, Mac OS X und MS Windows.\n\nGeothek ist eine Abspaltung von Marble. Geothek wird vom Verlag Ed. Hölzel entwickelt und als Software für Schulatlanten vertrieben.\n\nDas Programm kann die Erdkugel und weitere Himmelskörper wie Mond, Mars oder Venus zeigen, die beliebig gedreht und vergrößert werden können. Der mitgelieferte Umfang beträgt 5–10 Megabyte an Vektor- und Bitmap-Daten. Weiteres Kartenmaterial wird automatisch aus dem Internet nachgeladen und kann manuell hinzugefügt werden. Zudem ist es auch möglich, eigene Karten zu erstellen und zu integrieren.\n\nViele weitere Funktionen wurden in den nachfolgenden KDE-Versionen hinzugefügt. So sind nun noch mehr Weltkartenansichten möglich. Neben der klassischen Weltkugel und einer flachen Karte ist auch eine Mercator-Projektion auswählbar. Wolkenbilder können über das Internet live auf die Weltkugel projiziert werden und aktuelle Wetterdaten können für viele Orte angezeigt werden. Ein Wikipedia-Modul erzeugt Symbole an den Orten, zu denen in der englischen Wikipedia ein Artikel existiert. Auch eine OpenStreetMap-Karte, die mit dem Internet abgeglichen wird, steht dem Benutzer zur Verfügung.\nFerner ist seit KDE SC 4.5 ein Routenplaner enthalten. In seiner mobilen Version läuft Marble auf dem Nokia N900.\n\nMarble gewann den „Qt Center Programming Contest 2007“ in der Kategorie „Desktop Application“.\n\n"}
{"id": "2018369", "url": "https://de.wikipedia.org/wiki?curid=2018369", "title": "Open ModPlug Tracker", "text": "Open ModPlug Tracker\n\nDer Open ModPlug Tracker, ursprünglich \"ModPlug Tracker\", ist ein Musik-Tracker für Windows. Er ist einer der bekanntesten und verbreitetsten Tracker. Das britische \"Computer Music Magazin\" kürte den MPT 2007 als einen der \"Top 5\" freien Musiktracker.\n\nDas Programm wurde ursprünglich von Olivier Lapicque auf Basis des \"ModPlug\" Browser-Plugin und des \"ModPlug Player\", die sich die Wiedergabe von Modulen beschränken, entwickelt. Die erste Version erschien im September 1997 und ist damit einer der ältesten reinen Windows-Tracker. Ältere bekannte PC-Tracker, wie der FastTracker oder Impulse Tracker, waren noch für MS-DOS konzipiert. Lapicque stellte im Jahr 2004 den Quellcode unter die GPL, und ermöglichte so die Weiterentwicklung unter dem Namen \"OpenMPT\". Der \"Schism Tracker\" ist ein weiterer Tracker der auf dem ModPlug-Code basiert. Im Rahmen dieses Projekts wurden viele Bugfixe an der ModPlug-Bibliothek vorgenommen, welche später wieder beim OpenMPT einflossen (Backport). Der OpenMPT steht ab der Version 1.17.02.53 unter der BSD-Lizenz.\n\nIm Gegensatz zu den meisten anderen Trackern nutzt der ModPlug Tracker für seine grafische Benutzeroberfläche die Funktionen und GUI-Elemente der WinAPI. Er besitzt damit das Standard-Windows \"Look and Feel\", was seine Bedienung intuitiver macht als die eher \"verspielten\" Eigendesigns anderer Tracker, die sich häufig noch an Trackern der DOS-Ära orientieren.\n\nAls einer der ersten Tracker unterstützte er das parallele Öffnen und Bearbeiten von mehreren Modulen.\nBis zu 127 Kanäle werden gleichzeitig unterstützt, auch können VST-Plugins (auch VST-Instrumente) genutzt werden und es existiert ASIO Support.\n\nDas Programm kann ungefähr zwei dutzend verschiedene Modul-Formate importieren, speichern kann es die Formate MOD, S3M, XM, IT und das eigene Dateiformat MPTM. Exporte von Modulen in diverse Stream-Formate (WAV, FLAC, Opus, Vorbis, und bei entsprechend installiertem Encoder auch MP3) sind möglich.\n\nVom ModPlug Tracker wurde ursprünglich die Bibliothek \"libmodplug\" abgespalten, um die Abspielroutine des Trackers auch unter Linux verwenden zu können, beispielsweise als Plugin für XMMS zum Abspielen von Musik-Modulen. In einigen Linux-Distributionen (z. B. Debian) ist das Plugin als Standardpaket vorinstalliert.\n\nDa die libmodplug-Bibliothek jedoch in den vergangenen Jahren nur noch wenige Updates erhalten hat, wurde die Bibliothek \"libopenmpt\" veröffentlicht, die parallel zu OpenMPT weiterentwickelt wird. Auf Basis dieser Bibliothek wurden beispielsweise Player-Plugins für XMPlay, Winamp und foobar2000 entwickelt, welche auf der offiziellen Website heruntergeladen werden können.\n\n"}
{"id": "2020353", "url": "https://de.wikipedia.org/wiki?curid=2020353", "title": "Apple TV", "text": "Apple TV\n\nApple TV ist eine Set-Top-Box des Herstellers Apple. Sie wird an ein Fernsehgerät oder an einen Bildschirm angeschlossen und kann auf diesem verschiedene Medieninhalte wiedergeben, die sie über ein lokales Netzwerk oder das Internet erhält.\n\nAm 1. September 2010 stellte Apple die zweite, am 7. März 2012 die dritte und am 9. September 2015 die vierte Generation vor.\n\nDie fünfte Generation wurde unter der Bezeichnung Apple TV 4K am 12. September 2017 eingeführt.\n\nNach dem Erfolg von iTunes ging Apple der Frage nach, wie das optimale Gerät für iTunes im Wohnzimmer aussehen könnte. In Form des iPods existierte bereits ein mobiles Gerät für iTunes. Anders als üblich kündigte Steve Jobs auf der Präsentation am 12. September 2006 ein neues Produkt namens iTV noch vor der Fertigstellung an. Dass eine Set-Top-Box keinen TV-Empfang und auch keinen DVD-Spieler beinhaltet, ist ungewöhnlich und wurde von Steve Jobs begründet mit der Überlegung, dass der typische Haushalt im Wohnzimmer bereits alle Geräte zum Abspielen von CD, DVD und zum Aufnehmen von Videos besitze. Das einzige, was fehle, sei ein iTunes-Player, mit dem man seine digitale Mediensammlung vom Computer in das Wohnzimmer bekomme.\n\nDas iTV wurde daher nur als WLAN-Empfangsgerät präsentiert. Steve Jobs begründete seine Argumentation mit zahlreichen Abbildungen typischer Wohnzimmer mit vielen übereinandergestapelten Geräten; dabei lag stets ein iTV obenauf.\n\nIm Januar 2007 wurde das fertige Produkt als Apple TV vorgestellt, um Namens-Konflikten mit dem britischen Fernsehsender Independent Television (ITV) aus dem Weg zu gehen.\n\nGegenüber der Präsentation vom 12. September hatte die erste Generation des Apple TV eine eigene Festplatte erhalten und ein vollständiges Betriebssystem auf Basis von Mac OS X. Auch mit der deutlich erhöhten Hardwareleistung blieb das Nutzungskonzept gleich.\n\nSeit April 2009 werden in iTunes auch deutschsprachige Kinofilme angeboten. Erst seitdem sind die IPTV-Funktionen (Internet-TV) im Apple TV auch in dem Umfang nutzbar wie bei der Markteinführung 2007 angekündigt.\n\nAls Betriebssystem wurden beim Apple TV der ersten Generation speziell angepasste Versionen von Mac OS X verwendet. Bei der ursprünglich \"Apple-TV-Software\" genannten ersten Version wurde noch eine angepasste Version des auch unter Mac OS X Tiger (10.4, 2005) verfügbaren Programms Front Row als Benutzeroberfläche genutzt. Bis Version 3 bildete Mac OS X weiterhin direkt die Basis der \"Apple-TV-Software\", da das erste Apple TV – wie die Computer von Apple ab 2006 – eine IA-32-Prozessorarchitektur (Prozessoren von Intel) bietet.\n\nAb Version 4 basiert die \"Apple-TV-Software\" direkt auf iOS und somit nur noch mittelbar auf Mac OS X. Daher ist sie nur auf der im Apple TV ab der zweiten Generation verwendeten ARM-Architektur – wie sie auch in mobilen Apple-Geräten wie iPhone, iPad und Apple Watch genutzt wird – lauffähig. Apple entwirft die eingesetzten ARM-Prozessoren selbst.\n\nAb der vierten Generation des Apple TV wird ein neues Betriebssystem namens tvOS verwendet, das allerdings weiterhin auf iOS basiert. Die Versionsnummer wurde an jene von iOS angeglichen, sodass die erste Version von tvOS die Versionsnummer 9.0 trägt. Auf älteren Generationen des Apple TV läuft tvOS nicht. Neben einer komplett überarbeiteten Benutzeroberfläche bietet es u. a. einen App Store und die Sprachsteuerung Siri.\n\nUrsprünglich konnte Apple TV nur mit der mitgelieferten Fernbedienung Apple Remote bedient werden, so dass Inhalte außerhalb von Apple TV immer eine zweite Fernbedienung erforderten. Später führte Apple weitere Bedienkonzepte ein:\n\n\n\n\n\nMit der vierten Generation von Apple TV kamen drei weitere Eingabewege im Dezember 2015 hinzu:\n\n\n\n\nDie erste Generation des Apple TV erschien am 21. März 2007. Es enthielt eine 40-GB-Festplatte, am 31. Mai 2007 erschien zudem ein Modell mit 160 GB. Während die 40-GB-Variante am 14. September 2009 vom Markt genommen wurde, blieb das 160-GB-Modell bis zum Erscheinen der zweiten Generation erhältlich. Es hat äußerlich eine große Ähnlichkeit mit dem ursprünglichen Mac mini, ist aber flacher und breiter und besitzt die Abmessungen der damals aktuellen Time Capsule bzw. des Mac mini von Apple. Trotz seiner Ähnlichkeit mit einem Mac mini zählt Apple den Apple TV nicht zur Mac-Produktreihe, sondern ordnete ihn auf der Apple-Webseite in die Produktreihe iPod und iTunes bzw. iTunes ein.\n\nÜber die WLAN- oder Ethernetschnittstelle werden Mediendateien (Musik, Videos, Fotos) aus der iTunes-Bibliothek eines Windows-PCs oder eines Macintosh-Rechners auf die Festplatte des Apple TV synchronisiert und können dann auf einem Fernseher oder Bildschirm betrachtet werden. Bis zu fünf weitere Computer können ihre Daten per Streaming an das Apple TV senden, die dort also nur unmittelbar angezeigt, aber nicht gespeichert werden. Weiter spielt das Apple TV auch Kinotrailer von der QuickTime-Webseite sowie Videos von YouTube ab. Mit der Betriebssystem-Version 2.0 können sowohl Musikstücke als auch Videos direkt vom Apple TV im iTunes Store gekauft werden. Sie werden ebenfalls auf die Festplatte des Apple TV heruntergeladen, die bei der nächsten Synchronisation mit iTunes abgeglichen wird. Auch Podcasts können direkt aus dem Internet „gestreamt“ werden. Das Gerät verfügt außer der Fernbedienung über keine Tasten. Ein Ausschalten ist nicht vorgesehen, es existiert lediglich ein Standby-Modus, der per Fernbedienung aktiviert werden kann.\n\nEinen Fernsehempfänger oder eine digitale Videorekorderfunktion besitzt das Gerät nicht, deshalb können nur Inhalte aus einer iTunes-Bibliothek abgespielt werden. Jedoch ist es möglich, einen externen USB-TV-Tuner anzuschließen und mit Hilfe geeigneter Betriebssysteme (z. B. Linux) weitere Funktionen nachzurüsten.\n\nAm 1. September 2010 stellte Steve Jobs (damals Apple-CEO) auf einer Pressekonferenz eine neue Generation des Apple TV vor. Seit dem 11. November 2010 ist Apple TV auch in der Schweiz, Österreich und Italien erhältlich; gleichzeitig bot nun dort der iTunes Store auch Filme. Der Kunde erhält mit der zweiten Generation die Möglichkeit, Filme in HD-Qualität (720p) anzuschauen und Fotos und Musik direkt vom Computer zu streamen. Ferner können Filme und Musik über AirPlay drahtlos von einem iPod, iPhone oder iPad an das Gerät im lokalen Netzwerk übertragen werden.\n\nGebrauchtgeräte dieser Generation erzielen gegenüber dem Folgemodell deutlich höhere Preise, da bei diesen mit Hilfe des Jailbreaks von Apple nicht vorgesehene Software wie das XBMC Media Center oder aTV Flash zum Einsatz kommen kann. Diese ermöglichen u. a. auch die Wiedergabe von Medienformaten wie DivX, Xvid und Matroska; ferner gibt es einen HTML5-fähigen Webbrowser.\n\nDie dritte Generation des Apple TV wurde im März 2012 vorgestellt. Äußerlich blieb das Gerät gegenüber der zweiten Generation unverändert, jedoch wurde der Hauptspeicher auf 512 MB vergrößert und ein Upgrade des Chipsatzes (Prozessor, Grafikeinheit, WLAN-Hardware) vorgenommen: Das Gerät verwendet den Apple A5 in der Single-Core-Variante. Dies ermöglicht jetzt auch Filme in Full-HD-Qualität (1080p) abzuspielen. Bis heute existiert für diese Version kein Jailbreak.\n\nIm März 2013 wurde das interne Design erneut überarbeitet; durch eine Veränderung des Chipdesigns konnten weitere Stromeinsparungen erzielt werden. Neue Funktionen wurden jedoch (bis auf Peer-to-Peer-AirPlay ab Apple-TV-Software 7.0) nicht implementiert. Das überarbeitete Modell wird als \"Apple TV (3. Generation) Rev A\" (A1469) bezeichnet.\n\nAm 9. September 2015 präsentierte Apple die vierte Generation des Apple TV. Die vierte Generation des Apple TV konnte ab dem 26. Oktober vorbestellt werden; die Auslieferung begann am 29. Oktober 2015. Das Gerät hat die gleiche Form wie das der zweiten und dritten Generation, ist jedoch etwas höher. Es verwendet eine Variante des Apple A8 mit 2 GB Hauptspeicher und beherrscht zusätzlich zu den von der dritten Generation unterstützten Funkstandards nun auch WLAN 802.11ac. Der Ethernet-Anschluss blieb bestehen und der optische Audioausgang wurde entfernt. Der Micro-USB-Anschluss des Vorgängermodells wurde durch USB-Typ C ersetzt. Dieser USB-Anschluss dient primär der Wartung und Diagnose, sekundär können Softwareentwickler diese auch offiziell zur Aufzeichnung von Bildschirmvideos nutzen. Zusätzlich gibt es noch einen Infrarot-Empfänger für Fernbedienungen von älteren Fernsehern und älteren \"Apple Remote\". Für Apps zum tvOS wurde das Gerät mit 32 oder 64 GB Flash-Speicher angeboten. Die mitgelieferte Fernbedienung wurde komplett überarbeitet und trägt den neuen Namen Siri Remote. Diese bietet nun ein Touchpad, einen Beschleunigungssensor und ein Gyroskop sowie zwei Mikrofone für die Nutzung von Siri.\n\nMit der Vorstellung des Nachfolgemodells wurde das 32-GB-Modell der 4. Generation im Preis gesenkt und die 64-GB-Variante eingestellt.\n\nMit dem Apple TV 4K wurde am 12. September 2017 die fünfte Generation des Apple TV vorgestellt. Namensgebend ist die Fähigkeit zur Wiedergabe von 4K- und HDR-Inhalten. Äußerlich gleicht es der vierten Generation, die Gehäuseabmessungen sind identisch. Mit dem Apple A10X Fusion kommt der SoC des iPad Pro der zweiten Generation zum Einsatz, im Apple TV jedoch mit 3 GB Arbeitsspeicher. Wegen der hohen Leistung ist zur Kühlung ein Lüfter verbaut, anders als beim Vorgängermodell. Erstmals im Apple TV wird Gigabit-Ethernet, \"simultanes\" Dualband-WLAN sowie Bluetooth unterstützt. Der USB-C-Anschluss für Wartung und Diagnose entfällt. Wie die vorige Generation ist das Gerät mit 32 oder 64 GB Flash-Speicher erhältlich und wird mit Siri Remote geliefert.\n\n\n"}
{"id": "2023068", "url": "https://de.wikipedia.org/wiki?curid=2023068", "title": "Windows Live Mail", "text": "Windows Live Mail\n\nWindows Live Mail, früher \"Windows Live Mail Desktop\", ist ein nicht mehr gepflegter E-Mail-Client von Microsoft. Das Programm ist der Nachfolger von Outlook Express für Windows XP bzw. von Windows Mail für Windows Vista.\n\nWindows Live Mail wurde vom selben Team entwickelt, das Outlook Express und daraus Windows Mail entwickelt hat. Die erste freigegebene Version wurde im November 2007 veröffentlicht und trug die Versionsnummer 12.\nMicrosoft hat den Support von Windows Live Mail am 10. Januar 2017 eingestellt und bietet es nicht mehr zum Download an.\n\nDas Programm konnte über den Installer der Produktlinie Windows Essentials installiert werden.\n\nIm Gegensatz zu Outlook Express und Windows Mail unterstützt Windows Live Mail keine Skriptsprache in Vorlagen mehr. Dafür ist ein Kalender integriert.\n\nWindows Live Mail enthält viele andere Funktionen aus Windows Mail und folgende Neuerungen:\n\n"}
{"id": "2045780", "url": "https://de.wikipedia.org/wiki?curid=2045780", "title": "Flutsch und weg", "text": "Flutsch und weg\n\nFlutsch und weg ist ein britisch-US-amerikanischer Computeranimationsfilm der Regisseure David Bowers und Sam Fell aus dem Jahr 2006. Die Komödie basiert auf einem Filmskript von Fell, der es gemeinsam mit den Drehbuchautoren Peter Lord, Dick Clement und Ian La Frenais verfasste. Der Film, eine Coproduktion von DreamWorks Animation und Aardman Animations, startete am 7. Dezember 2006 in deutschen Kinos.\n\nRoddy St. James, eine verwöhnte Ratte im Londoner Stadtteil Kensington, hat so gut wie alles, was man zum Leben braucht: einen goldenen Käfig, reichlich zu essen und einen Fernseher mit DVD-Spieler, den er, wenn seine Besitzer aus dem Haus sind, als Autokino benutzt. Das Einzige, was ihm fehlt, sind Freunde, denn die Spielfiguren, mit denen er sich abgibt, sind nicht besonders gesprächig. All dies ändert sich, als eines Nachts die unflätige und fußballbegeisterte Kanalratte Sid aus dem Spülbecken kommt und vorhat, in Roddys Haus zu bleiben. Roddy versucht Sid vorzutäuschen, dass die Toilette ein Whirlpool ist, um den ungebetenen Störenfried wieder loszuwerden. Allerdings durchschaut Sid den Trick und spült stattdessen Roddy in die Kanalisation hinab. Nach einer turbulenten Reise durch die Abwasserkanäle sieht er, dass es unten eine Stadt gibt, die genau wie London aussieht. Der größte Wunsch von Roddy ist es jedoch, wieder in die \"Oberwelt\" zu gelangen. Ein alter Seebär rät ihm, sich an Rita, Kapitän der \"Jammy Dodger\" zu wenden.\n\nRoddy macht sich auf die Suche nach Rita und findet sie auch. Sie besitzt einen vermeintlich echten Rubin, den der kaltblütige Obergauner \"Kröte\" gerne besitzen würde. In einer Verfolgungsjagd schaffen sie es jedoch, zu entkommen und gleichzeitig das Hauptkabel für eine Maschine der Kröte zu entwenden, die nun funktionsunfähig ist. Sie entdecken aber, dass der Rubin nicht echt ist. Roddy und Rita vereinbaren, dass er ihr echte Rubine gäbe, sollte sie ihm helfen, wieder nach Hause zu kommen. Auf dem Weg zurück in die Oberwelt besuchen sie Ritas Familie. Roddy stellt fest, dass Rita und ihre Familie trotz ihrer rustikalen und finanziell knappen Lebensweise weitaus reicher sind, als er je war. Auch die hitzköpfige Kröte hat noch nicht aufgegeben und will ihren Plan in die Tat umsetzen, mit Hilfe der Maschine (die ein geschlossenes Schleusentor bedient) die ganze Stadt während des Finales der Fußball-Weltmeisterschaft zu ertränken, damit er und seine Kaulquappen den Platz der Ratten in der Kanalisation übernehmen können. Zu dem Zweck benötigt er jedoch das Hauptkabel, das Rita seit ihrer Flucht als Gürtel benutzt. Weil seine zwei Handlanger, die dümmliche weiße Laborratte Bleichie und die hitzköpfige Ratte Spike, aber mehr als unfähig sind, schickt er seinen französischen Cousin \"Le Frosch\" los, um die zwei Freunde zu beseitigen und das Hauptkabel zurückzuholen.\n\nRoddy und Rita schaffen es zwar, ihm und seinen Kumpanen zu entkommen, doch bei der Verfolgungsjagd versinkt die \"Jammy Dodger\" in den Tiefen des Abwasserkanals. Roddy und Rita gelangen jedoch mit Hilfe eines Plastiksackes, den sie als Fallschirm benutzen, in die Oberwelt. In Roddys Haus angekommen, überreicht er Rita den versprochenen echten Rubin aus einer Schatulle seiner Besitzerin. Zudem stellt Rita fest, dass Roddy in einem Käfig wohnt. Jedoch ist er zu stolz, um zuzugeben, dass er nicht frei ist. Rita beschließt, in die Unterwelt zurückzukehren, wo es Le Frosch und seinen Kumpanen gelingt, Rita gefangen zu nehmen und das Hauptkabel der Kröte zurückzubringen. Diese kann die todbringende Maschine wieder in Gang bringen. Roddy sieht sich derweil mit Sid zusammen die Fußball-Weltmeisterschaft an. Als dieser zufällig erwähnt, dass Roddy nicht zu viel trinken solle, damit er erst in der Halbzeit auf die Toilette müsse, wird Roddy klar, wie „der Plan der Kröte“ lautet.\n\nRoddy entschließt sich, Sid seinen Platz in Kensington zu überlassen, damit er die Stadt und vor allem Rita vor der Überflutung retten kann. Roddy gelingt das Unglaubliche und er kann auch die Kröte und Le Frosch außer Gefecht setzen. Roddy hat jetzt in der Unterwelt alles, was er braucht, um glücklich zu sein, vor allem seine Rita. Sid hingegen hat es in seinem neuen Heim bequem, bis sein Frauchen ihm einen „Spielgefährten“ mitbringt: Eine Katze.\n\n\nDer Film wurde im Jahr 2006 als \"Bester animierter Film\" für den Satellite Award nominiert. Er wurde 2007 in der jeweils vergleichbaren Kategorie für den BAFTA Award, den Saturn Award, den Broadcast Film Critics Association Award und den \"Motion Picture Producer of the Year Award\" nominiert. Der Film gewann 2007 den für animierte Filme vorgesehenen Annie Award in fünf Kategorien und wurde in drei weiteren Kategorien für den gleichen Preis nominiert. Er wurde 2007 für den Tonschnitt für den \"Golden Reel Award\" nominiert.\n\nDie Deutsche Film- und Medienbewertung FBW in Wiesbaden verlieh dem Film das Prädikat besonders wertvoll.\n\nDie Produktionskosten betrugen schätzungsweise 143 Millionen US-Dollar. Der Film spielte in den Kinos der USA etwa 64,5 Millionen US-Dollar ein und in den britischen Kinos etwa 10,6 Millionen Pfund Sterling.\n\n\n"}
{"id": "2053917", "url": "https://de.wikipedia.org/wiki?curid=2053917", "title": "Active Desktop", "text": "Active Desktop\n\nActive Desktop ist eine Funktion des Betriebssystems Microsoft Windows, um Webseiten direkt auf dem Desktop anzuzeigen. Sie ist Bestandteil der \"Active Platform\". Anwender können beliebige Webseiten oder spezielle \"Channels\" als voneinander unabhängige Anzeigeblöcke auf dem Desktop platzieren. Es ist möglich, Inhalte aus dem Internet in regelmäßigen Abständen synchronisieren zu lassen, um so die Inhalte auf den aktuellen Stand zu bringen, ohne die betreffende Webseite im Browser aufrufen zu müssen.\n\nDer Active Desktop wurde mit der Fertigstellung des Internet Explorers 4.0 für Windows 95 und Windows NT 4.0 1997 eingeführt. Nach der Argumentation von Microsoft sollte der Active Desktop das Argument schlechthin für den Kauf von Windows 98 darstellen. Mit ihm wurde es in Windows 98 erst möglich, Hintergrundbilder in den Formaten JPG, GIF oder PNG zu verwenden (allerdings vorerst nur, indem man sie in ein HTML-Dokument integriert). Vorher konnten nur Bilder im BMP-Format verwendet werden. Dabei wurde jedoch gerne verschwiegen, dass dieses zusätzliche Feature einen beträchtlichen Teil des Arbeitsspeichers der damaligen Computer für sich beanspruchte.\n\nWindows 2000 und Windows XP beinhalten diese Funktion noch. Das Feature wurde von Microsoft jedoch seit einigen Jahren nicht mehr weiter entwickelt.\n\nSeit Windows Vista ist diese Funktion nicht mehr enthalten. Abgelöst wurde es durch die Sidebar, unter Windows 7 „Desktop Gadgets“, mit denen man Multimedia-Inhalte und Windows-Live-Gadgets anzeigen lassen kann.\n\n"}
{"id": "2054074", "url": "https://de.wikipedia.org/wiki?curid=2054074", "title": "ZRA 1", "text": "ZRA 1\n\nDer Zeiss-Rechen-Automat 1, kurz ZRA 1, war der erste serienmäßig hergestellte programmierbare Digitalrechner in der DDR. Er wurde beim VEB Carl Zeiss in Jena entwickelt und hergestellt.\n\nBereits während der Erprobung des Relaisrechners OPREMA 1955 begannen die Entwickler Wilhelm Kämmerer und Herbert Kortum mit der Konzeption einer elektronischen Rechenanlage. Ziel der Entwicklung sollte ein leistungsfähiger Rechner mit wesentlich mehr Speicherplatz zur Bearbeitung wissenschaftlicher und technischer Aufgaben bei hoher Zuverlässigkeit sein. Die Programmerstellung sollte extern erfolgen, damit die Anlage während der Programmierung nicht still stand, wie das bei der OPREMA der Fall war. So entstand der Plan für eine speicherprogrammierbare, bit-seriell arbeitende Ein-Adress-Maschine mit einer Wortlänge von 48 Bit. Kämmerer lieferte die theoretischen Grundlagen, während Kortum die Projektleitung übernahm.\n\nDa die zu dieser Zeit verfügbaren Transistoren für nicht zuverlässig genug erachtet wurden, entschied man sich für Halbleiter-Dioden und Ferrit-Ringkerne als Bauelemente für die logischen Schaltkreise sowie Elektronenröhren zur Signalaufbereitung und Verstärkung. Ende 1956 war der ZRA 1 im Wesentlichen fertig aufgebaut. Zu Schwierigkeiten kam es jedoch mit dem als Hauptspeicher vorgesehenen Scheibenspeicher. Dafür kam 1958 der von Nikolaus Joachim Lehmann an der TH Dresden entwickelte Trommelspeicher mit einer Kapazität von 4096 48-Bit-Worten zum Einsatz. Die Trommel rotierte mit 12.000 Umdrehungen pro Minute, was eine mittlere Zugriffszeit von 2,5 Millisekunden ermöglichte. Insgesamt kamen 12.000 Germaniumdioden (OA 170), 8500 Ferritkerne und 720 Elektronenröhren (PL84) sowie einige Relais zur Steuerung der Peripheriegeräte zum Einsatz. Als Eingabegerät diente ein Lochkartenleser, von dem Programme und Daten in den Hauptspeicher eingelesen wurden.\nZur Ausgabe der Rechenergebnisse wurde das Druckwerk einer bestehenden Tabelliermaschine benutzt.\nDie Anlage benötigte einen Raum von wenigstens 6 × 8 m², die Leistungsaufnahme betrug 19 Kilowatt.\n\nStrukturell handelte es sich um eine Von-Neumann-Architektur mit gemeinsamem Programm- und Datenspeicher. Als Ein-Adress-Maschine war ein Akkumulator, hier Rechenregister genannt, vorhanden. Zusätzlich zum Hauptspeicher gab es acht so genannte Schnellspeicher (Prozessorregister in heutiger Terminologie), in denen oft benötigte Operanden gespeichert werden konnten; damit umging man die relativ langen Zugriffszeiten des Trommelspeichers. Daneben war ein Programmzähler sowie Indexregister vorhanden, einen Stack gab es nicht.\n\nDer Befehlssatz umfasste alle Befehlsgruppen heutiger CPUs:\n\n\nDie Befehle und Daten wurden mit speziellen Lochern binär codiert auf Lochkarten gestanzt; eine Karte fasste zwölf Worte. Später wurde ein Compiler für eine Untermenge von Algol 60 entwickelt.\n\nEinige Verarbeitungszeiten:\n\n\nDamit lässt sich eine mittlere Leistung von etwa 120 FLOPS abschätzen. Zum Vergleich: Ein im Jahr 2005 handelsüblicher PC leistet um drei Milliarden FLOPS.\n\n1960 wurde der ZRA 1 auf der Leipziger Frühjahrsmesse ausgestellt. Gleichzeitig begann im Zeiss-Zweigwerk Saalfeld die Serienfertigung, dort wurden insgesamt 31 Anlagen hergestellt. Die Verteilung der Rechner auf die Institutionen erfolgte durch eine Kommission des Forschungsrates der DDR:\n\n\nEnde 1963 wurde die Herstellung des Rechners zu Gunsten des vom VEB Elektronische Rechenmaschinen in Karl-Marx-Stadt entwickelten, voll transistorisierten Digitalrechners \"Robotron 100\" eingestellt. Eine politische Entscheidung war die Einstellung der Arbeiten am Nachfolgemodell \"ZRA 2\", die zu dieser Zeit schon weit fortgeschritten waren – die Entwicklung von Digitalrechnern sollte beim Kombinat Robotron konzentriert werden. Der Einsatz der Maschinen dauerte bis Ende der 1960er Jahre, als die Robotron 300, die ab 1968 gebaut wurden, in größerer Zahl verfügbar wurden.\n\nTrotz der geringen Stückzahl hatte der ZRA 1 großen Einfluss auf die Informatik in der DDR, da viele Datenverarbeitungs-Fachkräfte der ersten Generation die ersten praktischen Erfahrungen mit Digitalrechnern auf einem ZRA 1 machten.\n\n\n"}
{"id": "2068433", "url": "https://de.wikipedia.org/wiki?curid=2068433", "title": "Psiphon", "text": "Psiphon\n\nPsiphon ist eine freie Software zur Umgehung von Internet-Zensur mittels sogenannter Sozialer Netzwerke (\"social networks\"). Es handelt sich um ein Projekt der Universität Toronto, Kanada, unter der Leitung von Professor Ronald Deibert, Direktor des Citizen Lab. Damit soll Internetbenutzern die Umgehung von verschiedenen Zensur- bzw. Inhaltsfiltersystemen ermöglicht werden.\n\nCitizen Lab setzt auf „vertrauenswürdige“ Kontakte und hofft, dafür möglichst viele Nutzer gewinnen zu können. Im Gegensatz zu öffentlich erreichbaren IP-Adressen von Großservern, die relativ einfach zu sperren sind, fungieren die Psiphon-Rechner privater Nutzer als unabhängige Zugangspunkte, deren IP-Adresse nur einem kleinen Kreis bekannt ist. Über diesen Umweg erschließen sich die Nutzer in den von Inhaltssperren betroffenen Ländern den unzensierten Zugang zum Internet. Die dabei abgerufenen Daten werden verschlüsselt übertragen, wobei der Datenverkehr z. B. über internationale Netzwerke für Finanztransaktionen laufen soll. Es dürfte somit der staatlichen Zensur schwerfallen, die betreffenden Daten aus diesem Datenverkehr herauszufiltern.\n\nDas Anwendungsprogramm muss nicht auf dem Computer des Anwenders installiert werden, sondern kann webbasiert über eine Log-in-Funktion aufgerufen werden. Als zensurfreie Proxyportale fungieren dabei die Rechner von Anwendern, die ihre Geräte dafür zur Verfügung stellen. Der Psiphon-Nutzer in einem von Zensur betroffenen Umfeld muss sich letztlich nur mit einem Psiphon-Nutzer in einem freien Land verbinden, um ungehinderten Zugang zum Internet zu bekommen.\n\nSeit dem 1. Dezember 2006 kann die (nur für die freiwilligen Anbieter notwendige) Software heruntergeladen werden. Sie wurde unter der GNU General Public License (GPL) veröffentlicht.\n\nPsiphon ist Teil des CiviSec Projekts am Munk Centre for International Studies an der Universität Toronto. Es wird unter anderem vom Open Society Institute unterstützt. Auf dem 35C3-Kongress in Leipzig gab es einen rund einstündigen Übersichtsvortrag von einem der Entwickler unter dem Titel \"Cat and Mouse: Evading the Censors in 2018\".\n\n"}
{"id": "2082076", "url": "https://de.wikipedia.org/wiki?curid=2082076", "title": "Olympia Multiplex 80", "text": "Olympia Multiplex 80\n\nOlympia Multiplex 80 war ein computergesteuertes Datenerfassungssystem der Olympiawerke in Wilhelmshaven, des Marktführers in den 1970er Jahren.\n\nOlympia Multiplex 80 ist eine für die Technikgeschichte beispielhafte Anwendung der PDP-8-Minicomputersysteme von DEC. Es war ein \"key to tape\"-Datenerfassungssystem, so wie nur einige Jahre später, Mitte der 1970er Jahre, Maestro I von Softlab.\n\nDEC PDPs waren verhältnismäßig preiswert (den PDP-8 gab es für unter 20.000 US-$) und fanden so schnell Verbreitung in Universitäten und als Prozessrechner, zum Beispiel in der Computerisierung des amerikanischen Telefonnetzes von AT&T.\n\nDie Zentraleinheit von Multiplex 80 wurde mit einem oder zwei DEC PDP-8-Minicomputern gesteuert. An die Zentraleinheit wurden etwa 20 Erfassungsplätze im Multiplexbetrieb angeschlossen.\n\nDie Steuersoftware von Multiplex 80 war in PDP-Assembler von Norbert Dumke geschrieben, die Logikbausteine und Hardwaresteuerung von Gerd Müller konstruiert. Die Anwendungs- und Vertriebskonzeption für den Bank- und Sparkassenbereich war von Kurt Günther und Klaus Hanken.\n\nDie Einweihung der Halle 1 der Hannover Messe CeBIT 1970 - \"Centrum der Büro- und Informationstechnik\" war für die Olympiawerke ein Höhepunkt in der Firmengeschichte. Bereits Ende der 1950er Jahre war die Büroindustrie auf den dritten Platz der auf der Hannover Messe ausstellenden Industriezweige vorgerückt. Olympia war 1970 der größte Aussteller in der neuen CeBIT-Halle und stellte Multiplex 80 vor.\n\nDie erste Installation von Multiplex 80 war bereits im Sommer 1969 bei der Deutschen Bank Hamburg erfolgreich abgeschlossen worden. Es folgten Installationen bei mehreren Großbanken und Sparkassen in Hannover, Frankfurt, Mannheim, München, Wien, Amsterdam und Paris.\n\nAnfang 1972 wurde die direkte Übertragung, ohne Umweg über Magnetbänder, zuerst an Siemens-Großrechnern entwickelt.\n\nDatenerfassungssysteme Multiplex 80 im Gesamtwert von mehr als 10 Millionen Mark wurden bis 1976 in der Bundesrepublik Deutschland installiert.\nEs überwogen kommerzielle Anwendungen bei diesem „zweigleisig“ vertriebenen System: Den Vertrieb für den Bank- und Sparkassenbereich übernahm Olympia direkt, für die Betriebsdatenerfassung wurde Multiplex 80 von der Kabel- und Metallwerke Gutehoffnungshütte AG (Kabelmetal) angeboten.\n\nKabelmetal hatte in den 1960er Jahren mangels anderer Beschaffungsmöglichkeiten für seine eigenen Fertigungsstätten ein DE-System mit dezentraler Erfassung und zentraler Aufzeichnung der Daten selbst entwickelt und dann begonnen, diese Systeme auch an andere zu verkaufen.\n\nDie Zentraleinheit von Multiplex 80 wurde mit DEC PDP-8-Minicomputern mit 4 oder 8 KB Hauptspeicher gesteuert.\n\nDie erfassten Daten wurden blockweise auf Band geschrieben, dann offline mittels IBM-kompatibler Magnetbänder auf eine Großrechneranlage übertragen. Die Bandaufzeichnung erfolgte mit 9-Spuren 800 CPI, NRZI oder 1600 CPI PE (Phase Encoding).\n\n\n"}
{"id": "2084841", "url": "https://de.wikipedia.org/wiki?curid=2084841", "title": "Maestro I", "text": "Maestro I\n\nMaestro I von Softlab in München war eine Plattform zur rechnergestützten Softwareentwicklung und die erste Integrierte Entwicklungsumgebung für Software. Ursprünglich wurde sie unter dem Namen PET/X1150 vertrieben. Diese Bezeichnung setzt sich aus der Verwendung \"Programm-Entwicklungs-Terminal-System\" und dem zugrundeliegenden Philips X1150 Datensammelsystem zusammen. Das System Maestro I wurde weltweit 22.000 Mal installiert, davon (bis 1989) 6.000 Mal in der Bundesrepublik Deutschland. Maestro I war in den 1970er und 1980er Jahren führend auf diesem Gebiet. Größter Abnehmer in den USA wurde die Bank of America. Ein erhaltenes Maestro-I-System ist im Museum of Information Technology in Arlington, Texas ausgestellt.\n\nMaestro I oder PET/X1150 ist ein Teil der Technikgeschichte und war ein wesentlicher Faktor für die Entwicklung von\n\n\nDer Arbeitstag für einen Programmierer sah vor 1975 oft so aus, dass er an einem Fernschreiber oder Kartenlocher ein Programm eintippte und damit zum Computer ging. Dort las er seinen Lochstreifen oder Lochkarten ein und nach dem Start des Programms auch die Daten auf diesen Datenträger.\n\nDie Verbreitung des IBM 3270 Bildschirmterminals, zusammen mit IBM ISPF (Interactive System Productivity Facility) war im Vergleich eine wesentliche Erleichterung. Die Entwicklung nach etwa 1972, bis Anfang der 1980er Jahre, war auch aus Kostengründen sehr langsam.\n\nDer im ISPF integrierte Texteditor ermöglicht es, Quellentexte für Programme im Teilnehmerbetrieb zu erstellen. Dieser Editor wird mittels Steuerbefehlen, Zeilenkommandos und Funktionstasten bedient. Nachteil: der Programmierer bekommt die Reaktionen auf seine Eingaben verzögert, nach dem Ausfüllen einer Seite, somit erscheint die Anwendung dem Benutzer insgesamt als träge und wenig intuitiv.\n\nVerzögert sich die Antwort im Dialogbetrieb, entstehen unweigerlich Brüche in der Arbeit. Wichtig ist das Kurzzeitgedächtnis (vgl. Literatur Atkinson und Shiffrin, 1968, die „Entdecker“ des Kurzzeitgedächtnisses). Beim Rezenzeffekt (engl. \"recency effect\") handelt es sich um ein psychologisches Phänomen. Er besagt, dass später eingehende Information einen größeren Einfluss auf die Erinnerungsleistung einer Person ausübt als früher eingehende Information. Im engeren Sinne ist der Rezenzeffekt ein Phänomen, welches das Kurzzeitgedächtnis betrifft. Im weiteren Sinne tritt er auf, wenn zuletzt wahrgenommener Information aufgrund der besseren Erinnerungsfähigkeit stärkeres Gewicht verliehen wird als früherer Information. Fazit: Bei Verzögerungen verliert der Programmierer den Faden.\n\nMaestro I war in dieser Zeit eine echte Innovation. Nach dem Volkswirt Joseph Schumpeter ist Innovation die Durchsetzung einer technischen oder organisatorischen Neuerung, nicht allein ihre Erfindung. Die „Erfindung“ Kurzzeitgedächtnis wurde technisch nutzbar gemacht. Bei Maestro I wurde jeder Tastendruck direkt zu der Zentraleinheit geleitet und die Reaktionen auf die Eingaben erfolgten unmittelbar, ohne Verzögerung. Dies wurde durch die sehr speziellen Hardwareeigenschaften der Basismaschine erreicht.\n\nEin Vergleich mit anderen Innovationen wie z. B. Ajax ist hier berechtigt. Im Jahr 2005 war der Begriff Ajax zunehmend in den Medien präsent. Google benutzte das asynchrone Kommunikations-Paradigma in interaktiven Anwendungen wie beispielsweise Google Maps. Traditionell übermitteln Webanwendungen Formulare, die zuvor vom Benutzer ausgefüllt wurden. IBM-3270-Bildschirmterminals arbeiten auch mit Auffüllen von Formularen, mit Verzögerungen, störenden Brüchen in der Arbeit. Maestro I hat diese Verzögerungen durch technologische Innovation, ähnlich wie später Ajax auch die früher störende Brüche in der Arbeit überwunden.\n\nHarald Wieler, Mitgesellschafter von Softlab, hat einen ersten Prototyp des PET auf Basis des Philips X 1150 Datensammelsystemes (original ein \"Four Phase system\") seit 1974 entwickelt. Wieler war vorher Architekt der Betriebssystementwicklung für Großrechner von Radio Corporation of America und Siemens. Die Entwicklung von Maestro I wurde mit BMFT-Mitteln gefördert mit dem Ziel eines interaktiver Programmierplatzes für monatlich 1000 D-Mark. Die Erstvorstellung des Systems erfolgte im Oktober 1975 auf der Systems in München.\n\nAnfang des Jahres 1977 wurden von Softlab Datenfernübertragungs-Prozeduren freigegeben, mit denen der PET-Basisrechner Philips X 1150 an IBM-Systeme des Typs S/360/370 beziehungsweise Siemens 4004/7000 Programmdaten versandt und auf diesen Großrechnern im Batchbetrieb kompiliert werden konnten. Dadurch war die Verbindung von interaktiver Programmierung und der Rechenleistung von Systemen möglich, die per Time-Sharing-Verfahren genutzt wurden.\n\nDer außereuropäische Vertrieb des Systems, vornehmlich in den USA, fand durch die Itel Corp. unter dem Namen Maestro statt. Über diesen Weg wurden bis 1978 1200 Programmierarbeitsplatz-Installationen vermarktet.\n\nNachdem Boeing im Jahr 1979 eine Untersuchung durchführte, indem es sein selbstentwickeltes, ähnliches System mit dem PET/X1150 verglich und die Eigenentwicklung zugunsten des PET aufgab, bestellte der amerikanische Flugzeughersteller sieben weitere Systeme bei Softlab. Durch diesen Großauftrag gelang es, auf dem US-amerikanischen Markt nachhaltig Fuß zu fassen. Größter Abnehmer in den USA wurde die Bank of America. Für ihrer Rechenzentrale in San Francisco schaffte die Bank 24 PET-Rechner mit 576 Bildschirm-Stationen an. Nachdem Softlab aufgrund dieses Erfolges eine Filiale in San Francisco gründete, konnten durch diese allein insgesamt rund 100 Systeme mit 2000 angeschlossenen Bildschirm-Arbeitsplätzen in Amerika verkauft werden.\n\nAb dem Jahr 1980 wurden mehrtägige Kurse für die Bedienung des Maestro Systems durch Softlab angeboten.\n\nDie DFÜ-Fähigkeit des PET/X1150 wurde 1982 erweitert, so dass die Maestro-IBM-3270-Emulation aus Effektivitätsgründen auf dedizierte Prozessoren verlagert werden konnte.\n\nNachdem die Herstellung der Philips X 1150 Ende der 1980er Jahre beendet und in der Folgezeit auch die Ersatzteilbeschaffung zunehmend schwieriger wurde, hat Softlab den Nachfolger Maestro II entwickelt.\n\nDie Basismaschine war ein \"Key-to-Disk\"-Datensammelsystem. Historische Vorgänger waren \"Key-to-Tape\"-Systeme Anfang der 1970er Jahre, wie zum Beispiel Olympia Multiplex 80.\n\nMögliche Konfiguration:\n\n\n"}
{"id": "2085051", "url": "https://de.wikipedia.org/wiki?curid=2085051", "title": "WorkNC", "text": "WorkNC\n\nWorkNC ist eine CAD/CAM-Software, die von der französischen Firma Sescoi für die maschinelle Bearbeitung in 2, 2.5, 3, 3+2 und 5-Achsen entwickelt wird. WorkNC wird von über 25 % der Unternehmen aus führenden Wirtschaftsländern, wie z. B. Japan verwendet und ist besonders dafür bekannt, seit seiner ersten Ausgabe im Jahre 1988 ein besonderes Augenmerk auf Automatisierung und Bedienkomfort zu richten. Im Jahre 2002 wurde WorkNC-CAD eingeführt und machte damit aus WorkNC eine komplette CAD/CAM-Anwendung, einen der weltweiten Marktführer in diesem Bereich. Die typischen Benutzer von WorkNC stammen aus folgenden Industriezweigen: Formenbau, Modellbau, Werkzeugbau, Medizin und Zahnmedizin, Automobil, Luftfahrt, Verteidigung und Ingenieurswesen. Der Support von WorkNC wird über die Sescoi-Niederlassungen in den USA, Großbritannien, Frankreich, Deutschland, Spanien, Japan, Indien, China und Korea abgewickelt und von mehr als 50 Vertriebshändlern geführt.\n\nSescoi ist auch ein weltweit führender Software-Lieferant von WorkPLAN, einem ERP-System für die Einzelfertigung und MyWorkPLAN, einer Job-Management-Lösung.\n\nDie erste Version der WorkNC CAM Software wurde von Sescoi 1988 herausgegeben. Die Initiatoren hinter dem Produkt waren Bruno Marko, Sescois Geschäftsführer, und Gérard Billard, Leiter F&E Innovation.\n\nIn den späten 1980er Jahren war die Programmierung von CNC-Maschinen für komplexe Bauteile eine schwierige und langwierige Angelegenheit. Sescoi hatte den Bedarf an 3-Achsen-CAM-Software erkannt und bahnte den Weg für die Entwicklung eines neuen, zuverlässigen und automatischen 3-Achsen-CAM-Systems. Über die Jahre hat Sescoi die ursprüngliche Philosophie hinter WorkNC bewahrt: Beschleunigung der Fräsbahn-Berechnungen, Sicherstellen optimaler Zuverlässigkeit zur Direktbearbeitung von harten Materialien und maximale Automation und Benutzerfreundlichkeit, damit die Programmierung direkt in der Werkstatt erfolgen kann. Automation ist der Leitfaden, der sich durch die gesamte Geschichte der Software zieht. Gemäß Bruno Marko „war es immer das Ziel von WorkNC, sich der CAM-Einknopf-Programmierung so weit wie möglich zu nähern“.\n\nDer Salomon Konzern war 1988 der erste Kunde, der mit WorkNC arbeitete, und verwendet die Software nun seit mehr als 20 Jahren, um Skischuhe und andere Sportausrüstungen herzustellen. Mit zunehmender Nachfrage nach WorkNC erweiterte Sescoi seinen Geschäftsbereich, indem 1991 eine Zweigstelle in den USA eröffnet wurde, 1995 andere in Deutschland und Japan, eine weitere 1997 in Großbritannien, gefolgt von Spanien, Indien, China und Korea.\n\n2002 erfolgte die Ausgabe von WorkNC-CAD und 2003 WorkNC 5-Achsen.\n\nWorkNC G3, die dritte Generation der Software, mit einer integrierten und intuitiven CAD/CAM Benutzerschnittstelle, erschien 2007. Im Jahre 2008 gab Sescoi WorkXPlore 3D heraus, einen extrem schnellen Viewer zum Visualisieren und Analysieren von 3D-CAD-Modellen in Teamarbeit, ohne dass die originale CAD-Anwendung benötigt wird.\n\nIm Jahr 2009 brachte das Unternehmen WorkNC Dental auf den Markt, eine CAD/CAM-Software für die automatische 3- bis 5-Achsen-Fräsbearbeitung von Prothesen, Implantaten oder Zahngerüsten, sowie WorkNC Wire EDM, eine Software für das Drahterodieren.\n\nIm Jahr 2010 stellte Sescoi die WorkNC Version 21, eine neue 64-Bit Version mit Multithreading und Parallel Computing vor. Diese zusätzliche Rechenleistung und Speichernutzung sorgt gerade bei großen Bauteilen oder komplexen 5-Achsen Berechnungen für einen deutlichen Geschwindigkeitszuwachs. Die Berechnungszeiten werden zwischen 30 und 70 % reduziert. WorkNC V21 enthält weiterhin verbesserte und neue Bearbeitungsstrategien.\n\nWorkNC bietet Strategien und Bearbeitungsverfahren für den Werkzeug-, Formen-, und Modellbau. Besonderes Augenmerk wird dabei auf die möglichst einfache, automatische Erzeugung passender Strategien für das Fräsen von Bauteilen gelegt. WorkNC bietet Strategien für die 2D-, 2.5D-, 3D-, 4-Achsen-, 5-Achsen-, Auto-5Achsen-, HVR- (High Volume Roughing), HSC- (High Speed Cutting), HPC- (High Performance Cutting), Drahterodieren- und Laser-Bearbeitung an.\n\nDas CAD-Modul WorkNC-CAD ist in die Software integriert und bietet dem Anwender die Möglichkeit, Formtrennungen zu definieren, Elektroden zu erzeugen und Flächen für die Bearbeitung aufzubereiten.\n\nDie hauptsächlichen Funktionen von WorkNC CAM umfassen:\n\n\n\nDie Spanne von 2- und 2½-Achsen-Strategien umfasst:\n\n\nWorkNC kann Dateien folgender CAD-Formate lesen: DXF, STEP, IGES, CATIA V4 & V5, Unigraphics, SolidWorks, Solid Edge, Parasolid, STL, etc.\n\nWorkNC Dental ist die CAD/CAM-Software von Sescoi für die automatische 3- bis 5-Achsen-optimierte Fräsbearbeitung von Prothesen, Implantaten, Kronen, Brücken und Zahngerüsten.\n\nWorkNC Dental verfügt über eine einfach zu verwendende grafische Benutzeroberfläche, die speziell für Zahnlabore und Zahntechniker ausgelegt ist, die keine Experten der Bearbeitungstechnologien sind. Die Software nähert sich weitgehend dem „Einkopf-CAM“ im zahnmedizinischen Bereich und wurde in Zusammenarbeit mit Fachkräften und Organisationen aus Zahnmedizin und -technik entwickelt und getestet. Ihre automatischen 3- und 5-Achs-Fräsbahnen verbinden sich mit der Nesting- und Orientierungs-Technologie für prothetische Implantate. Zusätzlich stehen Werkzeuge zum Hinzufügen von Haltern und Identifikationsmarkierungen zur Verfügung, so dass die Software eine Lösung für die schnelle Herstellung von Prothesen ist.\n\nSTL- und native Dental-CAD-Formate werden in WorkNC Dental importiert, damit der Bearbeitungs-Assistent den Benutzer dann durch den Herstellungsprozess führt. Das System wählt automatisch die Werkzeuge, Bearbeitungsfolgen und Schnittbedingungen, die für bestimmte Materialtypen wie Chrom-Cobalt-Molybdän, Titan und Zirconium(IV)-oxid und für bestimmte Prothesentypen wie Kronen und Brücken optimiert wurden. Die komplexe Natur einiger Implantate bedarf der Verwendung von 5-Achsen-Bearbeitungsmethoden, um alle Teile des Werkstücks erreichen zu können. Dazu werden normalerweise hochqualifizierte Programmierer benötigt. WorkNC Dental beseitigt dieses Problem mit seiner automatischen 5-Achsen-Software. Die dem System innewohnende Intelligenz berücksichtigt die Grenzen und Kinematik der Werkzeugmaschine und produziert automatisch zuverlässige und kollisionsfreie 5-Achsen-Fräsbahnen.\n\nWorkNC MPM ist ein CAD/CAM Modul, das dem Benutzer erlaubt, einfach mehrere Teile gleichzeitig auf derselben Maschine zu bearbeiten. Die Maschinenbediener werden mit etlichen Problemen aufgrund der vielen Werkzeugwechsel konfrontiert: Kollisionen, Stillstandszeit und mangelnde Präzision\n\nDas Modul MPM von WorkNC beseitigt diese Probleme und bietet wirklichen Produktivitätszuwachs durch eine Optimierung der Arbeitsgänge. Es ist keine Programmierung erforderlich und es ist auch nicht notwendig, zusätzliche Werkstück-Nullpunkte zu definieren.\n\nAuch die Anzahl der Werkzeugwechsel wird erheblich reduziert. Probleme aufgrund von fehlerhafter Werkzeug-Nummerierung werden beseitigt und es gibt keine Kollisionen zwischen den Werkstücken.\n\nDie Verwendung von vordefinierten Paletten Systemen garantiert eine schnelle und sichere Fräsbearbeitung.\nMPM kann die gesamte, mit Elektroden bestückte Palette als ein zu bearbeitendes Bauteil betrachten, wobei jedes Werkzeug für alle Elektroden auf der Palette verwendet wird. Die Software sichert kollisionsfreie Fräsbahnen über die gesamte Palette und vermindert drastisch die Anzahl der Werkzeugwechsel, die anderenfalls nötig wären. MPM ermittelt automatisch eine sichere Rückzugshöhe, die sich aus der höchsten Elektrode ergibt, und die klare Darstellung im Programm ermöglicht dem Bediener, auch kleinste potentielle Probleme sofort zu erkennen.\n\nDie hauptsächlichen Vorteile von WorkNC MPM sind folgende: eine Programmierung auf der Maschine ist nicht nötig, einfache und zuverlässige Positionierung der Werkstücke, mannlose Fräsbearbeitung, optimale Benutzung von Aufspannungen und Paletten, erhebliche Verminderung der Werkzeugwechsel, Flexibilität und Anpassungsfähigkeit bei Änderungen, Spiegeln und Rotation der Werkstücke, ohne eine Neuberechnung der Fräsbahnen vornehmen zu müssen.\n\nWorkNC-LMP ist eine CAD/CAM Software, um Teile in Schichten zu fräsen. Vorteile dieser Technologie sind die Möglichkeiten tiefe Sicken und enge Kavitäten zu fräsen.\n\nWorkNC-LMP teilt ein 3D Modell automatisch in Schichten und generiert Fräsbahnen für jede Schicht. Diese Technologie kann auf jeder Fräseinheit angewendet werden. Die Programmierung und anschließende Fräsbearbeitung wird durch die Aufteilung einer komplexen Geometrie in viele Schichten vereinfacht.\n\nSescoi entwickelte in Zusammenarbeit mit F. Zimmermann diese Technologie durch die Kombination von der Genauigkeit und Geschwindigkeit von Zimmermann LMC (Layer Milling Centre) mit Sescoi’s WorkNC-LMP. Mit der Benutzung dieser Software in Verbindung mit der Fräsmaschine, alle Fräsbahnen und Maschinenbedienungssequenzen wurden automatisch generiert und ein mannloser Betrieb war möglich.\n\nDie LMC arbeitet unter Benutzung von Hochgeschwindigkeitsbearbeitung von unten nach oben, um jede Schicht herzustellen. Jede Schicht wird nacheinander geschruppt und geschlichtet und wird dann mit der nächsten Platte verklebt. Diese wird im nächsten Schritt wiederum bearbeitet und somit wird das Werkzeug nach und nach aufgebaut. WorkNC-LMP arbeitet automatisch vom CAD Modell bis zum fertigen Werkzeug. Diese Technologie ist ideal für die Hochgeschwindigkeitsbearbeitung mit kurzen Fräsern und Reduzierung von Kollisionen. WorkNC-LMP erlaubt die Auswahl von Materialien aus einer Materialbibliothek und Einstellung von Oberflächenqualität, sowie die Einstellung der Klebermenge. Überflüssiger Kleber wird durch die Überlappung von Fräsbahnen entfernt. Die Software ermöglicht eine visuelle Kontrolle der Fräsbahnen, sowie eine Abschätzung der Fräszeit.\n\nWorkNC-LMC kombiniert die Vorteile des konventionellen Fräsens mit den Vorteilen von Generativen Fertigungsverfahren des Rapid Prototypings.\n\nWorkNC-CAD ist eine CAD Software für die Fertigung, die sowohl Funktionen zur Modellierung von Flächen als auch von Festkörpern enthält. Die Software ist kostenfrei standardmäßig als Komponente in WorkNC enthalten. Bietet sie alle Features, um Formen und Werkzeuge zu konstruieren und herzustellen, ohne dass zusätzliche Anwendungen oder Zulieferer gebraucht werden.\n\nWorkNC-CAD verfügt über fortgeschrittene und intelligente Funktionen zum Wandeln von Flächen, um einfache oder komplexe Kavitäten zu füllen, über eine automatische 2D Feature-Erkennung und Zyklusdefinition für Bohren, Senken, Reiben und Gewindeschneiden, und über eine automatische Trennung von Kern und Matrize.\n\nWorkNC-CAD Hybrid Modeling (HM) ist eine 3D CAD Software, die von Sescoi 2010 für Design und Vorbereitung der maschinellen Fertigung entwickelt wurde. Sie kann komplexe Flächen zu erzeugen und verfügt über integrierte Funktionen zur Modellierung von Solids in einer benutzerfreundlichen Umgebung. Die Software kann als unabhängiges CAD-Produkt verwendet werden. Sie nutzt D-Cubed Software Komponenten von Siemens PLM.\n\nWorkNC-CAD HM verwendet parametrische Funktionen auf Solid- und Flächenmodellen, um CAD Geometrien einfach zu editieren und zu modifizieren. Außer einer Vielzahl von CAD Schnittstellen enthält das Programm auch Module für die Erzeugung von Elektroden, der Trennung von Kern/Matrize und zum Drahterodieren. Das WorkNC Elektroden Modul nutzt die Möglichkeiten von WorkNC-CAD Hybrid Modeling zum Ableiten der formgebenden Elektrodengeometrie direkt aus dem Solid- oder Flächenmodell. Die Elektrode kann jederzeit geändert und modifiziert werden und es können Halter und Rohteile aus einer Bibliothek hinzugefügt werden, um eine vollständige Elektrode herzustellen. Die Kollisionsprüfung von WorkNC stellt sicher, dass die Elektrode nicht mit dem Werkstück kollidiert, indem ggf. automatisch Verlängerungen hinzugefügt werden. Die Software generiert eine Dokumentation und das Koordinatensystem der Elektrode, um eine korrekte Positionierung für die Funkenerosion zu gewährleisten.\n\nWorkNC-CAD Hybrid Modeling enthält u. a. folgende Funktionen:\n\nWenn das System als eigenständige Software in den technischen Bereichen der Unternehmen verwendet wird, verfügen Werkzeug- und Formenbauer über ein komplettes, integriertes CAD/CAM Produkt für das gesamte Herstellungsverfahren.\n\nWorkXPlore 3D ist ein extrem schneller Viewer (Dateibetrachter) zum Visualisieren und Analysieren von 3D CAD Modellen in Teamarbeit, ohne auf die originale CAD-Anwendung zurückgreifen zu müssen. Die Software ist ganz einfach zu verwenden und so ausgelegt, dass auch Nichtexperten im CAD-Bereich alle Arten von 2D/3D-CAD-Dateien untersuchen können. Mit WorkXPlore 3D kann der Benutzer Messungen an 3D-Geometrien vornehmen und spezielle Analysetools erlauben die Bestimmung von hinterschnittenen Bereichen sowie ebenen Flächen, Materialstärken, Volumen, Flächeninhalten, Gewicht. Auch die Visualisierung dynamischer Schnitte kann erfolgen. 2D-Zeichnungen werden nicht mehr gebraucht, da Bemaßungen für Größe und Geometrie, Anmerkungen und Labels direkt in das 3D-Modell eingefügt werden können.\n\nWorkXPlore 3D erlaubt dem Benutzer 3D-Teile und Baugruppen Subunternehmern, Kunden und Mitarbeitern ganz einfach zur Verfügung stellen. Dazu ist eine kompakte und reduzierte Anwendung vorhanden, die als ausführbare Datei ganz leicht via Internet versandt werden kann. Der Empfänger kann sich sofort das 3D-Modell anzeigen lassen und damit arbeiten. WorkXPlore 3D kann große 3D-Dateien extrem schnell öffnen und verarbeiten. Eine kostenlose Viewer-Version und eine Gratis-Testversion sind verfügbar.\n\n"}
{"id": "2090000", "url": "https://de.wikipedia.org/wiki?curid=2090000", "title": "Configuration Interaction", "text": "Configuration Interaction\n\nConfiguration Interaction (CI) bezeichnet eine Methode zur Lösung der Schrödinger-Gleichung (bzw. ihrer relativistischen Verallgemeinerungen), die besonders in der Quantenchemie verwendet wird. Die Vielteilchen-Wellenfunktion wird dabei in eine Basis aus Slater-Determinanten entwickelt, wodurch die Schrödinger-Gleichung auf ein Matrix-Eigenwertproblem reduziert wird. Die (teilweise) Diagonalisierung dieser Matrix liefert dann die Eigenzustände des quantenmechanischen Systems.\n\nDie Schrödingergleichung\n\nstellt eine Operatorengleichung für abstrakte Vektoren in einem Hilbertraum dar. Zu deren Lösung wählt man eine bestimmte Darstellung der Wellenfunktion. Eine Einteilchenwellenfunktion lässt sich z. B. durch Entwicklung in eine Basis formula_2 der Größe formula_3 auf einem Einteilchen-Hilbertraum formula_4 darstellen:\n\nformula_6-Teilchenwellenfunktionen sind Elemente des Tensorproduktraums formula_7, der sich aus den jeweiligen Einteilchen-Hilberträumen zusammensetzt. Eine Basis von formula_8 ist durch alle möglichen Produkte der Einteilchenbasis gegeben, sodass die Wellenfunktion wie folgt entwickelt werden kann:\n\nDabei werden die Basisvektoren\n\nals Hartree-Produkte bezeichnet.\n\nAufgrund des Pauliprinzips muss die elektronische Wellenfunktion antisymmetrisch gegenüber Vertauschung zweier Teilchenkoordinaten sein, d. h. formula_11 lebt nur in dem Unterraum formula_12 der antisymmetrischen Funktionen. Die Hartree-Produkte erfüllen diese Forderung nicht, weswegen auch die Wellenfunktion nicht antisymmetrisch sein muss. Um die Antisymmetrisierung zu gewährleisten, kann man die Wellenfunktion auf formula_12 projizieren. Weitaus häufiger jedoch projiziert man bereits vorher die Basisvektoren auf formula_12, wodurch man aus den formula_15 Hartree-Produkten formula_16 Slater-Determinanten erhält,\n\nwobei die Summe über alle möglichen Permutationen geht. Durch die Slater-Determinanten erhält man eine geeignete Basis zur Entwicklung der Wellenfunktion,\n\nSlater-Determinanten sind Eigenfunktionen des projizierten Spins formula_19, jedoch im Allgemeinen keine Eigenfunktionen des Gesamtspins formula_20. In der Praxis wählt man deshalb häufig auch Configuration State Functions (CSF) als Basisfunktionen. Eine CSF lässt sich als eine Linearkombinationen von einigen wenigen Slater-Determinanten angeben. Ihr Vorteil liegt darin, dass die Wellenfunktion automatisch Eigenfunktion des Spins ist, und dass man weniger CSFs als Determinanten zur Entwicklung braucht. Es sollte jedoch erwähnt werden, dass die zur Zeit erfolgreichsten CI Codes mit Slater-Determinanten arbeiten.\n\nDie Configuration Interaction Methode erhält man nun sehr einfach. Man setzt die Entwicklung der Wellenfunktion in die Schrödingergleichung ein,\n\nund multipliziert sie mit formula_22. Wegen der Orthonormalität der Slater-Determinante (folgt aus der orthonormalen Einteilchenbasis) erhält man\n\nund damit ein Matrix-Eigenwertproblem,\n\nIn der Quantenchemie ist der Hamiltonian häufig gegeben durch\n\nd. h. als Summe aus Einteilchentermen (kinetische + potentielle Energie) sowie der Zweiteilchen-Coulomb-Wechselwirkung. formula_26 und formula_27 bezeichnen die Spinvariablen.\n\nUm das Eigenwertproblem zu bestimmen, müssen Matrixelemente der Form\n\nberechnet werden. Die Auswertung dieser Matrixelemente geschieht mit den Slater-Condon-Regeln.\n\nDie Methode ist im Prinzip exakt, die einzige Näherung besteht in der Wahl einer endlich großen Einteilchenbasis. Dadurch ist die Wellenfunktion keine Eigenfunktion des Hamilton-Operators. Eine große Einschränkung ist allerdings durch die Skalierung der Hamiltonmatrix gegeben. Für eine gewählte Anzahl an Teilchen formula_6 und Anzahl an Basisfunktionen formula_3 hat die Matrix die Dimension formula_31. Durch Ausnutzung von Symmetrien, z. B. formula_32 kann diese Zahl zwar reduziert werden, die exponentielle Skalierung bleibt aber bestehen.\n\nIn der Praxis verwendet man deswegen iterative Methoden zur Lösung des Eigenwertproblems (z. B. Arpack), oder andere Minimierungsmethoden (z. B. Formen des Newton-Verfahrens), mit denen man nur einige wenige Eigenfunktionen erhält, typischerweise den Grundzustand.\n\nIn vielen Fällen wird dabei die Hamiltonmatrix nicht explizit gebildet, sondern nur ihre Wirkung auf den Koeffizientenvektor berechnet, eine Variante die man „Direct CI“ nennt.\n\nAufgrund der exponentiellen Skalierung wird die CI-Entwicklung in der Praxis meist an einer bestimmten stelle abgebrochen. Die Determinanten bzw. CSFs werden dabei danach klassifiziert, durch wie viele \"Anregungen\" (formal Anwendung von Leiteroperatoren) sie sich aus der Referenzdeterminante generieren lassen. So bezeichnet CIS eine CI-Entwicklung, die nach den \"Singles\", also den Einfachanregungen abgebrochen wird, während CISD auch die \"doubles\" enthält. CIS stellt oft eine einfache Näherung zur Beschreibung der ersten angeregten Zustände von Molekülen dar, liefert aber (bei Verwendung konvergierter Hartree-Fock-Orbitale) keine verbesserte Beschreibung des Grundzustandes, da die entsprechenden Matrixelemente aufgrund des Brillouin Theorems gleich null sind.\n\nFull-CI ist größenkonsistent (size consistent), d. h. die Energie zweier Untersysteme ist immer gleich der Energie des Gesamtsystems. Wird die CI-Entwicklung hingegen vorher abgebrochen, ist die CI-Methode (abgesehen von CIS) nicht größenkonsistent.\n\nVerwandte Methoden sind: \n"}
{"id": "2090819", "url": "https://de.wikipedia.org/wiki?curid=2090819", "title": "Coupled Cluster", "text": "Coupled Cluster\n\nCoupled Cluster (CC) bezeichnet eine Methode zur Lösung der Schrödinger-Gleichung, die besonders in der Quantenchemie als eine von vielen post-Hartee-Fock ab initio Methoden verwendet wird. Es handelt sich um ein der Configuration Interaction ähnliches Verfahren. Die Vielteilchen-Wellenfunktion wird dabei in eine Basis aus Slater-Determinanten entwickelt, wodurch die Schrödinger-Gleichung auf ein Matrix-Eigenwertproblem reduziert wird. Die (teilweise) Diagonalisierung dieser Matrix liefert dann die Eigenzustände des quantenmechanischen Systems. \n\nDa die Genauigkeit z. B. der Hartree-Fock (HF) Lösungen in der Regel nicht ausreichend ist muss im Anschluss an z. B. eine HF-Rechnung eine korrelierte Rechnung durchgeführt werden, wobei die vorher berechneten unbesetzten Orbitale zum Einsatz kommen. \n\nDie CC-Theorie ist die perturbative Variante der Vielelektronentheorie (MET) von Oktay Sinanoğlu. Da die MET schwierig zu berechnen ist wird in der heutigen Computerchemie CC verwendet.\n\nDie CC-Theorie verspricht eine exakte Lösung der zeitunabhängigen Schrödinger-Gleichung:\n\nDie Wellenfunktion wird in der CC-Theorie als Exponentialansatz beschrieben: \n\nWobei formula_3, die Referenzwellenfunktion (bzw. das Referenzorbital) ist, welche normalerweise als Slaterdeterminante aus HF-Molekülorbitalen erhalten wird (aber auch andere Wellenfunktionen können benutzt werden, z.B: aus MCSCF-Rechnungen). formula_4 ist der Cluster-Operator, der angewendet auf formula_3 eine Linearkombination aus angeregten Determinanten erzeugt. \n\nIm Gegensatz zu anderen Ansätzen, wie z. B. der Konfigurationsinteraktion (CI) ist der Exponentialansatz größenkonsistent und -extensiv. \n\nDer Cluster-Operator wird in folgender Form geschrieben:\n\nwobei formula_7 der Operator aller Einzelanregungen (singles), formula_8der Operator aller Doppelanregungen (doubles)... ist.\n\nDiese Anregungsoperatoren werden ausgedrückt als:\n\nund für den allgemeinen n-fachen Clusteroperator:\n\nIm obigen Ausdruck werden mit formula_12 and formula_13 die Erzeugungs- bzw. Vernichtungsoperatoren bezeichnet. Dabei stehen i und j für besetzte und a sowie b für unbesetzte (Teilchen-)Orbitale.\n\nformula_7(Einteilchen-Cluster-Operator) und formula_8 (Zweiteilchen-Cluster-Operator) konvertieren die Referenzfunktion formula_3in eine lineare Kombination der einfach und doppelt angeregten Slater-Determinanten, wenn sie ohne Exponentialfunktion angewendet werden. Wenn man den Exponentialclusteroperator auf die Wellenfunktion anwendet, kann man aufgrund der verschiedenen Potenzen von formula_7 und formula_8, die in den resultierenden Ausdrücken erscheinen, mehr als doppelt angeregte Determinanten erzeugen. Das Bestimmen der unbekannten Koeffizienten formula_19 und formula_20ist notwendig, um die approximierte Lösung formula_21 zu finden.\n\nDer Exponentialoperator formula_22kann in einer Taylor-Reihe ausgedrückt werden (hier werden nur formula_7und formula_8berücksichtigt):\n\nObwohl diese Reihe in der Praxis endlich ist, weil die Anzahl besetzter Molekülorbitale endlich ist, wie auch die Anzahl der Anregungen, ist sie immer noch sehr groß, so dass selbst moderne Hochleistungscomputer Schwierigkeiten mit der Berechnung haben. Die Berechnung wird daher nach einer bestimmten Anzahl an höhere Anregungstypen abgebrochen. So werden z. B. bei CCSD höhere Anregungstypen durch Produkte der singles- und doubles-Koeffizienten approximiert. Die Entwicklung läuft bis unendlich in singles- und doubles-Kombinationen, hat aber keine \"reine\" triples-Anregung, bzw. quadruples etc.\n\nDie Klassifizierung der traditionellen CC-Methoden beruht auf der höchsten Anzahl von Anregungen, die in der Definition von formula_4 erlaubt sind. Die Abkürzungen für Coupled Cluster Methoden beginnen gewöhnlich mit den Buchstaben \"CC\", gefolgt von:\n\n\nSo hat der formula_4- Operator in CCSDT die Form:\n\nBuchstaben in runden Klammern weisen darauf hin, dass diese Begriffe auf der Grundlage der Störungstheorie berechnet werden. Zum Beispiel bedeutet CCSD(T):\n\n\nFür hinreichend genaue Ergebnisse ist eine CCSD-Berechnung oft ausreichend. Bessere Ergebnisse werden aber z. B. mit CCSDT oder CCSDTQ erzielt, deren Nachteil aber die stark steigenden Kosten sind.\n"}
{"id": "2099858", "url": "https://de.wikipedia.org/wiki?curid=2099858", "title": "PC Tools", "text": "PC Tools\n\nDie PC Tools waren eine Zusammenstellung von Programmen von Central Point Software ursprünglich für DOS. Die Funktionalität umfasste unter anderem das Aufspüren und Beheben von Fehlern im Dateisystem, die Wiederherstellung gelöschter Dateien sowie Mittel zur Systemoptimierung und Systemsicherung.\n\nDie Sammlung ergänzte Funktionen, die im Lieferumfang des Betriebssystems DOS nicht enthalten waren. Mit MS-DOS 6.0 / PC DOS 6.1 haben Microsoft bzw. IBM Teile der PC Tools lizenziert und in das Betriebssystem integriert.\n\nDie letzte erhältliche Version für DOS war PC Tools Pro 9.0. Es gab auch eine Version der PC Tools für Windows, welche neben den entsprechenden Windows-Varianten der von der DOS-Version her bekannten Programme auch einen verbesserten Datei-Manager und einen Ersatz für den Programmmanager von Windows 3.1 enthielten. Der Ersatz des Programmmanagers war revolutionär. Lange vor Windows 95 bot der PC Tools-Desktopmanager viele Features, die erst später mit Windows 95 eingeführt wurden, z. B. die Möglichkeit, Ordner in Ordnern anzulegen, verschiedene Desktops zu verwalten, verschiedene Anzeigemodi für unterschiedliche Ordner (Liste, Details, kleine Icons etc.).\n\nMit MS-DOS 6.0 (Microsoft) bzw. PC DOS 6.1 (IBM) wurden einige Programme vom Hersteller der PC Tools, Central Point Software lizenziert und selbst in das Betriebssystem integriert.\n\nDen Sprung in das 32-Bit-Zeitalter haben die PC Tools nicht mehr geschafft. Die Firma Central Point Software wurde im Juni 1994 − wenige Monate vor dem Erscheinen von Windows 95 − von ihrem größten Konkurrenten Symantec aufgekauft. Symantec ist vor allem bekannt durch die Norton Utilities.\nIn überarbeiteter Form wurden von Symantec (im Wesentlichen: um FTP erweitert, diverse Umbenennungen, *.Pak schreiben entfernt, neue Version von Sfx) der Dateimanager und das in Systemdoktor umbenannte Crashguard auf Windows NT portiert und zusammen mit dem Norton-Programm Systeminformation als Norton NT-Tools (für Windows NT 3.51) verkauft. Eine Weiterentwicklung erfolgte nicht und so arbeiten die Programme der NT-Tools bereits unter Windows 2000 (NT 5.0) nicht mehr in jedem Fall vollständig.\n\n\n\n\n2004 hatte sich das australische Unternehmen WinGuides Network in PC Tools Pty Limited umbenannt und bot diverse System- und Sicherheitsprogramme für Windows an. Diese haben mit den ursprünglichen PC Tools von Central Point aber nichts gemeinsam. Im August 2008 wurde die Übernahme durch Symantec angekündigt. Symantec bietet nun wiederum zusätzlich zu den bisherigen Produkten (Norton) auch solche unter der Bezeichnung \"PC Tools\" an (z. B. PC Tools Internet Security).\n"}
{"id": "2103346", "url": "https://de.wikipedia.org/wiki?curid=2103346", "title": "Laplink", "text": "Laplink\n\nLaplink ist ein Programm vom gleichnamigen Hersteller zur direkten Datenübertragung zwischen zwei Computern für DOS und Windows.\n\nEs war besonders in den 1980er-Jahren verbreitet, weil es damals eine der wenigen Möglichkeiten darstellte, größere Datenmengen zwischen zwei Computern auszutauschen. Der Universal Serial Bus (USB) war noch nicht erfunden, Netzwerkschnittstellen im Privatbereich kaum verbreitet und der Datenaustausch über Disketten langsam und wegen der geringen Kapazität der Disketten mühselig.\n\nDie Datenübertragung erfolgt über die serielle oder parallele Schnittstelle. Ein passendes Kabel lag der Software bei. Heute hat Laplink einen erheblich erweiterten Funktionsumfang und kann Daten auch über die USB-Schnittstelle übertragen. Die Bedeutung des Programms hat aber abgenommen, da mittlerweile fast alle PCs mit Netzwerkschnittstellen ausgerüstet sind und neuere Betriebssysteme Funktionen zur Datenübertragung bereits fest integriert haben (etwa Ethernet-Verkabelung mit Netzwerkfreigaben). Auch über USB-Sticks lassen sich problemlos größere Datenmengen austauschen.\n\nAb der MS-DOS-Version 6.00 wurden von Microsoft eigens entwickelte, für den Datenaustausch benötigte Gerätetreiber (\"INTERLNK.EXE\" und \"INTERSVR.EXE\") mit ausgeliefert. IBM lieferte die Treiber bereits mit PC DOS 5.02 aus. Passende Kabel musste man selbst anfertigen oder im Fachhandel beziehen.\n\n\n"}
{"id": "2104205", "url": "https://de.wikipedia.org/wiki?curid=2104205", "title": "Advanced Simulation and Computing Program", "text": "Advanced Simulation and Computing Program\n\nDas Advanced Simulation and Computing Program (ASC), früher bekannt unter dem Namen Accelerated Strategic Computing Initiative (ASCI) ist ein Programm der US-Regierung, das 1995 begonnen wurde und in erster Linie zur Simulation von Kernwaffentests dient, die seit 1992 einem Moratorium der US-Regierung unterliegen. Das Programm untersteht der Nuklearsicherheitsbehörde (National Nuclear Security Administration/NNSA) des US-Energieministeriums und verfügt über ein Jahresbudget von rund 600 Mio. US-Dollar. Das Programm ist besonders durch die TOP500-Liste der weltweit schnellsten Supercomputer bekannt, wo Rechner des Programms regelmäßig Spitzenplätze belegen. An dem Programm nehmen die Forschungszentren Los Alamos National Laboratory/LANL (Los Alamos, New Mexico), Lawrence Livermore National Laboratory/LLNL (Livermore, Kalifornien), und Sandia National Laboratories/SNL (Albuquerque, New Mexico) sowie mehrere amerikanische Universitäten teil. Bekannte Rechner des Programms sind unter anderem:\n\nBereits außer Dienst gestellt oder abgeschaltet sind:\n\n"}
{"id": "2105520", "url": "https://de.wikipedia.org/wiki?curid=2105520", "title": "Electrologica X1", "text": "Electrologica X1\n\nDie Electrologica X1 (oder einfach EL X1) war ein Digital-Computer, der in den Niederlanden konstruiert und von 1958 bis 1965 produziert wurde. Etwa 30 Anlagen wurden gebaut und auch ins Ausland verkauft.\n\nDie X1 wurde im \"Mathematisch Centrum Amsterdam\" von Carel Scholten und Bram Loopstra entworfen. Produziert wurde die X1 von der \"Electrologica NV\", einer Firma, die eigens dazu vom Mathematisch Centrum und der Versicherungsfirma Nillmij 1958 gegründet worden war.\n\nEine Anlage wurde an eine Kaffeefirma in Deutschland verkauft, von wo sie auf Initiative von Horst Herrmann 1962 als Gebrauchtmaschine zur TU Braunschweig gelangte, wo sie bis 1975 im Einsatz war (die Maschinen behielten bis zum Schluss einen gewissen Kaffeeduft). Es gab dort eine etwas größere Anlage, die per Lochstreifen, Lochkarte oder Magnetband gefüttert werden konnte und die nur von professionellen Operatoren oder von eingewiesenen Benutzern bedient wurde, sowie eine kleinere, die nur mit Lochstreifen (Eingabe und Ausgabe) und elektrischer Schreibmaschine ausgestattet war und im Selbstbedienungsbetrieb durch die Studierenden lief. Sie wurden praktisch ausschließlich in Algol 60 programmiert.\n\nDie X1 war ein volltransistorisierter Binärcomputer mit Ringkernspeicher. Die Schaltungen waren als Steckmodule in Metallbechern von etwa Zigarettenschachtelgröße ausgeführt. Ein Modul enthielt in diskreter Transistor-Logik ein einzelnes logisches Gatter, also meist einen oder zwei Transistoren. Die CPU war ein würfelförmiger Schrank von etwa einem Kubikmeter Volumen.\n\nDie Wortlänge des Speichers war 27 Bit. Eine kleinere Maschine hatte davon etwa 7 KWorte, was einen zweiten Schrank von gleicher Größe wie die CPU füllte. Maximal konnten 32.768 Speicherplätze adressiert werden, da 15 Adressbits vorhanden waren.\n\nDie „kleine X1“ konnte direkt ca. 3 kByte Speicher benutzen, mit „geteiltem Compiler“ 8 kByte; die „große X1“ konnte 16 kByte Speicher benutzen.\n\nAls Peripherie waren Lochstreifen, Lochkarten, Magnetband, Zeilendrucker, DIN-A1-Plotter und elektrische Schreibmaschinen verfügbar. Die X1 war einer der ersten europäischen Computer mit einem Interrupt-System. Darauf aufbauend konnten die Schnittstellen zu Peripheriegeräten wesentlich effizienter ausgeführt werden, so dass sie vor allem einen gewissen Puffer zwischen schneller CPU und langsamer Peripherie boten, nach Art eines Ausgabekanals späterer Großrechner.\n\nWie bei den Konkurrenzmodellen Zuse Z22 und der ZEBRA konnten alle Befehle, nicht nur die Verzweigungen, bedingt (\"conditional\") ausgeführt werden. Dies ermöglichte besonders kompakt geschriebene Programme. Das folgende Beispiel zeigt das Laden des Absolutbetrags des Speicherwertes aus Speicherstelle \"n\" in den Accumulator \"A\":\n\nEine bemerkenswerte Eigenheit der X1, oder zumindest der Leute, die mit ihr arbeiteten, war die Benutzung von 32-bittiger Notation in einer eigenen Basis-32-Zahlendarstellung für die Adressen.\n\nDie X1 war der Gegenstand von Edsger W. Dijkstras Doktorarbeit und die Zielmaschine für den ersten komplett implementierten Algol-60-Compiler, fertiggestellt von Dijkstra und Jaap Zonneveld. 1965 wurde die X1 von der X8 abgelöst. Electrologica wurde im folgenden Jahr von Philips übernommen.\n\nDie folgenden Bilder (bis auf das letzte) wurden aufgenommen, kurz bevor und nachdem 1975 die X1 der TU Braunschweig abgerissen wurde.\n\n"}
{"id": "2106487", "url": "https://de.wikipedia.org/wiki?curid=2106487", "title": "Red Storm", "text": "Red Storm\n\nRed Storm ist ein ab 2004 von Cray Inc. als Nachfolger von ASCI Red für die Sandia National Laboratories in Albuquerque (New Mexico) gebauter Supercomputer. Er ist das erste Modell mit der Cray XT3-Architektur für Hochleistungsrechner und wird für Simulationsaufgaben, unter anderem im Rahmen des amerikanischen Advanced Simulation and Computing Program eingesetzt.\n\nDas System besteht aus 14.348 Rechenknoten, die jeweils aus einem Doppelkern-AMD Opteron-Prozessor für Rechenaufgaben und einem PowerPC 440-basierten Prozessor (SeaStar) für Kommunikationsaufgaben bestehen. Es handelt sich um ein MPP-System mit verteiltem Speicher und MIMD-Architektur.\n\nAls Betriebssystem kommt auf den Rechenprozessoren Catamount (basierend auf dem bei ASCI Red verwendeten Cougar) sowie auf den Kommunikationsprozessoren eine Variante von Linux zum Einsatz.\n\nDas System belegt eine Fläche von etwa 300 m² und hat eine Leistungsaufnahme von rund 2,2 MW.\n\nIn der ersten Ausbaustufe ab 2004 erreichte das System mit 10.386 auf 2,0 GHz getakteten Einkern-Opterons eine LINPACK-Leistung von rund 42 TFlops. Nach der Erhöhung der Knotenzahl auf 14.348 und der Umrüstung auf 2,4-GHz-Doppelkern-Opterons (2006) stieg die Gesamtleistung auf 101,4 TFlops (124,4 TFlops Spitzenleistung), womit Red Storm Rang 3 (Stand: Juni 2007) der TOP500-Liste der Supercomputer hinter dem BlueGene/L des Lawrence Livermore National Laboratory (280,6 TFlops) und dem „Jaguar“ des Oak Ridge National Laboratory (101,7 TFLOPS) belegt.\n\n"}
{"id": "2107149", "url": "https://de.wikipedia.org/wiki?curid=2107149", "title": "Macintosh Portable", "text": "Macintosh Portable\n\nDer Macintosh Portable war der erste tragbare Computer von Apple.\n\nDer Mac Portable war im Jahre 1989 Apples erster tragbarer Macintosh. Er besaß einen Schacht für ein 3,5″-Laufwerk (mit halber Höhe) und optionaler Festplatte (mit proprietärem SCSI-Anschluss, bis maximal 40 MB), und man konnte bis zu zwei SuperDrives (Diskettenlaufwerke für das Macintosh-Format mit 1,4 MB Speicherkapazität) anschließen. Auf den internen Steckplätzen konnte Speicher, sowie ein Modem nachgerüstet werden. Als Besonderheit konnte der eingebaute Trackball gegen ein numerisches Tastenfeld getauscht werden, auch konnte der Trackball wahlweise links oder rechts im Gehäuse installiert werden. Größter Pluspunkt waren die Bleiakkumulatoren (ohne Memory-Effekt), mit denen der Portable eine auch für heutige Verhältnisse beachtliche Laufzeit von bis zu zehn Stunden erreichte. Auch ohne diese Akkumulatoren erreichte der Mac Portable bereits ein ansehnliches Gewicht. Das Display kam zunächst ohne eigene Beleuchtung aus, erst in einer späteren Revision wurde das Gerät um eine Hintergrundbeleuchtung ergänzt. Die Reaktionen auf den Portable waren schlecht, und so wurde der Macintosh Portable bereits im Oktober 1991 vom Markt genommen. Der Verkaufspreis lag bei 6.500 US-Dollar.\n\n\nWie auch bei Portable-Modellen anderer Hersteller, schränkte das hohe Gewicht die Tragbarkeit deutlich ein, wodurch es kaum Vorteile zu anderen Macintosh-Modellen gab, zumal die alten \"Würfel-Macs\" (Macintosh Plus, Macintosh SE, Macintosh Classic) durchaus leicht zu transportieren waren. Gleichzeitig war der hohe Preis sehr abschreckend, der vergleichbar schnelle und kaum schwerere, zur gleichen Zeit gebaute Mac Classic, kostete nur ein Drittel.\n\n"}
{"id": "2108916", "url": "https://de.wikipedia.org/wiki?curid=2108916", "title": "ASC Purple", "text": "ASC Purple\n\nASC Purple ist ein Supercomputer des Lawrence Livermore National Laboratory in Livermore (Kalifornien). Er wurde in Zusammenarbeit mit IBM mit Mitteln des Advanced Simulation and Computing Program entwickelt und im Oktober 2005 in Dienst gestellt.\n\nDas System besteht aus 196 miteinander verschalteten IBM eServer pSeries p5 575 SMP-Großrechnern mit insgesamt 12.288 IBM Power5-Prozessoren mit 1,9 GHz. Das System verfügt über insgesamt 49,2 Terabyte Hauptspeicher sowie 2,8 Petabyte Festplattenspeicher. Als Betriebssystem kommt IBM AIX 5.3 zum Einsatz.\n\nDie Leistungsaufnahme von ASC Purple inklusive des Kühlsystems liegt bei rund 7,5 MW. Das ist etwa das 100.000-fache eines Büro-PCs (75 Watt).\n\nASC Purple erreichte im November 2005 mit einer LINPACK-Leistung von 63,39 TFLOPS (theoretische Spitzenleistung: 77,82 TFLOPS) Platz 3 der Supercomputer-Weltrangliste TOP500. Im November 2008 war der Rechner mit 75,76 TFLOPS bei 92,78 TFLOPS theoretischer Spitzenleistung noch auf Platz 33 gelistet.\n\n"}
{"id": "2113089", "url": "https://de.wikipedia.org/wiki?curid=2113089", "title": "Feurio!", "text": "Feurio!\n\nFeurio! ist ein auf Audio-CDs spezialisiertes Brennprogramm für das Betriebssystem Windows von Microsoft. Entwickelt wurde es von Jens Fangmeier, die erste veröffentlichte Version erschien 1997 als Beta-Version 0.90.\n\nBis Version 0.935 erschien \"Feurio!\" als Freeware, war jedoch als Beta-Version zum Testen gedacht und daher nur bis zu einem festgesetzten Datum lauffähig. Mit Erscheinen von Version 1.0 Ende 1998 entfiel das „Ablaufdatum“, gleichzeitig wurde das Programm Shareware und ist seither in der Standardversion uneingeschränkt nutzbar. Bis zur aktuellen Version wurde \"Feurio!\" aktiv weiterentwickelt. Seit 2004 scheint die Entwicklung jedoch stehengeblieben zu sein. Eine neuere Version von Feurio! wurde zwar entwickelt, wegen möglicher Komplikationen mit dem deutschen Urheberrecht jedoch nicht mehr veröffentlicht.\n\nGrundsätzlich gibt es nur eine Installationsversion von \"Feurio!\", welche aber mit der Eingabe entsprechender Lizenzschlüssel als Standardversion oder als Professional-Version freigeschaltet werden kann.\n\nDie Shareware-Variante ist derzeit gegenüber der Standardversion nicht eingeschränkt. Die Professional-Version bietet zusätzliche Funktionen zum gleichzeitigen Brennen auf mehreren CD-Brennern sowie zum Kopieren von Daten-CDs und zum Brennen von ISO-Abbildern.\n\n\"Feurio!\" besteht aus den Einzelprogrammen „Feurio! CD-Manager“, „Feurio! CD-Writer“, „Feurio! Trackeditor“ und „Feurio! Covereditor“. Zusätzlich bietet das Programm einen CD-Player sowie einen Wave-Player.\n\nDass \"Feurio!\" auf Audio-CDs spezialisiert ist, macht ein kurzer Blick auf den Funktionsumfang des Programms deutlich. Es beinhaltet neben dem „CD-Manager“, in dem man seine Projekte mit WAV- und MP3-Dateien zusammenstellen kann, eine CDDB-Abfrage, CD-Text-Unterstützung, Audio-Grabbing, eine Funktion zur automatischen Aussteuerung und einen einfachen Wave-Editor. Viele Funktionen sind in heutigen Brennprogrammen selbstverständlich, in \"Feurio!\" gibt es sie schon seit vielen Jahren, einige Beispiele:\n\nIm CD-Manager lassen sich Projekte aus \".wav\"- und/oder \".mp3\"-Dateien erstellen. Die Dateien können sich auf der Festplatte befinden und sich von dort in das Projekt verweisen lassen oder es lässt sich eine Zusammenstellung aus den Titeln verschiedener CDs in das Projekt kopieren. Bei der Einbindung von MP3-Dateien kann man auswählen, ob die Dateien erst beim Brennvorgang „on the fly“ in das Wave-Format konvertiert werden und dabei gleichzeitig normalisiert (also in ihrer Lautstärke einander angepasst) werden sollen (historisch: was im Jahr 1999 zu Zeiten von Pentium II-Rechnern nicht selbstverständlich war). Aus dem Projekt heraus lassen sich die Tracks in den Track-Editor laden und z. B. Trackmarken setzen, was nach analoger Aufnahme von Schallplatten oder Kassetten aus dem CD-Manager heraus sehr hilfreich und einfach zu bewerkstelligen ist. Beim Grabben von Audio-CDs ist es möglich, durch die Einbindung eines freien externen MP3-Encoders, z. B. des LAME-Encoders (lameenc.dll), direkt MP3-Dateien zu erstellen, und das unter Verwendung der Online-CD-Datenbanken freedb oder CDDB oder einer heruntergeladenen freedb-Version zur Erstellung der ID3-Tags. Das Format der Tags lässt sich individuell definieren.\n\nDer CD-Writer ist das Brennmodul von \"Feurio!\". Er kann mit einer Vielzahl gängiger CD-Laufwerken umgehen, jedoch nur in der Professional-Version kann man damit auch Daten-CDs kopieren und ISO-Abbilder brennen. In der Standard-Version ist damit ausschließlich das Brennen von Audio-CDs möglich. Überlange CD-Rohlinge, die vom ANSI-Standard IEC-908 („Red Book“) abweichen und mehr als 74 Minuten speichern können, sowie das Überbrennen werden vom Brennmodul unterstützt. \"Feurio!\" kann sogar mit 99-Minuten-Rohlingen umgehen, dabei ist jedoch zu beachten, dass nicht alle CD-Laufwerke am Computer das Brennen bzw. das Abspielen oder Auslesen von solchen Rohlingen unterstützen, und vor allem dass die wenigsten CD-Player solche Audio-CDs abspielen können, weil sie weit außerhalb der CD-Audio-Spezifikation (wie sie im „Red Book“ definiert ist) liegen.\n\nDer CD-Writer war eines der ersten Programme, das das Brennen von CD-Text-Informationen unterstützte. Dazu verwendet das Programm die Informationen von der Quell-CD oder aus dem CD-Manager, der seine Informationen wiederum aus der Offline-Version der freedb oder aus den Online-Versionen von CDDB oder freedb bezieht. Neben der eigentlichen Brennfunktion bietet der CD-Writer vielfältige Diagnosefunktionen, z. B. zur Überprüfung von Systemtreibern oder zur Ermittlung der Länge eines CD-Rohlings in einem Simulationsbrennvorgang, wodurch sich das Überbrennen eines überlangen CD-Projektes sicherer gestalten lässt.\nIm CD-Writer lässt sich ein Datenpuffer einrichten, der ein sicheres Brennen auch mit Brennern ohne „buffer underrun protection“-Funktion ermöglicht.\n\n\"Feurio!\" läuft auf jedem 32-Bit-Windows, also Windows 9x ab Windows 95. Empfohlen werden jedoch NT-basierte Windows-Versionen wie Windows NT 4.0 und Windows 2000. Das Programm benötigt vergleichsweise wenig Computerleistung. Es genügt ein Pentium-90 mit 32 MB RAM, ab Windows NT mindestens 64 MB RAM.\nTrotz des relativen Alters kann \"Feurio!\" in Version 1.68 problemlos mit Windows 7 (32-Bit) und Windows Vista (32-Bit) betrieben werden, obwohl Windows Vista bei der Installation über eine mögliche Inkompatibilität warnt. Auch unter Windows 7 x64 (64-Bit) funktioniert das Programm weitgehend problemlos, auf einigen Hardwarekonfigurationen funktioniert das Abspielen von Stücken im Track-Editor jedoch nicht. Dieses Problem lässt sich durch den Einsatz einer virtuellen Maschine, wie dem XP-Modus von Windows 7 Professional/​Enterprise, umgehen.\n\"Feurio!\" läuft auch unter Windows 8, 8.1 und 10 (64-Bit), der Abspielmodus im Trackeditor funktioniert je nach Hardwarekonfiguration.\n\n"}
{"id": "2116102", "url": "https://de.wikipedia.org/wiki?curid=2116102", "title": "Dependency Walker", "text": "Dependency Walker\n\nDependency Walker (oder depends.exe) ist ein kostenloses Programmierwerkzeug zum Auslesen von Abhängigkeiten zwischen Windows-PE-Dateien. Als Benutzerschnittstelle kommt entweder eine grafische Oberfläche oder die Kommandozeile zum Einsatz. Für eine Übersicht über alle verlinkten Module fungiert ein Baumdiagramm, die im- und exportierten Funktionen werden jeweils in tabellarischer Form dargestellt. Die letzte Version 2.2 des Programms ist von 2006. In früheren Versionen war das Programm Bestandteil der \"Windows XP SP2 support tools\" und des \"Microsoft Visual Studio\". Die Lizenz für Dependency Walker Version 2.2 erlaubt die Bündelung mit anderen Produkten nicht mehr. Unterstützte Plattformen sind x86 (32 bit), x64 und IA64 (64 bit). Die Unterstützung für Alpha/AXP, MIPS und PowerPC wurde eingestellt.\n\nStand Oktober 2017 gibt es auf GitHub eine Portierung von Dependency Walker nach C#. Der Funktionsumfang ist noch nicht komplett. Das Programm berücksichtigt Windows API-Sets und WinSxS.\n\n"}
{"id": "2116590", "url": "https://de.wikipedia.org/wiki?curid=2116590", "title": "DOS-Trend", "text": "DOS-Trend\n\nDOS-Trend war eine Fachzeitschrift für Software und wurde von 1989 bis 1996 von der \"Trend Redaktions- und Verlagsgesellschaft mbH\" herausgegeben. \"DOS-Trend\" befasste sich hauptsächlich mit den Themen Public Domain und Shareware.\n\nJeder Ausgabe der Zeitschrift lag eine Diskette mit ausgewählten Shareware-Programmen bei; die letzten Ausgaben waren auch mit CD-ROM erhältlich. Da der Trend-Verlag eine Kooperation mit PEARL hatte, wurde im Mittelteil der Zeitschrift häufig auch ein Werbekatalog des Versandhandels beigelegt. Dort konnten unter anderem weitere Sharewareprogramme bestellt werden.\n\nEs erschienen auch diverse \"DOS-Trend\"-Extra-Ausgaben, zum Beispiel eine Extra-Ausgabe mit dem Virenscanner \"Thunderbyte Anti-Virus\" oder der Shareware-Version des Spiels Doom (Ausgabe 4/1993).\n\n\"DOS-Trend\" wurde durch den mittlerweile ebenfalls eingestellten Nachfolger namens \"CD plus Extra\" (mit CD-ROM) abgelöst.\n\nDie ersten Ausgaben der Zeitschriften \"fast geschenkt!\" und \"Bestseller-Games\" hatten noch ein kleines DOS-Trend-Logo in der Ecke auf dem Titelblatt, bei späteren Ausgaben kommt das Wort „DOS“ im Logo nicht mehr vor.\n\n"}
{"id": "2119703", "url": "https://de.wikipedia.org/wiki?curid=2119703", "title": "NorthStar Horizon", "text": "NorthStar Horizon\n\nDer NorthStar Horizon ist ein US-amerikanischer 8-Bit-Computer, der mit einem Z80A-Mikroprozessor (4 MHz) ausgestattet ist. Der Computer wurde von der Firma North Star Computers hergestellt. Erstmals wurde der Rechner im Jahre 1979 auf den Markt gebracht.\n\nDer Rechner unterstützt die Betriebssysteme CP/M und NSDOS (NorthStars Disk Operating System).\n\nNSDOS enthielt auch ein NorthStar BASIC, ein Dialekt des Standard-BASICs.\n\nDer Rechner wurde besonders in US-amerikanischen Universitäten verwendet, da er mit seinem S-100-Bus als Schnittstelle besonders gut als Kontroll- und Steuerungssystem für unterschiedliche wissenschaftliche Experimente verwendet werden konnte.\n\n"}
{"id": "2120795", "url": "https://de.wikipedia.org/wiki?curid=2120795", "title": "GNewSense", "text": "GNewSense\n\ngNewSense ist eine GNU/Linux-Distribution, basierend auf Debian von der Free Software Foundation. Das Ziel ist ein benutzerfreundliches Betriebssystem ohne proprietäre Software.\n\ngNewSense geht sehr streng gegen proprietäre Software vor. Zum Beispiel wurden alle Dokumentationen entfernt, die erklären, wie man proprietäre Software installiert.\n\nDas Projekt wurde 2006 von Brian Brazil und Paul O’Malley ins Leben gerufen. Damals basierte es noch auf Ubuntu. Ab Version 1.0 unterstützte die Free Software Foundation das Projekt. 2011, als 2 Jahre keine neue Version erschienen war, klassifizierte Distrowatch das Projekt als „dormant“ (englisch für „ruhend“, „schlafend“). Im September 2012 wurde auf Distrowatch der Status zu „active“ (englisch für „aktiv“) geändert und am 6. August 2013 kam die erste direkt auf Debian basierende Version heraus.\n\nStandardmäßig nutzt gNewSense GNOME, dies kann allerdings auch geändert werden.\n\ngNewSense kann mit einer Live-CD installiert werden.\n\ngNewSense hat aktuell 4 Major-Versionen:\n\n"}
{"id": "2121831", "url": "https://de.wikipedia.org/wiki?curid=2121831", "title": "ReadyBoost", "text": "ReadyBoost\n\nReadyBoost ist eine Cache-Technik, die in den Microsoft-Betriebssystemen seit Windows Vista enthalten ist. ReadyBoost erlaubt es, Flash-Speicher wie beispielsweise SD- oder CompactFlash-Karten als zusätzlichen Festplattencache einzubinden. Dies bringt potenziell eine höhere Systemleistung, da Flash-Speichermedien in der Regel wesentlich geringere Zugriffszeiten besitzen als Festplattenspeicher. Es erlaubt zudem die Entlastung der Festplatte, wenn Daten von einem schnelleren Laufwerk in ein langsameres Laufwerk geschrieben bzw. kopiert werden. Dabei können unter bestimmten Umständen die Zugriffszeiten des langsameren Laufwerkes gesteigert werden.\n\nDa der Flash-Zwischenspeicher als Cache für alle im System befindlichen Massendatenspeicher genutzt wird, betrifft die Geschwindigkeitssteigerung nicht nur die Auslagerungsdatei oder Systemdateien. Normale Flash-Speicher sind im sequentiellen Lesen und Schreiben langsamer als Festplatten, deshalb wurde ReadyBoost so ausgelegt, dass es beim Erkennen bzw. beim Einstecken des Flash-Speichers zuerst einen Geschwindigkeitstest durchführt. Dieser erkennt auch, ob der Flash-Speicher schnell genug für ReadyBoost ist. Damit wird verhindert, dass große sequentielle Lese- und Schreibvorgänge langsamer ausfallen als das direkte Schreiben auf die Festplatte. Schreibzugriffe auf den Flash-Datenträger werden möglichst gleichmäßig verteilt, um Verschleiß an besonders häufig beschriebenen Stellen vorzubeugen.\n\n\nWindows Vista und Windows 7 bieten zur Überprüfung dieser Voraussetzungen das Kommandozeilenprogramm winsat an. Für einen Lesetest ruft man es wie folgt auf:\nDie Kommandozeile muss als Administrator gestartet werden, da sonst die Ausgabe des Programms in einem neuen Fenster erfolgt, welches sofort wieder geschlossen wird und daher nicht lesbar ist.\n\nBeispiel für einen Lesetest mit nicht-sequenziellem Zugriff bei einer Blockgröße von 4 KiB auf Laufwerk S:\nwinsat disk -read -ran -ransize 4096 -drive S\nBeispiel für einen Schreibtest mit nicht-sequenziellem Zugriff bei einer Blockgröße von 512 KiB auf Laufwerk S:\nwinsat disk -write -ran -ransize 524288 -drive S\n\nIn Windows 7 kann der Test über den Karteireiter \"ReadyBoost\" bei den Laufwerkseigenschaften angestoßen werden.\n\nBeim Zugriff auf ein ReadyBoost-fähiges Speichergerät zur Zwischenspeicherung ermöglicht Windows wahlfreie Lesevorgänge mit einer Geschwindigkeit, die üblicherweise höher ist als die herkömmlichen Lesevorgänge von einer Festplatte.\n\nBenchmarks zeigen, dass ReadyBoost in der aktuellen Fassung unterschiedliche Ergebnisse hervorbringen kann. Gerade auf Rechnern mit wenig physischem RAM kann ReadyBoost einen messbaren Leistungsvorteil bringen. Nach Angaben von Mike Trainor (Chief Mobile Technology Evangelist von Intel) soll ein Rechner mit 1 GB RAM zuzüglich 1 GB Flash-Speicher etwa 60 bis 80 % der Leistung eines Rechners mit 2 GB RAM erreichen. Der Einsatz auf Grundlage von Turbo Memory auf dem Mainboard lohne sich derzeit kaum, solle jedoch nach Angabe von Intel weiterentwickelt werden.\n\nWenn ein kompatibles Gerät angeschlossen wird, bietet das Windows-AutoPlay-Dialogfenster eine zusätzliche Option zur Beschleunigung des Systems an. Ein zusätzlicher ReadyBoost-Reiter wird im Eigenschaften-Dialog des jeweiligen Laufwerks hinzugefügt, wo die Menge des dafür vorgesehenen Speicherplatzes angepasst werden kann. ReadyBoost kann auch über die Eigenschaften des USB-Sticks aktiviert werden.\n\n"}
{"id": "2122341", "url": "https://de.wikipedia.org/wiki?curid=2122341", "title": "F-Spot", "text": "F-Spot\n\nF-Spot ist eine freie Software zur Verwaltung von Fotos, die für den GNOME-Desktop entwickelt wurde. Das Programm ist unter der GNU GP-Lizenz veröffentlicht worden. \nDas Programm gehörte zusammen mit Eye of Gnome ab der Version 10.04 zur Standardsoftware von Ubuntu und ersetzte hier die Bildbearbeitungssoftware GIMP. \nMit Ubuntu 10.10 wurde F-Spot dort durch Shotwell in der Standardinstallation ersetzt, wobei man F-Spot zunächst weiterhin nachinstallieren konnte.\n\nIn Fedora gehörte es bis Version 13 zur Standardinstallation. \n\nF-Spot kombiniert die Benutzeroberfläche eines üblichen Bildbrowsers mit weiteren Funktionen wie dem Markieren von Bildern mit Stichworten, der Darstellung von Exif- und XMP-Informationen und Bildbearbeitung. Mit Hilfe von gPhoto können Fotografien von der Digitalkamera importiert werden. Auch das Brennen von Foto-CDs ist möglich. Das Programm stellt eine eigene Bibliothek zur Bildverwaltung bereit. Von dort können Fotos ins Internet hochgeladen werden, z. B. zu Flickr, Picasa-Webalben etc.\n\nDas Programm unterstützt übliche Bilddateiformate wie JPEG, PNG, TIFF, DNG und verschiedene herstellerspezifische RAW-Formate (CR2, PEF, ORF, SRF, CRW, MRW und RAF). Weiterhin werden GIF, SVG und PPM unterstützt. RAW-Dateien können derzeit noch nicht mit F-Spot bearbeitet werden.\n\nMöglich ist das Beschneiden oder das Drehen von Bildern, die Entfernung von roten Augen und Farbbalance, sowie Helligkeits- und Weißabgleich, Farbschattierung sowie Sättigungs- und Kontrastanpassung.\n\nF-Spot wurde in der Programmiersprache C# und unter Benutzung des Mono-Frameworks geschrieben. Ettore Perazzoli begann mit der Programmierung von F-Spot, heute leitet Larry Ewing das Projekt.\n\n"}
{"id": "2126275", "url": "https://de.wikipedia.org/wiki?curid=2126275", "title": "BitLocker", "text": "BitLocker\n\nBitLocker ist eine Festplattenverschlüsselung des Unternehmens Microsoft, die serverseitig ab Windows Server 2008 und clientseitig in den Ultimate- und Enterprise-Versionen von Windows Vista und Windows 7 sowie den Pro- und Enterprise-Versionen von Windows 8, Windows 8.1 und Windows 10 enthalten ist.\n\nUm das Systemlaufwerk verschlüsseln zu können, benötigt Bitlocker eine eigene Partition der Festplatte, welche bei Bedarf automatisch erstellt wird. Es startet vor dem Betriebssystem und greift standardmäßig auf ein Trusted Platform Module (TPM) zu, um zu prüfen, ob die Hardware unverändert und somit vertrauenswürdig ist. Microsoft empfiehlt, zusätzlich die Eingabe einer PIN zu erzwingen. Allerdings ist bei Auswahl der PIN darauf zu achten, dass diese bei der Startroutine zu einem Zeitpunkt abgefragt wird, bei dem länderspezifische Einstellungen der Tastatur noch nicht geladen sind, also die Tastatur immer dem US-englischen Standard entspricht. Damit sind Y und Z gegenüber der deutschen Tastatur vertauscht, Sonderzeichen liegen vielfach auf anderen Tasten, Umlaute können nicht per Tastatur eingegeben werden. Alternativ oder zusätzlich zur PIN kann das Starten des Systems davon abhängig gemacht werden, ob ein USB-Stick mit einer Schlüsseldatei eingesteckt ist. Wenn keines von beidem konfiguriert wird, tritt BitLocker nicht in Erscheinung, solange die Umgebung der Festplatte unverändert bleibt. Bei Computern ohne Trusted Platform Module kann alternativ eine Schlüsseldatei auf einem USB-Stick zum Einsatz kommen oder, außer bei der Systempartition, die Eingabe einer PIN vorgesehen werden.\n\nDie Verschlüsselung erfolgt durch AES mit einer Schlüssellänge von 128 oder 256 Bit.\nGegenüber Windows Vista unterstützt BitLocker ab Windows 7 auch die Verschlüsselung von USB-Medien („BitLocker to Go“), welche auch unter Windows Vista und XP gelesen werden können.\n\nEs ist grundsätzlich auch möglich, die Systempartition gänzlich ohne TPM zu verschlüsseln und stattdessen die PIN-Eingabe zu verwenden.\n\nBitLocker speichert die Recovery-Daten zur Entschlüsselung der Partition ohne Passwort während des Verschlüsselungsprozesses im Klartext auf einem Datenträger und in gemanagten Umgebungen zusätzlich in das Active Directory. Hier wird pro Partition ein Key angelegt. Wenn ein TPM-Chip verwendet wird, so wird dessen Recovery-Passwort ebenfalls abgelegt. Für eine Entschlüsselung ist entweder das ursprüngliche Passwort oder das TPM-Passwort notwendig, eine Challenge-Response-Authentifizierung ist derzeit nicht vorgesehen.\n\nEs wird auf dem internationalen Markt eine Software angeboten, die an Polizeidienststellen, Behörden und Privatdetektive verkauft wird. Die Funktion dieses Programmpaketes liegt darin, dass zunächst bei einem gemounteten BitLocker-Laufwerk der Arbeitsspeicher ausgelesen wird. Dazu wird ein Programm zum Kopieren des Inhalts des RAM über den FireWire-Port mitgeliefert. Anschließend kann auf einem anderen PC das Speicherabbild verarbeitet und das darin vorhandene Passwort angezeigt werden. Damit ist ein Zugriff auf die geschützten Daten des angegriffenen Rechners sofort oder zu einem späteren Zeitpunkt möglich. Allerdings ist ein Speicherabbild und folglich das Auslesen des Passworts nur auf einem eingeschalteten Computer möglich, bei dem das Passwort bereits eingegeben wurde. Dieselbe Angriffsmöglichkeit besteht auch für vergleichbare Programme wie TrueCrypt. Letzteres hat jedoch Funktionen, welche das Passwort wieder automatisch aus dem Flashspeicher löschen.\n\nJe nach Einstellung von BitLocker lässt sich der Start des Computers durch Unbefugte, und somit das Abgreifen von Daten, mit einem zusätzlichen Passwort oder einer PIN verhindern.\n\n"}
{"id": "2129182", "url": "https://de.wikipedia.org/wiki?curid=2129182", "title": "GWGET", "text": "GWGET\n\nGWGET ist der Downloadmanager des GNU Network Object Model Environments (Gnome).\n\nMit GWGET können Downloads mit Hilfe folgender Funktionen komfortabel verwaltet werden:\n\n\nDie Firefox-Erweiterung FireGet funktioniert nur bis Firefox Version 1.6. In aktuelleren Firefox Versionen kann man Gwget mit der Erweiterung FlashGot integrieren.\n\nWährend des Downloads zeigt GWGET auf Wunsch die geschätzte Restdauer des Vorgangs, die bereits übertragene Datenmenge oder weitere Informationen an.\n\n"}
{"id": "2129917", "url": "https://de.wikipedia.org/wiki?curid=2129917", "title": "Palo (OLAP-Datenbank)", "text": "Palo (OLAP-Datenbank)\n\nPalo ist ein speicherbasierter, multidimensionaler Real-Time-OLAP-Datenbank-Server (MOLAP) zur Verwaltung von betriebswirtschaftlichen oder statistischen Datenbeständen (Multidimensionale Datenbank). Neben der multidimensionalen Abfrage können Daten auch zurückgeschrieben und in Echtzeit konsolidiert werden.\n\nPalo hält alle Daten komplett im Arbeitsspeicher, um einen schnellen Zugriff auf die Daten zu ermöglichen. Der Server ist Open Source. Eine Microsoft Excel Add-in Komponente führt die Kommunikation zwischen Palo OLAP-Datenbank und Excel aus. Es stehen zusätzlich ein vollständiger ETL-Server und Client Libraries zur Verfügung.\n\nÜber APIs in Java, PHP, C/C++ oder .NET kann Palo in andere Softwareumgebungen integriert werden. Zudem existiert eine Open-Source-Integration in OpenOffice.org unter dem Namen PalOOCa (Palo for OpenOffice.org Calc).\n\nIn Verbindung mit Microsoft Excel wird Palo als Business-Intelligence- und Performance-Management-Anwendung zumeist für Controlling und Finanzplanung eingesetzt. Mit Palo können beliebig viele Excel-Arbeitsplätze online miteinander verknüpft werden, die alle auf einen zentralen Datenbestand zugreifen („Single Point of Truth“).\n\nPalo ist Bestandteil der Business-Intelligence-Softwarelösung Jedox. Daten können dort über das eingesetzte Frontend zurück in die Palo OLAP-Datenbank geschrieben werden, sowohl über ein lokales Excel-Add in als auch über eine Web-Oberfläche. Der Server ist als Open-Source- und proprietäre Software erhältlich.\n\nDer MOLAP-Server Palo wird von der Firma Jedox AG aus Freiburg im Breisgau entwickelt.\n\n\n"}
{"id": "2130270", "url": "https://de.wikipedia.org/wiki?curid=2130270", "title": "Cross-Language Evaluation Forum", "text": "Cross-Language Evaluation Forum\n\nDas Cross-Language Evaluation Forum (\"kurz\": CLEF) ist aus der TREC-Aufgabe Cross-Language Information Retrieval (CLIR) entstanden, welches sich hauptsächlich mit dem Cross-Language Information Retrieval europäischer Sprachen befasste.\n\nCLEF ist mittlerweile ein eigenständiges EU-Projekt und bietet eine Plattform zur Evaluierung und Verbesserung von Information-Retrieval-Systemen für europäische Sprachen.\n\nDie seit 2000 von CLEF jährlich organisierten System-Evaluations-Kampagnen sollen die Zusammenarbeit von Forschern und Entwicklern fördern und somit zukünftige Initiativen zur Zusammenarbeit von Gruppen mit ähnlichen Interessen vereinfachen und fördern.\nEs geht hierbei darum, Nutzeranfragen, die in einer beliebigen europäischen Sprache gestellt werden, in beliebigsprachigen Dokumentmengen abzuarbeiten und eine nach Relevanz geordnete Ergebnismenge zu erhalten, die auf diese Frage eine Antwort darstellt.\nAuch einsprachiges Information Retrieval stellt einen Schwerpunkt der Evaluierung dar, ist jedoch vor allem für Teams vorgesehen, die das erste Mal an der Kampagne teilnehmen.\nEs bestehen auch Kooperationen mit ähnlichen, anderssprachigen Initiativen aus den USA und Asien.\n\nDas eigentliche Ziel ist, die Entwicklung der europäischen Cross-Language Retrieval Systeme zu unterstützen und anzuregen, damit ihre Wettbewerbsfähigkeit auf dem Weltmarkt gesichert ist.\n\nDie Datenbestände in CLEF bestehen hauptsächlich aus Zeitungsartikeln und Meldungen von Nachrichtenagenturen und entstammen in jeder Sprache demselben Jahr bzw. Zeitraum, um sicherzustellen, dass dieselben Ereignisse und Themen in den einzelnen Datenbeständen jeder Sprache vorkommen. Weiterhin liegen auch Datenbestände aus wissenschaftlichen Quellen für fachliches Cross-Language Information Retrieval vor.\n\nFür die Auszeichnung der enthaltenen Datenelemente sind die einzelnen Dokumente mit SGML-Tags versehen. \n\nDie Kernsprachen sind Deutsch, Englisch, Französisch, Italienisch und Spanisch. Vereinzelt liegen auch Datenbestände in weiteren Sprachen vor.\n\nDie Themenstellungen müssen von den verschiedenen Sprachgruppen erarbeitet werden und sollen die Inhalte der entsprechenden Dokumente hinreichend wiedergeben bzw. zusammenfassen.\n\nVon jeder Sprachgruppe werden dann mehrere Vorschläge für Themen verfasst, wovon letztlich 50 ausgewählt werden, die den Evaluierern anschließend zur Verfügung gestellt werden. Diese 50 Topics werden nun in alle beteiligten Sprachen übersetzt, was anschließend noch einmal von Fachübersetzern geprüft wird, um eine gewisse Konsistenz in den Übersetzungen zu gewährleisten.\n\nDie gewählten Topics mit SGML-Tags bestehen aus einer fortlaufenden Nummer (num), einem Titel (title), einer kurzen Beschreibung (desc) sowie einer ausführlichen Beschreibung (narr).\n\nAusgangssprache (hier englisch)\n\ncodice_1\n\nZielsprache (hier italienisch)\n\ncodice_2\n\nDas Bewertungsverfahren für CLEF beruht auf der Pooling-Methode von TREC. Dazu müssen die teilnehmenden Systeme ihre integrierten, geordneten Ergebnislisten pro Themenstellung liefern. In diesen Listen findet man die Nummern derjenigen Dokumente für die jeweiligen Themen, die von den Systemen als relevant ermittelt wurden und zwar in absteigender Reihenfolge der vermuteten Relevanz. In einem Pool finden sich die ersten 60 Dokumente für das entsprechende Topic wieder. Entscheidend ist nur, dass alle Ergebnislisten zu einer der 50 Themenstellungen der Hauptaufgabe bzw. zu einer der je 25 Themenstellungen der domänenspezifischen Aufgabe (GIRT) und der wissenschaftlichen Aufgabe (MARYLLIS) zusammengespielt werden und danach in eine Zufallsreihenfolge gebracht werden. So ist nicht mehr feststellbar, welches Dokument von welchem System stammt oder an welcher Stelle der vermuteten Relevanzreihenfolge es vorher zu finden war. Diese Listen werden anschließend nach Sprachen aufgeteilt. Hier werden die entsprechenden Dokumentnummern aus den Korpora, die zu einer bestimmten Sprache gehören, zusammengeführt. Man erhält so pro Themenstellung eine umfangreiche Sammlung von Dokumenten zu einer jeweiligen Sprache, um anschließend eine Relevanzbewertung vornehmen zu können.\n\nBei der Relevanzbewertung werden die geordneten Ergebnislisten einer Sprache von Juroren einer jeweiligen Sprachgruppe beurteilt. Die Beurteilung wird mit Hilfe der von NIST entwickelten Bewertungssoftware ASSESS festgehalten. Die Bewertungen der Juroren, ob die Ergebnislisten für ein Thema relevant oder nicht relevant sind, werden den sprachbezogenen Ergebnislisten jeder Themenstellung hinzugefügt. Die Juroren ziehen bei ihrer Beurteilung die Themendiskussionen der Sprachgruppen als Richtlinien für die Relevanzentscheidung in Betracht und sie benutzen die Narratives der Themenstellungen als Entscheidungshilfen.\n\nCLEF zielt vor allem auf die Weiterentwicklung von multilingualen IR-Systemen ab. Dabei sollte aber nicht vernachlässigt werden, dass auf dem Weg zum Testen mehrsprachiger IR-Systeme, weitere Sprachen mit einbezogen werden können und auch das Sammeln von Erfahrungen bei der Ausrichtung von Tests war ein wichtiger Punkt. Aus diesem Grunde wurden unterschiedliche Aufgabenstellungen (Tasks) formuliert, denen sich die Teilnehmer stellen konnten.\nDie Hauptaufgabenstellung von CLEF ist das mehrsprachige Information Retrieval (multilingual task). Hierbei werden Dokumente in allen Hauptsprachen gesucht, wobei eine dieser Sprachen als Anfangssprache dient. Anschließend wird eine Liste erstellt, die sämtliche Ergebnisse aus allen Dokumentsammlungen (d. h. aus allen Hauptsprachen) beinhaltet. Es ist aber auch möglich weitere Sprachen als Ausgangssprache zu verwenden (z. B. Finnisch, Russisch, Schwedisch), da entsprechende Übersetzungen der Themenstellungen dieser Gruppen erstellt werden. Die Hauptsprache bleibt dabei ebenfalls die Zielsprache.\n\nBei der zweisprachigen Aufgabenstellung (bilingual task) wird in einer beliebigen Ausgangssprache, die nicht gleich der Zielsprache ist, nach Dokumenten z. B. in englischer oder holländischer Sprache gesucht. Aus diesem Grund stellen die CLEF-Organisatoren auch Übersetzungen der Themenstellungen ins Holländische sowie weitere linguistische Ressourcen für das Holländische (Stoppwortliste, Stemmer, Holländisch-Englisch Lexikon) zur Verfügung.\n\nDie einsprachige Aufgabenstellung (monolingual task) sieht auf der anderen Seite vor, nach Dokumenten z. B. in deutscher, englischer, französischer, holländischer, italienischer und spanischer Sprache in einer der entsprechenden Dokumentsammlungen zu suchen. Die englische Sprache wird in diesem Fall ausgeschlossen, da durch den Ad-hoc-Retrieval Task von TREC dieser Bereich bereits in der Vergangenheit abgedeckt wurde und somit keine neu Herausforderung im Hinblick auf linguistische Probleme und Übersetzungsfragen darstellt. Die einsprachige Aufgabenstellung ist als Einstieg für CLEF-Teilnehmer gedacht und auf diese Weise können neue Sprachen für multilinguale Aufgabenstellungen eingeführt werden.\n\nDie wissenschaftliche bzw. fachbezogene Aufgabenstellung (scientific and domain-specific) erlaubt nach (sozial)wissenschaftlichen Dokumenten in speziellen Dokumentsammlungen nämlich GIRT (German Indexing and Retrieval Testdatabase) oder AMARYLLIS zu suchen. Damit reagierte CLEF auf die immer wieder aufkommenden Vorwürfe, dass CLEF große Evaluierungen immer nur auf Basis von Zeitungstexten durchführe und man so nicht zu übertragbaren Ergebnissen gelange. Die Dokumente der GIRT- und AMARYLLIS-Datenbanken enthalten auch intellektuell vergebene Schlagwörter jeweils aus einem (sozial)wissenschaftlichen Thesaurus, der ebenfalls zur Verfügung gestellt wird (auch in englischer bzw. bei GIRT auch in russischer Übersetzung). Außerdem werden dafür spezifische Themenstellungen auf Englisch und Deutsch bzw. Französisch (bei GIRT außerdem in Russisch) bereitgestellt.\n\nDie letzte Aufgabenstellung ist die interaktive Aufgabenstellung (interactive task). Diese soll vor allem eine experimentelle Aufgabenstellung definieren. Ziel ist hier, die Evaluierung von interaktiven CLIR zu erforschen und Vergleichsmaßstäbe zu entwickeln, an denen weitere Forschungen gemessen werden können. Hier wird also die Retrievaleffektivität in Kombination mit der Benutzungsoberfläche bewertet. Explizit geht es hier um die Möglichkeiten, die Anfrage zu formulieren und zu verändern und die Ergebnisdokumente schnell bewerten zu können. Die Bearbeitung der Anfragen übernehmen in diesem Fall Testpersonen. Somit werden die Anfragen nicht automatisch vom System oder von Experten erstellt.\n\nHierbei führen die Teilnehmer mit unterschiedlichen Retrievalsystemen eine Suche zu einem Thema durch. Die Anfrage an die Retrievalsysteme wird in einer Sprache gestellt und sie liefern Dokumente in allen Zielsprachen. Die Retrievalsysteme benutzen systemspezifische Methoden um die Suche, die Übersetzung oder die Transformation in andere Sprachen zu lösen. Am Ende des Rückgewinnungsprozesses müssen sie einen integrierten und geordneten Ergebnissatz der Dokumente liefern, von denen angenommen wird, dass sie für die Themenstellung relevant sind. Die Integration der Ergebnisse aus verschiedenen Datenbeständen ist neben der Lösung der Übersetzungsprobleme eine weitere Herausforderung.\n\nSeit 2003 gibt es eine Frage-Antwort-Disziplin (QA Track, kurz: QA@CLEF), die Frage-Antwort-Systeme für nicht-englische europäische Sprachen evaluiert. Im Jahr 2007 wurden die Dokumenten-Kollektionen massiv geändert, indem für jede beteiligte Sprache ein Schnappschuss der Wikipedia zu den traditionellen Nachrichten-Korpora hinzugenommen wurde. Im Jahr 2009 wurde ein komplett neues Korpus mit EU-Dokumenten (JRC-Acquis) genommen.\nIn den verschiedenen Jahren wurden auch weitere Aufgaben bei QA@CLEF angeboten, z. B. Fragebeantwortung für gesprochenen Sprache, Fragebeantwortung für geographisch gefärbte Fragen zu Wikipedia-Inhalten (GikiP, GikiCLEF).\n\nJedes Jahr seit 2000 veranstaltet CLEF auch einen Workshop, wo die aktuellen CLEF-Ergebnisse präsentiert und diskutiert werden. Dabei orientiert sich der Veranstaltungsort stets(?) an der Konferenz ECDL.\nIm Folgenden sind die Tagung-Orte angegeben:\n\n"}
{"id": "2134274", "url": "https://de.wikipedia.org/wiki?curid=2134274", "title": "Macintosh II", "text": "Macintosh II\n\nDer Macintosh II war ein Apple Macintosh-Rechner und der erste der Macintosh-II-Serie. Er erschien 1987 und wurde meist kurz „Mac II“ genannt.\n\nEr verfügt über einen Motorola 68020-Prozessor mit einer Taktfrequenz von 16 MHz. Der Arbeitsspeicher war standardmäßig 1 MB groß und aus SIMMs aufgebaut. Der Maximalausbau liegt bei 20 MB. Die FDHD-Erweiterung ermöglicht den Ausbau auf bis zu 68 MB. Die optionale Festplatte verfügte über eine Kapazität von 20 MB und war mittels SCSI angeschlossen. Durch den SCSI-Bus bieten sich weitere Möglichkeiten zur Erweiterung, so können mehrere externe Geräte betrieben werden, wie Scanner, weitere Festplatten, CD-ROM-Laufwerke oder Streamer zur Datensicherung. Für Erweiterungskarten stehen sechs NuBus-Steckplätze zur Verfügung.\n\nDer Macintosh II war der erste Macintosh, der modular aufgebaut war und nicht über einen fest ins Gehäuse integrierten Monitor verfügte. Er bildete die Grundlage für eine Serie von Macintosh-II-Rechnern, wie den Macintosh IIx oder den Macintosh IIfx.\n\n"}
{"id": "2140229", "url": "https://de.wikipedia.org/wiki?curid=2140229", "title": "Disc-EDV-Report", "text": "Disc-EDV-Report\n\nDisc-EDV-Report (D.E.R.) war von 1988 bis 1994 eine Softwarezeitschrift mit 5,25\"-Diskette für IBM-PCs und kompatible aus dem Verlag Erwin Simon, Ulm (heute bekannt als S.A.D. GmbH).\n\nDie Erscheinungsweise war zunächst monatlich, ab 1993 dann alle zwei Monate.\nNeben Anleitungen zu der Shareware- und Public Domain-Software, die sich auf der beigelegten Diskette befand, wurde in der Zeitschrift unter anderem neue Software (sowohl kommerzielle, als auch Shareware) vorgestellt und getestet, Computerbücher vorgestellt, Spieletipps und Programmierkurse sowie Leserbriefe abgedruckt.\nAuf der Diskette befand sich zunächst ausschließlich Software für DOS, in Ausgabe 1/2 1993 dann erstmals ein Programm für Windows (ein Kartenspiel).\nDamals beliebte Software auf der Heftdiskette war beispielsweise McAfee VirusScan, diverse Kommandozeilentools, das Spiel Hülsi vom Autor und Redaktionsmitglied Roland G. Hülsmann (später bekannt durch XProfan) oder Spiele von Apogee Software wie Commander Keen. Der Preis der Zeitschrift betrug 14,80 DM.\n\nDer Verlag Simon hatte nach eigenen Angaben 1987 als erster eine Diskettenzeitschrift, also eine komplette Zeitschrift auf Diskette, veröffentlicht. Diese war der Vorgänger von Disc-EDV-Report.\n\n\"Ähnliche Zeitschriften auf bzw. mit Diskette waren:\"\n"}
{"id": "2141024", "url": "https://de.wikipedia.org/wiki?curid=2141024", "title": "Linux Mint", "text": "Linux Mint\n\nLinux Mint ist eine Linux-Distribution für PC in zwei parallel verfügbaren Ausgaben. Die Hauptausgabe, einfach \"Linux Mint\" genannt, basiert auf der Linux-Distribution Ubuntu und ist in verschiedenen Varianten verfügbar, nämlich als Cinnamon-, MATE-, Xfce- und KDE-Edition. Die zweite (äußerlich sehr ähnliche) Ausgabe beruht auf Debian und wird zur Unterscheidung \"Linux Mint Debian Edition (LMDE)\" genannt. Maintainer für Linux Mint und LMDE ist Clément Lefèbvre.\n\nLinux Mint wurde im Jahr 2006 aus Ubuntu abgezweigt, um beliebte und frei verfügbare Software besser in eine Distribution zu integrieren. Neben quelloffener freier Software sollte dies vor allem auch für proprietäre, nicht-freie, aber beliebte Software wie z. B. Adobe Flash oder die überwiegende Zahl von Multimedia-Codecs (wie MP3 oder H.264) gelten. In der sehr populären Mutterdistribution Ubuntu dagegen wurde – zum damaligen Zeitpunkt – freie und nicht-freie Software aus politischen und ideologischen Gründen strikt voneinander getrennt; nicht-freie Software wurde in ein optionales Zusatzangebot ausgelagert.\nLinux Mint hatte mit diesem zunächst an beliebter nicht-freier Software orientierten integrativen Konzept Erfolg. Damit erweiterten sich aber auch die selbstgesteckten Ziele und Ambitionen.\n\nIm Mai 2014 entschieden sich die Entwickler von Linux Mint, der Stabilität und Integration aller Komponenten noch größeres Gewicht als vorher zu geben. Seit Mai 2014 werden sämtliche kommenden Linux-Mint-Veröffentlichungen nur noch auf der aktuellen Ubuntu \"Long Term Support (LTS)\" Codebasis, und seit August 2014 diejenigen der Debian Edition auf der aktuellen Debian \"Stable\" Codebasis beruhen. Das bedeutet eine besonders hohe Stabilität der Codebasis beider Ausgaben von Linux Mint und damit bestmögliche Vorbedingungen für eine besonders gute Integration aller Komponenten in Linux Mint. Gleichzeitig versprachen die Entwickler aber, die wesentlichen und für Endanwender wichtigen Desktop-Programme trotz der stabilisierten Codebasis von Zeit zu Zeit zu aktualisieren. Die zweite Veröffentlichung unter den neuen Regeln, Linux Mint 17.1 \"Rebecca\", brachte Ende November 2014 in der Tat neuere Versionen der wichtigsten Anwenderprogramme mit.\n\nAls Fenster zum Anwender setzt Linux Mint auf den Einsatz eigens entwickelter Desktop-Umgebungen wie Cinnamon. Damit soll der erreichte Grad der Integration innerhalb der Distribution dem Nutzer in einfacher und benutzerfreundlicher Form zugänglich gemacht werden. Cinnamon startete als Fork der Gnome Shell, um eine Benutzeroberfläche zu schaffen, die moderne Konzepte von Gnome 3 mit der traditionellen Bedienung von Gnome 2 verbindet. Auch an der Entwicklung von MATE, der Weiterentwicklung der 2010 eingestellten Benutzeroberfläche Gnome 2, sind die Entwickler beteiligt. Linux Mint ist eine der wenigen Distributionen, die ihre bevorzugten Desktop-Umgebungen auf der Basis der eigenen Bedürfnisse und zum Erreichen der selbstgesteckten Ziele selbst entwickeln.\n\nDas Gesamtpaket nach den Regeln des neuen Konzeptes von Mai 2014 inklusive einer stabilen Codebasis, Integration aller Komponenten, Updates wichtiger Anwender-Programme, Benutzerfreundlichkeit und Desktop-Umgebungen wird – mit Abstrichen bei der Bereitstellung der neuesten Anwenderprogramme – von Fachmedien (u. a. The Register, Ars Technica) von sehr gut bis teils enthusiastisch bewertet.\n\nBeide Ausgaben von Linux Mint, die Hauptausgabe und LMDE, liegen sowohl in einer 32-Bit- als auch einer 64-Bit-Version vor. Für die Installation hat man anschließend die Wahl zwischen mehreren DVD-Installationspaketen (mittels herunterladbarer ISO-Dateien), die jeweils eine andere vorkonfigurierte Desktop-Umgebung mitbringen. Die offiziellen Desktop-Umgebungen von Linux Mint sind MATE und Cinnamon. Ausschließlich die auf Ubuntu basierende Hauptausgabe von Linux Mint bietet zudem die Desktop-Umgebungen KDE und Xfce vorkonfiguriert an. Alle anderen Desktop-Umgebungen lassen sich in beiden Ausgaben von Linux Mint immer auch mittels Paketverwaltung nachträglich installieren, dann allerdings ohne ausgefeilte Vorkonfiguration.\n\nLinux Mint enthält im Gegensatz zu den im Hauptteil nur aus freier Software bestehenden Linux-Distributionen Ubuntu und Debian bereits Codecs für verschlüsselte DVDs, MP3 oder DivX sowie Plugins wie Adobe Flash und Oracle Java. Zudem ist NDISwrapper für die Unterstützung von WLAN-Karten ohne eigenen Linux-Treiber vorinstalliert und es gibt einige Programme und Anleitungen, um die Kommunikation mit Windows-Systemen auf dem gleichen oder anderen Computern zu vereinfachen. Technisch benutzt man die Paketquellen von Ubuntu bzw. Debian (letzteres für LMDE) sowie eine weitere, eigene, mit den veränderten und zusätzlichen Paketen. Dadurch sind für die Benutzer von Linux Mint alle Aktualisierungen von Ubuntu bzw. Debian ebenfalls verfügbar.\n\nZur Software, die spezifisch für Linux Mint entwickelt wurde und wird, gehört die Desktop-Umgebung \"Cinnamon\", sowie die \"MintTools\", die unter anderem das Systemmenü \"MintMenu\" enthalten. Dieses ist im Aufbau angelehnt an die Menüs des SUSE Linux Enterprise Desktop (SLED) oder auch von Microsoft Windows Vista. Besonderheiten sind hier die Möglichkeit, das Menü selbst zu durchsuchen, Optionen, um zuletzt genutzte Dateien und Ordner, als auch ausgewählte Ordner anzuzeigen, und um favorisierte Programme prominent zu platzieren. Dazu gibt es unter dem Namen \"Romeo\" ein Betaversion-ähnliches Paketverzeichnis nach Art der \"Debian unstable\", aus der die selbst entwickelten Programme (wie die Komponenten der Desktop-Umgebungen Cinnamon und MATE) erst in die beiden Ausgaben Linux Mint und LMDE übernommen werden, wenn sich diese als hinreichend stabil erwiesen haben.\n\nDie vor allem von Linux Mint eingesetzten Desktop-Umgebungen sind Cinnamon und MATE. Darüber hinaus sind auch Versionen mit Xfce und KDE verfügbar, diese werden jedoch nicht so umfangreich angepasst und unterstützt. Die Version 18.3 war zudem die letzte, die mit KDE ausgeliefert wurde.\n\nBis einschließlich Version 11 von Linux Mint wurde mit Gnome 2 nur eine Desktop-Umgebung verwendet. Der Versionssprung auf Gnome 3 war mit größeren Veränderungen verbunden. Um verschiedenen Bedürfnissen gerecht zu werden, kam es zu einer Aufspaltung, bei der MATE als Fork von Gnome 2 weiterentwickelt wird, während Cinnamon Gnome 3 integrierte.\n\nUm den Nutzern die neuen Funktionen von Gnome 3, aber auch ein vertrautes Aussehen des Desktops anzubieten, wurden die Mint Gnome Shell Extensions (MGSE) eingeführt, die eine Taskleiste sowie ein Startmenü bereitstellen. Da es sich bei den MGSE lediglich um Plugins der Gnome-Shell handelte, stießen sie bald an ihre Grenzen. Deshalb wurde beschlossen, die MGSE in einen Fork der Gnome-Shell mit dem Namen Cinnamon (englisch „Zimt“) umzuwandeln, der ab Version 13 von Linux Mint eingebettet wurde.\n\nDie genannten Zahlen gelten für die Desktop-Umgebungen MATE und Cinnamon. Den geringsten Hauptspeicherverbrauch aller Editionen zeigen LMDE MATE und LMDE Cinnamon mit 282–285 MB direkt nach der Installation. KDE verlangt dagegen bereits einen Hauptspeicher von 2 GB.\n\n32-bit-x86-Prozessoren mit Physical-Address Extension (PAE) (ab dem Pentium Pro bzw. Athlon) als auch grundsätzlich alle 64-bit-AMD64-Prozessorarchitekturen werden von beiden Linux-Mint-Ausgaben unterstützt. Einige ältere 32-bit-Prozessoren (Pentium M) aus der Zeit 2003/2004 machen ihre Unterstützung für PAE nicht kenntlich. Für diesen Fall existiert seit Linux Mint „Qiana“ und „Rebecca“ ein spezieller Kernelparameter, der die Installation erzwingt.\n\nAlle x86-Prozessoren vor dem Pentium Pro / Athlon unterstützen PAE grundsätzlich nicht. Für diese Prozessoren ist die Hauptausgabe von Linux Mint ab Version 17.2 ungeeignet. Die „Linux Mint Debian Edition“ hingegen unterstützt in der 32-bit-Version Prozessoren ohne PAE „out-of-the-box“. LMDE ist eine der wenigen verbliebenen Möglichkeiten, ältere Rechner mit solchen Prozessoren mit einem aktuellen Betriebssystem auszustatten.\n\nHier existieren auch eine spezielle 64-Bit-\"OEM-Version\" (mit Cinnamon) und eine 32/64-Bit-\"No-Codecs-Version\"; erstere ermöglicht Vertreibern von Computern eine Vorinstallation auf Geräten. Die \"No-Codecs-Version\" (vormals \"USA-Japan Distribution, Light Edition\" oder \"Universal Edition\") enthält keinerlei proprietäre oder patentierte Software, wodurch der Multimedia-Support praktisch entfällt. Diese ist vor allem für Benutzer in Ländern geeignet, in denen das Herunterladen einer Distribution mit proprietärer oder patentierter Software verboten ist. Adobe Flash ist hier durch \"Gnash\" ersetzt, Unterstützung für verschlüsselte DVDs, Windows-Codecs, Unterstützung für geschützte Formate (zum Beispiel MP3), Unrar und Sun Java ist nicht vorhanden. Die no-Codecs-Version kommt mit den vorkonfigurierten Desktop-Umgebungen MATE oder Cinnamon.\n\nAlle Versionen ab Linux Mint 17 basieren seit Ende Mai 2014 technisch ausschließlich auf den \"LTS\"-Versionen von Ubuntu, die alle zwei Jahre veröffentlicht werden (vorher basierten neue Linux Mint-Versionen auf den halbjährlich veröffentlichten regulären Ubuntu-Ausgaben). Die Codebasis von Linux Mint basiert daher für zwei Jahre bis 2018 auf der im April 2016 veröffentlichten Ubuntu LTS-Version Ubuntu 16.04 LTS. Alle auf der Codebasis von Ubuntu 16.04 LTS basierenden Linux Mint-Zwischenversionen werden als LTS-Versionen bis April 2021 von den Entwicklern unterstützt und bis dahin regelmäßig mit Sicherheitsupdates versorgt. Neben diesen Updates wird es bis zum Erscheinen der nächsten Ubuntu LTS-Version im Jahr 2018 (Ubuntu 18.04 LTS) etwa alle sechs Monate Zwischenversionen geben. Damit erhalten die Nutzer fehlerbereinigte Versionen von Programmen aus der Ubuntu 16.04 LTS-Codebasis mit vereinfachtem Upgrade-Mechanismus. Diese Zwischenversionen bringen zudem neuere Versionen der Linux Mint-Eigenentwicklungen (wie Cinnamon) sowie neue Versionen einer begrenzten Auswahl besonders populärer Programme und des Linux-Kernels mit. Grundsätzlich weiterentwickelte und neue Programmpakete mit neuen Hauptversionsnummern wird es in Linux Mint erst wieder 2018 geben, wenn Ubuntu 18.04 LTS erscheint. Auf neuere Hardware-Treiber und damit eine zukunftsfähige Gerätekompatibilität müssen Nutzer dagegen nicht verzichten, dafür gibt es einen von Ubuntu entwickelten automatischen Scharniermechanismus, der dem Anwender geeignete Treiber zur Verfügung stellt.\n\nDie hier aufgelisteten Versionen beziehen sich ausschließlich auf die Hauptausgabe von Linux Mint, die am Erscheinungstag für gewöhnlich zunächst mit den Editionen mit den vorkonfigurierten Desktop-Umgebungen Cinnamon und MATE erscheinen. Alle weiteren Editionen der Hauptausgabe folgen zumeist in den nächsten Wochen. Die nicht-numerischen Codenamen der jeweils etwa halbjährlichen Veröffentlichungen sind weibliche Vornamen mit Endung „a“, deren Anfangsbuchstaben alphabetisch fortlaufend sind.\n\nÄltere Versionen von Linux Mint, als \"Community Editions\" bezeichnet, offerierten auch eine speziell für Mint optimierte Desktop-Umgebung LXDE, auf der Lubuntu-Variante von Ubuntu basierend, sowie eine vorkonfigurierte Variante mit Fluxbox.\n\nDie „Linux Mint Debian Edition“ (LMDE) ist eine zweite Ausgabe von Linux Mint. LMDE gleicht in der Philosophie und im Erscheinungsbild der Hauptausgabe von Linux Mint und soll dieselbe Funktionalität bieten, basiert jedoch auf der Distribution Debian. Da Debian wiederum die Distribution ist, auf der Ubuntu basiert (die die Grundlage der Hauptausgabe von Linux Mint darstellt), sind die Unterschiede bei der Codebasis zwischen beiden Ausgaben von Linux Mint nicht immer besonders groß. Dennoch ist LMDE nicht mit Ubuntu kompatibel und verwendet Programmpakete, die aus den Paketverzeichnissen der Distribution Debian entstammen. Ein „Cross-Upgrade“ zwischen beiden Ausgaben von Linux Mint ist damit nicht möglich. Wie die Hauptausgabe von Linux Mint benutzt auch LMDE die Eigenentwicklungen von Linux Mint, u. a. sind dies die Desktop-Umgebungen Cinnamon und MATE.\n\nEinige der Hauptgründe, eine zweite Linux-Mint-Ausgabe – eben LMDE – basierend auf Debian herauszugeben, waren nach Angaben der Entwickler von Linux Mint:\n\nLMDE wurde im Anfangsjahr 2010 von den Linux-Mint-Entwicklern zunächst als Experiment angesehen, welches weiter verfolgt wurde, da es eine gute Resonanz fand. LMDE basierte zu dieser Zeit auf Debian Testing, einer semistabilen Edition von Debian, von der trotz des permanenten Einfließens aktueller Programmpakete eine höhere Stabilität als bei regulären Ubuntu-Veröffentlichungen erwartet wurde. LMDE wurde zunächst als „Rolling Release“-Distribution konzipiert, d. h. es flossen permanent neue Programmversionen in das LMDE-Paketverzeichnis ein. Da sich dieses Vorgehen nicht bewährte, ging man 2011 zu einem „Semi-Rolling-Release“ über, mit mindestens einem DVD-Abzug und zwei „Update Packs“ im Jahr, um die Integrität der LMDE-Codebasis auf den Rechnern der LMDE-Nutzer zu gewährleisten. Im März 2014 erschien das finale Update-Pack für LMDE (Update Pack 8 bzw. LMDE 201403), es wird keine weiteren Updates aus „Debian Testing“ mehr geben. Stattdessen wurde LMDE aufgewertet.\n\nAm 10. April 2015 erschien LMDE 2.0 (Codename „Betsy“), das auf dem zu dieser Zeit aktuellen Debian Stable (Debian 8.0 „Jessie“) basiert. Debian Stable erhält ebenfalls LTS-Support, ähnlich wie Ubuntu LTS. Damit vollzog LMDE einen sehr ähnlichen Schwenk hin zu stabilen Paketquellen wie die Hauptausgabe von Linux Mint. Die grundsätzlichen Vorteile der Nutzung von Debian gegenüber Ubuntu (wie die Schnelligkeit, Stabilität) sollen dabei erhalten bleiben. Im Unterschied zur Mutterdistribution Debian 8.0 „Jessie“ ist bei LMDE 2.0 das init-System SysVinit voreingestellt.\n\nZusätzlich soll es in zukünftigen Zwischenversionen von LMDE 2.x Sicherheitsupdates und fehlerbereinigte Versionen sowie allgemein größere Updates bei populären Anwendungen geben. Außerdem werden periodisch Treiber für neue Hardware zusammen mit fehlerbereinigten Linux-Kerneln zur Verfügung gestellt, um eine maximale Hardware-Kompatibilität sicherzustellen. LMDE 2.x nutzt dafür den regulären Update-Mechanismus von Debian Stable, der nur Sicherheitsaktualisierungen vorsieht. Neue Versionen von Anwendungen stellte das Mint-Projekt selbst bisher vom Webbrowser Mozilla Firefox, dem E-Mail-Client Mozilla Thunderbird und den systemeigenen Hilfsprogrammen zur Verfügung; zudem wird die Desktop-Umgebung zeitnah auf die jeweils aktuelle Version aktualisiert. Aktualisierungen des Kernels und weiterer Anwendungen, die über reine Sicherheitsupdates hinaus gehen, muss der Anwender aus dem Backport-Repository des Debian-Projektes beziehen und sein System entsprechend konfigurieren.\n\nAm 13. März 2017 stellte das Mint-Projekt neue ISO-Abbilder für LMDE 2.0 (keine neue Versionsnummer) zur Verfügung, die alle bisher erschienenen Updates für die vorkonfigurierte Software-Auswahl enthalten. Die Desktop-Umgebung Cinnamon liegt jetzt in Version 3.2 vor.\n\nDie neue Version LMDE 3 „Cindy“ steht seit dem 31. August 2018 als ISO-Abbild in einer 64-bit- und einer 32-bit-Variante zur Verfügung. Die bisherige Version 2 wird nur noch bis 1. Januar 2019 unterstützt. Ein Upgrade ist ohne Neuinstallation möglich.\n\nDie hier aufgelisteten Versionen beziehen sich ausschließlich auf die periodisch freigegebenen ISO-Installationsdateien der „Linux Mint Debian Edition“ (LMDE) von Linux Mint. Eine echte Versionsnumerierung mit Codenamen begann erst 2015. Ab 2012 erschienen am jeweiligen Erscheinungstag zwei 32-bit und 64-bit Editionen mit den vorkonfigurierten Desktop-Umgebungen Cinnamon und MATE. Mit LMDE 3 entfielen die beiden MATE-Editionen.\n\nIn den Standardeinstellungen der mitgelieferten Aktualisierungsverwaltung \"mintUpdate\" wurden vorhandene Aktualisierungen zentraler Kernkomponenten von Linux Mint ausgeblendet. Das Programm unterschied hierbei zwischen „nicht sicheren Aktualisierungen“ (Ebene 4; u. a. X.Org-Server, D-Bus, Mesa 3D, Systemd/Upstart) und „gefährlichen Aktualisierungen“ (Ebene 5; u. a. Linux-Kernel, GRUB), die die Stabilität des Systems „möglicherweise“ oder „bekanntermaßen“ negativ beeinflussen sollen.\n\nDieses Verhalten schloss auch Sicherheitsaktualisierungen mit ein, wodurch ein mit Standardeinstellungen betriebenes System dauerhaft bekannte Sicherheitslücken aufwies. Dies führte im November 2013, ausgelöst durch kritische Beiträge von Entwicklern der Mutterdistribution Ubuntu, zu einer Kontroverse um die Sicherheit von Linux Mint.\n\nLinux Mint verteidigte dieses Verhalten mit der Begründung, dass die Abwägung von Stabilität und Sicherheit bei Linux Mint „ein zu konfigurierendes Merkmal“ sei und Linux Mint in den Standardeinstellungen den Fokus auf Stabilität statt Sicherheit legen wolle.\n\nBis Linux Mint 17.3 wurde dieses Verhalten unverändert beibehalten. Seit Juni 2016 (Linux Mint 18) wird der Benutzer bei erstmaliger Nutzung von \"mintUpdate\" gebeten, eine „Aktualisierungsrichtlinie“ auszuwählen. Die für „unerfahrene Benutzer“ empfohlene Konfiguration blendet Sicherheitsaktualisierungen weiterhin aus, lediglich die Konfiguration für „erfahrene Benutzer“ tut dies nicht. Mit der Überarbeitung von \"mintUpdate\" im Juli 2017 (Linux Mint 18.2) werden Sicherheits- und Kernelaktualisierungen zwar standardmäßig angezeigt, allerdings nicht automatisch zur Installation ausgewählt. Mit Linux Mint 19 (Juni 2018) wurde, zusammen mit Einführung der Snapshot-Funktion, \"mintUpdate\" überarbeitet und die Einstufung von Aktualisierungen in Ebenen entfernt. Seither werden alle Aktualisierungen automatisch zur Installation ausgewählt. Zudem ist nun auch eine vollautomatische Aktualisierung des Systems ohne Zutun des Nutzers möglich.\n\nAm 20. Februar 2016 wurde die Website von Linux Mint angegriffen. Hierbei wurden Download-Links zu ISO-Abbildern der Distribution manipuliert, so dass einige Ausgaben von Linux Mint 17.3 Cinnamon-Edition an diesem Tag mit einer Backdoor ausgeliefert wurden. Zudem wurden über 70.000 Forenkonten gekapert, wodurch für Forennutzer, deren Forenkennwort mit ihrem E-Mail-Kennwort, oder ihrem auf einer anderen Seite genutzten Kennwort identisch ist, ein weiteres Risiko besteht.\n\nAls Reaktion auf die Angriffe wurden zum Schutz viele Einschränkungen auf den Servern von Linux Mint eingerichtet und die meisten Websites des Projektes auf HTTPS umgestellt. Die Verifikation der ISO-Abbilder soll durch Veröffentlichung von SHA-256-Prüfsummen und GPG Information präziser werden. Kritiker werfen den Projektbetreibern vor, zu spät auf die Probleme reagiert zu haben und nicht genügend Maßnahmen zu ergreifen, um einen erneuten Angriff zu vereiteln.\n\nVon Vertretern der Free Software Foundation, insbesondere von Richard Stallman, wird Linux Mint wegen seines Umgangs mit proprietären Betriebssystembestandteilen kritisiert. Da Linux Mint keine Richtlinie gegen die Aufnahme unfreier Software hat, liefert es unfreie Programme, Codecs und Binärblobs in Treibern des Betriebssystemkerns aus, was von Befürwortern der Freien-Software-Bewegung als Einschränkung der Freiheit des Benutzers gesehen wird. Die Projektbetreiber reagierten auf die Kritik, indem sie ab der Version Linux Mint 18 einige Codecs nicht mehr standardmäßig mit ausliefern, sondern diese, ähnlich wie bei Ubuntu, über die Paketquellen zur Installation anbieten.\n\n\n"}
{"id": "2145515", "url": "https://de.wikipedia.org/wiki?curid=2145515", "title": "IPhone", "text": "IPhone\n\nDas iPhone [] ist eine im Jahr 2007 eingeführte Smartphone-Modellreihe des US-amerikanischen Unternehmens Apple. Bislang wurden 21 verschiedene Modelle vorgestellt; die aktuellen Versionen erschienen im September 2018 – iPhone Xs sowie das iPhone Xr. Zuvor war am 21. März 2016 auch ein Ableger für die 4-Zoll-Modelle in Form des iPhone SE hinzugekommen.\n\nDas iPhone verwendet als Betriebssystem Apples eigenes System iOS, auf dem in den vorinstallierten Anwendungen die Funktionen eines Mobiltelefons genutzt werden können. Die restlichen vorinstallierten Apps entsprechen größtenteils den auch in Apples macOS enthaltenen Programmen, die jedoch für den Einsatz auf dem iPhone entsprechend angepasst wurden. Darunter befindet sich beispielsweise der Webbrowser \"Safari\" und das E-Mail-Programm \"Mail\". Weiterhin stehen in Apples zentraler Vertriebsplattform, dem App Store, mehr als 1,52 Millionen Programme zum Herunterladen bereit.\n\nDas Bedienkonzept des iPhone mit seiner weitgehenden Steuerung über den Multi-Touch-Bildschirm und die damit verbundene Benutzerfreundlichkeit gilt als maßgeblich für den Erfolg des iPhone. Es hatte und hat auch wesentlichen Einfluss auf die Gestaltung von Smartphones anderer Hersteller. Das amerikanische Nachrichtenmagazin \"Time\" wählte das iPhone zur „Erfindung des Jahres 2007“. Kritisch beurteilt wurden in den Medien hingegen übereinstimmend die schlechten Arbeitsbedingungen bei der Herstellung und Rohstoffgewinnung der für das iPhone benötigten Rohstoffe und juristische Auseinandersetzungen bei der Vermarktung. Bis Juli 2016 konnten weltweit etwa eine Milliarde Geräte verkauft werden.\n\nIn einem Interview erzählte Steve Jobs, damaliger Apple-CEO, dass er bereits Anfang der 2000er Jahre die Idee hatte, einen Multi-Touch-Bildschirm zu entwickeln, auf dem man wie auf einer Computertastatur tippen konnte. Dieser Bildschirm war ursprünglich für ein Tablet gedacht, Jobs entschied jedoch, dass zuerst ein Telefon gebaut werden sollte. 2004 begann die Entwicklung des späteren iPhones unter dem Codenamen „Project Purple“; das Apple-interne Programm zum Flashen von iPhones und iPhone-Prototypen heißt deshalb \"Purple Restore\", und das Programm zum Einrichten des iPhone seit iOS 5 \"Purple Buddy\". Während der Entwicklung wurde das Projekt selbst vor vielen Apple-Mitarbeitern geheimgehalten, es wurde sogar eine Benutzeroberfläche namens \"SkankPhone\" entwickelt, um nicht die eigentliche Oberfläche namens \"SpringBoard\" allen Mitarbeitern am \"Project Purple\" zeigen zu müssen. Für den endgültigen Namen des Smartphones waren einige Bezeichnungen im Gespräch. So hätte es TelePod, ein Kofferwort mit den beiden Begriffen \"Telephone\" und \"iPod\", oder Mobi, die Kurzform von mobile, heißen können. Außerdem war der Vorschlag TriPod im Gespräch, der die drei Hauptfunktionen des Handys (iPod, Telefon und Internet) beschreiben sollte. Eine weitere Namensidee war iPad, die dann ab 2010 für das Tablet von Apple verwendet wurde.\n\nNach Angaben von Steve Jobs wurden während der Entwicklung des iPhone über 300 Patente und Geschmacksmuster angemeldet, unter anderem die Multi-Touch-Funktion und die Entsperrtechnik \"slide to unlock\" (Zum Entsperren streichen).\n\nIm September 2005 stellte Steve Jobs das Motorola \"ROKR E1\" vor, das als erstes Mobiltelefon mit Apples Mediensoftware iTunes synchronisiert werden konnte. Schon kurz darauf sickerte jedoch durch, dass er mit dem \"ROKR\" unzufrieden sei, weil es als Fremdprodukt nicht in die Designlinie der Apple-Produktpalette passte. Diese Einschätzung wurde im September 2006 von Apple durch den Entzug der \"ROKR\"-Unterstützung bei \"iTunes\" bestätigt. Stattdessen wurde eine weitere \"iTunes\"-Aktualisierung mit Unterstützung für ein noch unbekanntes Mobiltelefon veröffentlicht, das offensichtlich nicht nur Audio-, sondern auch Video- und Bilddateien wiedergeben können sollte. Dies führte in verschiedenen Medien zu Spekulationen über ein zu erwartendes Apple-Mobiltelefon, die bis zum Jahresende 2006 immer konkreter wurden.\n\nSchließlich wurde die erste iPhone-Generation (auch genannt: iPhone Classic, iPhone 2G) am 9. Januar 2007 auf der Macworld Conference & Expo in San Francisco vorgestellt. Dabei pries Steve Jobs die einfach zu bedienende und trotzdem funktionelle Benutzeroberfläche an. Da die virtuelle Software-Tastatur nur bei Bedarf eingeblendet wird, entsteht mehr Platz für Inhalte auf dem Bildschirm.\n\nAnfang Juni 2007 wurde der Verkaufsbeginn in den Vereinigten Staaten am 29. Juni durch die Ausstrahlung eines Fernsehwerbespots angekündigt. Vorerst waren die Geräte nur in den Apple Stores und Verkaufsstellen von AT&T erhältlich. In Europa wurde das Gerät ab dem 9. November 2007 angeboten. Zu diesem Zeitpunkt begann der Vertrieb in Deutschland ausschließlich über die heutige Telekom zum Preis von 399 Euro, gekoppelt mit einem auf das Telekom-Netz beschränkten SIM-Lock, im Gegenzug beteiligte die Telekom Apple an den monatlichen Umsätzen.\n\nDer Verkauf der Nachfolgegeneration, des iPhone 3G, startete am 11. Juli 2008 parallel in 21 Ländern, darunter Deutschland, Österreich und der Schweiz. Vorgestellt worden war die zweite Geräte-Generation am 9. Juni 2008 im Rahmen der WWDC 2008. Neu waren unter anderem die Unterstützung neuer Mobilfunkstandards sowie die Rückseite aus schwarzem Kunststoff.\n\nDie dritte iPhone-Generation, das iPhone 3GS, wurde etwa ein Jahr später, am 8. Juni 2009 vorgestellt. Neuerungen waren vor allem die bessere Kamera, der digitale Kompass sowie der schnellere Prozessor. Das Design des Geräts blieb bis auf den Schriftzug auf der Rückseite unverändert. Der Verkauf in Deutschland wurde am 19. Juni gestartet. Das \"S\" in der Modellbezeichnung steht für \"\" (engl. für ‚Geschwindigkeit‘).\n\nMit der Veröffentlichung des iPhone 4 erlangte die iPhone-Reihe die bis dahin größte Bekanntheit – nach der Vorstellung auf der WWDC am 7. Juni 2010 ging das Smartphone laut Apple an den ersten drei Verkaufstagen 1,7 Mio. Mal über die Ladentheke. Das Aussehen wurde von Grund auf verändert, die Vorder- und Rückseite bestehen aus flachem Glas. Neu sind zudem das hochauflösende Retina-Display und eine Frontkamera für Videotelefonate. In die Kritik geriet das iPhone 4 wegen seiner Empfangsprobleme, die bei zu festem Umklammern des Gehäuses auftraten.\n\nDas iPhone 4s wurde am 4. Oktober 2011 vorgestellt, dem Tag vor dem Tod Steve Jobs’; es kam am 14. Oktober 2011 auf den Markt. Neu war vor allem der Spracherkennungsassistent Siri, der in diesem Gerät erstmals zur Verfügung steht. Im Design unterscheidet sich das Gerät nur geringfügig vom Vorgänger. Das \"S\" in der Modellbezeichnung steht für Siri.\n\nDas iPhone 5 wurde am 12. September 2012 vorgestellt. Der Bildschirm wurde vergrößert, trotzdem ist es dünner und leichter als der Vorgänger. Als SoC kommt Apples A6-Chip zum Einsatz.\n\nDas iPhone 5s wurde am 10. September 2013 vorgestellt und am 20. September auf den Markt gebracht. Bei nahezu gleichem Design wie der Vorgänger iPhone 5 bietet es den schnelleren A7-Chip sowie Neuerungen im Kamerasystem (\"TrueTone-Blitz\", größeres Objektiv, \"SlowMotion-Mode\"). Hauptaugenmerk dieser Version ist ein in der Home-Taste integrierter Fingerabdruckscanner \"(Touch ID)\" und die neue Farbvariante \"Gold\".\n\nGleichzeitig mit dem iPhone 5s stellte Apple ein zweites iPhone-Modell vor, das iPhone 5c. Bei nahezu identischer Hardware wie das iPhone 5 ist es äußerlich einfacher gestaltet und verfügt wie das ältere iPhone 3G über eine Kunststoffrückseite in verschiedenen Farbvarianten.\n\nDas iPhone 6 wurde am 9. September 2014 in zwei Versionen mit 4,7 Zoll (iPhone 6) und 5,5 Zoll (iPhone 6 Plus) Displaygröße vorgestellt. Neben größeren Displays gibt es einige Detailverbesserungen bei der Kamera und ein integriertes Barometer zur Erfassung der Höhe, das präziser und unabhängig vom GPS-Empfang arbeitet. Erstmals wurde ein NFC-Modul zur ausschließlichen Nutzung von Apple Pay verbaut.\n\nAm 9. September 2015 wurde genau ein Jahr nach dem iPhone 6 der Nachfolger, das iPhone 6s, vorgestellt. Mit ihm zusammen wurde wieder eine 5,5-Zoll-Variante mit dem Namen iPhone 6s Plus angekündigt. Es besitzt ein druckempfindliches Display mit dem Namen \"3D Touch\" und unterstützt den neuesten Bluetooth-Standard . Der Prozessor im Apple-A9-SoC soll laut Apple bis zu 70 % schneller arbeiten und die integrierte Grafikeinheit um bis zu 80 % schneller sein als die Vorgängergeneration. Die Kameras wurden beidseitig mit höheren Auflösungen verbessert, wobei die rückseitige iSight-Kamera auch 4K-Videos aufnehmen kann. Die Touch-ID-Home-Taste soll nun den Fingerabdruck schneller erkennen. Das Design wurde weitestgehend vom iPhone 6 übernommen, kleinere Unterschiede sind ein S-Logo auf der Rückseite und die neue Farbvariante \"Roségold\".\n\nAm 21. März 2016 stellte Apple das 4-Zoll-Gerät iPhone SE vor, das bei Abmessungen und Design wie dem iPhone 5s über ähnliche technische Spezifikationen wie das iPhone 6s verfügt.\n\nDas iPhone 7 und iPhone 7 Plus wurden am 7. September 2016 vorgestellt. Das Design blieb weitestgehend identisch zum Vorgänger iPhone 6s; durch Verzicht auf einen Kopfhörerausgang ist das Gehäuse nun spritzwassergeschützt. Die Kamera hat eine optische Bildstabilisierung; durch eine zusätzliche Teleobjektiv-Kamera mit 2x-Zoom-Funktion ermöglicht das größere iPhone 7 Plus einen Bokeh-Effekt. Zur Verbesserung der Akkulaufzeit besitzt der Quad-Core-Prozessor A10 Fusion je zwei Kerne für leistungsstarke Aufgaben und zwei für hohe Effizienz.\n\nAm 12. September 2017 wurden von Apple drei neue Geräte vorgestellt: das iPhone 8, das iPhone 8 Plus und das iPhone X. Alle drei Geräte haben ein SoC, das von Apple als A11 Bionic Chip bezeichnet wird; wie auch das iPhone 4 und 4s haben alle drei Geräte eine Glasrückseite. Die Rückkamera der Geräte kann Videos mit einer Auflösung von 4K und einer Bildwiederholrate von bis zu 60 Hz aufzeichnen. Das drittgenannte Gerät hat anders als die Vorgängergeräte einen Bildschirm, der die gesamte Vorderseite umfasst, ohne dass es einen Rand gibt. Erstmals verzichtete Apple auf den Homebutton. Der Fingerabdrucksensor \"Touch ID\" wurde durch die Gesichtserkennung \"Face ID\" ersetzt. Der Verkauf startete am 3. November 2017.\n\nAm 12. September 2018 wurden von Apple wieder drei neue Geräte vorgestellt: Das iPhone XR, das iPhone XS sowie das iPhone XS Max. Alle drei Geräte sind mit dem neuen Prozessor, Apple A12 Bionic, ausgestattet. Im Gegensatz zum Vorgänger iPhone X gab es beim iPhone XS keine optischen Änderungen. Das iPhone XR ist das günstigste der drei neuen Modelle. Es ist schwächer ausgestattet, besitzt keine Dualkamera und hat ein LCD.\n\nDas iPhone wird in China von verschiedenen EMS-Anbietern endmontiert. Das erste iPhone wurde einzig vom Weltmarktführer Foxconn produziert. Ab dem iPhone 6 holte Apple zudem das Unternehmen Pegatron ins Boot. Das iPhone 7 wird von Pegatron und Foxconn produziert, während für das iPhone 7 Plus der Lieferant Wistron zusätzlich zu Foxconn beauftragt wurde.\n\nDie nachfolgend aufgelisteten Hersteller liefern eine oder mehrere iPhone-Baugruppen:\n\nAlps Denki (Kompass), Authentec (Touch-ID-Sensor), Bosch (Beschleunigungssensor), Broadcom (Touchscreen-Controller, Controller-Chips, Hochfrequenz-Modul), Cirrus Logic (Audio-Chipsatz), Corning (Bildschirm), Fairchild (Halbleiter), Globalfoundries (Chipsatz, Prozessor), Green Point (Kunststoffhülle des iPhone 5c), GT Advanced Technologies (Bildschirm), Hi-P (Kunststoffhülle des iPhone 5c), Huizhou Desay Battery (Akkumulator), Japan Display (Bildschirm), LG Display (Bildschirm), Maxim Integrated (Halbleiter), NXP Semiconductors (Mixed-Signal-Chip, NFC-Chip), OmniVision (Frontkamera), PMC-Sierra (integrierte Schaltkreise), Qorvo (Sender, Verstärker), Qualcomm (Baseband-Prozessor, Hochfrequenz-Modul), RF Micro Devices (Hochfrequenz-Modul), Samsung (Akkumulator, Chipsatz, Prozessor, Flash-Speicher), Sharp (Display), Skyworks (Sender, Verstärker), SK Hynix (DRAM), Sony (Kamera), STMicroelectronics (Gyroskop), TDK (Induktionsspulen), Texas Instruments (Halbleiter), Toshiba (Flash-Speicher), TriQuint Semiconductor (Hochfrequenz-Modul), TSMC (Chipsatz, Kamera, Touch ID-Sensor, Prozessor, DRAM), Win Semiconductors (Hochfrequenz-Modul), Xintec (Touch ID-Sensor).\n\nDer iPhone-Verkaufsstart in den Vereinigten Staaten war am 29. Juni 2007. Das Mobiltelefon wurde in den USA ausschließlich in Kooperation mit dem amerikanischen Mobilfunkkonzern AT&T Wireless angeboten. In Europa wurde das Gerät ab dem 9. November 2007 verkauft; zuerst in Deutschland und Großbritannien, ab dem 28. November in Frankreich und ab dem 14. März 2008 in Österreich und Irland. In Deutschland und Österreich war das iPhone ausschließlich bei der Telekom erhältlich.\n\nIn fast allen Ländern, in denen das iPhone 3G verfügbar war, begann der Verkauf parallel am 11. Juli 2008. Innerhalb der ersten drei Tage konnte Apple eine Million Geräte verkaufen.\n\nVerkaufsstart des iPhone 3GS war am 19. Juni 2009, unter anderem in den USA und Deutschland. Bis zum Oktober 2009 war das iPhone 3GS auch in China und November 2009 in Südkorea erhältlich; damit war das Gerät in insgesamt 86 Ländern erhältlich. Innerhalb der ersten drei Tage konnte Apple wie beim Vorgänger eine Million Geräte verkaufen.\n\nZum Verkaufsstart des iPhone 4 stellten sich besonders im Ausland viele Menschen an den Apple Stores an. Der Verkauf begann in den USA, Frankreich, Großbritannien, Japan und Deutschland am 24. Juni 2010. In den ersten drei Tagen wurden über 1,7 Millionen iPhone 4 abgesetzt. Jedoch war das Modell kurze Zeit später ausverkauft, weitere Exemplare waren erst einen Monat später verfügbar.\n\nIn Deutschland lagen die exklusiven Vertriebsrechte des iPhone bis zum 27. Oktober 2010 bei der Telekom. Seitdem ist das iPhone auch bei Vodafone, O und Apple direkt erhältlich. Auch in der Schweiz bieten es alle größeren Netzbetreiber an.\n\nSeit dem 29. November 2010 bieten in Österreich neben T-Mobile Austria und Orange Austria auch die Netzbetreiber 3 und A1 Telekom Austria und Apple selbst das iPhone an.\n\nObwohl viele über die geringen Änderungen beim iPhone 4s enttäuscht waren, stellten sich rund 1000 Menschen am Apple Store in Frankfurt am Main an, um das iPhone 4s zu erwerben. Apple verkaufte innerhalb des ersten Wochenendes vier Millionen Geräte.\n\nAuch zum Verkaufsstart des iPhone 5 stellten sich Hunderte bei herbstlichen Temperaturen an den Apple Stores an. Dabei wurden innerhalb des ersten Verkaufswochenendes über fünf Millionen Geräte verkauft.\n\nDer Verkaufsstart von iPhone 5c und iPhone 5s war am 20. September 2013, u. a. in den USA, Deutschland und China. Am ersten Verkaufswochenende wurden über neun Millionen Geräte verkauft.\n\nDas iPhone 6 und iPhone 6 Plus konnten ab dem 19. September 2014 erworben werden. Apple gab dabei bekannt, dass die Modelle in den ersten 24 Stunden insgesamt vier Millionen Mal vorbestellt wurden und am ersten Verkaufswochenende über zehn Millionen Geräte veräußert wurden.\n\nSeit dem 25. September 2015 sind das iPhone 6s und iPhone 6s Plus erhältlich, welche sich am ersten Verkaufswochenende über 13 Millionen Mal verkaufen konnten.\n\nDas iPhone SE ist seit dem 31. März 2016 erhältlich.\n\nErstmals wurden zum Verkaufsstart am 16. September 2016 keine offiziellen Verkaufszahlen zum iPhone 7 und iPhone 7 Plus veröffentlicht, da laut Apple aufgrund der hohen Nachfrage bereits absehbar war, dass die Telefone ausverkauft sein würden und die Statistik somit verfälscht werden würde. T-Mobile US gab jedoch bekannt, dass die Anzahl der Vorbestellungen die des iPhone 6s und iPhone 6s Plus um das Vierfache übersteigen.\n\nIm Juli 2014 ging Apple mit IBM eine Partnerschaft im Geschäftskundenbereich an. Im Rahmen dieser Partnerschaft entwickelt IBM branchenspezifische Anwendungen und Apps exklusiv für iPhone und iPad; zudem arbeiten beide Firmen bei Vertrieb, Verwaltung und Support der iOS-Geräte zusammen.\n\nAm 19. November 2007 erwirkte Telekom-Konkurrent Vodafone (D2) beim Landgericht Hamburg eine einstweilige Verfügung gegen den Exklusivvertrieb des iPhone in Deutschland. Vodafone-Geschäftsführer Friedrich Joussen erklärte, man wolle nicht den Vertrieb an sich verbieten lassen, sondern nur den Verkauf des Gerätes ohne zwangsweise Vertragsbindung ermöglichen. Vodafone selbst hatte sich im Sommer 2007 aus den Vertragsverhandlungen mit Apple zurückgezogen, nachdem Apple eine Umsatzbeteiligung von rund einem Drittel verlangt hatte. Die Telekom kündigte am 20. November 2007 Einspruch an, das Unternehmen wolle sich aber bis zu einer endgültigen Entscheidung an die Auflagen der Verfügung halten. In dieser heißt es unter anderem, dass das iPhone nicht mehr verkauft werden darf, „wenn es nur in Verbindung mit dem Abschluss eines Mobilfunkvertrages […] mit einer Mindestvertragslaufzeit von 24 Monaten angeboten […] wird.“ Der Mobilfunk-Anbieter debitel legte ebenfalls am 20. November 2007 wegen der Telekom-Vertragsgestaltung Beschwerde bei der Bundesnetzagentur ein. Bereits am Tag danach korrigierte die Telekom ihr Vertriebsmodell: Vertragsgebundene Geräte würden weiterhin für 399 Euro verkauft, zusätzlich bestehe jedoch die Möglichkeit, für 999 Euro ein iPhone ohne SIM-Lock zu erwerben, das in allen Mobilfunknetzen eingesetzt werden könne. Geräte, die in der 47. Kalenderwoche bereits verkauft wurden, könnten kostenlos entsperrt werden. Am 4. Dezember 2007 hob das Landgericht Hamburg seine einstweilige Verfügung wieder auf, anschließend erklärte die Telekom, dass ab sofort wieder nur noch vertragsgebundene iPhones verkauft würden. Der Vertrieb der SIM-Lock-freien Geräte wurde eingestellt. Gegen das Urteil wurde innerhalb der einmonatigen Frist keine Berufung eingelegt; es wurde somit im Januar 2008 rechtskräftig.\n\nVerschiedene Händler verkauften das iPhone in Deutschland ohne Vertrag. Meist handelte es sich um Geräte, die aus dem EU-Ausland importiert wurden. Am 25. Juni 2009 startete der Mobilfunkprovider simyo die Petition \"Free iPhones\". Die Initiative setzte sich für den freien Verkauf des iPhone ein, und zwar unabhängig von Anbietern, Tarifen und Netz. Die Petition wurde am 8. April 2010 durch simyo mit mehr als 25.000 abgegebenen Stimmen beendet und an Apple übergeben. Die Telekom wurde im August 2009 für die Aussage „exklusiv bei T-Mobile“ von einem Mitbewerber abgemahnt.\n\nSeit der Einführung des ersten iPhones lagen die Exklusivvertriebsrechte des iPhone bei der Telekom. Seit dem 27. Oktober 2010 können jedoch iPhones mit oder ohne Vertragsbindung bzw. SIM-Lock auch bei den anderen deutschen Mobilfunkanbietern, wie Vodafone und Telefónica, bei Apple direkt oder im Einzelhandel erworben werden.\n\nBereits 1996 brachte das Unternehmen Infogear Technology ein Tischtelefon mit E-Mail-Client unter dem Namen \"iPhone\" heraus und ließ dies markenrechtlich schützen. Das Unternehmen wurde im Jahr 2000 von Cisco Systems aufgekauft; damit ging auch das Markenrecht an \"iPhone\" in den USA auf Cisco über. Im Dezember 2006 gab dann Ciscos Tochterunternehmen Linksys die Markteinführung einer Produktfamilie von VoIP-Telefonen unter der Bezeichnung \"iPhone\" bekannt.\n\nNach einer Markenrechtsklage Ciscos gegen Apple vom 10. Januar 2007 erzielten die beiden Unternehmen am 22. Februar 2007 nach außergerichtlichen Verhandlungen eine Einigung, die vorsah, dass beide Unternehmen den Markennamen weltweit nutzen durften. Im Gegenzug wurde geprüft, ob eine Interoperabilität beider Unternehmen in den Bereichen Sicherheit sowie Kommunikation für Verbraucher und Geschäftskunden möglich sei.\n\nNeben Cisco Systems beanspruchte auch das kanadische Unternehmen Comwave Telecom aus Toronto die Markenrechte an \"iPhone\". Comwave Telecom vertreibt seit 2004 einen VoIP-Dienst einschließlich eigenen Mobilgeräts unter dieser Marke. Allerdings wurde von Comwave Telecom der Markenschutz in Kanada erst 2005 beantragt, aber das \"Canadian Intellectual Property Office\" (CIPO) hatte bislang die Rechte an \"iPhone\" noch nicht vergeben.\n\nIm selben Jahr 2007, als das erste iPhone in den USA auf den Markt kam, ließ in China der Unternehmer Xintong Tiandi seine Marke „IPHONE“ für Lederwaren, etwa Hüllen für Mobiltelefone schützen. Da Apple die Marke iPhone in China (2002) zwar für Elektronikgeräte, jedoch nicht für Lederwaren schützen ließ und überdies die iPhone-Smartphones 2007 nicht allgemein in China bekannt waren, darf das chinesische Unternehmen seine Marke weiter führen, wurde im Mai 2016 höchstinstanzlich entschieden.\n\nIn Deutschland betreibt außerdem die Freenet AG einen VoIP-Dienst unter dem Namen \"iPhone\".\n\nEinige Monate nach der Veröffentlichung des iPhone-Betriebssystems erschien Android, welches 2008 der einzige Konkurrent zum gestenbasierten iPhone-Betriebssystem war. Steve Jobs empfand Android als Plagiat und wollte dagegen kämpfen.\n\nApple verklagte die größten Android-Hersteller, wie Samsung und HTC, auf Patentverletzungen. Unter anderem soll Samsung das typische Design des iPhone durch abgerundete Ecken und App-Icons auf dem Home-Bildschirm nachgeahmt haben und einige Software-Funktionen kopiert haben. Samsung wehrte sich ebenfalls, indem beispielsweise die unrechtmäßige Nutzung von LTE im iPhone 5 angeklagt wurde. Apple und Samsung versuchen seit Dezember 2012, Schlichtungsgespräche zu führen, jedoch erzielten diese bisher keinen Erfolg.\n\"→ Hauptartikel: iPhone (erste Generation), iPhone 3G, iPhone 3GS, iPhone 4, iPhone 4s, iPhone 5, iPhone 5c, iPhone 5s, iPhone 6, iPhone 6 Plus, iPhone 6s, iPhone 6s Plus, iPhone SE, iPhone 7, iPhone 7 Plus, iPhone 8, iPhone 8 Plus, iPhone X, iPhone Xr, iPhone Xs, iPhone Xs Max\"\n\nDer Ein-Aus-Schalter befindet sich bei Geräten bis zu einer Bildschirmgröße von 4 Zoll am rechten Rand der Oberseite des Telefons, bei größeren Bildschirmen wurde der Ein-Aus-Schalter an die rechte Gehäuseseite verschoben, wo er – aufgrund der größeren Gehäusemaße – besser erreichbar ist. Die Anordnung der restlichen Hardwaretasten ist bei jedem iPhone identisch. Der Stummschalter ist oberhalb der Lautstärketasten an der oberen linken Gehäuseseite angebracht, auf der Vorderseite sitzen oberhalb des Bildschirms zentral ein Lautsprecher, Annäherungssensor, Umgebungslichtsensor und seit dem iPhone 4 auch eine Frontkamera; unterhalb des Bildschirms zentral die Home-Taste. Auf der Unterseite ist mittig der Anschluss für das USB-Kabel angebracht, rechts daneben befindet sich ein Mikrofon, links ein Lautsprecher (diese Anordnung wurde mit dem Erscheinen des iPhone 5 vertauscht). Die Front- bzw. Rückseite wird mit zwei Schrauben ebenfalls an der Unterseite des iPhone fixiert. Der SIM-Kartenschacht ist ehemals von der Oberseite des iPhone an die rechte Seite gewandert, die Kopfhörerbuchse von der linken Oberseite links neben das Mikrofon an der Unterseite. Alle iPhones haben eine Kamera in der linken, oberen Ecke der Gehäuserückseite, seit dem iPhone 4 befindet sich rechts neben der Kamera zusätzlich noch ein Blitz. Ebenfalls seit dem iPhone 4 gibt es ein weiteres Mikrofon, welches die Umgebungsgeräusche bei Telefonaten herausfiltert. Seit Erscheinen des iPhone 5 werden 3 Mikrofone im iPhone verbaut: Neben dem Mikrofon in der Gehäuseunterseite und dem Frontmikrofon (beim iPhone 4 und 4s neben der 3,5-mm-Klinkenbuchse, bei neueren Geräten im Lautsprecher oberhalb des Bildschirms) gibt es ein weiteres Mikrofon auf der Rückseite zwischen der iSight-Kamera und dem LED-Blitzlicht.\n\nDie Frontseite und Rückschale des iPhone bilden jeweils eine Einheit. In der Rückschale befinden sich der Akku und die Hauptplatine (Logicboard); diese ist verplombt. Über den einzelnen Chips sind großflächige Metallbleche angebracht. Die Frontseite besteht aus vier bzw. fünf Teilen:\n\n\nLediglich der Rahmen und der Bildschirm sind verschraubt, das Digitizer-Glas ist geklebt. Die Frontseite ist mit drei Kabeln an die Hauptplatine angeschlossen und mit zwei Schrauben an der Rückschale fixiert. Eine Ausnahme bilden das iPhone 4 und iPhone 4s, bei denen die Frontseite mit dem Antennenrahmen verschraubt ist und das Telefon durch das Entfernen der Glasabdeckung auf Rückseite geöffnet werden muss.\n\nDie Flexkabel im iPhone sind mit orangefarbenen Nummern markiert, die die Funktionen der einzelnen Flexkabel besser kenntlich machen. Sämtliche Flexkabel werden ähnlich einem Legostein eingesteckt und ggf. mit einem Plättchen zusätzlich fixiert; eine Ausnahme bildet das Kabel für den Lautsprecher, das mit einer Vorrichtung eingeklemmt wird.\n\nDas Logicboard ist vergleichbar mit dem Mainboard eines herkömmlichen PCs. Hier sind sämtliche Chips fest verlötet, welche für den Betrieb des iPhone benötigt werden.\nDas Schema enthält nur die wichtigsten Teile, die nach Funktionsbereich angeordnet sind\n\nDas iPhone verwendet ausschließlich Lithium-Polymer-Akkumulatoren. Die Ladungsträgerkapazität hat sich dabei anfangs nur unwesentlich geändert, Apple verbaute Akkumulatoren mit etwa 1400 bis 1500 mAh, seit dem iPhone 6 (etwa 1810 mAh) und dem iPhone 6 Plus (2915 mAh) haben die Kapazitäten jedoch stark zugenommen. \"(Genaue Angaben können der untenstehenden Tabelle entnommen werden.)\" Apple empfiehlt, den Akku des iPhone nur bei Temperaturen von 0 bis 35 °C in Betrieb zu nehmen und nur zwischen −20 und 45 °C zu lagern; die optimale Betriebstemperatur liegt jedoch zwischen 16 und 22 °C. Die Ladeelektronik des iPhone führt bis zu einer Akkuladung von etwa 80 % eine Schnellaufladung durch, um dann auf Erhaltungsladung umzuschalten. Die Akkus müssen nicht vor jeder erneuten Aufladung zu 100 % entladen werden, um eine optimale Lebensdauer zu erreichen, diese Pflegemaßnahme eines Lithium-Akkus ist sogar schädlich, da sie die Ladungsträgerkapazität stark beeinträchtigt. Apple gibt an, dass die Akkus des iPhone für 500 vollständige Ladezyklen bis zu 80 % der Originalkapazität behalten.\n\nDie Generationen der iPhones werden von Apple nicht offiziell konkretisiert, allerdings sind die iOS-Installationsdateien in Generationen und Revisionen eingeteilt. Die aktuelle Generation wäre die neunte; das europäische iPhone 7 wird als \"iPhone9,3\" angegeben (iPhone-Generation 9, Revision 3). Die Revisionsangaben beziehen sich meistens auf das Modem, so ist das originale iPhone (iPhone 1,1) nur mit einem GSM-Modem ausgestattet, während das iPhone 3G (iPhone 1,2) zusätzlich ein 3G-Modem hat. Das ursprüngliche iPhone und das iPhone 3G würden hier die erste iPhone-Generation bilden und sich nur in der Revision unterscheiden. Einige Revisionen sind bestimmten Regionen vorbehalten, so etwa ist das iPhone 5s in der \"iPhone6,2\"-Ausführung in Europa nicht erhältlich, da es primär für die nordamerikanischen CDMA2000-Funknetze ausgelegt ist und nicht das in Europa übliche 2,6-GHz-LTE-Frequenzband unterstützt.\nDas iPhone und dessen Betriebssystem iOS basieren auf einem ARM-Prozessor. Dieser ist mit dem Grafikprozessor zusammen in ein Samsung-SoC oder TSMC-SoC integriert. Das erste vom iPhone unterstützte Funknetz war das GSM-Funknetz, mit den Nachfolgemodellen kamen weitere Funknetze hinzu. Die Leistungsfähigkeit der einzelnen Komponenten wurde vom ersten iPhone bis zu den aktuellen Modellen stetig gesteigert; so etwa soll der A8-Chip des iPhone 6 laut Apple „bis zu 50-mal schneller“ als der S5L8900-Chip des ersten iPhones sein. Von Beginn an wurden alle iPhones mit Flüssigkristallanzeigen (LCDs) ausgerüstet. Ab dem iPhone 4 wurden die bis dahin verwendeten TN-LCDs von IPS-LCDs für das höher auflösende Retina-Display abgelöst. Seit dem iPhone X wird erstmals ein OLED-Display eingesetzt. Einzelheiten lassen sich den Hauptartikeln der einzelnen Geräte und den unten anliegenden Tabellen entnehmen.\n\nAls Betriebssystem dient iOS (früher \"iPhone OS\"), welches zur Interaktion mit dem Benutzer den Home-Bildschirm und die installierten Programme \"(Apps)\" bereitstellt. Der Home-Bildschirm stellt die eigentliche Benutzeroberfläche von iOS dar, von dem sich Programme aufrufen lassen, die bereits vorinstalliert sind oder aus dem App Store heruntergeladen wurden. Allgemein besitzt iOS eine starke Anbindung an Apple-Dienste, wie dem iTunes Store, App Store oder iCloud.\n\nDer Kern von iOS ist ein angepasstes macOS, welches das Betriebssystem des Macs ist. Allerdings fällt der Funktionsumfang durch Beschränkungen, wie zum Beispiel fehlende Root-Zugriffe, geringer aus.\n\nDas iPhone wird praktisch vollständig über den Multi-Touch-Bildschirm bedient, wobei die verwendete grafische Benutzeroberfläche jeweils nur ein Programmfenster anzeigt. Der Bildschirm ist meist folgendermaßen aufgeteilt:\n\nSeit iOS 7 sind viele Elemente des Betriebssystems, wie die Statusliste und Menübereich, leicht transparent und weichgezeichnet und zeigen den Programminhalt, der sich dahinter befindet.\n\nDer Touchscreen wird mit verschiedenen Fingerbewegungen bedient:\n\nMit der Einführung von \"3D Touch\" auf dem iPhone 6s können durch Druck auf dem Bildschirm \"(Peek und Pop)\" weitere Inhalte, Optionen und Vorschauansichten angezeigt werden.\n\nDie Texteingabe erfolgt über eine im Programmfenster eingeblendete Bildschirmtastatur. Umlaute und andere Zusätze von lateinischen Schriftzeichen können durch Halten statt Tippen der Grundtaste und anschließendem Bewegen des Fingers zu dem eingeblendeten Zeichen eingegeben werden. Bei eingestelltem Tastaturlayout Deutsch sind deutsche Umlaute und das ‚ß‘ direkt als Tasten vorhanden. Der eingegebene Text wird in einem kleinen Feld am oberen Bildrand oder direkt über der Tastatur angezeigt. Die Genauigkeit der Eingabe hängt von der Größe der Finger und dem manuellen Geschick des Bedieners ab, wobei eine lernfähige Korrekturfunktion die Eingabe unterstützt.\n\nApple versucht, auch behinderten Menschen den Zugang zum iPhone zu ermöglichen. Aus diesem Grund verfügt das iPhone seit dem iPhone 3GS über zahlreiche Bedienungshilfen für Menschen mit Hör-, Seh- und Körperbehinderung. Das iPhone ermöglicht vor allem sehbehinderten Nutzern durch den gestenbasierten Screenreader VoiceOver eine barrierefreie Bedienung. Außerdem verfügt das iPhone über zahlreiche optische Anpassungsmöglichkeiten wie eine integrierte Zoom-Funktion, welche es Menschen mit einer Sehschwäche gestattet, das iPhone zu verwenden.\n\nMit \"Visual Voicemail\" können aufgesprochene Nachrichten übersichtlich in einer Liste angezeigt werden. Das Anrufen des Anrufbeantworters entfällt so. Die Mobilfunkanbieter müssen für diesen Dienst Server mit Apple-Software betreiben. In Deutschland, Österreich und der Schweiz bieten diesen Dienst die Netzbetreiber Vodafone, Telekom, O, Swisscom, Sunrise Communications und Salt Mobile in ihren iPhone-Tarifen an.\n\nÜber iTunes können Kontakte (Namen, Telefonnummern, Adressen, E-Mail-Adressen), Kalender-Termine und -Ereignisse, E-Mail-Konto-Einstellungen, Lesezeichen für Webseiten, Notizen, Klingeltöne, Musik, Hörbücher, Fotos, Podcasts, Filme, Fernsehsendungen, Musikvideos und aus dem iTunes Store geladene Programme mit einem Computer synchronisiert werden. Das iPhone lässt sich auch über einen Microsoft-Exchange-Server oder, wie heute üblich, den hauseigenen iCloud-Service synchronisieren.\n\nIn seiner Keynote zur Einführung des iPhone wies Steve Jobs auf Cocoa Touch als Haupt-Programmierschnittstelle (API) der iPhone-Software hin.\n\nAuf der WWDC 2007 wurde zunächst bekanntgegeben, dass andere Hersteller keine klassischen Anwendungen für das iPhone schreiben konnten und dies stattdessen über Webapplikation gelöst werden solle, die auf offenen Standards wie Ajax basieren und im Webbrowser Safari angezeigt werden können. Von Safari aus könnten dann iPhone-eigene Anwendungen wie Google Maps oder die Telefonfunktion genutzt werden. Eine ebenfalls angekündigte Version von Safari für Microsoft Windows ermöglichte das Mac-OS-X-unabhängige Testen solcher Anwendungen für Entwickler aus der Windows-Welt. Durch das dabei verwendete, auch von Java bekannte, Sandkasten-Prinzip sollte das iPhone vor Fehlfunktionen und Manipulationen durch Software besser schützen.\n\nAm 17. Oktober 2007 stellte Steve Jobs nach zahlreichen Protesten von Entwicklern auf der Apple-Webseite als \"Hot News\" ein Entwicklungswerkzeug, auch für native Anwendungen, in Aussicht. Das Entwicklungssystem (engl. \"Software Development Kit\" (SDK)) hatte eine lange Entwicklungszeit weil Apple versuche, zwei entgegengesetzte Ziele zu verwirklichen – eine offene Plattform für Entwickler zu bieten und gleichzeitig das iPhone vor Viren, Schadprogrammen, Angriffen auf private Daten usw. zu schützen. Am 6. März 2008 wurde dann auf einer Veranstaltung die iPhone-OS-Version 2.0 vorgestellt, die neben Microsoft Exchange Server und anderen Netzwerkprotokollen auch das iPhone-SDK unterstützt. Die Software ist seit dem 11. Juli 2008 öffentlich verfügbar.\n\nApple entwickelte für das iPhone eine mobile Variante seines Cocoa-Frameworks namens \"Cocoa touch\". Das SDK wird zusammen mit einer neuen Version von Apples integrierter Entwicklungsumgebung Xcode ausgeliefert. Darin enthalten ist auch ein iPhone-Simulator, der es weitestgehend ermöglicht, die Anwendungen während der Entwicklungsphase auf dem Mac zu testen. Der Vertrieb der Programme erfolgt über den App Store. Die Entwickler können den Preis für ihre Software selbst festlegen, Apple nimmt jedoch 30 Prozent davon als Provision. Während das SDK selbst kostenlos von Apples Entwicklerseiten bezogen werden kann, ist für die Veröffentlichung im \"App Store\" ein kostenpflichtiges Entwicklerkonto zum Preis von 99 $ (Standard) oder 299 $ (unternehmensinterne Anwendungen) pro Jahr erforderlich.\n\nIn der Zwischenzeit hatten Programmierer Verfahren etabliert, um Programme auf dem Gerät lauffähig zu machen, die nicht als Webapplikation ausgeführt sind (sogenannte native Applikationen). Nachdem es Hackern im Juli 2007 mithilfe des ersten Jailbreaks erstmals gelungen war, ein Hallo-Welt-Programm auf dem iPhone auszuführen. Apple stand anfangs diesen Programmieransätzen neutral gegenüber; störte also die Entwicklungen nicht, bemühte sich aber auch nicht, die Lauffähigkeit solcher Programme mit späteren Versionen des Betriebssystems zu erhalten. Die Entwicklung des Jailbreaks nahm weitere Fortschritte an und wurde in der Hochzeit des Jailbreaks, den Jahren 2010 bis 2012 zu einem Wettrüsten zwischen Jailbreakentwicklern und Apple. Mittlerweile hat der Jailbreak jedoch einen deutlichen Rückgang zu verzeichnen.\n\nSeit das iPhone auf dem Markt ist, gibt es Bestrebungen, das proprietäre Betriebssystem iOS durch ein quelloffenes zu ersetzen. Insbesondere die Programmierer \"planetbeing\" und \"CPICH\" haben dieser Entwicklung Vorschub geleistet. Aus ihrer Entwicklungsarbeit ist iDroid hervorgegangen. Teil davon ist der quelloffene Boot-Loader OpeniBoot, der alternativ zu Apples iBoot auf den ersten beiden iPhone-Generationen installiert werden kann. OpeniBoot erlaubt es, eine beliebige Firmware auf dem iPhone zu booten (Apples iBoot startet ausschließlich von Apple signierte Firmware).\n\nIm Dezember 2008 demonstrierte \"PlanetBeing\" auf dem iPhone erstmals eine Linux-Distribution, daraufhin im April 2010 Googles Betriebssystem Android. Der Nutzer hat hierbei durch ein Boot-Menü die Wahl, welches System er booten möchte – iOS bleibt weiterhin startbar.\n\nIn der Praxis haben sich alternative Betriebssysteme bisher nicht etabliert, da die einzigen öffentlichen Android-Portierungen nur mit Geräten funktionieren, die ältere Prozessoren nutzen. Auf neueren iPhones, die andere Prozessoren verwenden, ist die Installation alternativer Betriebssysteme aufgrund zunehmend geschlossener Sicherheitslücken mittlerweile kaum möglich.\n\nKurz nach der Veröffentlichung des iPhone kritisierte Steve Ballmer, damaliger CEO von Microsoft, dass das iPhone mit einem Preis von 500 US-Dollar das teuerste Telefon der Welt und wegen fehlender Software-Funktionen und der virtuellen Tastatur nicht für Geschäftskunden geeignet sei.\n\nNachdem das iPhone überwiegend positive Kritiken erhielt und die Marktanteile ausbaute, reagierten vor allem asiatische Unternehmen wie Samsung und LG mit Touchscreen-Telefonen. Mit dem Betriebssystem Android von Google, welches 2008 erschien, gelang es den Herstellern, eigene gleichartige Touchscreen-Telefone herzustellen. Ab 2010 wurde Android immer populärer, weil unter anderem die meisten Android-Telefone deutlich günstiger waren. Daher überholte Android im ersten Quartal von 2010 das iPhone-Betriebssystem iOS in den Marktanteilen.\n\nNokia, Blackberry und Microsoft sahen erst spät ein, dass Touchscreen-Handys den Markt dominieren würden. Somit sanken die Marktanteile von Symbian-, Blackberry- und Windows-Mobile-Telefonen bis 2011 stark ab. Microsoft versuchte mit Windows Phone ein neues Betriebssystem für Touchscreen-Smartphones zu entwickeln und kooperierte mit Nokia. Windows Phone gewann jedoch nur langsam Marktanteile. 2011/12 erzielte das iPhone mit 23 % seinen höchsten Marktanteil. Danach sanken die Marktanteile des iPhone zugunsten von Android-Geräten bis April 2016 auf 15,3 % ab und fielen bis September 2017 auf unter 15 %.\n\nApple-CEO Tim Cook zufolge geht es jedoch nicht darum, hohe Marktanteile zu besitzen, sondern ein hochwertiges Produkt zu entwickeln, welches viel benutzt wird und zufriedene Benutzer hat.\n\nIm vierten Quartal 2016 verkaufte Apple 45,5 Millionen iPhones weltweit, bis Juli 2016 wurden insgesamt eine Milliarde Geräte verkauft. Somit ist das iPhone das wichtigste Produkt für Apple, denn allein mit dem iPhone erwirtschaftete der Konzern im zweiten Quartal 2015 40,3 Milliarden US-Dollar und somit mehr als zwei Drittel des gesamten Geschäfts.\n\nDas Finanzjahr von Apple läuft von Oktober bis September. Dementsprechend umfasst das erste Quartal die Monate Oktober bis Dezember, also auch das Weihnachtsgeschäft. Das zweite Quartal umfasst die Monate Januar bis März, das dritte die Monate April bis Juni. Im vierten Quartal wird üblicherweise die neueste iPhone-Version vorgestellt.\n\nHäufig wird die abgeschlossene Natur der Plattform kritisiert. Einige Nutzer fühlen sich durch die von Apple getroffenen Einschränkungen bevormundet und stören sich an der zu starken Kontrolle. Beispielsweise sind die Personalisierungsmöglichkeiten stark eingeschränkt. Eine beliebte Abhilfe stellt das Jailbreaking dar.\n\nBeispielsweise überprüft Apple alle Programme, die für den App Store eingereicht werden, vor der Veröffentlichung auf eine Reihe von technischen – etwa Sicherheit und Stabilität –, aber auch inhaltlichen Kriterien. Da es Nutzern schwer möglich ist, aus anderen Quellen als dem App Store native Programme zu beziehen, sehen Kritiker in der Nichtzulassung von Programmen eine Zensur.\n\nAndere Autoren sehen die Kontrolle des App Stores dagegen als möglichen Vorteil für Nutzer an:\nViel Kritik erhielt Apple anfangs dafür, dass es für iOS keinen Flash Player gab. Nach langen Diskussionen stellte Adobe im November 2011 die Entwicklung des Flash Players für mobile Endgeräte ein, im August 2012 wurde der Download komplett eingestellt.\n\nUnter iOS 6 wurde ein eigener Kartendienst eingeführt, der aufgrund von gravierenden Fehlern im Kartenmaterial stark kritisiert wurde. Apples CEO Tim Cook hat sich in einem offenen Brief entschuldigt und versichert, dass das Kartenmaterial verbessert werden soll.\n\nHäufig wurde beim Kauf des iPhone bei einem Netzbetreiber, wie der Telekom, das Gerät mit einem SIM-Lock versehen und konnte dann nicht mit der SIM-Karte eines anderen Anbieters benutzt werden. Solche Geräte können jedoch in der Regel beim Netzbetreiber gegen eine Gebühr innerhalb der Vertragslaufzeit oder kostenfrei nach der Vertragslaufzeit entsperrt werden. Nach einem Jailbreak ist es mit zusätzlicher Software auch möglich, das SIM-Lock auf inoffiziellem Wege zu umgehen.\n\nSeit Februar 2013 wird das iPhone in Deutschland bei allen Netzanbietern ohne SIM-Lock verkauft. Jedoch muss zur erstmaligen Aktivierung des iPhone eine SIM-Karte eingelegt werden.\nAuch in vielen anderen Ländern ist das iPhone bei Apple oder bei Netzbetreibern ohne SIM-Lock erhältlich.\n\nAm 20. April 2011 wurde publiziert, dass das iPhone und iPad kontinuierlich Positionsdaten, bezogen von Funkmasten und WLAN-Stationen, speichern und damit den Aufenthaltsort des Nutzers mit einem Zeitstempel in einer speziellen Datei ablegen.\n\nIn einer Presseerklärung gab Apple am 27. April 2011 bekannt, dass ein Softwarefehler für die Aufzeichnung der Daten \"–\" trotz Deaktivierung \"–\" und deren lange Speicherdauer verantwortlich gewesen sei. Am 4. Mai 2011 veröffentlichte Apple mit iOS 4.3.3 eine Aktualisierung, womit die Datenbank nur noch die letzten Tage der Geodaten vorhielt. Diese Datenbank wurde nicht mehr durch iTunes auf den Rechner übertragen und beim Deaktivieren des CoreLocation-Dienstes gelöscht.\n\nNach dem Terroranschlag in San Bernardino wandte sich das FBI an Apple mit der Bitte, beim Entschlüsseln der Daten auf iPhones der Attentäter behilflich zu sein. Apple wurde in diesem Zusammenhang auch gerichtlich angewiesen, dem FBI beim Entsperren eines iPhones 5c zu helfen. Apple weigerte sich aber und löste eine Debatte um die Nutzung von Verschlüsselung aus. Schließlich gelang es dem FBI selbst, an die Daten auf dem Handy zu gelangen. Nach Presseinformationen hatte das FBI dafür aus Hackerkreisen Informationen über eine Schwachstelle gekauft, die es ermöglichten, den Passwortschutz des Mobiltelefons auszuhebeln.\n\nDas iPhone ist seit der Markteinführung mit verschiedenen Speichergrößen (derzeit – je nach Modell – wahlweise 32, 64, 128, 256 oder 512 GB) erhältlich.\n\nDer tatsächlich verfügbare Speicher hängt primär vom verwendeten Betriebssystem ab. Das iOS misst seinen Speicher in GiB, gibt jedoch GB als Einheit an. Deshalb stellt die „16 GB“-Variante tatsächlich nur 14,9 GiB Speicher zur Verfügung, auf dem auch das etwa 2,1 GiB große Betriebssystem (iOS 9) gespeichert ist. Zusätzlich dazu müssen 200 MiB Speicherplatz frei bleiben, da iOS Speicherplatz für Cache benötigt. Somit bleiben bei der 16-GB-Variante des iPhone 6 Plus noch 12,6 GiB nutzbarer Speicher übrig. In die Kritik geraten bei Smartphones immer wieder die kleinsten Speicherkapazitäten, da sie oftmals nicht dem entsprechen, was Konsumenten erwarten würden. Der britische Blog \"Which?\" verglich die 16-GB-Modelle verschiedener Hersteller auf den tatsächlich nutzbaren Speicher. Dabei schnitt das iPhone 5c mit 12,6 GiB am besten ab.\n\nApple stellte den Verkauf von kleinen Speichergrößen beim ersten iPhone recht schnell ein. Bereits im September 2007, acht Monate nach der Vorstellung des iPhone, wurde der Verkauf der 4-GB-Variante mit Ausnahme von Restposten eingestellt. Beim iPhone 5c hingegen brachte Apple im März 2014 nachträglich wieder eine 8-GB-Variante auf den Markt.\n\nZur Einführung des iPhone 7 wurde die 16-GB-Basisspeichergröße zugunsten einer 32-GB-Variante ersetzt. Das iPhone 8 ist in der kleinsten Größe standardmäßig mit 64 GB ausgestattet.\n\n2015 kam mit \"Tangerine L.A.\" der erste Breitbildformat-Kinofilm, der ausschließlich mit iPhones gedreht wurde, in die Kinos.\n\nZum Erscheinen der ersten iPhones und iPads wurden die Apps und die lange Akkulaufzeit positiv bewertet, während der geringe Lieferumfang, die fehlende Unterstützung für Adobe Flash, sowie der nicht vorhandene USB-Anschluss bemängelt wurden. \n\nApple hat zugegeben, dass die Leistung älterer Modelle dynamisch gedrosselt werden kann, um das unerwartete Ausschalten des Geräts bei hoher Leistung zu verhindern. Die Drosselung setze immer dann ein, wenn der Lithium-Ionen-Akku nicht mehr in der Lage ist, Spitzenlasten bei der Stromversorgung zu liefern. Jedoch hat Apple angekündigt, iPhone-Nutzern die umstrittene Drosselung der Leistung ihrer Geräte bei abgenutzten Batterien abschalten zu lassen.\n\nDie Arbeitsbedingungen bei der Fertigung der iPhones beim Unternehmen Foxconn in China wurden kritisiert. So kam es dort zu mehreren Selbstmorden.\n\n\n"}
{"id": "2149206", "url": "https://de.wikipedia.org/wiki?curid=2149206", "title": "Veritas Cluster Server", "text": "Veritas Cluster Server\n\nVeritas Cluster Server (VCS) bezeichnet ein Softwareprodukt des Unternehmens Veritas Software Corporation zur Zusammenschaltung mehrerer Rechner zu einem Rechnerverbund (Cluster). Im Jahr 2016 wurde der Cluster Teil eines neuen Produktbundles und wird nun Veritas InfoScale Availability genannt.\n\nDiese Software verbindet zwei oder mehr Computer unabhängig vom Betriebssystem zu einem sogenannten Computercluster. Computer werden in einem Clustersystem auch allgemein als Knoten bezeichnet. Die zu einem Rechnerverbund zusammengeschalteten Computer erhöhen durch die Clusterbildung in der Regel die Ausfallsicherheit des Gesamtsystems für allgemeine Aufgaben als Server.\n\nEine der Besonderheiten des Veritas-Cluster ist, dass Abhängigkeiten zwischen Servicegruppen recht einfach (via GUI) modelliert werden können. Über Phantom-Ressourcen lassen sich weiterhin Abhängigkeiten zwischen Ressourcen verschiedener Servicegruppen formulieren.\n\nEine weitere Besonderheit ist die Unabhängigkeit von einem bestimmten Betriebssystem. Die Veritas-Cluster-Software kann auf\nmit dem „Veritas Storage Foundation HA“ eingesetzt werden. Voraussetzung ist aber, dass auf allen beteiligten Clusterknoten das gleiche Betriebssystem (eines aus der genannten Auswahl) installiert wurde.\n\nDie Datenbank-Versionen 9i, 10g, 11 und 12 von Oracle sind für die Cluster-Softwareversion für Datenbanken „Storage Foundation for RAC“ zugelassen. Das Vorhandensein von zwei Heartbeatverbindungen zwischen den beteiligten Knoten wird gefordert. Die Verwendung anderer Datenbanksysteme (wie DB2/MySQL o. ä.) ist prinzipiell ebenfalls möglich.\n\nDas Softwareprodukt läuft unabhängig vom Betriebssystemkern (auch User-Level Cluster Software genannt) in normalen Systemprozessen. Es kann in unterschiedlichen Konfigurationen (LAN/MAN/WAN) eingesetzt und i. d. R. um applikationsspezifische Agenten ergänzt werden. Es existiert auch eine spezielle Version, die die Implementation von Oracle Datenbanken in ein Veritas Cluster ermöglicht („Veritas Storage Foundation for Oracle RAC“).\n\nVergleichbare Funktionalität eines „High-Availability“- (HA-) Clustersystems findet sich bei IBM Tivoli System Automation for Multiplatforms (IBM SA MP), IBM HACMP, Sun Cluster, Linux-HA oder Microsoft Cluster Server (MSCS).\n\nDas Betriebssystem (z. B. Sun Solaris, Windows Server 2003) wird auf zwei Hostsystemen (d. h. Rechnern bzw. Knoten) installiert, die in ihrer Hardware weitgehend übereinstimmen sollten. Für Computer mit Windows-Betriebssystem wird anschließend die Version „Veritas Storage Foundation HA“ als Kombinationsprodukt von \"Veritas Cluster Server\" und \"Veritas Storage Foundation\" installiert und konfiguriert.\n\nDie Hardware sollte weitgehend übereinstimmen, um den Benutzern bei Ausfall eines Systems (dem sogenannten Failover) immer noch eine ausreichende Systemleistung zur Verfügung stellen zu können. Hierbei muss zur Erhöhung der Ausfallsicherheit beachtet werden, dass bei der Auswahl der Hardware mindestens zwei unabhängige Netzwerkkarten pro Clusterknoten zum Einsatz kommen. Auch die doppelte (oder mehrfache) unterbrechungsfreie Verfügbarkeit weiterer kritischer Systembestandteile wie Speichermedien (z. B. durch NAS, SAN), Netzwerkkomponenten (Switches, Verkabelung) oder Stromversorgung (mehrere Hot-Swap-Netzteile, USV) erhöht die Verfügbarkeit des Systems (siehe Single Point of Failure).\n\nDer Grund für die beiden unabhängigen Netzwerkkarten ist die Funktionalität jedes Clustersystems, der heartbeat. Unter „heartbeat“ versteht man die interne Kommunikation der Systeme, die als Clusterknoten agieren sollen. Die beiden Computer informieren sich auf diesem Wege untereinander, ob der jeweilige andere Partner (Host oder Teilclustersystem) noch funktionsfähig ist. Sollte dies nicht mehr zutreffen, übernimmt der andere Host oder Teilclustersystem die Arbeit.\n\nDie Funktion der Software wird auf sogenannte „Servicegruppen“ aufgeteilt, die in den meisten Fällen Datenbanken, Netzwerkdateisysteme (NFS) oder kritische Applikationen für die Anwender bereitstellen.\n\n\n\n"}
{"id": "2149564", "url": "https://de.wikipedia.org/wiki?curid=2149564", "title": "Macworld - iWorld", "text": "Macworld - iWorld\n\nDie Macworld | iWorld (bis 2011: \"Macworld Conference & Expo\") war eine US-amerikanische Technik-Messe, die von 1985 bis 2014 vom IDG-Verlag veranstaltet wurde. Sie fand jährlich gegen Jahresanfang in San Francisco statt, und wurde oft von Apple zur Vorstellung neuer Produkte genutzt. Im Jahr 2009 gab Apple bekannt, dass man in Zukunft nicht mehr an der Messe teilnehmen werde. Im Oktober 2014 gab IDG bekannt, dass die Messe vorerst eingestellt würde.\n\nUnter dem gleichen Namen wurden auch in New York City, Boston und Tokyo Messen veranstaltet, die jedoch seitdem eingestellt wurden.\n\nDie erste Macworld wurde 1985 veranstaltet und nach dem 1984 vorgestellten Macintosh benannt.\n\nSteve Jobs verkündet eine Zusammenarbeit zwischen Microsoft und der angeschlagenen Firma Apple. Bill Gates wird per Videokonferenz hinzugeschaltet, was vom Publikum mit Pfiffen und Buhrufen beantwortet wird.\n\nVorstellung des ersten iMac.\n\nVorstellung des ersten iBooks, sowie des darin verbauten AirPort (WLAN IEEE802.11 Standard) und Vorstellung von .\n\nPräsentation der Developer Preview 3 von Mac OS X 10.0 und der neuen Aqua-Oberfläche.\n\nVorstellung des Webbrowsers Apple Safari.\n\nJobs demonstrierte einige Neuerungen von Mac OS X Tiger. Außerdem wurden neue Versionen von Final Cut Pro, iLife und iWork, sowie der neue Mac mini und der neue iPod shuffle vorgestellt.\n\nEs wurden iLife '06 (neu mit iWeb) und iWork '06 vorgestellt.\n\nNeue Versionen der professionellen Werkzeuge Final Cut Pro, Aperture und Logic wurden angekündigt. Dabei wurde betont, dass diese neuen Programme bereits als Universal Binaries vorlagen, das heißt sowohl auf PowerPC- als auch auf Intel-basierten Macs (x86-Prozessor) nativ liefen.\n\nPaul Otellini, CEO von Intel, überreichte Jobs einen symbolischen Wafer, um zu zeigen, dass die Arbeiten am Umstieg auf Intel-Prozessoren abgeschlossen waren. Anschließend wurden die ersten Intel-basierten Macs, der iMac und das MacBook Pro mit Core Duo-Prozessoren, vorgestellt.\n\nSteve Jobs demonstrierte zunächst die Set-Top-Box Apple TV, die bereits unter dem Codenamen iTV auf einem „Special Event“ im September 2006 vorgestellt wurde.\n\nIm zweiten Teil der Keynote präsentierte Jobs das iPhone erstmals der Weltöffentlichkeit.\n\nDie Keynote für 2008 fand am 15. Januar statt. Steve Jobs präsentierte die Time Capsule, welche die Datensicherung mittels Time Machine vereinfachen soll. Danach präsentierte Jobs die neue iPod- und iPhone-Firmwareversion 1.1.3. Im Anschluss folgten der iTunes Store Filmverleih und ein neues MacBook Air.\n\nMicrosoft kündigte auf der Messe den Verkaufsstart von Microsoft Office 2008 für Mac an.\n\nApple gab bekannt, dass sie 2009 zum letzten Mal an der Macworld teilnehmen werden. Die Keynote wurde nicht von Steve Jobs, sondern von Phil Schiller gehalten. Es wurden iLife und iWork '09 sowie ein neues 17\" MacBook Pro vorgestellt.\n\nIm Jahr 2012 wurde die Konferenz in „Macworld | iWorld“ umbenannt. IDG kündigte an, dass durch Konzerte, Filmpremieren und Kunstausstellungen auch der kulturelle Einfluss von auf Apple-Geräten entstandenen Multimedia-Inhalten gezeigt werden soll.\n\n"}
{"id": "2149667", "url": "https://de.wikipedia.org/wiki?curid=2149667", "title": "CramFS", "text": "CramFS\n\nDas CramFS (\"Compressed ROM File System\", alternativ: \"„cram a filesystem onto a small ROM“\") ist ein freies und unter der GPL stehendes Read-only-Dateisystem mit integrierter Datenkompression unter Linux. Es wird hauptsächlich bei eingebetteten Systemen eingesetzt, weshalb ein Hauptaugenmerk auf die Einfachheit und die Effizienz des benötigten Speicherplatzes gelegt wurde.\n\nIm Gegensatz zu einem komprimierten konventionellen Dateisystem muss ein CramFS nicht erst entpackt, sondern es kann direkt darauf zugegriffen werden. Aus diesem Grund verwenden manche Linux-Distributionen das CramFS als Dateisystem für initiale Ramdisks (Debian) oder als Installations-Abbilder (SuSE bis openSUSE 10.2), da diese einigen Einschränkungen bezüglich ihrer Größe unterliegen. Auch in eingebetteten Systemen wie beispielsweise WLAN-Routern wird CramFS eingesetzt.\n\nDateien im CramFS sind mit der zlib komprimiert. Die Metainformationen dieser Dateien sind unkomprimiert, werden jedoch in einer knapperen Struktur repräsentiert als in konventionellen Dateisystemen. Da ein schreibender Zugriff auf ein komprimiertes Dateisystem nicht einfach zu realisieren ist, kann auf CramFS nur lesend zugegriffen werden. \n\nUm ein CramFS-Dateisystem zu erstellen und Dateien darin aufzunehmen, werden standardmäßig Werkzeuge wie codice_1 mitgeliefert. Für eine Bearbeitung unter Linux muss der Inhalt in ein Verzeichnis kopiert werden. Danach kann aus dem Verzeichnis ein neues Image erstellt werden. Unter Windows gibt es Tools zur direkten Bearbeitung. Eines davon ist newtuxflashtools.zip.\n\nCramFS hat einige Einschränkungen wie beispielsweise:\n\nSquashFS ist ein 2002 veröffentlichtes komprimiertes Dateisystem, was gegenüber CramFS unter anderem eine effektivere Kompression bietet und mit größeren Dateien zurechtkommt, allerdings mehr Arbeitsspeicher benötigt.\n\n"}
{"id": "2155863", "url": "https://de.wikipedia.org/wiki?curid=2155863", "title": "KDE Display Manager", "text": "KDE Display Manager\n\nDer KDM (Akronym für \"KDE Display Manager\") ist ein graphischer Displaymanager für unixähnliche Betriebssysteme. Er ist eine der zentralen Komponenten der grafischen Benutzeroberfläche KDE Plasma Workspaces, kann aber auch für andere X-basierte Benutzeroberflächen eingesetzt werden. Ab KDE Plasma 5 wird der neu entwickelte Simple Desktop Display Manager bevorzugt.\n\nKDM ermöglicht Benutzern, sich mit ihrem Benutzernamen und Passwort anzumelden, und startet mit Hilfe dieser Daten die gewünschte Sitzung. Dies kann eine KDE-Plasma-Sitzung sein, aber auch beispielsweise eine Gnome- oder Kommandozeilen-Sitzung.\n\nKDM setzt auf dem X Window System auf und ersetzt dessen Standard-Anmeldemanager XDM. Wie auch XDM bietet KDM einen XDMCP-Chooser. Anders als XDM basiert KDM jedoch auf der Qt-Bibliothek und fügt sich daher mit seiner Bedienphilosophie nahtlos in die weiterentwickelte KDE-Oberfläche ein.\n\nKDM kann über das KDE-Kontrollzentrum konfiguriert und über Themes optisch angepasst werden. Auch Benutzericons sind möglich.\n\n"}
{"id": "2161785", "url": "https://de.wikipedia.org/wiki?curid=2161785", "title": "VirtualBox", "text": "VirtualBox\n\nVirtualBox ist eine Virtualisierungssoftware des US-amerikanischen Unternehmens Oracle, die ursprünglich von der \"InnoTek Systemberatung GmbH\" aus Baden-Württemberg entwickelt wurde. Nach der Übernahme durch Sun Microsystems im Februar 2008 wurde es Sun xVM VirtualBox bezeichnet, da Sun es in sein xVM-Portfolio eingliederte. Sun Microsystems wurde 2010 von Oracle übernommen, das Oracle VM VirtualBox nunmehr ebenfalls in sein VM-Portfolio eingliederte. Die freie Variante behielt jedoch den ursprünglichen Namen.\n\nVirtualBox kann auf den Betriebssystemen FreeBSD, Linux, macOS, OS/2 bzw. eComStation, Solaris, Windows und Genode als Wirtssystem auf x86- (32 Bit) und x86-64-Systemen (64 Bit) eingesetzt werden.\n\nAls Gastsystem können wiederum x86- bzw. x64-Betriebssysteme eingesetzt werden. Für eine Vielzahl an Betriebssystemen werden Treiber, Kernel-Module bzw. mitgeliefert; diese stehen bei der Einrichtung einer neuen virtuellen Maschine zur Auswahl.\n\nAb Version 1.3.2 (Anfang 2007) bis einschließlich Version 3 (Ende 2010) waren zwei unterschiedliche Varianten (Editionen genannt) mit unterschiedlichen Lizenzen verfügbar: \"Oracle VirtualBox\" mit allen Funktionen unter proprietärer Lizenz (), welche für persönliche sowie zu jeglicher Verwendung in Bildungseinrichtungen kostenfrei genutzt werden durfte, und \"VirtualBox Open Source Edition (OSE)\", welcher diverse Funktionen fehlten und die unter der GNU General Public License (GPL) stand. Ab Version 4.0 vom 22. Dezember 2010 stellt Oracle nur noch eine unter der GPL stehende Edition zur Verfügung, die in etwa der früheren \"Open Source Edition\" entspricht und mit Modulen erweitert werden kann. Lediglich der Funktionsumfang wurde um USB-1.1-Unterstützung erweitert. Die Funktionen der proprietären Version 3 sind nun in das Modul \"\" ausgelagert, welches wieder unter der PUEL steht. Für einen Wechsel zwischen beiden Versionen muss daher lediglich das Zusatzpaket installiert bzw. entfernt werden.\n\nBis Version 9 der PUEL fällt unter \"Personal Use\" (englisch für \"persönlicher Gebrauch\") auch, wenn ein Angestellter in einer Firma die unter der PUEL stehenden Teile persönlich installiert und verwendet. Ausgeschlossen ist daher nur eine automatische Installation des \"\" oder der Gasterweiterungen im Gastsystem z. B. durch den Systemadministrator und auch die Nutzung mit Fernwartungssoftware (wie beispielsweise VNC), nicht aber die kommerzielle Nutzung – solange sie persönlich erfolgt. Ab Version 10 der PUEL, vom 20. Juli 2017 mit Version 5.1.20 aktualisiert, ist die kommerzielle Nutzung jedoch explizit ausgeschlossen und somit das ab diesen Versionen nicht mehr unter der PUEL gratis in Firmen nutzbar.\n\nVirtualBox wurde von dem in Weinstadt ansässigen Unternehmen \"Innotek\" (ursprünglich \"InnoTek Systemberatung GmbH\") entwickelt. Zunächst hatte Innotek dem Hypervisor Virtual PC von Connectix zur Unterstützung des Betriebssystems OS/2 verholfen. Nachdem Connectix von Microsoft aufgekauft worden war, begann Innotek im Jahr 2004 mit der Entwicklung von VirtualBox und gewann unter anderem Behörden als Anwender. Im Januar 2007 stellte Innotek VirtualBox erstmals als freie Software zur Verfügung. Im Februar 2008 wurde Innotek von Sun Microsystems übernommen. Sun Microsystems wiederum wurde im Januar 2010 von Oracle aufgekauft. Seit dieser Übernahme wird VirtualBox von Oracle vertrieben.\n\nFestplatten werden in Containerdateien, von VirtualBox auch als \"Virtual Disk Images\", (kurz VDI) bezeichnet, emuliert. Neben diesem eigenen Dateiformat kann VirtualBox auch mit Festplattendateien von VMware-Virtualisierungsprodukten (mit der Dateiendung „.vmdk“), dem „“-Format (mit der Dateiendung „.vhd“) von Windows Virtual PC, HDD-Dateien von Parallels sowie mit Abbildern im QED- (') und QCOW-Format (') der Emulations- und Virtualisierungssoftware \"QEMU\" umgehen. Zudem können iSCSI-Objekte als virtuelle Festplatten genutzt werden, wobei der hierfür benötigte iSCSI-Initiator bereits in VirtualBox enthalten ist. Mit dem zu VirtualBox gehörenden Kommandozeilen-Werkzeug VBoxManager kann man diese fremden Formate auch konvertieren.\n\nDie freie GPL-Edition von VirtualBox emuliert im Gastsystem u. a. folgende Komponenten:\n\n\nDie Grafikauflösung ist ohne entsprechende Treiber (als Gasterweiterung) auf bzw. beschränkt.\n\nDie VMs lassen sich wahlweise über mehrere Frontends bedienen:\n\nDie Virtualisierungserweiterungen der aktuellen Intel-CPUs mit der Bezeichnung VT-x und dessen AMD-Pendant AMD-V werden, sofern vorhanden, genutzt. Hierbei werden auch neuere Funktionen dieser Befehlssatzerweiterungen wie \"\" unterstützt.\n\nFür Systeme ohne VT-x/AMD-V oder bei manueller Abwahl dieser Funktionen besitzt VirtualBox den „Raw Mode“. Hierbei versucht VirtualBox, so viel Code wie möglich nativ auszuführen. In den meisten Fällen läuft Ring-3-Code des Gastsystems nativ auf dem Wirtssystem. Versucht das Gastsystem, Ring-0-Code auszuführen, führt das Wirtssystem diesen stattdessen im Ring-1 aus (der normalerweise nicht genutzt wird). Wenn es nicht möglich sein sollte, Code nativ auszuführen, muss dieser von einem Emulator ausgeführt werden, der auf dem Quellcode von QEMU basiert. Da die Ausführung von Ring-0-Code im Ring-1 zu sehr vielen Ausnahmen führt (privilegierte Instruktionen dürfen nur im Ring-0 ausgeführt werden), betreibt VirtualBox eine Art \"in situ\"-Patching. Hierbei wird der Gastcode zur Laufzeit und unmittelbar vor Ausführung mit Hilfe einer Disassembler-Komponente (CASM) auf problematische Segmente hin analysiert und gegebenenfalls von einem Patch Manager (PATM) so verändert oder ersetzt, dass Ausnahmen reduziert werden und sich die Ausführungsgeschwindigkeit erhöht. In vielen Fällen ist der klassische Ansatz mit Patch Manager effizienter als VT-x/AMD-V, es gibt jedoch Einschränkungen in der Kompatibilität mit weniger verbreiteten Gastsystemen.\n\nDa VirtualBox einen x86-Prozessor in einer virtuellen Umgebung bereitstellt, werden auch nur für diese Prozessorarchitektur geschriebene Betriebssysteme, sowohl als Gast- als auch als Wirtbetriebssystem, unterstützt. Die Virtualisierung beschränkt sich so auf das Erstellen einer VM, deren Prozessor dem tatsächlich im System verbauten Prozessor entspricht. Der Systemprozessor wird also, anders als bei QEMU, nicht emuliert, was in der Regel mehr Rechenleistung benötigen würde.\n\nFolgende Wirtssysteme werden unterstützt (aktuelle Version):\n\nDarüber hinaus gibt es auch ein Startprogramm, mit dessen Hilfe \"VirtualBox\" für Windows-Betriebssysteme leicht übertragbar (\"portabel\") gemacht und gestartet werden kann. Dieses Startprogramm wird unabhängig von Oracle von der deutschen nLite-Gemeinschaft, in der Skriptsprache \"AutoIt\", entwickelt und gepflegt.\n\nMac OS X/​OS X/​macOS kann ab Version 3.2 auch als Gastsystem ausgeführt werden, was aus lizenzrechtlichen Gründen jedoch nur auf Apple-Hardware zugelassen ist. Da mittels \"Boot Camp\" auch Windows auf jedem Intel-basierten \"Mac\"-Rechner Installiert werden kann, ist folglich macOS als Gastsystem auch unter Windows als Wirtssystem möglich.\n\nAb Version 2.1 können die unterstützten Gastsysteme unabhängig vom Wirtssystem sowohl als 32-Bit- als auch als 64-Bit-Virtualisierung nutzen, sofern der Prozessor des Wirtssystems dies unterstützt. Zusätzlich zu den bereits als unterstützte Wirtssysteme gelisteten Betriebssystemen sind auch folgende Systeme virtualisierbar:\n\nEs ist durchaus möglich, VirtualBox mit weiteren Gast-Betriebssystemen zu betreiben. Das Aktivieren der Virtualisierungserweiterung moderner x86-Prozessoren (bei Intel VT-x, AMD-V bei AMD) kann dabei helfen, ein sonst nicht unterstütztes Betriebssystem in der virtuellen Umgebung von VirtualBox laufen zu lassen.\n\nDie nur in englischer Sprache verfügbaren Gasterweiterungen (englisch \"\") von VirtualBox erweitern die Integration zwischen Wirt- und Gastsystem. Diese liegen für Windows ab NT 4.0 und OS/2 Warp als Binärdaten (als eine Art Treiber-CD), für Linux und Solaris als Quellcode und Installationspaket vor und werden im virtuellen CD-Laufwerk innerhalb der VM bereitgestellt.\nDie folgenden Komponenten werden dabei erweitert:\n\nDie Gasterweiterungen stehen unter der proprietären Lizenz (PUEL), sind jedoch über eine Ausnahmeregelung in der Lizenz frei verteilbar. Ab Version 4 wird auch die neue, auf Compiz basierende Benutzeroberfläche Unity der Linux-Distribution Ubuntu unterstützt. Für Windows-Versionen der 9x-Linie und andere Betriebssysteme gibt es die Gasterweiterungen nicht, ferner wird nur eine begrenzte Anzahl von Linux-Distributionen (Fedora/Red Hat, Ubuntu, openSUSE) offiziell unterstützt. Die Gasterweiterungen sind auch für Mac OS X Snow Leopard Server beziehungsweise ab Mac OS X Lion Standard und Server nicht verfügbar, da diese als Gastsystem nur eine untergeordnete Rolle spielen.\n\nEinige Funktionen, die zusätzlich im \"\" enthalten sind:\n\nDas Modul steht für den privaten Einsatz kostenlos unter der PUEL sowie für den Unternehmenseinsatz unter proprietärer Lizenz zur Verfügung.\n\nProdukte, die in direkter Konkurrenz zu VirtualBox stehen:\nWeitere Virtualisierungsprodukte:\n\n\n"}
{"id": "2165815", "url": "https://de.wikipedia.org/wiki?curid=2165815", "title": "QuickDic", "text": "QuickDic\n\nQuickDic ist ein kostenloses Wörterbuch-Format. Die deutsch↔englische Version hat über 300.000 Begriffe und Redewendungen in beiden Sprachen.\n\n\n"}
{"id": "2167120", "url": "https://de.wikipedia.org/wiki?curid=2167120", "title": "Hogrefe Testsystem", "text": "Hogrefe Testsystem\n\nDas Hogrefe Testsystem (HTS), \"bis zur Version 4 Hogrefe TestSystem\") ist ein System zur computerunterstützten Psychodiagnostik. Es wurde von 1992 bis 2012 (Version 4) herausgegeben von Klaus-Dieter Hänsgen, im Rahmen eines Drittmittelprojektes vom Zentrum für Testentwicklung und Diagnostik an der Universität Fribourg entwickelt und vom Hogrefe Verlag Göttingen international vertrieben. Seit 2013 übernimmt der Hogrefe Verlag (ab Version 5) die Entwicklung von Nachfolgeversionen in eigener Regie.\n\nZielsetzung des HTS ist es, Durchführung, Auswertung und Interpretation der wichtigsten professionellen psychologischen Testverfahren, die sich für eine computergestützte Umsetzung eignen, in eine einheitliche Umgebung zu integrieren und damit die psychodiagnostische Tätigkeit zu vereinfachen. Im internationalen Maßstab werden die herkömmlichen Durchführungen mittels „Papier und Bleistift“ immer mehr durch computerunterstützte Verfahren verdrängt. Kostengründe sind dafür ebenso verantwortlich wie die Notwendigkeit, genaue Ergebnisse schnell zur Verfügung zu haben, da die Auswertung der meisten Tests sehr aufwändig ist. Das Internet erlaubt außerdem, dass Diagnostiker und Diagnostizierte nicht mehr am gleichen Ort sein müssen.\n\nDie Anwendung ist vor allem in den folgenden Bereichen für folgende Fragestellungen möglich:\n\nEin Vorläufer-System wurde von 1986 bis 1989 unter BASIC für Kleincomputer KC85/1 von Hänsgen an der Humboldt-Universität zu Berlin entwickelt. Von 1989 bis 1994 wurden verschiedene Module fragestellungsspezifisch zusammengestellt (LEILA = Leistungsdiagnostisches Labor, CORA = Computerbasierte Ratingverfahren, KIDIS = Kinderdiagnostisches System, PERSYS = Persönlichkeitsdiagnostisches System), seit 1992 wird die Bezeichnung „Hogrefe TestSystem“ als Sammelname verwendet. Ab 1994 wurden sie unter dem einheitlichen Konzept des HTS (Version 2) integriert. Von 1989 bis Ende 1996 wurde eine MS-DOS-Version mit Pascal entwickelt, die am Ende eine eigene standardisierte Grafikoberfläche benutzte. Seit 1997 existiert eine unter Windows lauffähige Version 3, seit 2006 die Version 4 mit ergänzendem Internet-Tests und der Nutzung von USB-Sticks zum mobilen Testen.\n\nDas HTS ermöglichte bis zur Version 4 die Administration von ca. 400 psychologischen Testverfahren in 10 Sprachen. HTS gehört im deutschen Sprachraum zu den verbreitetsten Testsystemen für die professionelle Psychodiagnostik. Seine Anwendung setzt psychodiagnostische Kenntnisse voraus. In der Eignungsdiagnostik gilt dabei die DIN-Norm 33430 bzw. die ÖNORM D4000 für Österreich.\n\nDie Testdurchführung war auf einem lokalen PC, im Internet/Intranet über einen Server oder mittels USB-Memorystick (Portable Testing) möglich.\nDie Version 4 existierte in einer deutschen, englischen, französischen, dänischen, holländischen, schwedischen, finnischen, norwegischen, slowakischen und tschechischen Fassung mit entsprechenden Verfahren aus diesen Ländern.\n\nSeit Ende 2017 wird die Version 4 nicht mehr unterstützt.\n\n\nFür die aktuelle Version 5, die nur noch über ein Online-Portal verfügbar ist, stehen bislang 171 Verfahren in 16 Sprachen zur Verfügung (Stand 01/2018). Testverfahren werden in allen gängigen Browsern durchführbar, neben Fragebogenverfahren auch zeitkritische Testverfahren aus dem Leistungsbereich. In der Auswertung wurden neue Funktionen umgesetzt wie Soll-Ist-Vergleiche von Testprofilen (Einzelprofile mit Idealprofilen bzw. Anforderungen), Erzeugung von Rangreihen mehrerer Kandidaten und Gruppenanamlysen. \n\nMan kehrt wieder zur fragestellungs- bzw. bereichsspezifischen Strukturierung zurück, um das System auf unterschiedliche Anwendungskontexte besser abzustimmen (z. B. HR- und Clinical Edition).\n\n"}
{"id": "2167273", "url": "https://de.wikipedia.org/wiki?curid=2167273", "title": "Computerunterstützte Psychodiagnostik", "text": "Computerunterstützte Psychodiagnostik\n\nUnter computerunterstützter Psychodiagnostik versteht man den Einsatz von Informationstechnologie als Hilfsmittel, um psychologische Tests und andere psychodiagnostische Methoden der Informationsgewinnung durchzuführen, auszuwerten oder zu interpretieren sowie automatisiert Befunde zu erstellen sowie diagnostische Entscheidungen zu unterstützen. In der psychologischen Diagnostik konkurriert dies mit der „Papier-und-Bleistift-Diagnostik“, wo die Verfahren papiergestützt durchgeführt werden.\n\n„Computerunterstützt“ betont, dass es sich um ein Hilfsmittel für die psychologische Diagnostik handelt, die nach dem Konzept des psychodiagnostischen Prozesses abläuft. Die Verantwortung für die Diagnosefindung bzw. diagnostische Entscheidung trägt der (menschliche) Diagnostiker, der alle Ergebnisse hinterfragt und ggf. durch weitere Untersuchungsmethoden ergänzt (vgl. für die Eignungsdiagnostik die Rollendefinitionen der DIN 33430).\n\nEine \"vollautomatisierte\" Testanwendung wie z. B. bei Online Self Assessments ist darüber hinaus auch möglich,\n\nDie Abkürzung CBT für Computer based testing bzw. im deutschen Sprachraum Computerbasiertes Testen wird dafür verwendet \nDie englischsprachige Abkürzung CAT für Computer assisted testing wird auch im deutschen Sprachraum verwendet, ist aber auch für Computerized adaptive testing (Computergestütztes adaptives Testen) als eine Unterform gebräuchlich.\n\nDie Verschränkung herkömmlicher und IT-basierter Elemente kann sehr vielfältig sein. Es können verschiedene Teile des diagnostischen Prozesses durch den Einsatz von Computern unterstützt werden:\n\nFür die Nutzung von Informationstechnologie bei der \"Durchführung\" von Tests sind verschiedene Methoden möglich.\n\nDie Einführung des Internets hat zu einer großen Methodenvielfalt geführt, die zum Teil noch theoretisch aufgearbeitet werden muss. Kennzeichnend ist, dass die Administration durch die Fachperson (Veranlassung der Testung, Auswertung) und die eigentliche Testdurchführung lokal getrennt sind, sich die Fachperson nicht mehr am gleichen Ort wie die getestete Person befinden muss. Eine weitere Spielart sind Online-Assessments, wo die Getesteten die Ergebnisse oft unmittelbar nach der Testdurchführung erhalten und meist keine Fachperson zum Interpretieren und Erklären notwendig ist (insbesondere bei Online Self Assessments, die zur Studienberatung eingesetzt werden). Auch hier trägt die Fachperson weiterhin die Verantwortung, dass die Ergebnisse verständlich sind und keine Schäden durch etwaige Verunsicherungen oder Fehldeutung auftreten können.\n\nUnter Bezug auf Dave Bartram werden heute vier Modi der computergestützten Diagnostik unterschieden. Alle vier Modi gelten für das Internet-Testen, beim Testen unter Aufsicht können auch lokal fest installierte Programme verwendet werden.\n\nBei der Testung können vier Modi unterschieden werden, die vor allem unterschiedlich hinsichtlich des Datenschutzes und auch des Komforts zu bewerten sind:. In entsprechenden Einverständniserklärungen sind die Getesteten auf diese Modi und mögliche Risiken hinzuweisen. Zu unterscheiden sind die Vorbereitung und Auswahl der durchzuführenden Tests (Diagnostiker), die eigentliche Testdurchführung, die Auswertung und die Datenspeicherung/Archivierung.\n\nVor- und Nachteile werden häufig gegenüber der Papier-und-Bleistift-Diagnostik diskutiert.\nAls Vorteile der computerunterstützten psychologischen Diagnostik sind beispielsweise anzuführen:\n\n\nNachteile können sein:\n\n\nNeben zahlreichen Einzelprogrammen existieren Testsysteme, die Probandenverwaltung, Testen, Auswerten und andere Hilfsprogramme für die psychologische Diagnostik unter einer einheitlichen Oberfläche zusammenfassen. Beispiele im deutschen Sprachraum sind das Hogrefe Testsystem, das Wiener Testsystem oder das CAT Testsystem.\n\nEs existieren einige weitere Testsysteme, deren Durchsetzungsproblem am Markt vor allem darin besteht, dass auch geeignete und nachgefragte Tests im System mit ausreichender Bandbreite angeboten werden müssen und wo die Autoren sich eher an den größeren Testsystemen orientieren. Traditionell ist eine Testentwicklung sehr aufwändig, und Testsysteme sind nur dann langfristig erfolgreich, wenn ausreichend Ressourcen für die Testentwicklung zur Verfügung stehen.\n\nDie traditionellen Testsysteme orientieren sich mehr an der Testanwendung (Testdurchführung, Auswertung) und überlassen den Diagnostikern die Interpretation und Entscheidungsfindung. Daneben haben sich sogenannte prozessorientierte Systeme entwickelt, die auch die Entscheidungsfindung stärker unterstützen (z. B. Diagnostik in Bewerbungsportalen) und vorgefertigte Auswertungsmöglichkeiten bieten. Ein Unterschied besteht auch darin, ob das Testsystem universell (für alle Fragestellungen) ausgelegt ist oder eine Spezialisierung auf bestimmte Fragestellungen erfolgt. Solche Systeme können stärker am Diagnoseprozess dieser Fragestellung orientiert sein und Verfahrensauswahl oder verfahrensübergreifende Auswertung, etwa orientiert an einer Anforderungsanalyse, liefern.\n\nIm Rahmen der empirischen Bildungswissenschaften beziehungsweise der internationalen Bildungsvergleichsstudien kommen verschiedene Testsysteme zum Einsatz, die insbesondere darauf ausgelegt sind, sehr viele Studienteilnehmer gleichzeitig testen zu können. Für die Forschung existieren auch Testsysteme für bestimmte Aufgabenstellungen (z. B. komplexe Probleme), welche die Erstellung computerisierter Aufgaben sowie die Testdurchführung vereinen und vereinfachen sollen.\n"}
{"id": "2168681", "url": "https://de.wikipedia.org/wiki?curid=2168681", "title": "Jupiter Ace", "text": "Jupiter Ace\n\nDer Jupiter Ace war ein Heimcomputer von \"Jupiter Cantab\", der im September 1982 erschien, entwickelt und vertrieben von zwei ehemaligen Sinclair-Angestellten: Richard Altwasser und Steven Vickers.\n\nEr hat viele Ähnlichkeiten mit dem Sinclair ZX81, etwa die Z80A-CPU mit 3,5 MHz Taktfrequenz, das 8192 Byte große ROM und die einfache Schwarzweiß-Grafik. Gehäuse und Tastatur der Serienmodells erinnern stark an den ZX Spectrum, einige Vorserienexemplare wurden im Gehäuse des Sinclair ZX80 an Redaktionen von Computerzeitschriften geliefert. Der Arbeitsspeicher war mit 3 KB recht knapp bemessen, konnte jedoch bis zu 51 KB ausgebaut werden.\n\nBesonderheit: Anstelle der Programmiersprache BASIC, die bei den frühen 8-Bit-Rechnern üblicherweise verwendet wurde, war in den Jupiter Ace FORTH implementiert. Damit war er drei bis zehn Mal schneller als ein baugleicher Computer mit BASIC als Programmiersprache. \n\nIn Deutschland konnte das Handbuch des Jupiter Ace vorab separat erworben werden, der Kaufpreis wurde beim späteren Kauf der Hardware angerechnet. Wie bei den Sinclair-Modellen war der implementierte Dialekt der Programmiersprache detailliert beschrieben und im Rahmen eines kleinen Kurses von Vickers didaktisch aufbereitet worden. Trotz dieser Marketingmaßnahmen und durchaus positiver Besprechungen in den Computerzeitschriften konnte sich das Gerät – vor allem wohl wegen des zu kleinen Arbeitsspeichers – nicht durchsetzen. Andere Gründe waren auch, dass BASIC zum damaligen Zeitpunkt bei Homecomputern als problemorientierte höhere Sprache bereits zum Quasi-Standard geworden war und es kaum kommerzielle Software für den Jupiter Ace gab. Wirtschaftlich war das Gerät ein Flop und nach kurzer Zeit (im Jahre 1983) wieder vom Markt verschwunden.\n\n"}
{"id": "2169635", "url": "https://de.wikipedia.org/wiki?curid=2169635", "title": "Windows Deployment Services", "text": "Windows Deployment Services\n\nDie Windows Deployment Services, kurz WDS (engl., Windows Bereitstellungsdienste), sind die Nachfolger des mit Windows 2000 eingeführten RIS-Dienstes (Remote Installation Services). Die WDS-Dienste bieten im Kompatibilitätsmodus (Mixed Mode) sowohl die alte RIS-Funktionalität, als auch ein neues, für Windows Vista und Microsoft Windows 7 entwickeltes, Imageverfahren.\n\n\n\n"}
{"id": "2169920", "url": "https://de.wikipedia.org/wiki?curid=2169920", "title": "FHP-Modell", "text": "FHP-Modell\n\nDas FHP-Modell ist ein elementares Gitter-Gas-Modell und ein zellulärer Automat zur Simulation von Gasen und Flüssigkeiten. Es ist auch als Lattice Gas Cellular Automata (LGCA) bekannt.\n\nDas FHP-Modell wurde 1986 von Uriel Frisch, Brosl Hasslacher und Yves Pomeau aufgestellt, deren Initialen namengebend für das Modell sind. Mit dem HPP-Modell von Hardy, Pomeau und de Pazzis aus dem Jahre 1973 hat es historisch einen Vorläufer. Der Grund für die vergleichsweise lange Zeit von 13 Jahren bis zur Weiterentwicklung ist, dass dem HPP-Modell die Isotropie als wichtige Eigenschaft fehlte und man glaubte, dass solche Modelle prinzipiell nicht isotrop sein können. Nachdem die Isotropie für das FHP-Modell bewiesen war, begann rasch eine intensive Untersuchung des Modells und einer Reihe Varianten. Die Entdeckung der Isotropie im FHP-Modell in Verbindung mit der hohen Recheneffizienz führte zum einen dazu, dass über das FHP-Modell auf der Titelseite der Washington Post berichtet wurde, zum anderen gab es zuvor schon Überlegungen das Modell und jegliche Forschung daran als geheim und militärisch bedeutsam zu klassifizieren, mithin Veröffentlichungen also zu unterbinden.\n\nWie die Bezeichnung Gitter-Gas besagt, spielt sich die gesamte Dynamik auf einem Gitter ab. Im Falle des FHP-Modells ist es ein Gitter aus lauter gleichseitigen Dreiecken. Es existiert folglich eine sechszählige (diskrete) Rotationssymmetrie. Das Dreiecksgitter ist der entscheidende Unterschied zum HPP-Modell, das auf einem orthogonalen Gitter (Schachbrett) basiert.\n\n\nStreuung: Zur Streuung kommt es, wenn auf einem Gitterpunkt gleichzeitig zwei, drei oder vier Teilchen sind, deren Impulse (Richtungen) sich zu null addieren. Bei zwei Teilchen bedeutet dies, dass die Teilchen entgegengesetzte Richtung haben müssen, bei dreien, dass die Winkel zwischen den Teilchen 120° betragen müssen und bei vier Teilchen, dass die unbesetzten Richtungen entgegengesetzt sein müssen.\nBei der Streuung von zwei Teilchen werden beide Richtungen um 60° nach rechts oder nach links gedreht, wobei die Richtung der Ablenkung zufällig und mit gleicher Wahrscheinlichkeit (50:50) gewählt wird. Bei der Streuung von drei Teilchen werden besetzte und unbesetzte Richtungen ausgetauscht und bei der Streuung von vier Teilchen wird die unbesetzte Richtung um 60° nach rechts oder links gedreht. In jedem Fall ist die Impulssumme also auch nach der Streuung null. Damit ist im gesamten Modell – von Randeffekten abgesehen – die Impulserhaltung gewährleistet. In einer deterministischen Version des Modells wird nicht per Zufall über die Ablenkungsrichtung entschieden, sondern abwechselnd nach rechts und links abgelenkt. Aus gleichen Anfangsbedingungen folgt in diesem Fall ein immer gleicher Simulationsablauf.\n\nSiehe auch die in NetLogo implementierte Simulation.\n\nDas FHP-Modell erfüllt im hydrodynamischen Grenzfall die Navier-Stokes-Gleichung.\n\n"}
{"id": "2172233", "url": "https://de.wikipedia.org/wiki?curid=2172233", "title": "Die Rotkäppchen-Verschwörung", "text": "Die Rotkäppchen-Verschwörung\n\nDie Rotkäppchen-Verschwörung (Originaltitel: \"Hoodwinked!\") ist ein US-amerikanischer computer-animierter Familienfilm aus dem Jahr 2005. Er wurde durch Blue Yonder Films in Mitarbeit mit Kanbar Entertainment produziert.\n\nEr wurde ab dem 16. Dezember 2005 von The Weinstein Company in ausgewählten Märkten gezeigt, ab dem 13. Januar 2006 US-weit. In Deutschland kam der Film am 27. Dezember 2006 ohne Altersbeschränkung in die Kinos. In der deutschen Version liehen unter anderem Sarah Kuttner, Jan Delay, Max Raabe, Smudo und Hans Werner Olm den Charakteren ihre Stimmen.\n\nIm Film wird die bekannte klassische Handlung von Rotkäppchen (im Film wird die US-Variation des Märchenstoffes tangiert) ein wenig abgewandelt und zum Krimi umgemünzt.\n\nNachdem die aus dem Märchen bekannten Geschehnisse sich bis zum Haus der Großmutter zugetragen haben, sperrt die hiesige Waldpolizei (alles Tiere) dieses als Tatort ab. Polizeichef \"Grizzly\" übergibt anschließend sämtliche Verhörmaßnahmen an den Frosch-Detektiv \"Nicky Flippers\", der alle Beteiligten nacheinander zum Hergang vernimmt. Hierbei stellt sich heraus, dass die Figuren nicht ganz ihren Vorlagen entsprechen: Rotkäppchen erweist sich als schlagfertiges Girlie mit Martial-Arts-Erfahrung, der Wolf als Enthüllungsreporter mit dem hyperaktiven Eichhörnchen \"Twitchy\" als Partner, der Holzfäller ist ein aus Deutschland (genauer aus Bayern) stammender Imbissbetreiber mit Schauspielambitionen und die Großmutter entpuppt sich als Extremsport-Freak.\n\nMit jeder Schilderung von je einem der Vier erschließen sich dem Zuschauer immer mehr die Zusammenhänge der Handlung: im Märchenwald müssen immer mehr Backstuben schließen, nachdem ein mysteriöser Dieb alle Rezepte stiehlt. Lediglich Rotkäppchens Großmutter, eine bekannte Bäckerin, wurde bislang verschont. Nachdem sich Rotkäppchen und der Wolf zunächst gegenseitig verdächtigen, kommt Flippers nach Auswertung aller Geschichten hinter den Plan des Oberschurken und entlarvt diesen: es ist der Hase \"Boingo\", welcher eine Bande von wintersportvernarrten Handlangern um sich geschart hat und mit den entwendeten Rezepten die Macht im Wald an sich reißen will. Als Boingo Rotkäppchen mit einer Bombe umbringen will, raufen sich die Märchenakteure zusammen und befreien das Mädchen. Grizzly und Flippers kommen am Schluss gerade rechtzeitig, um Boingo und seine Bande zu verhaften.\n\nDie Synchronarbeiten fanden bei der Interopa Film statt. Michael Nowka schrieb das Dialogbuch und führte die Dialogregie.\nDer Film wurde 2006 für einen Saturn Award in der Kategorie \"Bester Animationsfilm\" nominiert.\n\n\nEine Fortsetzung des Films mit dem Titel \"Das Rotkäppchen-Ultimatum\" sollte ursprünglich am 15. Januar 2010 in die US-amerikanischen Kinos kommen. Die Produktionsfirma Kanbar Entertainment befindet sich jedoch derzeit in einem Rechtsstreit mit der Weinstein Company, nachdem letztere den Starttermin verschoben hatte.\n\nDas Erscheinungsdatum in den US-amerikanischen Kinos wurde auf den 29. April 2011 verschoben. In Deutschland war der Film seit dem 21. Juli 2011 in den Kinos zu sehen.\n\n"}
{"id": "2175942", "url": "https://de.wikipedia.org/wiki?curid=2175942", "title": "IT-Business", "text": "IT-Business\n\nIT-Business (eigene Schreibweise: \"IT-BUSINESS\") ist eine deutsche Fachhandelszeitschrift für Telekommunikation, Informationstechnik und Cloud Computing. \"IT-Business\" erschien erstmals zur CeBIT im März 1991. Neben Nachrichten zum IT-Markt widmet sie sich ausführlich technischen Schwerpunkten aus der Telekommunikation, der Informationstechnologie sowie strategischen Business-Fragen, die für ITK-Hersteller,-Handelsunternehmen und - Systemhäuser relevant sind.\n\nDie verbreitete Auflage beträgt 26.004 Exemplare (4. Quartal 2018, Quelle: IVW). IT-Business bedient mit seiner Auflage den gesamten ITK-Markt, insbesondere Systemhäuser, IT-Dienstleister, Managed Service Provider, Retailer und E-Tailer.\n\nIT-Business erscheint bei den Vogel IT-Medien in Augsburg, ein Tochterunternehmen der Vogel Communications Group.\n\nDie Gründung der Publikation geht auf eine studentische Unternehmung unter Beteiligung von Werner Nieberle zurück. Die Studenten waren seit 1989 auch als IT-Reseller tätig und erkannten recht bald die Marktlücke einer unabhängigen Publikation für den damaligen EDV-Markt.\n\nZur CeBIT 1991 kamen sie mit der Neugründung „EHZ – EDV-Handelszeitung“ an den Markt. Seit dieser Zeit hat sich die Publikation drei Mal wesentlich gewandelt, um sich den Anforderungen des Marktes und des Leserverhaltens anzupassen: 1998 wurde aus dem Monatsmagazin „EHZ“ das Wochenjournal „IT-Sales Week“, im Jahr 2000 veränderte sie sich zur Zeitung „IT-Business News“ und im Januar 2007 zur zweiwöchentlichen Zeitschrift „IT-Business“ im Magazin-Format.\n\nIT-Business tritt am Markt jedoch nicht alleine auf, sondern als „IT-Business Medien“ im Cross-Media-Verbund mit dem Online-Angebot IT-Business.de und dem Veranstaltungsbereich Vogel IT-Akademie (ehemals IT-Business Akademie). In dieser Konstellation wird ein Portfolio angeboten, welches auf die Entscheidungsträger im indirekten Vertrieb von Telekommunikation und Informationstechnologie zugeschnitten ist.\n\n"}
{"id": "2180396", "url": "https://de.wikipedia.org/wiki?curid=2180396", "title": "Sony Hit Bit HB-75", "text": "Sony Hit Bit HB-75\n\nDer Sony Hit Bit HB-75 der japanischen Firma Sony ist ein Heimcomputer, der im Jahre 1984 auf den Markt gebracht wurde.\n\nEs handelt sich hierbei um einen MSX-Computer. Das Gerät wird von einem Zilog Z80A-Prozessor mit einer Taktfrequenz von 3,58 MHz betrieben. Der Hit Bit HB-75 verfügt über 64 KByte RAM plus 16 KByte Video-RAM und 32 KByte ROM plus 16 KByte Firmware. Als Grafikchip wird ein Texas Instruments TMS9918A verwendet, der Soundchip ist ein General Instrument AY-3-8910. Das Gerät besitzt eine Schreibmaschinentastatur (QWERTY) mit 73 Tasten. Als I/O-Ports sind folgende Schnittstellen vorhanden: 2 × Modulport, 2 × Centronics, 1 × Kassette, 1 × RGB, 1 × Video, 1 × HF (Antenne), 2 × Joystick.\n\nDer HB-75 hat mehr RAM als das gleichzeitig auf dem Markt gebrachte Modell Sony Hit Bit HB-55, welches nur 16 KByte Speicher besitzt. Dieses Modell hat ebenso wie sämtliche aus der Hit-Bit-Serie eingebaute Software und zwar eine Adressverwaltung, ein Notizbuch und einen Terminkalender. Der Computer wurde mit einem BASIC-Handbuch ausgeliefert, welches an Anfänger gerichtet war.\n\nDer HB-75 wurde zu damaliger Zeit gerne mit dem C64 verglichen, der die gleiche Speicherkapazität besaß, aber ein schnelleres Floppy-Laufwerk und vorinstallierte Software besaß. Er konnte sich in den deutschsprachigen Ländern nicht durchsetzen.\n\n\n\n"}
{"id": "2188075", "url": "https://de.wikipedia.org/wiki?curid=2188075", "title": "Linux Foundation", "text": "Linux Foundation\n\nDie Linux Foundation ist ein Zusammenschluss der Open Source Development Labs (OSDL) und der Free Standards Group (FSG). Ziel des gemeinnützigen Konsortiums ist es, das Wachstum von Linux zu unterstützen und zu fördern. Die Linux Foundation fördert, beschützt und standardisiert Linux, indem sie einheitliche Mittel und Dienste anbietet, die von Projekten für Open Source Software benötigt werden, um erfolgreich mit proprietären Plattformen wie z. B. Windows zu konkurrieren.\n\nDer Linux Foundation gehören über 500 Mitglieder aus den IT-Bereichen Hardware, Software, Netzwerk und Telekommunikation an. Während die Kosten für die \"Collaborative Projects\" 2015 noch auf 5 Milliarden $ geschätzt wurden, erreichten sie im September 2017 15,6 Milliarden $.\n\nAm 21. Januar 2007 wurde die Linux Foundation, aus einem Zusammenschluss der „Open Source Development Labs“ (OSDL) und der „Free Standards Group“ gegründet.\n\nIm September 2009 traten der Linux Foundation der Mikroprozessor-Hersteller VIA Technologies, der Mikroprozessor-Architekt ARM Limited und der Software-Hersteller Citrix – sowie weitere Mitglieder – bei.\n\nIm August 2010 trat unter anderem der Software-Entwickler Qualcomm Innovation Center (QuIC) bei.\n\nIm Juli 2011 trat Toyota als erster großer Automobilhersteller der Linux Foundation bei. Die Mikroblogging-Plattform Twitter trat der Foundation im August 2012 bei.\n\nIm November 2016 trat Microsoft mit einer Platin-Mitgliedschaft der Linux Foundation bei.\n\nNeben der Standardisierung sind der rechtliche Schutz von Open-Source-Entwicklern, die Bezahlung wichtiger Linux-Entwickler wie etwa Linus Torvalds oder Greg Kroah-Hartman, die Bereitstellung eines neutralen Forums zur Zusammenarbeit zwischen Linux-Unternehmen und der Schutz und die Verwaltung der Marke Linux die Hauptaufgaben der Linux Foundation.\n\nNeben der bekanntesten Arbeitsgruppe, der Linux Standard Base, gibt es noch weitere Arbeitsgruppen, die sich mit einer Standardisierung beschäftigen. So arbeitet die Gruppe \"OpenI18n\" an einer Basis für die sprachliche Internationalisierung von Programmen und Distributionen, um diese später wiederum einfacher zu lokalisieren. Die Arbeitsgruppe \"OpenPrinting\" beschäftigt sich mit den Ansprüchen an professionelle Drucker-Lösungen wie Management, Verlässlichkeit, Sicherheit, Skalierbarkeit usw., während die Gruppe \"Accessibility\" Standards definiert, um den Zugang zu Linux-Systemen auch Menschen mit Behinderungen zu ermöglichen. Um das \"obere Ende\" des Leistungsspektrums modernen Rechnens mit Linux kümmert sich die \"openHPC\"-Initiative.\n\nAndere, teilweise kleinere Arbeitsgruppen beschäftigen sich jeweils mit anderen Teilbereichen zum Gesamtthema Standardisierung von Linux.\n\nDie Finanzierung der Linux Foundation geschieht größtenteils über Mitgliedsbeiträge.\n\nDie Linux Foundation teilt ihre Mitglieder nach Jahresbeitrag in \"Platinum\", \"Gold\" und \"Silver Members\" ein. Platin- und Gold-Mitglieder sind Stand 19. November 2016 die folgenden Unternehmen und Forschungseinrichtungen:\n\nZu den über 100 Silver Members gehören u. a. Adobe, AMD, ARM, Barnes & Noble, Canonical, China Mobile, Daimler AG, Dell, DreamWorks SKG, EMC Corporation, Epson, J. P. Morgan, Lexmark, LG, Linpus, NTT, Nvidia, MIPS Technologies, Parallels, Red Hat, Ricoh, Siemens, Texas Instruments, Twitter, VIA, VMware und Yahoo.\n\nSpenden werden \"zu 100% für Diversity-Projekte verwendet\".\n\n"}
{"id": "2189798", "url": "https://de.wikipedia.org/wiki?curid=2189798", "title": "Diskless Shared Root Cluster", "text": "Diskless Shared Root Cluster\n\nEin Diskless Shared-Root-Cluster ist eine Systemplattform für Hochverfügbarkeits-Infrastrukturen.\n\nEin Linux-Cluster-Filesystem, zum Beispiel GFS und OCFS2, ist die Grundlage, um ein angebundenes Storage Area Network (SAN) zu einem Single System Image (SSI) auf Dateisystemebene zu verbinden.\n\nDie Architektur eines Diskless Computerclusters ermöglicht die Trennung von Server-System und Storage-Array. Sowohl Betriebssystem, als auch die eigentlichen Nutzdaten (z. B. Dateien, Datenbanken oder Webseiten) werden zentral und konkurrierend auf dem angehängten Storage-System vorgehalten. Ein als Cluster-Knoten fungierender Server kann bei Bedarf leicht ausgetauscht werden.\n\nObwohl es einen potentiellen Flaschenhals darstellt, kann ein Cluster für einfachere Aufgaben auch ohne SAN aufgebaut werden, indem die Daten auf einem NFS-Server vorgehalten werden. Es ist aber zu empfehlen, dass der NFS-Server selbst als 2-Knoten-Cluster implementiert wird, um einen Single Point of Failure (SPOF) zu verhindern.\n\nDurch die Abstraktion zwischen Speichersystem und Rechenleistung der Server kann die Infrastruktur gut skaliert werden. Speicherkapazität, Rechenleistung und Netzwerkkapazität können unabhängig voneinander an die aktuellen Anforderungen angepasst werden.\n\nEine ähnliche Technologie ist im UNIX-Bereich beispielsweise im TruCluster (Tru64 UNIX) zu finden.\n\nEine Open-Source-Implementierung eines Diskless Shared-Root-Clusters wird vom \"Open-Sharedroot\"-Projekt entwickelt.\n\n\n"}
{"id": "2190123", "url": "https://de.wikipedia.org/wiki?curid=2190123", "title": "Freeway (Software)", "text": "Freeway (Software)\n\nFreeway ist ein WYSIWYG HTML-Editor der englischen Firma Softpress Systems. Freeway wird für macOS angeboten, ältere Versionen sind auch unter Mac OS 9 und 8 lauffähig. Freeway wird in zwei Versionen angeboten, Freeway Pro und Freeway Express.\n\nDie Software dient zur Verwaltung von Webseiten-Projekten und der Gestaltung von Webseiten. Sie bietet dem Benutzer eine Bedienungs-Oberfläche, die an Desktop-Publishing-Programme erinnert. Die vom Benutzer gestalteten Seiten werden in einer internen Datenbank abgelegt. HTML-Code wird erst zum Zeitpunkt eines Uploads erzeugt, also wenn die Seiten auf einen Webserver geladen werden. Mit der aktuellen Version kann der Benutzer Online-Shops generieren und im Internet eröffnen, ohne sich dazu mit Programmierung oder Datenbanken auseinandersetzen zu müssen.\nXHTML und erweiterte CSS-Funktionalität sind in dem Programm integriert.\n\nEin derartiges Programm wird gelegentlich auch als Web-Generator oder HTML-Generator bezeichnet. Freeway preist sein Programm damit an, einfach Websites zu gestalten, „ohne damit eine einzige Zeile Code schreiben zu müssen“.\n\n"}
{"id": "2190602", "url": "https://de.wikipedia.org/wiki?curid=2190602", "title": "Cdparanoia", "text": "Cdparanoia\n\ncdparanoia ist ein freier CD-Ripper von der Xiph.Org Foundation. Dabei sind als Zielformate \"rohe Audiodaten\" (so wie von CD gelesen und mit wählbarer Byte-Reihenfolge der Abtastwerte) und die unkomprimierten Audioformate RIFF WAVE, AIFF und AIFF-C möglich.\n\ncdparanoia ist primär als Back-end für andere, meist grafische Audio-CD-Leseprogramme, genannt CD-Ripper, und CD-Brennprogramme gedacht, die, statt eigene Programmfunktionen für das Lesen von Audio-CDs zu implementieren, auf das lange erprobte cdparanoia oder die darin enthaltene libparanoia zurückgreifen können.\nIn dieser Form hat cdparanoia eine erhebliche Bedeutung auf der Linux-Plattform erlangt.\n\nViele Laufwerksmodelle liefern den Audiodatenstrom mit sporadischen Aussetzern und Wiederholungen an den Computer an, wodurch ohne Gegenmaßnahmen Störgeräusche (z. B. Klickgeräusche) hörbar werden können. Da beim Auslesen einer CD (im Gegensatz zum Abspielen) keine Echtzeitanforderung vorliegt und mithin Daten mehrfach ausgelesen werden können, analysiert cdparanoia diese Daten und versucht, daraus einen Datenstrom ohne die beschriebenen Mängel zusammenzusetzen. cdparanoia verzichtet auf die Auswertung bzw. Bewertung der C2-Fehlerkorrektur-Informationen, die ohnehin nur von einigen CD-ROM-Laufwerksmodellen überhaupt (und von noch weniger Modellen zuverlässig) für das Betriebssystem bzw. die Anwendersoftware zur Verfügung gestellt werden. Weiterhin gleicht es den Leseoffset (im Millisekundenbereich liegende modellabhängige Abweichungen der tatsächlichen von der vom Laufwerk angeforderten Leseposition) nicht aus.\n\nDie Notwendigkeit dieses Vorgehens hat seine Ursache in der fehlerbehafteten Firmware der meisten Computer-CD-Laufwerke, die die Rohdaten meist nicht ohne Weiteres zuverlässig als kontinuierlichen Datenstrom bereitstellen können.\n\nDie Xiph.Org Foundation entwickelt cdparanoia und stellt öffentlichen Lesezugriff auf die Versionsverwaltung (Subversion) bereit. cdparanoia begann als eine Sammlung von Anpassungen von cdda2wav. Diese ermöglichten gewisse Fehlerkorrekturmechanismen, deren Wirksamkeit war jedoch begrenzt und die Laufwerksunterstützung war noch sehr beschränkt. Mit der Veröffentlichung von Paranoia III im Januar 1998 wurde es eine eigenständige Bibliothek. Diese läuft jedoch nur auf Linux.\nDie Entwicklung stagnierte jedoch lange Zeit – es gab während mehr als einem Jahr keine Codeveränderungen und die Seite wurde seit 2002 nicht mehr aktualisiert. Im August 2006 wurde die Entwicklung wieder aufgenommen und eine Vorabversion der Version 10.0 herausgegeben.\nAb Version 10.2 (vom 11. September 2008) wird auch das Übergehen des Laufwerkslesepuffers unterstützt. Die aktuelle Entwicklerversion unterstützt nicht das Auslesen von Metadaten und kann nicht mit CDs umgehen, auf denen sich defekte Metadaten befinden (z. B. ein defektes Inhaltsverzeichnis oder ein Audiotrack, der als Datentrack verzeichnet ist).\nAls libparanoia ist ein Großteil des Funktionsumfangs der cdparanoia wieder in cdda2wav zurückgeflossen.\n\nParanoia IV, die zukünftige Entwicklerversion seit 1999, wurde als flexibler, portabler und leistungsfähiger angekündigt. Einige der geplanten Merkmale waren die Unterstützung von CD-Laufwerken für die parallele Schnittstelle, das Erkennen und Entfernen von Pregaps sowie Portierungen für NetBSD und Solaris. Mittlerweile beschränken sich die Pläne darauf, ein Update für Paranoia III zu schaffen, welches das Auslesen von stark beschädigten Medien und die Fehlerbehandlung verbessert. Bislang ist dazu aber noch kein Code in den Repositories aufgetaucht.\n\n"}
{"id": "2191171", "url": "https://de.wikipedia.org/wiki?curid=2191171", "title": "Internet Magazin", "text": "Internet Magazin\n\nDas Computermagazin Internet Magazin erschien im WEKA-Verlag von 1996 bis 2014 monatlich. Das rund 90-seitige Heft behandelte Themen wie Webdesign, Tipps & Tricks, Schwerpunktthema und Neuigkeiten. In den früheren Ausgaben lag eine CD-ROM mit entsprechender Software (Vollversionen und Shareware, Freeware und PD) bei, die neueren Ausgaben waren ohne CD oder DVD erhältlich.\n\nAb November 2013 erschien das Internet Magazin in neuer Profilierung unter dem Titel IntMag. In der Eigendarstellung bezeichnete sich die Zeitschrift nunmehr als \"Das Magazin der Digitalen Wirtschaft\". Es beschäftigte sich vorwiegend mit dem Einsatz von Internet-Technologien für Unternehmen. Zusätzlich erschien viermal jährlich das Magazin \"Screen Guide\", welches sich im Stile des bisherigen Internet Magazins an Webentwickler wendet und technologische Schwerpunkte bedient.\n\nIm April 2014 kündigte Weka Media die Einstellung des Internet Magazins an. \n\nIm vierten Quartal 2012 lag die durchschnittliche verbreitete Auflage nach IVW bei 6.103 Exemplaren. Das sind 832 Exemplare pro Ausgabe weniger (–12,0 %) als im Vergleichsquartal des Vorjahres. Die Abonnentenzahl nahm innerhalb eines Jahres um 589 Abonnenten auf durchschnittlich 4.628 pro Ausgabe ab (–11,29 %); damit bezogen rund 75,83 % der Leser die Zeitschrift im Abo.\n"}
{"id": "2195555", "url": "https://de.wikipedia.org/wiki?curid=2195555", "title": "Profile Intermedia", "text": "Profile Intermedia\n\nProfile Intermedia war ein internationales Medien- und Designfestival in Bremen.\n\nAb 1998 organisierte jedes Jahr ein Team von Studenten der Hochschule für Künste Bremen unter der Leitung von Peter Rea und Nick Kapica diese dreitägige Veranstaltung. Dabei ging es um den \"„Crossover in Design, Kunst, Musik, Medien und Theorie“\". Der Veranstaltungsort befand sich in einer ehemaligen Fabrikanlage in der Überseestadt Bremen. Das \"Very Fast Film Festival\" war ab 2005 Teil der Konferenz.\n\nDie Konferenz steht jedes Jahr unter einem Motto:\n\n\n"}
{"id": "2196351", "url": "https://de.wikipedia.org/wiki?curid=2196351", "title": "SquashFS", "text": "SquashFS\n\nSquashFS (.sfs oder .sqfs) ist ein von Phillip Lougher entwickeltes, freies (GPL), komprimiertes Dateisystem für GNU/Linux-Betriebssysteme, welches nur lesbar ist. SquashFS komprimiert Dateien, Inodes und Verzeichnisse, und unterstützt zur besseren Komprimierung Blockgrößen bis zu 1 Mebibyte. Der Zugriff darauf erfolgt über ein Kernel-Modul, als Virtuelles Dateisystem.\n\nSquashFS ist als universelles, nur lesbares Dateisystem gedacht, z. B. als Alternative zu komprimierten Verzeichnisstrukturen (z. B. .tar.gz-Archiven), oder in Anwendungen, in denen nur eine geringe Speicherkapazität vorhanden ist (z. B. in eingebetteten Systemen).\n\nZur Datenkompression wird standardmäßig Deflate (zlib) verwendet, wobei auch Unterstützung für den Lempel-Ziv-Markow-Algorithmus (LZMA) vorhanden ist, der wesentlich bessere Komprimierungsverhältnisse erlaubt.\n\n\nZu SquashFS gibt es einen Satz Werkzeuge, die \"squashfs-tools\", die unter anderen \"mksquashfs\" (zur Erzeugung eines Dateisystems) und \"unsquashfs\" enthalten.\n\nSquashFS wird häufig zusammen mit UnionFS verwendet, um temporär auch Schreibzugriff auf Dateien zu erhalten.\n\nopenSUSE verwendet ab der Beta-Version 1 von openSUSE 10.3 squashfs als Dateisystem für das Installationssystem.\n\nAm 23. Oktober 2002 wurde die erste Version (1.0) veröffentlicht. Mit Version 3.3 wurde die effiziente Behandlung von Sparse-Dateien hinzugefügt. Nachdem sich die SquashFS-Entwickler bereits mehrfach um die Aufnahme des Dateisystems in den Linux-Kernel bemüht hatten, hielt Version 4 des SquashFS-Codes schließlich in die am 23. März 2009 veröffentlichte Version 2.6.29 des Kernels Einzug, nachdem sich Linus Torvalds aufgrund der verbreiteten Nutzung dafür aussprach. Derzeit ist Version 4.3 vom 12. Mai 2014 und ab Version 2.6.29 im Linux-Kernel integriert.\n\n\n"}
{"id": "2204690", "url": "https://de.wikipedia.org/wiki?curid=2204690", "title": "Ratatouille (Film)", "text": "Ratatouille (Film)\n\nRatatouille ist ein US-amerikanischer Computeranimationsfilm aus dem Jahr 2007. Es ist der achte abendfüllende Animations-Kinofilm der Pixar Animation Studios. Regisseure des Films sind Brad Bird und Jan Pinkava, die schon für ihre jeweils letzten Werke bei Pixar und auch für diesen Film mit dem Oscar ausgezeichnet wurden. Er lief am 29. Juni 2007 in den US-amerikanischen Kinos an; Kinostart für die deutschsprachige Version in Deutschland, Österreich und der Schweiz war der 3. Oktober 2007.\n\nDie literarische Vorlage für die Filmgeschichte stammt von Jan Pinkava, Jim Capobianco und Brad Bird.\n\nDer Held des Films, Rémy, ist eine Wanderratte vom Lande mit einem selbst für Ratten ungewöhnlich feinen Geruchssinn. Neben einem kurzen Einsatz als Giftschnüffler für seine Rattenfamilie entwickelt er die Fähigkeit und die Liebe zu kulinarischen Kompositionen. Allein schon für Zutaten zum leckeren Essen begibt er sich in Lebensgefahr. Einer erschreckt wütenden Hausfrau können er und seine Sippe entkommen, bei der Flucht verliert er aber Familie und Freunde aus den Augen. Es verschlägt ihn zufällig durch lange Abwasserröhren nach Paris in die Nähe eines Feinschmecker-Lokals, welches sein verstorbenes Vorbild Gusteau, ein besonders dicker und gutmütiger Koch, früher geführt hat. Gusteau vertrat zu seinen Lebzeiten das Motto „Jeder kann kochen“ und hatte einen Kochbuch-Bestseller unter diesem Namen veröffentlicht. Während des ganzen Films führt Rémy teils tiefsinnige Zwiesprache mit dem Geist dieses Mannes, welcher ihm immer wieder erscheint, ihm hilft, Entscheidungen zu treffen, sich jedoch selbst als Phantasiegebilde Rémys bezeichnet.\n\nIm Lokal angekommen beobachtet er den tollpatschigen und als Koch unfähigen Küchenjungen Linguini bei seiner Arbeit. So sieht Rémy, wie Linguini eine teilweise verschüttete Suppe mit Wasser und anderen Zutaten stümperhaft zu strecken versucht. Rémy – der Superkoch – rettet die Suppe heimlich durch leckere Zutaten. Nur Linguini erkennt dies und versteckt ihn vor dem heranrauschenden cholerischen Küchenchef Skinner unter einem Kochsieb. Kurz darauf wird die Suppe serviert und schmeckt just einer erschienenen Restaurantkritikerin vorzüglich. Linguini, der als Urheber angesehen wird und als einziger weiß, dass eigentlich die Ratte Rémy für diesen guten Geschmack verantwortlich ist, soll die Suppe nochmal zubereiten. Rémy wird bei seinem folgenden Fluchtversuch von Skinner entdeckt und sogleich von Linguini in einem Glas gefangen. Er erhält vom hinterhältigen Skinner den Auftrag, die gefangene Ratte weit vom Restaurant entfernt zu töten. Draußen am Flussufer klagt Linguini der Ratte sein Leid, woraufhin die beiden sich verständigen und in der Küche zusammenarbeiten wollen.\n\nTags darauf hat das kulinarische Rettungsmanöver Rémys zu einer Überraschung geführt: Nach einem herausragenden Bericht über die Suppe in einer einschlägigen Zeitung erlebt das sich im Niedergang befindende Restaurant einen unerwarteten Aufschwung. Die Gäste und Kritiker loben deren vorzüglichen Geschmack und bestellen rund um die Uhr Linguinis Suppe. Rémy, unter Linguinis Kochmütze versteckt, dirigiert nach einigen Anfangsschwierigkeiten den Küchenjungen mit Hilfe seiner Haare wie eine Marionette. Durch Gewitztheit und Schnelligkeit kann Rémy zunächst seine Entdeckung durch den misstrauischen Küchenchef verhindern. So gelingt es, den Schein zu wahren, Linguini wäre ein guter Koch. Auf diese Weise kommt der junge Mann zu einem immer besseren Ruf, soll in der nächsten Zeit auch weitere Gerichte kredenzen und zieht so auch die Aufmerksamkeit der auf den plötzlichen Erfolg zunächst eifersüchtigen Köchin Colette auf sich. Skinner selbst beobachtet ihn misstrauisch, meint, hin und wieder auch Rémy zu entdecken, kann jedoch seine Existenz letztendlich nicht zweifelsfrei feststellen. Zusätzlich fürchtet er den Tellerwäscher Linguini, weil der Tollpatsch laut einem Brief seiner bereits verstorbenen Mutter der Sohn Gusteaus ist und damit der eigentliche Erbe und Besitzer des Lokals, was aber nur ein geheimes Testament beweisen kann. Rémy kommt durch Zufall dahinter und schafft es auch, dem Bösewicht diese Papiere abzujagen. Kurz vor Ende der Vollstreckungsfrist wird Linguini dadurch neuer Chef des Restaurants. Er und Colette sind bald ein Paar, und aufgrund des großen Erfolges des Restaurants können er und Rémy sich eine neue luxuriöse Wohnung leisten, mit Blick über die ganze Stadt.\n\nSeine steile Karriere steigt Linguini zu Kopf, auf Fragen der Journalisten nach seiner Inspiration gibt er Colette an und verleugnet damit Rémy. Der wehrt sich zunächst noch durch kräftiges Haareziehen, wird dann aber von Linguini verstoßen mit der Begründung, er sei nicht Rémys Marionette. Enttäuscht plündert Rémy zusammen mit seiner wiedergefundenen Rattenfamilie die Speisekammer des Restaurants, wird von Linguini, der sich eigentlich bei Rémy entschuldigen wollte, dabei entdeckt und fortgejagt. Dies alles geschieht, kurz bevor der bedeutende Restaurantkritiker Ego dem Lokal einen erneuten Besuch abstatten will. Nach seinem lange zurückliegenden letzten Besuch war Egos Kritik der Grund, dass das Lokal in den Niedergang geriet. Es ist entscheidend für die Zukunft des Lokals, wie die neue Restaurantkritik des mächtigen und überheblichen Mannes ausfallen wird. Nach einer kurzzeitigen Gefangennahme Rémys durch Skinner und prompter Befreiungsaktion durch seine Rattenfamilie entscheidet sich Rémy, Linguini zu helfen. In der Küche angekommen stellt sich Linguini schützend vor ihn und gesteht in seiner Verzweiflung der Belegschaft, dass die kleine Ratte hinter dem Erfolg stehe, wonach diese geschlossen ungläubig die Küche verlässt und Linguini mit Rémy allein zurückbleibt.\n\nRémys Rattenvater erkennt die Courage Linguinis und die Bedeutung des Kochens für seinen Sohn. Zusammen mit den zahllosen Ratten stellt er sich Rémys Anweisungen zur Verfügung. Alle werden kurzerhand heiß desinfiziert und ersetzen dann, von Rémy militärisch dirigiert, die komplette Küchenmannschaft und fabrizieren leckere Menüs für die wartenden Gäste. Linguini entfaltet plötzlich sein unerkanntes Talent: die fixe Bedienung auf Rollschuhen. Zusätzliche Unterstützung erfahren alle von der zurückgekehrten Colette. Der ungeduldige und überhebliche Ego macht sich inzwischen seine Notizen. Als Schwierigkeit hatte er dem Küchenchef die Auswahl des Gerichtes überlassen, mit welchem seine Zunge verwöhnt werden soll. Intuitiv entscheidet sich Rémy, Ego das „Bauerngericht“ Ratatouille zu servieren. Dieses Gericht scheint zwar zu simpel, weckt aber durch seine hervorragende Qualität Kindheitserinnerungen in Ego. Angeregt durch den besonderen Geschmack sieht sich Ego als kleiner Junge, welcher nach einem Sturz vom Fahrrad von der Mutter eben mit dieser Ratatouille verwöhnt wurde. Sein verbittertes Herz öffnet sich, er ist begeistert und möchte sich bedanken. Nach Aufklärung über den wahren Urheber des Gerichts durch Linguini und Colette verlässt er höflich, aber wortlos das Lokal, schreibt geläutert eine lobende Kritik und bekennt sich dazu, ein treuer Fan des Restaurants zu sein. In seiner Kritik gesteht er auch ein, dass er Gusteaus Motto „Jeder kann kochen“, welches er stets abgelehnt hatte, nun endlich verstanden hat.\n\nInzwischen hat der abgehalfterte ehemalige Küchenchef Skinner den amtlichen Lebensmittelkontrolleur zu Hilfe gerufen. Dieser sieht die vielen Ratten bei der Arbeit in der Küche und veranlasst – nach einem ersten Hinderungsversuch durch einen Rattentrupp – pflichtgemäß die endgültige Schließung des Lokals. Linguini und Colette eröffnen daraufhin mit Rémy ein Bistro namens „La Ratatouille“, das sich sogleich großer Beliebtheit erfreut. Rémy und Colette kochen, Linguini sorgt für den perfekten Service, und Rémy führt zusätzlich einen kleinen Speiseraum für seine Rattenfreunde. Der nach der verkündeten Rattenplage unglaubwürdig gewordene Kritiker Ego ist Teilhaber des neuen Restaurants und ihm ein immer wiederkehrender, treuer Gast.\n\nDer Regisseur des Films ist Brad Bird, der zuletzt 2004 bei dem Pixar-Film \"Die Unglaublichen – The Incredibles\" Regie führte. Der ursprünglich geplante Regisseur, Jan Pinkava, Regisseur des Pixar-Kurzfilms \"Geri’s Game\" aus dem Jahr 1997, ist nun Co-Regisseur. Die Drehbuchautorinnen Emily Cook und Kathy Greenberg geben bei \"Ratatouille\" ihr Debüt.\n\nZur Vorbereitung auf den Film waren Bird und Filmproduzent Brad Lewis mehrmals Gast in französischen Restaurants wie im \"French Laundry\" (Napa, San Francisco) und testeten dort Menüs. Lewis soll im French Laundry sogar ein zweitägiges Praktikum absolviert haben. Außerdem nahm die gesamte Filmcrew an diversen Kochseminaren teil, um sich ein genaues Bild von den Aufgaben eines Kochs machen zu können.\n\nEine große technische Weiterentwicklung gegenüber früheren Animationsfilmen sind die dargestellten Textilien und Gewebe. Eine naturgetreue digitale Nachbildung dieser flexiblen Materialien galt lange als unmöglich. Die Entwicklung spezieller Software hierfür setzte erst 2001 mit dem Pixar-Film \"Die Monster AG\" ein. Dort zeigte man für wenige Sekunden ein zerknittertes T-Shirt in annehmbarer, den physikalischen Gesetzen gehorchender Bewegung. Mit \"The Incredibles – Die Unglaublichen\" wurden im Jahr 2005 neue Maßstäbe gesetzt; die Kleidung der Filmfiguren dort war allerdings zu großen Teilen aus latexähnlichem Stoff, der der digitalen Animation keine größeren Schwierigkeiten bereitet.\n\nFür \"Ratatouille\" entwarf das Animationsteam zwei Jahre später zum ersten Mal eine abwechslungsreiche Garderobe für die Filmfiguren. Neben verschiedenartiger Kleidung waren auch textile Requisiten wie z. B. Tischdecken vorgesehen. In der Endfassung des Films kommen insgesamt 190 unterschiedliche Objekte aus Stoff vor. Die besondere Schwierigkeit in der Darstellung lag hierbei in den vielschichtigen Kostümen samt Accessoires wie Schürze oder Kochmütze.\n\nAus Zeitgründen wurde bei den menschlichen Figuren auf die Modellierung ihrer Zehen verzichtet. Bis auf diese Ungenauigkeit haben sie aber einen anatomisch korrekten Körperbau. Küchenjunge Linguini hat eine Körpergröße von 1,92 Metern, die Ratte Rémy misst 18 Zentimeter. Die Figur Colette hat 176.030 animierte Haare auf dem Kopf. Pixar wies in diesem Zusammenhang darauf hin, dass der echte Durchschnittsmensch zwischen 100.000 und 200.000 habe. Die Ratte trägt auf ihrem digitalen Körper sogar über 1.150.000 Haare.\n\nUm eine möglichst realitätsnahe Abbildung der 270 im Film gezeigten Nahrungsmittel und Gerichte schaffen zu können, wurden diese zunächst in Wirklichkeit zubereitet, um dann sorgfältig fotografiert und digital nachgebildet zu werden. Außerdem beobachteten die Animatoren sorgfältig den Verderb von 15 Naturprodukten (Obst und Gemüse) und dokumentierten ihn ebenfalls mit Fotografien. Die so entstandenen Bilder und Beobachtungen dienten als Vorlage für einen Komposthaufen.\n\nKamerafrau Sharon Calahan berichtete nach den Dreharbeiten zu \"Ratatouille\" von ihrer Intention, dem gesamten Film einen „satten Look“ zu geben. Zu diesem Zweck habe sie mit kräftigen Farben den Eindruck eines „perfekten Oktobertages“ in Frankreich zu vermitteln versucht. Viel gearbeitet habe sie mit einer Technik, die im Jahr 2004 für \"Findet Nemo\" entwickelt worden war. Diese verhelfe computeranimierten Figuren dazu, „lichtdurchlässig“ zu wirken, und lasse sie deshalb realistischer erscheinen. Für die Darstellung der Gerichte habe sie eine gewisse „Appetitlichkeit“ erreichen wollen, dazu seien verschiedene Lichtquellen in warmen Farben vonnöten gewesen, welche die natürlichen Farben von Lebensmitteln besser zum Vorschein brächten. Den Ratten sei mit der Belichtungstechnik zu Niedlichkeit und gleichzeitig Glaubwürdigkeit verholfen worden. Etwas stärker als der Rest des Tierkörpers wurden dazu die Ohren belichtet.\n\nAls Filmkomponist für \"Ratatouille\" fungierte Michael Giacchino, der bereits die Filmmusik für \"The Incredibles – Die Unglaublichen\" geschrieben hatte. Die verwendeten Instrumente sind vor allem Klavier und Streichinstrumente, die oft pizzicato gespielt wurden, aber auch Mundharmonika und Akkordeon. Neben einem musikalischen Hauptthema schrieb Giacchino zu jeder Filmfigur eigene charakteristische Melodiepassagen. Zur Hauptfigur Rémy existieren sogar zwei verschiedene Melodien: Ein Thema verdeutlicht mit seiner geheimnisvollen Energie Rémys Dynamik und Vitalität, das andere untermalt seine Sehnsüchte und Wünsche mit orchestralem Klang. Außerdem teilen sich Rémy und Linguini ein „Kumpelthema“, welches sich bei der ersten Begegnung der beiden zögerlich aufbaut und zum Ende des Films hin in ein triumphales Finale mündet. Als Gegenstück zur durchgängigen Computeranimation der Bilder sind weite Teile der Filmmusik rein akustisch aufgenommen.\n\nWeitere wichtige Themen gehören zu den Kochszenen im Restaurant; sie werden zumeist in Gang gesetzt durch die Figur der Colette. Die Musikuntermalung der Handlung um Skinner basiert auf einem Jazz-Motiv, um das herum im Laufe des Films immer konfuser und verrückter improvisiert wird und das damit die Rollenentwicklung Skinners widerspiegelt.\n\nFerner enthält der Soundtrack auch das Chanson \"Le Festin\" in einer Interpretation der Sängerin Camille. Michael Giacchino wurde für seine Musik für den Oscar nominiert.\n\nIm offiziellen Trailer und auf den Filmplakaten wird darauf hingewiesen, dass der Titel (engl.) „rat·a·too·ee“ [] ausgesprochen wird, nicht „rat·at·ouille“ bzw. „rat·at·will“ (dt.: „Ratte nach Belieben“). Das Wortspiel mit „Ratatouille“ und „rat“ (engl.: Ratte) ist offensichtlich. Auf den deutschen Plakaten wird es zu „ratte·tuu·ii “ [], da man in Deutschland der französischen Sprechweise folgt. Im Film wird mit „ratte·pfuu·ii“ erneut auf den Titel angespielt.\n\nGusteau ist vom Hörbild eng an Gusto angelehnt, den italienischen Begriff für Geschmackssinn.\n\nDie Ratten Rémy und Django sollten ursprünglich die Namen „Art“ (engl.: Kunst) und „Pesto“ (ital. Würzsauce) tragen. Mit Vornamen heißt Linguini Alfredo und Gusteaus Vorname Auguste ist ein Anagramm seines Nachnamens. Weiterhin ist Linguini eine Pasta-Art.\n\nFür die deutsche Buch- und Dialogregie war Axel Malzacher verantwortlich. Die zuständige Synchronfirma war die FFS Film- & Fernseh-Synchron GmbH.\n\nIm Film gibt es mehrere Verbindungen zu früheren Pixar-Filmen: Als Linguini in einer Sequenz seine Hose öffnet, ist auf seiner Unterhose deutlich das „Incredibles“-Logo zu sehen, und während einer Straßenszene läuft im Hintergrund Bomb Voyage durchs Bild, eine Figur ebenfalls aus \"The Incredibles – Die Unglaublichen\". Außerdem fährt auf der Seine-Brücke der „Pizza-Planet“-Truck aus \"Toy Story\" (1995), ein Auto, das in nahezu jedem Pixar-Film zu sehen ist.\n\nDas Geschäft, bei dem Rémy angesichts dessen Schaufensterdekoration Zweifel kommen, ob Ratten und Menschen Freunde sein können, gibt es tatsächlich. Im Schaufenster hängen ununterbrochen seit 1925 21 Ratten, deren Genicke durch Fallen gebrochen wurden. Wie viel Geld Pixar für das Verwertungsrecht an Aurouze bezahlt hat, ist unbekannt.\n\nIn dem auf der DVD enthaltenen Kurzfilm \"Dein Freund, die Ratte\" kommt in einer der späteren Szenen WALL·E, der Darsteller des Nachfolgerfilms \"WALL·E – Der Letzte räumt die Erde auf\" vor, wie er ein Fahrzeug auf dem Mars steuert.\n\nVorfilm beziehungsweise DVD-Bonus zu \"Ratatouille\" ist \"Lifted\" (2006).\n\nAuf der DVD des Filmes gibt es als Bonus den etwa 10-minütigen Kurzfilm \"Dein Freund, die Ratte\". Darin klären Rémy und sein Bruder auf humorvolle Art, aber durchaus mit Anspruch auf Korrektheit die Geschichte der Ratten. Dabei betonen sie zudem, dass sie selbst Wanderratten und keine Hausratten sind. Sie begründen die besondere Beziehung zwischen Mensch und Ratte damit, dass Ratten sich dem Menschen gegenüber auf Augenhöhe sehen, während sich Hunde dem Menschen unterwerfen und Katzen wiederum verächtlich auf den Menschen herabsehen. Des Weiteren räumen sie auch mit Vorurteilen auf, etwa dem der Ratte als Krankheitsüberträger, und betonen, dass nicht die Ratte, sondern der Rattenfloh die Pest übertrug.\n\nZu Ratatouille erschien auch ein Videospiel. Es ist erhältlich für PlayStation 2, Nintendo Wii, Nintendo DS, Xbox 360 und PC.\n\nAuf neueren Kreuzfahrtschiffen der Disney Cruise Line wird in Anspielung an den Film ein luxuriöses französisches Restaurant unter dem Namen \"Remy\" angeboten.\n\nIm Abspann erscheint eine Widmung an den Comic-Zeichner \"Dan Lee\", der im Jahr 2005 im Alter von nur 35 Jahren an Lungenkrebs verstarb.\n\nDie Kritik begegnete dem Film mit viel Lob. Bezüglich der Tierart stellte man fest, dass Rémys „riesige Augen“ und die „zartrosa Knuddelnase“ jede Rattenphobie verhinderten. Rémy sei kultiviert, gepflegt, und alles an einer Ratte potenziell Eklige hätten die Macher vermieden: „Eine rundum angenehme und possierliche Ratte, die man sich in jedem Kinderzimmer sehr gut vorstellen kann.“ Die Animationen wurden vielerorts enthusiastisch aufgenommen, insbesondere die Gestik und das Mienenspiel Rémys wurden als „sensationell“, „differenziert“ und „perfekt“ bezeichnet. Eine solche Körperkomik habe man seit der Stummfilmzeit nicht mehr gesehen. „Jede Bewegung – sei es die einer Figur, sei es die der Kamera selbst – ist von pixar-typischer, flüssiger und musikalischer Gewandtheit: Sie wirkt natürlich, obwohl sie ganz und gar künstlich ist“ urteilte der \"Tagesspiegel\", derweil die \"Berliner Zeitung\" feststellte: „Wie die Animatoren durch die Haltung des Körpers, das Spiel der Augen und Pfoten die allmähliche Verfertigung der Rattengedanken beim Schnuppern und Schmecken zu zeigen verstehen – das hat man so im Kino noch nicht gesehen.“ Zudem sei der Kritiker Anton Ego die bislang überzeugendste Darstellung einer menschlichen Figur in einem am Rechner animierten Film. Die Kritiker hoben die visuelle Sinnlichkeit hervor, die Düfte und Geschmäcker, „lockende Farben“ und appetitlich anzusehende Speisen. Die beim Essen entstehenden synästhetischen Visionen stammten von ähnlichen Mitteln in Fantasia ab. Einhellig war die Meinung, dass \"Ratatouille\" detailversessen sei. Jedes dieser Details habe Seele; nicht auf Naturalismus, sondern auf Emotionen habe der Regisseur gesetzt.\n\nOriginell und reich an Ideen fanden die Rezensenten die erzählte Geschichte, wie seit den Zeiten der Person Walt Disneys nicht mehr, da stecke die ganze Liebe des Regisseurs. Ihm sei eine klare Dramaturgie und Figurenmotivation gelungen, eine wunderbare, seltene Mischung aus Humor, Gefühl und Spannung, ein Film, der mit unverkrampfter Leichtigkeit zwischen Komödie, Melodram und Action wechselt. Neben Lob am perfekten Timing etwa bei Verfolgungsjagden und dem „balletösen“ oder „rasantem“ Slapstick gab es Tadel, der den Slapstick für eher misslungen erklärte. Die \"F.A.Z.\" bemängelte zudem zu viel Niedlichkeit nach Art des Disney-Studios, und im Mittelteil würden Tempo und Spannung durch die Liebesgeschichte gehemmt. Genau umgekehrt deutete die \"Frankfurter Rundschau\", dass Gusteaus Name durch seinen Nachfolger verwertet wird: „Die Analogie zur Trickfilmgeschichte ist unübersehbar: So wie hier unter einem großen Namen lieblos alte Rezepte verkocht werden, arbeitete man zuletzt bei Disney.“ Auf der einen Seite hieß es, das Parisbild sei eine Hommage an Disneys Aristocats, und man höre Melodien aus Mary Poppins. Auf der anderen Seite war zu vernehmen, das überzeugende hermetische Universum komme ohne popkulturelle Zitate aus. Dazwischen lag die Position, trotz Hommagen an verschiedene Trickfilmklassiker bleibe \"Ratatouille\" auch ohne diese Hintergrundkenntnisse verständlich. „Anspielungen müssen nicht als Gags herhalten, mit denen etwa die „Shrek“-Trilogie überfrachtet ist.“ Der Film sei „nostalgisch, aber nicht vorgestrig“ und überzeuge „auch diejenigen, die im Kino in den letzten Jahren zu viele witzige sprechende Tiere gesehen haben.“ Im Unterschied zu üblichen Trickfilmen haben die Figuren ein Herz und eine Seele. Ein Glück sei auch, dass die deutsche Synchronisation auf nichtprominente, dafür aber begabte Stimmen setze.\n\nÄhnlich, aber mit Nuancen, waren die Einschätzungen, wer das Zielpublikum sei – ein Film für die ganze Familie, nicht nur für Kinderaugen, oder nicht in erster Linie an Kinder gerichtet? Oder kein Kinderfilm, weil das Milieu der Haute Cuisine jungen Zuschauern fremd sein dürfte, aber auch für Kinder geeignet? Bezeichnete eine Kritik das Werk als gesellschaftskritisch, war einer anderen das Sozialgefüge nicht ausreichend dargestellt. Kulturpessimismus liege diesem Film fern: „Bei Pixar versucht man gegenwärtig lediglich zu beweisen, dass das Beste auch das Erfolgreichste sein kann. Egal welchen Müll die Leute sonst wo essen.“ Die Pixar-Macher müssten sich ihrer Sache sehr sicher gewesen sein, dass sie es wagten, einen Kritiker vorzuführen. Es sei „ganz gewiss Pixars größter künstlerischer Erfolg.“\n\n2016 belegte \"Ratatouille\" bei einer Umfrage der BBC zu den 100 bedeutendsten Filmen des 21. Jahrhunderts den 93. Platz.\n\n\n\n\n\n\n\n\n\nDie Deutsche Film- und Medienbewertung (FBW) verlieh dem Film das Prädikat „besonders wertvoll“\n\nWeitere Auszeichnungen und Nominierungen sind bei der IMDb nachzulesen.\n\n\n"}
{"id": "2213894", "url": "https://de.wikipedia.org/wiki?curid=2213894", "title": "Microprofessor I", "text": "Microprofessor I\n\nMicroprofessor I (MPF 1) ist ein Einplatinencomputer, der im Jahre 1981 auf den Markt gebracht wurde. Der Computer wurde von der taiwanischen Firma Multitech (heute Acer) hergestellt. Er gehört wohl zu den am längsten verkauften Computern, die seit dem Verkaufsstart nicht mehr verändert wurden. Der MPF I war ein einfach zu nutzendes Trainingssystem für den Z80-Mikroprozessor von Zilog mit einer Taktfrequenz von 1,79 MHz. Der Rechner war mit einem RAM von 2 KB (erweiterbar bis 4 KB) und einem ROM von 2 KB (erweiterbar bis 8 KB) ausgestattet. Nachfolger des Rechners waren der Microprofessor I-b (welcher zusätzlich ein BASIC-ROM hatte und alternativ zu Assembler die Programmierung in dieser Hochsprache erlaubte), Microprofessor II und Microprofessor III.\n\nBis heute wird der Computer von Flite Electronics International hergestellt und verkauft.\n\n\nFür den MPF-I waren zahlreiche Erweiterungsplatinen und -Chips erhältlich:\n\n\n\n"}
{"id": "2219512", "url": "https://de.wikipedia.org/wiki?curid=2219512", "title": "Windows Mail", "text": "Windows Mail\n\nWindows Mail ist die in Windows Vista enthaltene Weiterentwicklung von Outlook Express.\n\nAnders als früher Outlook Express wird Windows Mail nicht zusammen mit neuen Versionen des Internet Explorer unter anderen Versionen von Windows installiert, sondern ist Windows Vista vorbehalten. Dennoch ist Windows Mail eng mit dem Internet Explorer verknüpft und von dessen Sicherheitszonen abhängig. Windows Mail nutzt auch den Phishing-Filter des Internet Explorer, der gleichzeitig mit dessen Version 7 eingeführt wurde.\n\nEin interessanter Aspekt ist, dass über Windows Mail keine Nutzung des von Microsoft angebotenen Dienstes Hotmail mehr möglich ist. Hotmail oder outlook.com lässt sich nur per POP verwenden. Bei Problemen mit Windows Mail rät Microsoft, stattdessen das Programm Windows Live Mail einzusetzen.\n\nWeitere Neuerungen:\n"}
{"id": "2222336", "url": "https://de.wikipedia.org/wiki?curid=2222336", "title": "PC Intern", "text": "PC Intern\n\nPC Intern war eine Computerzeitschrift aus dem Verlag Data Becker mit dem Themenschwerpunkt interne Details der PC-Architektur vonseiten der Hardware, aber auch der Software einschließlich Programmierung. Die Zeitschrift war aus dem gleichnamigen, bei Data Becker erschienenen, Systemprogrammierungs-Buch entstanden.\n\nAls eigenständige Zeitschrift erschien sie im Herbst 1995 zunächst monatlich, zeitweise auch zweimonatlich und seit 2001 quartalsweise. Während die Zielgruppe in den Anfängen noch der Power-User und „PC-Freak“ war, vermittelte sie später zwar immer noch detailliertes PC-Wissen, allerdings auch für Fortgeschrittene verständlich. 2006 hatte das Heft bei vierteljährlicher Erscheinungsweise eine Auflage von 45.000 Exemplaren (nicht IVW-geprüft).\n\nSeit Mitte 2004 trug sie den Zusatz „PC-Praxis-Sonderheft“. Wie in dem Marktsegment üblich, lag dem Heft seit etwa 1998 eine CD/DVD mit Software bei. Im Februar 2007 wurde das Magazin eingestellt; die letzte Ausgabe erschien am 28. April 2007.\n\n2013 erschien die Zeitschrift in unregelmäßigen Abständen wieder bis zur Schließung des Verlages Anfang 2014.\n"}
{"id": "2222418", "url": "https://de.wikipedia.org/wiki?curid=2222418", "title": "Linux Intern", "text": "Linux Intern\n\nLinux Intern war eine 1999 gegründete Computerzeitschrift aus dem Verlag Data Becker, die Themen um das freie Betriebssystem Linux behandelte. Sie erschien quartalsweise (in den Anfängen unregelmäßig) und wurde als Sonderheft der PC Praxis geführt. Die Auflage betrug im Januar 2007 43.000 verkaufte Zeitschriften (nicht IVW-geprüft). Der Verlag gab eine Druckauflage von 49.404 an (Stand: Dezember 2012). Im Januar 2013 wurde vom Verlag die Einstellung der Zeitschrift bekanntgegeben.\n\nDas etwa 160-seitige Heft erschien mit beiliegender CD/DVD, auf der sich verschiedene Linux-Distributionen und Linux-Software befanden, deren Nutzung und Installation im Heft erklärt wurde. Neben Produkttests fanden sich Anleitungen zur Konfiguration und Nutzung von Hardware und Software sowie nützliche Tipps für einen Umstieg auf Linux.\n\nUnter dem Namen Linux Intern gab es ebenfalls seit dem Jahr 1998 ein Computerbuch im Data Becker Verlag, das in mehreren Auflagen erschienen ist.\n"}
{"id": "2223851", "url": "https://de.wikipedia.org/wiki?curid=2223851", "title": "Kernel-based Virtual Machine", "text": "Kernel-based Virtual Machine\n\nDie Kernel-based Virtual Machine (KVM; ) ist eine Infrastruktur des Linux-Kernels zur Virtualisierung, die auf mit den Hardware-Virtualisierungstechniken von Intel (VT) oder AMD (AMD-V) ausgestatteten X86-Prozessoren sowie auf der System-z-Architektur lauffähig ist. KVM wurde im Oktober 2006 veröffentlicht und ist ab Version 2.6.20 des Linux-Kernels in diesem enthalten. Es wurde unter der Federführung von Avi Kivity bei dem israelischen Unternehmen \"Qumranet\" entwickelt. Qumranet wurde im September 2008 von Red Hat gekauft. Es existieren auch Portierungen von KVM nach FreeBSD und illumos in Form von Kernelmodulen.\n\nKVM wurde zunächst für die x86-Plattform entwickelt und besteht für diese aus dem Kernel-Modul kvm.ko sowie aus den hardwarespezifischen Modulen kvm-intel.ko (für Intel-Prozessoren) oder kvm-amd.ko (für AMD-Prozessoren). Inzwischen gibt es KVM auch für weitere Plattformen wie PowerPC, System z und ARM. KVM selbst nimmt keine Emulation vor, sondern stellt nur die Infrastruktur dazu bereit; QEMU ist derzeit die einzige Möglichkeit, diese zu nutzen. Dazu stellt QEMU für virtualisierte Gastsysteme die notwendigen Geräte wie Festplatten, Netzwerk-, Sound- und Grafikkarten zur Verfügung. Nach dem Laden des Moduls arbeitet der Linux-Kernel selbst als Hypervisor für virtuelle Maschinen. Als Gastsysteme unterstützt KVM Linux (32 und 64 Bit), Windows (32 und 64 Bit), Haiku, AROS, ReactOS, FreeDOS, Solaris und diverse BSD-Derivate. KVM läuft auch auf SMP-Hostsystemen, SMP-Gastsysteme sind ebenfalls möglich. Die Unterstützung für Paravirtualisierung ist mittlerweile in KVM vorhanden und wird unter Linux mittels der Paravirtualisierungsschnittstelle Virtio (seit Kernel 2.6.25 im Kernel enthalten) für Festplatten- und Netzwerkgerätetreiber zur Verfügung gestellt. Für Windows existieren ebenfalls paravirtualisierte Gerätetreiber. Vorteile sind ein geringerer Overhead sowie erhöhte Performance, da das Gastsystem „weiß“, dass es auf virtualisierter Hardware läuft und mit dem Hypervisor zusammenarbeitet. Seit Kernel 3.1 unterstützt KVM nested Virtualization auf Intel-CPUs. Für AMD-CPUs ist dies bereits ab Version 2.6.30 verfügbar. Nested Virtualization ermöglicht es Hostsystemen, die Virtualisierungsunterstützung der CPU für die Gastsysteme verfügbar zu machen, welche so ihrerseits „Unter“-Gäste virtualisieren können.\n\nDie Bestandteile von KVM sind Open-Source-Software und stehen unter verschiedenen Varianten der GPL-Lizenz zur Verfügung:\n\nIm Mai 2011 gründeten BMC Software, Eucalyptus Systems, HP, IBM, Intel, Red Hat und SUSE die Open Virtualization Alliance (OVA), um KVM für Virtualisierung und cloudbasierte Lösungen auf dem Markt zu etablieren. Dieser Organisation, die 2016 nach Erreichen des Zieles aufgelöst wurde, gehörten über 200 Mitglieder aus der ganzen Welt an. Die großen Distributoren Ubuntu, Red Hat und SUSE Linux haben bei der präferierten Virtualisierungslösung schon seit einiger Zeit von Xen auf den Neuling KVM gewechselt.\n\nKVM ist eine wesentliche Komponente der Cloud-Computing-Software OpenStack.\n\nNeben kommerziellen Anbietern setzen auch öffentliche Anbieter wie beispielsweise die bwCloud der baden-württembergischen Hochschulen und Universitäten auf KVM.\n2017 hat das Bundesamt für Sicherheit in der Informationstechnik eine Sicherheitsanalyse für KVM durchgeführt und dabei festgehalten, „dass die untersuchten Komponenten – allen voran KVM, QEMU und libvirt – dazu geeignet sind, eine technisch ausgereifte und sichere Virtualisierungsumgebung zu realisieren“.\n\nFür KVM sind mehrere Programme zur Steuerung möglich. So ist es möglich, virtuelle Maschinen mit Hilfe von Kommandozeilenprogrammen wie qemu/kvm oder virsh zu erstellen. Angenehmer und übersichtlicher gelingt dies jedoch mit grafischen Frontends wie dem Virtual Machine Manager (VMM), AQemu oder dem UCS Virtual Machine Manager. Es existieren auch Lösungen, die das Management über Weboberflächen und somit das Verteilen einer virtuellen Infrastruktur in Firmen ermöglichen. Hier ist das oVirt-Projekt und das darauf aufbauende kommerzielle Redhat Enterprise Virtualization zu nennen oder die FOSS-Cloud, welche als reine Open-Source-Lösung zur Verfügung steht, sowie Kimchi, ein in HTML5 geschriebenes Verwaltungwerkzeug. Weiters dient die Open-Source-Virtualisierungslösung Proxmox VE als Mangementplattform für KVM und LXC Container.\n\nEs bestehen auch andere kommerzielle Lösungen für das Aufbauen virtueller Desktop- und Serverinfrastrukten wie beispielsweise VERDE von Virtual Bridges. Diese Lösungen sind jedoch bisher nicht sonderlich weit verbreitet.\n\nKVM ist formal ein Typ2-Hypervisor. Dies bedeutet, dass er im nicht privilegierten Ring 3 läuft. Hierzu besteht eine historische Debatte, ob KVM wirklich ein reiner Typ2-Hypervisor ist, da auch Teile in Ring 0 laufen, was für einen Typ1-Hypervisor spricht.\n\n\n"}
{"id": "2224621", "url": "https://de.wikipedia.org/wiki?curid=2224621", "title": "The GodFather", "text": "The GodFather\n\nThe GodFather ist eine proprietäre, kostenlose Software für Windows zum Verwalten von Musikdateien. Sie ist in deutscher Sprache erhältlich.\n\nMit The GodFather kann man die Metadaten der Musikdateien, auch Tags genannt, bearbeiten (Tag-Editor). Es stehen dazu zahlreiche Möglichkeiten zur Verfügung. Man kann die fehlenden Informationen manuell einfügen, oder man kann beispielsweise direkt für ein ganzes Album den Künstler bestimmen und diesen automatisch in alle Musikdateien eintragen lassen. The GodFather bietet auch umfangreiche Möglichkeiten, um Informationen für die Tags aus dem Internet abzurufen (CDDB) oder sie aus den Dateinamen abzuleiten.\n\nWeiterhin kann die Software Musikdateien nach einem frei wählbaren Schema umbenennen. Dazu müssen jedoch die oben erwähnten Tags vorhanden sein, denn aus diesen bezieht The GodFather die Informationen zum Umbenennen. Außerdem bietet dieses Programm eine Funktion zum Einsortieren der Musik in eine bestimmte Verzeichnisstruktur und eine nicht so ausgereifte Funktion zum Erkennen doppelter Musikdateien. Das Programm unterstützt viele gängige Musikformate, neben MP3 werden auch Ogg Vorbis, mpc, Monkey’s Audio, FLAC, AAC, apl, wv, ofr und Speex unterstützt. Die Dateiformate MP1, MP2 und WMA werden jedoch nicht unterstützt.\n\nEine weitere Fähigkeit des Programms ist, dass man von der Programmoberfläche aus Skripte anpassen und starten kann, welche das Umbenennen und Einsortieren der Musik stark vereinfachen können. Als Skriptsprache wird Standard Pascal verwendet und dem Programm liegen bei der Installation einige Skriptbeispiele bei, welche den Einstieg in diese Technik erleichtern sollen.\n\n"}
{"id": "2225392", "url": "https://de.wikipedia.org/wiki?curid=2225392", "title": "Arthur und die Minimoys", "text": "Arthur und die Minimoys\n\nArthur und die Minimoys (Originaltitel: \"Arthur et les Minimoys\") ist ein französischer Spielfilm von Luc Besson aus dem Jahr 2006. Der Film ist eine Mischung aus Realfilm und Computeranimation. Der Film startete am 25. Januar 2007 in den deutschen Kinos.\n\nHauptperson ist ein Junge namens Arthur, der bei seiner Großmutter wohnt, da seine Eltern ständig unterwegs sind. Sein Großvater ist auf mysteriöse Weise verschwunden. Abends vor dem Einschlafen erzählt ihm seine Großmutter oft Geschichten aus Afrika – von den „Bogomatasalei“ und den „Minimoys“, die sein Großvater sogar persönlich gekannt habe.\n\nMr. Davido, ein Immobilienmakler, möchte ihnen das Haus, in dem sie wohnen, wegnehmen. Und auch sonst gibt es eine Vielzahl an unbezahlten Rechnungen. Arthur bleiben 48 Stunden Zeit, um die Rubine seines Großvaters, die er von den Bogomatasalei geschenkt bekommen hat, zu finden. Während schon der Gerichtsvollzieher im Haus ist, findet Arthur im Zimmer seines Großvaters einen Plan, wie er zu den Minimoys gelangen kann. Er befolgt die Anweisungen und Hinweise, die sein Großvater hinterlassen hat und begegnet den leibhaftigen Bogomatasalei, großgewachsenen, afrikanischen Menschen in Stammeskleidung und Schmuck. Er rutscht letztlich miniaturisiert durch ein Fernrohr ins Land der Minimoys, der kleinen elfenartigen Wesen, die den Garten bevölkern. Aber er hat nur 36 Stunden Zeit, um wieder zurückzukehren, da sich die Pforte des Lichts dann wieder schließt.\n\nKaum ist Arthur im Land unter der Erde angekommen, findet eine Zeremonie statt, bei der ein Schwert der Macht aus einem Stein gezogen werden muss. Prinzessin Selenia bemüht sich vergebens und inzwischen greifen bewaffnete Häscher des bösen „M“ (Maltazard) auf Moskitos an. So gerät Arthur mitten in die turbulenten Luftkämpfe. Um schnell zu einer Waffe zu kommen, greift Arthur zu dem Schwert im Stein und zieht es wie König Artus heraus. Sogleich feiern die Minimoys Arthur als Helden.\n\nZusammen mit Prinzessin Selenia und ihrem kleinen, ebenso rothaarigen Bruder Beta begeben sie sich auf die Reise, um Maltazard, der die sieben Königreiche der Minimoys unter seine Herrschaft bringen will, zu bezwingen und gleichzeitig Arthurs Großvater zu finden. Ihr Weg führt sie an die Oberfläche in Arthurs Garten, wo sie in einige Gefahren geraten. Zunächst kollidieren sie mit einer Hummel, geraten an einen wütenden Regenwurm und treiben ungesteuert in einer Nussschale im Wasser. Zur Übernachtung machen sie es sich in einer Mohnblume bequem, aber damit sind auch schon die ersten 24 Stunden vergangen. Am nächsten Tag gibt es Libelleneier zum Frühstück, aber auch eine böse Überraschung. Denn der böse M stiehlt die Bewässerungsanlage, die Arthur aus Trinkhalmen gebastelt hat, um Radieschen zu bewässern. In den Händen des bösen M können sie aber zur Gefahr für die Minimoys werden, die keinerlei Wasser vertragen. Sie reisen mit den Trinkhalmtransportern, gelangen in eine unterirdische Disco-Bar und müssen sich die aufdringlichen Discobesucher vom Hals halten. Die Reise geht weiter in die Tiefe der Erde zum Palast des bösen M. Aus Taktik trennen sich ihre Wege und Prinzessin Selenia gibt Arthur einen Abschiedskuss. Beta erklärt ihm, dass die beiden nach dem Gesetz der Minimoys nun verheiratet sind.\n\nSelenia trifft auf den bösen M, der damit rechnet, dass der erste Kuss der Prinzessin ihm sein altes Aussehen zurückgibt. Aber sie hat ihren ersten Kuss bereits an Arthur vergeben. Dieser wird unterdessen zusammen mit Beta im Gefängnis gefangengehalten und trifft dort auf seinen Großvater Archibald. Auch Selenia wird zu ihnen gebracht und alle vier müssen durch den Tunnel fliehen, den der bösen M in Kürze fluten will. Arthur findet im Tunnel eines seiner Spielzeugautos. Damit können sie sich rasant vor den Wassermassen in Sicherheit bringen. Wieder zu Hause im ersten Königreich angekommen, ist es eine Minute vor Zwölf und Arthur muss sich mit seinem Großvater beeilen, die Pforte des Lichts zu erreichen. Gerade noch rechtzeitig gelangen sie an die Erdoberfläche, wo schon Mr. Davido wartet, um das Grundstück zu übernehmen.\n\nDank seines kleinen Freundes Mino kann Arthur die Rubine lokalisieren und nach oben holen. Dabei zerstört er gleichzeitig das Reich des bösen M, der die Flucht ergreift. Mit einem Rubin aus dem Schatz kann der Großvater nun seine Schulden bezahlen. Mr. Davido versucht mit Waffengewalt den gesamten Schatz, auf den er die ganze Zeit aus war, an sich zu bringen, wird aber von den Bogomatasalei aufgehalten und der Polizei übergeben. Danach bringt Arthur Mino mitsamt dem Schwert wieder zu den Minimoys zurück.\n\nPrinzessin Selenia stößt das Schwert wieder in den Stein, in der Hoffnung, dass Arthur wie versprochen in zehn Monden wieder zu Besuch kommt.\n\nDie Kulissen wurden wirklich gebaut und gefilmt, dann erst wurden sie mit den computeranimierten Figuren wie Arthur und Selenia ins Bild gesetzt. Etwa 100 Zeichner waren an der Produktion beteiligt. Sie benötigten 27 Monate, um aus 20 Millionen einzelnen Computerbildern den fertigen Film zu fertigen. Mit einem Budget von 65 Millionen Euro ist \"Arthur und die Minimoys\" der bisher teuerste europäische Trickfilm.\n\nPremiere hatte der Film in Paris. In Frankreich strömten in der Folge rund 6,4 Millionen Zuschauer in die Kinos. Weltweit konnte der Film 113 Millionen US-Dollar einspielen.\n\nDie deutsche Synchronbearbeitung entstand durch die FFS Film- & Fernseh-Synchron, München/Berlin. Für Dialogbuch und -regie war Marius Clarén zuständig.\n\nFür das \"Lexikon des Internationalen Films\" war \"Arthur und die Minimoys\" eine „[ü]berladene, von einer Realfilmhandlung gerahmte 3D-Fantasy-Animation, die vor allem am hastigen Abhandeln von abenteuerlichen Prüfungen und den damit verbundenen unlogischen Brüchen krankt.“ \"Cinema\" zog das Fazit: „Inhaltlich wenig originelle, dafür um so perfekter inszenierte Familienunterhaltung auf Hollywood-Niveau.“\n\nLaut \"Prisma\" erzähle Luc Besson „hier eine Fantasygeschichte, die sich schamlos aus gängigen Genrewerken bedient und kaum eine eigene Idee aufweist“.\nAuch \"filmstarts.de\" bemerkte, dass Besson zu sehr auf Ideen aus \"Liebling, ich habe die Kinder geschrumpft\", dem „\"Harry-Potter\"-Universum“ und seinem Science-Fiction-Film \"Das fünfte Element\" zurückgegriffen habe. Dennoch käme „gepaart mit Bessons eigenem Ideenreichtum […] immer noch eine lustige Reise dabei heraus.“\n\n\"Kino.de\" hingegen beschreibt den Film als „eine äußerst originelle und kreative Verbindung von Real- und Animationswelten, Science Fiction- und Action-Elementen sowie jede Menge Humor“.\n\nIm November 2009 erschien die Fortsetzung \"Arthur und die Minimoys 2 – Die Rückkehr des bösen M\". 2011 wurde der dritte Teil \"Arthur und die Minimoys 3 – Die große Entscheidung\" in Deutschland direkt auf DVD veröffentlicht.\n\n\n"}
{"id": "2226357", "url": "https://de.wikipedia.org/wiki?curid=2226357", "title": "Crypto Operating System", "text": "Crypto Operating System\n\nDas Crypto Operating System (\"COS\", nicht zu verwechseln mit dem Cray Operating System) war ein angeblich alternatives Betriebssystem für Apple Macintosh Computer. 1997 sollte COS abgesichert nach B2-Klassifikation, mit integriertem PGP-Client, auf den Markt kommen. Die damals tätige Firma, mit dem Namen Omega, produzierte allerdings nur den wahrscheinlich größten Fake in der Geschichte des Macintosh.\n\n\nDie Geschichte wurde nach über zehn Jahren von ApfelWiki.de recherchiert und nach und nach aufbereitet. Heute sind viele verloren geglaubte Fakten wieder ans Licht befördert worden.\n\n"}
{"id": "2231951", "url": "https://de.wikipedia.org/wiki?curid=2231951", "title": "Microsoft Windows 7", "text": "Microsoft Windows 7\n\nMicrosoft Windows 7 ist ein Betriebssystem des US-amerikanischen Unternehmens Microsoft. Es erschien am 22. Oktober 2009 und ist der Nachfolger von Microsoft Windows Vista. Der weltweite Marktanteil von Windows 7 unter den Windows-Desktop-Betriebssystemen lag im November 2018 bei 35,55 Prozent. Die Unterstützung von Windows 7 und damit die Belieferung mit Sicherheitsupdates wird am eingestellt.\n\nWährend das Unternehmen eine Betriebssystemversion mit dem Codenamen \"Longhorn\" entwickelte, die später als Windows Vista veröffentlicht wurde, begann Microsoft zunächst unter dem Codenamen \"Blackcomb\", ab 2006 als \"Vienna\", die Entwicklung der nachfolgenden Version. Im Oktober 2008 gab der Hersteller „Windows 7“ als Namen für das Nachfolgesystem von Windows Vista bekannt.\n\nDie interne Versionsnummer von Windows 7 ist NT 6.1. Microsoft begründet die seltsame Nummerierung damit, dass man von der internen Versionsnummer 7.0 Abstand nehmen müsse, damit für Windows Vista geschriebene Programme auf Windows 7 weiterhin lauffähig blieben. Da sich Windows Vista und 7, abgesehen von zahlreichen Bugfixes und einer neuen Oberfläche, sehr ähnlich sind, kann die Nummer im Produktnamen auch ohne jeden Zusammenhang mit der Version interpretiert werden: Man entschied sich nach Angabe von Microsoft zum einen wegen der Zahlensymbolik für Sieben, als auch aus dem Grund, dass Windows 7 nach der unternehmenseigenen Zählweise die siebte Windows-Produktserie sei:\n\nDie erste Vorabausgabe wurde am 28. September 2008 an die Teilnehmer der \"\" (\"PDC\") verteilt.\n\nAnlässlich der \"Consumer Electronics Show 2009\", die am 7. Januar begann, wurde eine Beta-Version offiziell für MSDN- und TechNet-Mitglieder zugänglich gemacht und anschließend am 9. Januar der Öffentlichkeit zum Download bereitgestellt (Build 7000).\n\nAufgrund des großen Interesses musste Microsoft den Download wegen Serverüberlastung zwischenzeitlich stilllegen, um die technische Infrastruktur zu erweitern. Das Download-Limit von 2,5 Millionen Downloads wurde danach aufgehoben und die Verfügbarkeit der Software bis zum 24. Januar festgelegt. Einen Tag vor der Beendigung wurde der Zeitraum verlängert, somit konnte der Beta-Download bis 10. Februar begonnen und bis 12. Februar 2009 beendet werden.\n\nIn der ersten Beta-Phase wurde nur die \"Ultimate\"-Edition, die alle Funktionen des Betriebssystems enthält, zum Download angeboten. MSDN-Subscriptions-Inhaber und Microsoft-Connect-Mitglieder hatten auch Zugang zu anderen Editionen, beispielsweise \"Home\" und \"Professional\". Die Laufzeit einer (aktivierten) Beta-Version war bis zum 1. August 2009 begrenzt. Nach der Beta 1 folgte keine weitere öffentliche Beta-Version.\n\nEs folgte der Release Candidate, Build-Nummer 7100, welcher am 30. April für TechNet- und MSDN-Abonnenten und am 5. Mai 2009 für die Öffentlichkeit erschien. Die Laufzeit eines (aktivierten) Release Candidate war begrenzt bis 1. März 2010. Nach diesem Termin fuhr das Betriebssystem alle zwei Stunden automatisch herunter. Seit Anfang Juni 2010 verweigert der Release Candidate den Start endgültig.\n\nAm 15. Juli 2009 wurde Windows 7 Home Premium in einer Vorverkaufsaktion zu einem Sonderpreis von 50 Euro in stark limitierter Zahl angeboten, es war in Deutschland zumeist innerhalb weniger Minuten vergriffen.\n\nAm 22. Juli 2009 wurde die Fertigstellung des Betriebssystems bekannt gegeben, das intern bei Microsoft bereits am 13. Juli 2009 kompiliert und am 22. Juli 2009 nach erfolgreichem Abschluss aller Tests bei Microsoft als endgültige \"RTM\"-Ausgabe (\"\") mit der -Nummer 7600.16385 bezeichnet wurde. Großkunden mit Volumenlizenzen erhielten seit Anfang August Zugriff auf die RTM-Version, seit Mitte August war sie auch in verschiedenen Sprachen verfügbar. Inzwischen sind auch verschiedene Lizenzschlüssel für alle Editionen von Windows 7 im Internet vorhanden, mit denen man Windows 7 illegal aktivieren kann; diese bedienen sich der integrierten Option, die Microsofts Partner zur Massenaktivierung von Vorinstallationen nutzen (OEM-Preactivation).\n\nBis zum 22. Oktober 2009, dem internationalen Verkaufsstart, wurden alle Sprachpakete („Language Packs“) für Windows fertiggestellt.\n\nIm Herbst 2014 kündigte Microsoft an, ab 31. Oktober des Jahres keine neuen Windows-7-Lizenzen an OEM-Partner zu liefern. Windows 7 Professional soll von diesem Stichtag allerdings nicht betroffen sein.\n\nSeit dem 13. Januar 2015 wird von Microsoft nur noch der erweiterte Support angeboten. Das heißt, es gibt nur noch Sicherheitsupdates und Updates für kritische Lücken im System. Es werden für Windows 7 keine Erweiterungen, neue Programme oder Verbesserungen mehr herausgegeben. Die Sicherheits-Updates werden am 14. Januar 2020 eingestellt; damit wird die Unterstützung für Windows 7 vollständig eingestellt.\n\nDas Betriebssystem ist in sechs verschiedenen Editionen zu gestaffelten Lizenzpreisen erhältlich:\n\n\nDie Unterschiede liegen im Funktionsumfang, in der Reichweite der Lizenz und bei der Supportdauer. Die genannten Versionen sind auch als Upgrade von Windows XP erhältlich, erfordern aber jeweils eine Neuinstallation.\n\nDiese Edition ist die einzige Version, die nur als 32-Bit-Version verfügbar ist und bei der der Arbeitsspeicher auf maximal 2 GB beschränkt ist. Außerdem gibt es nur die Aero-Basic-Oberflächen und der vorinstallierte Windows Media Player ist in seiner Funktion eingeschränkt. So können im Windows Media Player beispielsweise keine DVDs abgespielt werden. Die Restriktion, dass außer systemgestarteten Prozessen (wie dem Desktop) maximal drei Benutzerprozesse gleichzeitig ausgeführt werden können, wurde im Vergleich zu den Starter-Editionen von Windows XP und Vista aufgehoben. Zudem lässt sich der Desktophintergrund nicht verändern. Die Oberfläche lässt sich zwar auf einem weiteren Monitor darstellen, der Darstellungsbereich lässt sich aber nicht durch einen zweiten Monitor erweitern bzw. vergrößern.\nDiese Version ist ausschließlich (meist vorinstalliert auf Netbooks) als OEM-Lizenz erhältlich.\n\nGrund für diese Einschränkungen ist, wie auch bei den Starter-Editionen von Windows XP und Vista, die Vorbeugung vor großflächiger Raubkopiererei in Entwicklungs- und Schwellenländern.\n\nHome Basic stellt eine in der Ausstattung verminderte Version von Home Premium dar. Es bietet Basisfunktionen und enthält kein Windows Media Center. Dafür ist der Windows Media Player enthalten. Home Basic und alle höheren Versionen unterstützen mehrere Monitore und ein schnelles Wechseln zwischen Benutzern ist möglich, jedoch unterstützt diese Edition maximal 4 GB Arbeitsspeicher in der 32-Bit-Version. In der 64-Bit-Version werden 8 GB unterstützt.\n\nDiese Version ist für den privaten Markt konzipiert, die Limitierung des Arbeitsspeichers beträgt 16 GB. Im Vergleich zu \"Home Basic\" hat sie einige zusätzliche Funktionen wie beispielsweise die Unterstützung von HDTV und das Abspielen und Schreiben von DVDs. Der Windows Media Player und das Windows Media Center sowie einige Spiele sind ab Home Premium enthalten.\n\nDiese Version von Windows 7 zielt vor allem auf den Unternehmensbereich und auf professionelle Anwender wie intensive Spieler mit eingebautem RAM-Speicher über 16 GB oder Benutzer mit weiterreichender Computererfahrung. Sie beinhaltet alle Funktionen der Home Premium Edition und besitzt, wie auch die weiteren Editionen Ultimate und Enterprise, eine Limitierung des Arbeitsspeichers von 192 GB. Sie unterstützt Windows Server Domains. Der XP-Modus erlaubt die Ausführung von Programmen, die unter Windows 7 sonst nicht funktionieren würden. Bei der Professional-Version müssen die Spiele wie Minesweeper, Solitär oder FreeCell erst in den Windows-Funktionen aktiviert werden. Der Spiele-Explorer hingegen ist standardmäßig aktiviert, da er nur ein spezieller Ordner im Windows-Explorer ist. Microsoft bietet für die Editionen Professional und Enterprise nach Ablauf der Mainstream-Support-Phase eine Extended-Support-Phase an.\n\nWindows 7 Ultimate enthält die Funktionen aller anderen Versionen und richtet sich an Kleinunternehmer, die ihren PC privat und geschäftlich nutzen, sowie an Privatanwender, die ihren Rechner sowohl zu Hause als auch im Unternehmensnetzwerk betreiben. Ultimate bietet zusätzlich unter anderem die Festplattenverschlüsselung BitLocker und das Starten von virtuellen Festplatten im VHD-Format. Auch ermöglicht es dem Anwender, jederzeit die Systemsprache zu ändern.\n\nDiese Version ist im Grunde ein Windows 7 Ultimate, das unter Volumenlizenz vertrieben wird. Bei der Enterprise-Version sind jedoch, wie bei der Professional-Version, Spiele wie Minesweeper, Solitär oder FreeCell standardmäßig nicht installiert.\n\nIn den N-Editionen von Windows 7 wurde der Windows Media Player nach der Vorgabe der Europäischen Kommission entfernt. Dieser lässt sich jedoch durch ein \"Media Feature Pack\" nachinstallieren.\n\nMit Windows 7 hat Microsoft die Benutzeroberfläche des Betriebssystems und einiger Anwendungen zur Verbesserung der Benutzerfreundlichkeit überarbeitet. Verbessert wurden ebenfalls die Systemsicherheit und die Unterstützung alternativer Eingabemethoden (beispielsweise mit Tablet-PCs). Verglichen mit Windows Vista fühlt sich Windows 7 schneller an, obwohl es objektiv zwar oft, aber nicht immer, schneller arbeitet.\n\nOptische Änderungen betreffen unter anderem die Gestaltung in Geometrien und Topologien der Taskleiste und des Desktop. In der Standardeinstellung ist die Taskleiste höher und größer als bei früheren Windows-Versionen und zeigt nicht nur offene Fenster an, sondern kann auch benutzt werden, um Anwendungen darauf abzulegen (ähnlich dem von Mac OS X bekannten Dock). Die Funktion der bisherigen Schnellstartleiste wird somit in die Taskleiste integriert (intern als „Superbar“ bezeichnet). Die Anzeige der Fenster in der Taskleiste ist schmaler geworden, da nur noch das Programmsymbol, nicht jedoch der Name bzw. Fenstertitel angezeigt wird. Außerdem werden mehrere Fenster desselben Programms als ein Icon zusammengefasst, dessen Schaltflächenrand dann mehrfach angezeigt wird, was eine Stapelung der Icons imitieren soll. Die Symbole lassen sich durch Klicken und Ziehen umordnen. Diese Standardeinstellungen können jedoch so verändert werden, dass auch das frühere Konzept mit einer beschrifteten Schaltfläche pro Fenster verfügbar bleibt.\nWird der Mauszeiger über ein Programmsymbol einer laufenden Applikation in der Taskleiste gezogen, so wird dazu eine Miniaturansicht des Fensters angezeigt. Zusätzlich können (wie beispielsweise beim Internet Explorer 8) auch alle geöffneten Registerkarten (Tabs) als einzelne Vorschau angezeigt werden. Diese Vorschau kann kleinere Funktionen (zum Beispiel „Zurück“, „Start/Pause“ und „Weiter“ beim Windows Media Player 12 und beim VLC media player) beinhalten. Sind von einer Anwendung mehrere Fenster geöffnet, so werden beim Zeigen auf das Programmsymbol alle Fenster nebeneinander als Vorschau gezeigt, dieses Merkmal muss vom jeweiligen Programm unterstützt werden. Die Vorschaufunktion ist als Teil von Aero in allen Windows-7-Versionen außer in der Starter-Edition enthalten und ist von anderen Desktop-Umgebungen bekannt.\n\nNeu in Windows 7 ist eine Funktion namens „Aero Snap“, die das schnelle Anordnen von Fenstern erlaubt, indem man sie an verschiedene Bildschirmränder zieht. Dabei können die Fenster jeweils rechts bzw. links halbseitig platziert werden (rechter und linker Bildschirmrand), oder aber maximiert werden (oberer Bildschirmrand). Das Prinzip wurde mittlerweile von mehreren Programmen aufgegriffen, welche die Funktion auch für die älteren Windows-Betriebssysteme 2000, XP und Vista verfügbar machen oder die Funktionalität sogar erweitern.\n\nDer Windows-Explorer wurde um neue virtuelle Ordner namens \"Bibliotheken\" ergänzt, die Mediendateien aus beliebigen Ordnern des Dateisystems und von per Netzwerk verbundenen Computern als virtuelle Sammlungen zusammenfassen. So gibt es beispielsweise die Bibliotheken \"Musik\" und \"Bilder\", die Audio- beziehungsweise Bilddateien von der ganzen Festplatte oder auch vom Heimnetzwerk beinhalten. Damit die Aufnahme eines Netzwerkspeichers in eine Bibliothek gelingt, muss sichergestellt sein, dass der Speicher von der Windows Search indexiert wird.\n\nZudem kann die Explorer-Suche durch eigene Datenquellen, wie Webservices und Datenbanken, erweitert werden (sogenanntes \"federated search\"). Diese können genauso wie Dateien Vorschauen und Miniaturansichten besitzen.\n\nDie sogenannten Gadgets (von Microsoft \"Minianwendungen\" genannt) konnten bei der Vorgängerversion noch in einer Sidebar platziert werden, mit der sich die Gadgets leichter an den Rand des Desktops andocken ließen. Diese Sidebar wurde entfernt.\nAufgrund schwerwiegender Sicherheitslücken empfiehlt Microsoft seit 2012 aber, die Gadgets zu deaktivieren.\n\nEs wird außerdem das Brennen von ISO-Dateien standardmäßig unterstützt.\n\nDas \"Sicherheitscenter\" von Windows 7 wurde gegenüber dem Vorgänger umstrukturiert und erneuert. Das in \"Wartungscenter\" umbenannte Programm kann den Status des Virenscanners und der Firewall überwachen und Systemsicherungen neu anlegen. Ab Windows Server 2008 R2 und Windows 7 unterstützt Windows standardmäßig eine biometrische Authentisierung mit Fingerabdrücken. Diese kann für den Zugang zum Betriebssystem oder zur Anmeldung, oder zur Rechteerhöhung für die Benutzerkontensteuerung genutzt werden.\n\nDie Benutzerkontensteuerung (UAC), die beim Vorgänger wegen ihrer vielen Nachfragen vor Änderungen am System kritisiert wurde, ist in Windows 7 stufenweise einstellbar und standardmäßig auf ein niedrigeres Niveau gesetzt. Wie bei Windows Vista arbeitet der Anwender nach der Installation des Betriebssystems standardmäßig mit einem eingeschränkten Benutzerkonto und bekommt lediglich für Administrationsaufgaben vorübergehend höhere Rechte. In der Standardeinstellung arbeitet die UAC mit einer Whitelist von Systemprogrammen, die automatisch mit höheren Rechten versehen werden, wenn sie ausgeführt werden. Da Windows an der digitalen Signatur erkennen kann, ob es sich tatsächlich um eine Original-Datei handelt, die nicht durch Malware verändert ist, wurde hier ein Kompromiss beschritten. Allerdings kann sich so Schadware durch DLL-Injection bei Systemprogrammen Administratorrechte erschleichen, ohne eine UAC-Abfrage auszulösen. Nur die höchste Stufe der Benutzerkontensteuerung („Always notify“) entspricht der Standardeinstellung von Windows Vista, da hier die Whitelist deaktiviert ist. Alternativ können getrennte Konten für Administrator- und Standardnutzer angelegt werden.\n\nDie Versionen Windows 7 Enterprise und Ultimate enthalten das Programm \"AppLocker\", dessen Verwendung vom Bundesamt für Sicherheit in der Informationstechnik (BSI) für Arbeitsplatz-PCs angeraten wird. Mit diesem Programm ist es möglich, die Ausführung aller Programme zu verbieten, wobei feinkörnigere Rechte und Ausnahmen (digitales Zertifikat, Pfad, Dateihash, Herausgebername, Produktname, Dateiname, Dateiversion) festgelegt werden können.\n\nWindows 7 enthält mehr vorinstallierte Codecs als alle früheren Windows-Versionen; unter anderem werden H.264, MPEG-2, MPEG-4 (zum Beispiel DivX und Xvid) oder AAC nun ohne Fremdtreiber unterstützt. Selbiges gilt für die Containerformate MOV und MP4. Somit ist für viele Formate eine manuelle Nachinstallation eines entsprechenden Codecs nicht mehr erforderlich. Neu ist auch die Unterstützung von Farbprofilen mit Farbtiefen von 30 und 48 Bit.\n\nWindows 7 wird mit dem Windows Media Player in Version 12.0 ausgeliefert. Dieser besitzt eine überarbeitete Oberfläche, bei der die Bibliothek und das Wiedergabefenster getrennt sind.\n\nDas Windows Media Center wurde überarbeitet.\n\nWindows 7 unterstützt Multi-Touch. So kann etwa Paint mit mehreren Fingern bedient werden.\n\nEine neue Funktionalität für Geräte sind die \"device stages\": Zum Gerät passend wird ein Fenster angezeigt, das häufige Aktionen für das Gerät (bei einem Mobiltelefon beispielsweise Organisation von Kontakten und Synchronisierung von Mediendateien) an einem zentralen Ort anbietet.\n\nDie beiden Windows-Bestandteile Paint und WordPad wurden überarbeitet. Sie wurden mit einer Ribbon-Oberfläche wie in Office ausgestattet. Ferner kann WordPad jetzt Dokumente in den Formaten DOCX und ODF öffnen und speichern, dafür fällt das DOC-Format weg. Das Bildbearbeitungsprogramm Paint, welches in Windows Vista noch fast den gleichen Aufbau wie der in Windows XP enthielt, wurde erweitert und kann mehr Zwischenschritte zwischenspeichern, um fehlerhafte Änderungen rückgängig zu machen, und es sind einfache Sticker wie Pfeile, geometrische Formen oder Sprechblasen implementiert worden.\n\nDer in Windows integrierte Taschenrechner wurde optisch überarbeitet und unterstützt jetzt unter anderem Maßeinheiten und finanzmathematische Berechnungen.\n\nDas in Windows XP eingeführte Programm \"Windows Bild- und Faxanzeige\" wurde besonders mit Windows Vista verbessert und in \"Windows-Fotogalerie\" umbenannt. In Windows 7 wurde es erneut optisch überarbeitet und erhielt seinen dritten Programmnamen. Die meisten Änderungen liegen in der Optik. So wurden zum Beispiel die Menüs in einer leicht geänderten Reihenfolge geordnet. Außerdem wurden in den Menüs die Icons entfernt. Die Windows-Fotoanzeige wird – so wie in Windows XP – wieder über DLL-Dateien geöffnet und nicht – wie in Windows Vista – über eine Exe-Datei.\n\nMit Windows 7 wurde DirectX 11 als neue Version der Programmierschnittstelle DirectX veröffentlicht. DirectX 11 umfasst zwar den Funktionsumfang der älteren Versionen, ist jedoch selbst nicht vollständig abwärtskompatibel zu bereits zum Beispiel auf DirectX 9 optimierten Programmen. DirectX 9 kann für derartige Programme neben DirectX 11 installiert werden.\n\nNeu ist unter anderem das Fehleraufzeichnungsprogramm \"psr.exe (Problem Steps Recorder)\". Es protokolliert nach seinem Start alle Mausklicks und weitere, für Programmierer und Supportmitarbeiter relevante Informationen und speichert diese als MHT-Datei. So soll es laut Microsoft auf einfache Art möglich sein, detaillierte Problemberichte zu erstellen.\n\nWindows PowerShell ist in Windows 7 vorinstalliert. Dieses Merkmal enthält eine Entwicklungsumgebung für Kommandozeilen-Skripte. Damit bietet sie eine Alternative zu cmd.exe und ähnelt UNIX-Shells wie beispielsweise der Bash.\n\nEinige Programme und Features, die Bestandteil der Vorgängerversion waren, sind in Windows 7 nicht mehr vorhanden oder wurden ausgelagert.\n\nEntfernt wurden das klassische Startmenü, einige Funktionen der Taskleiste, Windows-Explorer-Features, Windows-Media-Player-Funktionen, einige Windows-Ultimate-Extras und das Spiel InkBall. Vier bekannte Anwendungen, wie die Windows-Fotogalerie, Windows Movie Maker, Windows-Kalender und Windows Mail, wurden in Windows 7 als Windows Live Essentials in ein separates Paket ausgelagert, das auf der Microsoft-Website kostenlos erhältlich ist.\n\nWindows 7 benötigt tendenziell etwas weniger Ressourcen als Windows Vista, dennoch sind die offiziell empfohlenen Mindestanforderungen etwas höher. Die Grafikkarten-Voraussetzungen hängen von den drei Grafikmodi (Visual-Designs) und der Auflösung ab. Dabei werden im Modus „Classic“ keine weiteren Anforderungen gestellt, in den Aero-Modi müssen jedoch noch weitere Voraussetzungen erfüllt werden.\n\nWindows 7 ist auf Netbooks besser nutzbar als Vista, wenn diese mindestens über einen 1-GHz-Prozessor sowie 1 GB Arbeitsspeicher verfügen. Es ist jedoch langsamer als das acht Jahre ältere Windows XP.\n\nWindows 7 soll laut Microsoft zu fast jeder Hard- und Software, die unter Vista lauffähig war, kompatibel sein. Im Vergleich zu früheren Windows-Versionen gibt es nicht mehr „zwingende“ und höhere „empfohlene“ Systemanforderungen, sondern nur noch einen Wert. Dieser entspricht den „empfohlenen“ Anforderungen von Vista. Microsoft stellt eine kostenlose Anwendung zur Verfügung, die Programme und Geräte auf Kompatibilität überprüft und auf notwendige Aktualisierungen hinweist. Im Februar 2010 veröffentlichte Microsoft zusätzlich eine Aktualisierung, die die Kompatibilität zu zahlreichen meist älteren Programmen verbessert.\n\nWindows 7 Professional, Enterprise und Ultimate enthalten einen sogenannten XP-Modus. Dieser ist eine virtuelle Maschine mit einem speziell darauf abgestimmten Windows XP Professional. Sie wird mit Windows Virtual PC betrieben, einer für Windows 7 weiterentwickelten Version von Microsoft Virtual PC. Der XP-Modus wurde für Programme entwickelt, die selbst im Kompatibilitätsmodus nicht funktionieren. Die Kommunikation mit dem Hauptrechner wurde im Vergleich zu Microsoft Virtual PC wesentlich vereinfacht. So stehen standardmäßig die Laufwerke des Hauptrechners als Netzlaufwerke zur Verfügung. Neue Laufwerke, die an den Hauptrechner angeschlossen werden, werden im XP-Modus automatisch erkannt und auch die Zwischenablage kann von Windows 7 und dem XP-Modus gleichzeitig verwendet werden. Ebenso werden USB-Geräte von der virtuellen Maschine erkannt. So lässt sich ältere USB-Hardware, für die es keine neuen Treiber gibt, innerhalb der virtuellen Maschine weiterhin nutzen. Auf 3D-Beschleunigung muss innerhalb der virtuellen Maschine jedoch verzichtet werden. Der Windows-XP-Modus ist somit für 3D-Spiele oder 3D-CAD nicht geeignet. Um den XP-Modus zu nutzen, wurde bis zu einer Aktualisierung im März 2010 ein Hauptprozessor mit AMD Virtualization oder Intel VT benötigt.\n\nErstmals erlaubte Microsoft Besitzern bestimmter Einzelplatzlizenzen, alternativ nicht nur den direkten Vorgänger der neuen Betriebssystem-Generation, sondern wahlweise den Vorvorgänger einzusetzen. Diese Downgrade-Option entfiel mit der Bereitstellung des ersten Service Packs für Windows 7.\n\nBereits vor der offiziellen Markteinführung am 22. Oktober 2009 war Windows 7 ein überwiegend positives Medienecho beschieden. Microsoft erreichte mit Windows 7 bis zum offiziellen Verkaufsstart einen Marktanteil von zirka 1,8 Prozent, fünf Wochen später hatte Windows 7 einen Anteil von 5 Prozent. Drei Monate nach der Veröffentlichung lag die Verbreitung von Windows 7 in Deutschland bei mehr als 20 Prozent, international bei 10 Prozent, was bereits mehr ist, als der Vorgänger Windows Vista jemals erreicht hatte. Der weltweite Marktanteil von Windows 7 liegt bei 38,5 Prozent (Stand Februar 2019) und damit sehr deutlich über dem des Nachfolgers Windows 8 mit nur noch einem Prozent Marktanteil sowie ebenfalls deutlich über dem Marktanteil von Windows 8.1 mit 4,9 Prozent.\n\nIm ersten Verkaufsquartal konnte Microsoft über 60 Millionen Lizenzen von Windows 7 absetzen, das damit das bislang am schnellsten verkaufte Betriebssystem ist und so den Unternehmensgewinn im Vergleich zum Vorjahr um 60 Prozent gesteigert hat. Bis Anfang März 2010 wurden über 90 Millionen Lizenzen verkauft. Laut Microsoft wurde Windows 7 in den ersten 365 Verkaufstagen rund 240 Millionen Mal abgesetzt. Bis 26. Oktober 2012, dem Tag der Markteinführung des Nachfolgers, wurde Windows 7 über 670 Millionen Mal verkauft.\n\nUrsprünglich sollte der Support für Windows 7 planmäßig bis Anfang 2015 bis einschließlich zur Edition \"Home Premium\" sowie \"Ultimate\" (sog. \"Mainstream-Phase\") und bis Anfang 2020 für die Editionen \"Professional\" und \"Enterprise\" (sog. \"Extended-Phase\") von Microsoft bereitgestellt werden. Damit wären die an Privatkunden gerichteten Editionen nur geringfügig länger unterstützt worden als jene des Vorvorgängers Windows XP, dessen Supportende deutlich aufgeschoben wurde. Am 20. Februar 2012 gab Microsoft bekannt, dass der \"Extended Support\" mit Sicherheits-Updates am 14. Januar 2020 enden wird.\n\nDas Service Pack 1 (SP1) wurde am 16. Februar 2011 von Microsoft über seine Entwicklerplattformen MSDN und TechNet für deren Mitglieder zum Download bereitgestellt. Das Service Pack hat eine Größe von bis zu 538 MB (32-Bit) bzw. 903 MB (64-Bit) und beinhaltet hauptsächlich die bis zu seiner Veröffentlichung publizierten Patches, aber auch mehrere kleine Stabilisierungen und Optimierungen. Das SP1 meldet sich mit der Build-Nummer 7601.\n\nDas SP1 wurde für alle Anwender am 22. Februar 2011 über Windows Update zur Verfügung gestellt. Der Download der SP1-Datei für die manuelle Installation ist direkt über die Microsoft-Website möglich.\n\nSeit dem 19. März 2013 wird das Service Pack automatisch und ohne Nachfrage über Windows Update verteilt. Ausgenommen davon sind Computer, die per System Center Configuration Manager (SCCM) oder WSUS-Server verwaltet werden.\n\n"}
{"id": "2235358", "url": "https://de.wikipedia.org/wiki?curid=2235358", "title": "Libsigc++", "text": "Libsigc++\n\nlibsigc++ ist eine C++-Programmbibliothek. Die Bibliothek stellt einen Signal-Slot-Mechanismus bereit, eine typsichere Form von Rückruffunktionen. Bereitgestellt wird sie unter der freien Lizenz LGPL.\n\nDie Implementierung von Rückruffunktionen ist insbesondere bei Bibliotheken für grafische Benutzeroberflächen von zentraler Bedeutung. Der Grundsatz der \"starken Typsicherheit\" in der Sprache C++ macht hierfür besondere Konzepte notwendig. Die \"libsigc++\" realisiert einen Signal-Slot-Mechanismus mit Hilfe von C++-Templates und Funktoren.\n\nDie erste Version von libsigc++ wurde für die gtkmm-Bibliothek entwickelt. Sie stellt ein C++-Interface für GTK+ und Gnome zur Verfügung, das beispielsweise von Inkscape benutzt wird. Jedoch verwenden auch einige andere Projekte, unabhängig von gtkmm, libsigc++. Die \"libsigc++\" ist das Vorbild für den Signal-Slot-Mechanismus der Bibliothek Boost (\"Boost.Signals\").\n\n"}
{"id": "2235744", "url": "https://de.wikipedia.org/wiki?curid=2235744", "title": "Gtkmm", "text": "Gtkmm\n\ngtkmm ist die C++-Schnittstelle für das freie GUI-Toolkit GTK+. Die Bezeichnung \"gtkmm\" steht für \"gtk-- (gtk minus minus),\" den ursprünglichen Namen des Projektes.\n\nDie \"gtkmm\"-Bibliothek steht unter der freien Lizenz LGPL und ist dadurch eine kostenlose Lösung auch für grafische Closed-Source-Programme unter Linux und Unix.\n\nDie Bibliothek kapselt unter anderem das GObject-System in eine funktionsgleiche C++-Klassenhierarchie. In der C++-Variante der GLib, \"glibmm,\" werden die Funktionen und Strukturen weitgehend durch Äquivalente aus der C++-Standardbibliothek ersetzt.\n\nTypsichere Rückruffunktionen (Signal-Slot-Konzept) realisiert \"gtkmm\" über die Bibliothek \"libsigc++.\"\n\nDas folgende Beispiel erzeugt ein Fenster mit einem Beschriftungsfeld (\"Label\") und einer Schaltfläche (\"Button\"). Letzteres wird mithilfe der libsigc++ mit der \"quit\"-Funktion verbunden, so dass das Programm bei einem Klick auf den Button beendet wird. Die beiden Widgets werden anschließend in einem Gtk+-typischen Container, einer vertikalen Box, untergebracht. Diese Box wird im Fenster schließlich angezeigt.\nusing namespace Gtk;\n\nint main(int argc, char *argv[]) {\n\nBenutzeroberflächen können mit \"gtkmm\" entweder explizit programmiert oder, wie bereits Gtk+-Oberflächen, mit Hilfe des Programms Glade erstellt werden.\n\nIn \"gtkmm\" geschrieben Programme laufen auf allen Plattformen, auf denen auch Gtk+ läuft (unter anderem macOS und Windows), wobei das Toolkit nicht primär zur Cross-Platform-Entwicklung gedacht ist, sondern im Bereich der Unix-Derivate (wie Linux) beheimatet ist.\n\nAktuell wird gtkmm 4 entwickelt basierend auf GTK+ 4.\n\nEine populäre Anwendung, die gtkmm benutzt, ist Inkscape.\n\nDer Funktionsumfang der \"gtkmm\"-Bibliothek ist in etwa vergleichbar mit dem der etwas bekannteren Bibliothek Qt. Anders als Qt enthält sie allerdings keine Funktionen, die über die GUI-Programmierung hinausgehen.\n\nVergleichbare in C++ geschrieben Grafikbibliotheken sind ferner, mit ähnlichem Funktionsumfang, wxWidgets. FLTK ist im Umfang erheblich geringer.\n\n\n"}
{"id": "2252656", "url": "https://de.wikipedia.org/wiki?curid=2252656", "title": "Die Ein-Mann-Band", "text": "Die Ein-Mann-Band\n\nDie Ein-Mann-Band (OT: \"One Man Band\") ist ein vierminütiger Kurzfilm aus dem Jahre 2005, produziert von Pixar. Er ist auf der DVD des Computeranimationsfilms Cars erhältlich. \n\nEin müde dreinschauender Musiker fängt auf einem menschenleeren Platz, auf dem ein Brunnen in der Mitte steht, an, ein Multifunktionsinstrument zu spielen. Während des Spielens schaut er auf den Boden auf eine leere Blechtasse und lässt seinen Blick über den Platz schweifen. Plötzlich kommt ein kleines Mädchen auf den Platz und geht zielstrebig auf den Brunnen zu, ohne den Musiker zu beachten. Als sie eine Goldmünze in den Brunnen werfen will, macht der Musiker mit einem schrillen Musikton auf sich aufmerksam. Der Musiker fängt wieder an zu spielen und das Mädchen geht interessiert auf ihn zu. Während des Spiels schiebt er mit dem linken Fuß die Blechtasse nach vorne. Als das Mädchen nach Ende des Musikspiels zögernd auf die Tasse schaut, deutet er dem Mädchen mit einer Handbewegung an, die Münze dort hineinzulegen. Unmittelbar, bevor das Mädchen dies vorhat, ertönt aus dem Hintergrund Gitarrenmusik. Der Musiker schaut überrascht in die Richtung dieser Musik und auch das Mädchen dreht sich um.\n\nEin Saitenmusiker öffnet eine an einer Staffel hängenden Papierrolle, auf der er geigenspielend abgebildet ist. Dann fängt er auf einem Saiteninstrument an zu spielen und begleitet sich selber auf einer Flöte. Fasziniert von dieser Melodie geht das Mädchen zu ihm herüber. Immer noch spielend, beugt sich der Spieler leicht nach vorne, während aus seinem Hut eine Kopffigur an einer Scherengelenkkonstruktion heraustritt, die ebenfalls einen Hut trägt, welcher sich automatisch vor den Kopf schwenkt und das Mädchen darauf hinweisen soll, seine Münze dort hineinzulegen. Als das Mädchen dies machen will, fängt der erste Musiker wieder an zu spielen, während er auf einer Trommel balanciert. Mit dieser akrobatischen Einlage überschätzt sich dieser aber und fällt zu Boden. Nach einer kurzen Stille schüttelt der Saitenmusiker nur den Kopf und fängt seinerseits wieder an zu spielen. Der erste Musiker rappelt sich auf und legt sich abermals ins Zeug, um die Aufmerksamkeit des Mädchens für sich zu gewinnen. Sichtlich genervt, zieht der Saitenmusiker den Bogen mit einem grässlichen Ton über sein Streichinstrument und lässt ihn zu Boden fallen. Rücklings aus einem Köcher zieht er einen neuen Bogen und fängt ein flottes Musikstück an. Ebenfalls stark verärgert zieht der erste Musiker an einer Art Reißleine und es öffnet sich ein Klappmechanismus, an dessen Ausleger 16 kleine Trompetenspieler ein infernalisches Geräusch loslassen. Der Saitenmusiker zieht alsdann eine Reißleine und flügelähnliche Ausleger treten links und rechts hinter seinem Rücken hervor, an denen 10 automatisch über Seilzüge spielende Geigen in das Musikstück einstimmen. \n\nIn dem nun folgenden „Musikduell“ steigern sich die beiden Kontrahenten so sehr abwechselnd in eine lautere und höhere Tonlage, dass das Mädchen hin- und hergerissen zwischen den beiden ist. Am Ende wird das Mädchen von den Musikern mit dem Rücken an den Brunnen gedrängt und erschrickt beim Finale so sehr, dass es sich, auch wegen der mittlerweile enormen Lautstärke, beide Ohren zuhält und ihm dabei die Goldmünze entgleitet. Diese rollt über einen Gullydeckel, dreht sich nochmal leicht, um dann durch den Gully in die Kanalisation zu fallen. Sechs Augenpaare schauen der Münze durch den Gullydeckel hinterher, bis nur noch ein entferntes Aufschlagen auf der Wasseroberfläche zu hören ist.\n\nDas Mädchen ist kurz davor zu weinen und seine Lippen beben leicht, als seine Traurigkeit in Wut umschlägt, während die beiden Musiker sie mit großen Augen hilflos anschauen. Mit bösem Blick hält sie abwechselnd den Musikern ihre linke, geöffnete Hand hin, um von ihnen Schadenersatz zu bekommen. Diese schauen sich nur gegenseitig völlig betreten an und tasten hastig an ihren Hosentaschen und Jacken, um dem Mädchen mit einer Hand- und Schulterbewegung klarzumachen, dass sie keine Münzen dabei haben. Jetzt noch wütender, deutet das Mädchen mit dem rechten Zeigefinger auf die linke, äußere Geige, die beim Saitenmusiker an den Auslegern hängt. Während der Saitenmusiker völlig entgeistert das Mädchen anschaut, reißt der andere Musiker wortlos diese Geige ab und überreicht sie dem Mädchen. Anschließend gibt er ihr noch den passenden Bogen dazu. Als das Mädchen das Instrument hat, wendet es sich von den Musikern ab und positioniert sich auf dem Platz. Dabei hat sie mit dem Bogen noch die Tasse des ersten Musikers aufgerichtet und vor sich hingestellt.\n\nBei den ersten Versuchen, der Geige Töne zu entlocken, kommt nur ein Kratzen zustande und die Musiker halten sich angewidert die Ohren zu. Das Mädchen stimmt die Geige einmal, zweimal, und schon spielt es wie ein junger Gott auf dem Instrument, so dass die Musiker überrascht aufhorchen. Während ihres Spiel hört man sich Schritte nähern und Sekunden später fällt ein Sack voller Goldmünzen auf die Tasse. Sofort beendet das Mädchen das Spiel, lässt Geige und Bogen fallen und macht sich mit dem Sack auf, den Platz zu verlassen. Als sie auf der Höhe des Brunnens ist, schaut sie gnädig zu den beiden Musikern, greift in den Sack und hält eine Goldmünze in der linken Hand. Die Mienen der Musiker erhellen sich, aber keiner der beiden weiß, wer von ihnen die Goldmünze erhalten wird. Das Mädchen macht eine kurze Handbewegung, und schon sieht man zwei Goldmünzen, die übereinanderlagen. Nun strahlen die Musiker und sie nicken dem Mädchen zu, ihnen die Münzen zu geben. Das Mädchen wedelt mit den Münzen und deutet den Musikern, sich diese bei ihr abzuholen. Als die Musiker auf das Mädchen zulaufen, wirft es mit einer gekonnten Bewegung die Münzen über ihre Schulter in das obere Becken des Brunnens. Entgeistert schauen die Musiker den Münzen nach, wie diese im Becken versinken. Während sie hoffnungslos hinterherschauen, reißt beim Saitenmusiker eine Saite am Instrument. Im Abspann sieht man noch, wie die Musiker während der Dämmerung versuchen, an die Münzen zu kommen, indem der erste Musiker auf einer Trommel balanciert und der Saitenmusiker auf dem Kopf und der großen Trommel des ersten Musikers steht und knapp vor dem oberen Becken des Brunnens die Arme ausstreckt. Als er das Becken gerade berührt, verlieren sie das Gleichgewicht und der Film ist zu Ende.\n\nDer Film wurde von Mark Andrews und Andrew Jimenez gedreht und von Pixar produziert. Er erschien auf der DVD von Cars. In dem Film wird gar nicht gesprochen, im Vordergrund steht die Musik. Der Kurzfilm wurde 2006 für einen Oscar in der Kategorie \"Bester animierter Kurzfilm 2006\" nominiert, verlor aber gegen den Kurzfilm \"„“\".\n"}
{"id": "2257529", "url": "https://de.wikipedia.org/wiki?curid=2257529", "title": "Rotstiftfunktion", "text": "Rotstiftfunktion\n\nDie Rotstiftfunktion, oder auch Redlining-Funktion ( – Korrigieren von Zeichnungen und Dokumenten) genannt, bezeichnet in der elektronischen Bearbeitung von Zeichnungen und elektronischen Dokumenten die Möglichkeit, diese mit Änderungshinweisen und Anmerkungen für den Ersteller zu versehen, ohne die Originaldatei zu verändern. Das ermöglicht die Zusammenarbeit verschiedener an einem Produktionsprozess Beteiligter.\n\nMicrosoft unterstützt mit dem Word Programm Anmerkungen, mit deren Hilfe die Korrektur und Zusammenarbeit verschiedener Autoren an einem Dokument vereinfacht. Dabei ist es möglich verschiedene Versionen eines Absatz zu betrachten und Kommentare hierzu darzustellen.\n\nBei dem Prozess der Erstellung und Pflege von CAD-Zeichnungen werden diese dabei zunächst mit einem CAD-Zeichenprogramm erstellt. Das Lesen und Prüfen der Zeichnungen erfolgt dann mit CAD-Betrachter-Programmen, mit denen keine Änderungen an der ursprünglichen Zeichnung möglich sind. Die Rotstiftfunktion der Betrachter ermöglicht dann durch einfaches intuitives Freihandzeichnen mit der Maus oder durch Texteingabe die Eintragung von Änderungshinweisen und Anmerkungen für die Zeichnungsüberarbeitung.\n\nDas technische Fundament für die Kommentierungstechnik bildet ein leistungsfähiger Viewer, der den Import zahlreicher Dateiformate ermöglicht. Ohne das Originaldokument zu verändern, wird gezeichnet wie auf einer Folie, die über dem Original liegt. Original und Einfügungen können dann in ein neues Dokument gespeichert werden.\n"}
{"id": "2264335", "url": "https://de.wikipedia.org/wiki?curid=2264335", "title": "BeckerCAD", "text": "BeckerCAD\n\nBeckerCAD ist ein CAD-Programm der Firma Data Becker, dessen Funktionsumfang Bereiche von \nMaschinenbau, E-Technik, Architektur, Haustechnik bis Hobby umfasst. Es unterstützt 3D-Zeichnung.\n\nNach der Schließung von Data Becker zum 31. März 2014 wurde das Programm vom Markt+Technik Verlag weitergeführt und ist nun in Form dreier neuer Versionen, BeckerCAD 10 - 2D, Becker CAD 10 3D und Becker CAD 10 3D Pro, erhältlich. \n\n\nBeckerCAD läuft unter Windows 7 / Vista / XP / Windows 2000 / NT. BeckerCAD 10 läuft auch unter Windows 10.\n\n"}
{"id": "2274921", "url": "https://de.wikipedia.org/wiki?curid=2274921", "title": "EPICS", "text": "EPICS\n\nEPICS (für \"Experimental Physics and Industrial Control System\") ist eine Softwareumgebung, um verteilte Kontrollsysteme für Großexperimente wie Teilchenbeschleuniger oder Teleskope zu entwickeln und zu realisieren. EPICS bietet dabei SCADA-Unterstützung. \n\nEPICS verwendet Client-Server- und Publish-Subscribe-Methoden für die Kommunikation zwischen den verschiedenen verwendeten Computern. Eine Sorte von Computern, die Input/Output-Controller (IOC), sammelt dabei in Echtzeit über die angeschlossenen Messinstrumente Experiment- und Kontrolldaten. Über ein spezielles Netzwerkprotokoll namens \"Channel Access\" (CA) werden diese Informationen an eine weitere Rechnersorte, die Clients, weitergegeben. CA unterstützt dabei weiche Echtzeit-Anforderungen, wie sie in wissenschaftlichen Experimenten anfallen.\n\nBei den IOCs handelt es sich entweder um handelsübliche Personalcomputer oder Standard-VME-Prozessoren, die bestimmte Module (etwa GPIB oder RS232) verwalten, die wiederum mit Kontrollsystem-Instrumenten (Oszilloskope, Netzwerkanalysatoren) und -Geräten (Motoren, Thermoelemente, Schalter und so weiter) in Verbindung stehen. \n\nAuf dem IOC läuft eine Datenbank mit \"Records\", die entweder Geräte oder Eigenschaften der zu steuernden Geräte repräsentieren. IOC-Software für harte Echtzeitbedingungen verwendet normalerweise RTEMS oder VxWorks, wenngleich an einer Portierung auf weitere Systeme gearbeitet wird. IOC-Software für weiche Echtzeitbedingungen läuft manchmal auf Linux- oder Windows-Systemen.\n\nWeitere Rechner im Netzwerk können mit den IOC über das Konzept der \"Channels\" kommunizieren. Als Beispiel diene ein Teilchenbeschleuniger mit Ventilen zwischen einzelnen Abschnitten. Zu einem Ventil gäbe es typischerweise mehrere Channels: Einen Ausgabe-Channel, um das Ventil ferngesteuert zu öffnen oder zu schließen; einen Eingabe-Channel, um den Zustand des Ventils abzufragen (z. B. geschlossen, offen, in Bewegung); und vielleicht weitere analoge Eingabe-Channels, die Druck und Temperatur auf jeder Seite des Ventils repräsentieren. \n\nHäufig wird auf den Clients ein GUI-Paket wie \"EDM\" (Editor/Display Manager) oder \"MEDM\" (Motif EDM) eingesetzt. Diese ermöglichen die Erzeugung und Verwendung von Skalen, Zeigern, Textboxen, einfachen Animationen usw. \n\n"}
{"id": "2280697", "url": "https://de.wikipedia.org/wiki?curid=2280697", "title": "Cambridge Z88", "text": "Cambridge Z88\n\nDer Cambridge Z88 ist ein kleines Notebook mit Flüssigkristallbildschirm auf Basis des Zilog Z80-Prozessors und wurde ab April 1987 gebaut.\n\nProduziert wurde er von Cambridge Computer, einem Unternehmen, das Sir Clive Sinclair gründete, nachdem er das Computergeschäft von Sinclair Research 1986 an den Konkurrenten Amstrad verkauft hatte. Aufgrund des Geschäfts mit Amstrad durfte er keine Computer mehr unter seinem eigenen Namen verkaufen. Trotz eines gewissen Erfolgs hauptsächlich in Großbritannien konnte sich der Z88 insgesamt nicht durchsetzen und war Clive Sinclairs letzter Computer.\n\nDer Z88 entstand aus Sir Clive Sinclairs Projekt \"Pandora Portable Computer,\" welches sich mit der Entwicklung des Rechners seit Mitte der 1980er Jahre beschäftigte.\n\nDer Z88 hat noch heute eine Fangemeinde, sodass das Gerät immer noch von Fans in Gebrauch ist. Eine ganze Reihe von Software für das Gerät kann noch gekauft werden, inklusive Spiele und Dienstprogramme. Seit 1998 gibt es eine 1 MiB große Flash-Speicherkarte, die als nichtflüchtiger Datenspeicher Verwendung findet. Der Z88 wurde zum ersten Mal der Öffentlichkeit in der \"Which Computer? Show\" am 17. Februar 1987 vorgestellt.\n\n"}
{"id": "2281016", "url": "https://de.wikipedia.org/wiki?curid=2281016", "title": "Gewichtetes Votieren", "text": "Gewichtetes Votieren\n\nDas gewichtete Voting () ist ein Verfahren, das die Datenintegrität bei replizierten Datenbanken gewährleisten soll. In Systemen, die aus einer Vielzahl von Einheiten bestehen, muss ein Weg gefunden werden, um im fehlerbehafteten Umfeld Daten von ihnen zu lesen und zu schreiben. Dabei soll auch Toleranz für Ausfälle der Einheiten gewährleistet werden, ohne die Konsistenz der Daten zu gefährden.\n\nGefordert wird Robustheit gegen Ausfälle von einzelnen Knoten (Netzwerkelement) und Konsistenz der Daten.\n\nDas Quorum-Consensus-Verfahren kann dabei nicht nur mit dem Ausfall einzelner Knoten umgehen, sondern auch Konsistenz beim Zerfall des Netzwerkes in einzelne unabhängige Partitionen garantieren. Wichtig dabei ist, dass bei der Bildung mehrerer Partitionen des Netzwerkes, die durch Kommunikationsfehler entstehen können, nur eine Partition Änderungen an den Daten vornimmt.\n\nDazu wird mit einem Quorum gearbeitet. Knoten die zu einer Partition gehören dürfen nur operieren, wenn sie das Quorum besitzen. Dieses ist im einfachen Fall die Mehrheit (die Hälfte der Mitglieder + ein Knoten), kann aber auch über eine Gewichtung der einzelnen Mitglieder erreicht werden.\n\nJeder Knoten des Systems erhält so ein Gewicht und besteht ein sogenanntes Lesequorum \"RT\" und ein Schreibquorum \"WT\", das bei einem Zugriff erfüllt werden muss. Zusätzlich wird eine Versionsnummer eingeführt, die beim Schreiben aktualisiert und beim Lesen ebenfalls ausgelesen wird.\n\nFür das Setzen von \"RT\" und \"WT\" muss gelten:\n\nBeim Schreiben eines Datums muss die Summe der Gewichte der beschriebenen Knoten das Schreibequorum erreichen. So wird nur bei Mehrheit aktualisiert und nur eine Partition kann Änderungen vornehmen, die Konsistenz der Datenbank bleibt erhalten. Die Knoten, die an dem Quorum teilnehmen werden aktualisiert, andere Knoten behalten ihren alten Wert.\n\nBeim Lesen muss das Lesequorum erreicht werden, es werden also im Allgemeinen mehrere Knoten gelesen. Dabei können verschiedene Versionen gelesen werden, das Quorum garantiert allerdings, dass mindestens eine aktuelle Version darunter ist. Diese wird verwendet.\n\nDie Wahl von \"RT\" und \"WT\" bietet Flexibilität. Hierdurch lässt sich in einem Datenbanksystem die Geschwindigkeit oder Priorität von Lesen und Schreiben einstellen (kleines \"RT\" für schnelles Lesen, kleines \"WT\" für schnelles Schreiben).\n\nSo kann durch formula_3 mit Gewicht 1 für jeden Knoten und formula_4 das Aktualisieren aller Knoten beim Schreiben und das Lesen nur eines Knotens modelliert werden (ROWA).\n\nAnders als bei anderen Verfahren zur verteilten Replikation ist hier bei dem Ausfall eines Knotens nachträglich keine Wiederherstellung (Recovery) nötig. Der ausgefallene Knoten kommt zurück in den Verbund und enthält möglicherweise veraltete Daten. Durch das Lesequorum ist aber sichergestellt, dass jeweils die aktuelle Version gefunden wird.\n\nGegeben seien 5 Knoten mit je einem Gewicht von 1. Setzt man \"RT\" = 1 und \"WT\" = 5, so bedeutet das, dass für eine Leseoperation nur ein Knoten zustimmen muss. Für einen Schreibzugriff muss man hingegen auf alle Ressourcen schreiben. Dieses System wäre allerdings nicht ausfallsicher.\n\nMan könnte hingegen auch \"WT\" = 4 setzen und \"RT\" = 2; hier wäre Schreiben beim Ausfall eines Knotens noch möglich.\n\nDas Quorum-Consensus-Verfahren generiert eine hohe Last beim Lesen von Daten, da mehrere Knoten gelesen werden müssen, um das Lesequorum zu erreichen.\n\nEbenso sind eine große Menge von Replikationen nötig um den Ausfall weniger Komponenten zu verkraften (z. B. 3 Knoten um den Ausfall eines Knotens zu überstehen).\n\nDurch den \"Missing-Writes-Algorithmus\" kann eine ROWA-Strategie verwendet werden, solange es zu keinen Ausfällen kommt. So wird jeder Knoten bei einer Änderung aktualisiert. Damit kann schnelles Lesen (nur von einem Knoten) erreicht werden. Erst bei einem Ausfall wird auf Quorum Consensus umgestellt um die ausgefallenen Knoten zu kompensieren.\n\n"}
{"id": "2286384", "url": "https://de.wikipedia.org/wiki?curid=2286384", "title": "TMNT – Teenage Mutant Ninja Turtles", "text": "TMNT – Teenage Mutant Ninja Turtles\n\nTMNT – Teenage Mutant Ninja Turtles (Originaltitel: \"TMNT\") ist eine US-amerikanische, komplett computeranimierte Adaption der Comicserie Teenage Mutant Ninja Turtles. Der Film greift auf Geschehnisse aus zwei Reihen zurück, da dieser Film sowohl eine Fortsetzung der Turtles-Realfilme Reihe aus den 90er-Jahren darstellt, als auch auf der neuen Zeichentrickserie der frühen 2000er-Jahre basiert. Dies ist unter anderem daran festzumachen, dass April O’Neal gleich der zweiten Serie Antiquitätenhänderlin ist, in Splinters Zimmer auf seinem Regal jedoch das Zeitreisezepter aus Turtles III zu sehen ist, sowie andere Reliquien aus den Realverfilmungen I – III.\n\nDer Filmstart in Deutschland war am 12. April 2007.\n\nShredder ist tot und die Turtles haben sich in alle Winde verstreut. Michelangelo arbeitet als Clown für Partys, Donatello arbeitet in der Telefonhotline und hilft bei Computerproblemen weiter und Raphael kämpft allein für Recht und Ordnung auf den Straßen von New York City. Leonardo wurde von Splinter in den Urwald geschickt, um zu trainieren und ein noch besserer Anführer zu werden.\n\nNachdem Leonardo nach über einem Jahr später aus seinem Training zurückkehrt, soll er aus der auseinandergefallenen Gruppe wieder ein Team machen. Die Aufgabe erweist sich als alles andere als einfach. Gerade Raphael hat die Zeit ohne seinen großen Bruder nicht wirklich gutgetan. Seine Nächte als heimlicher Rächer und sein Doppelleben haben ihn „rebellisch“ gemacht und er will sich keinem Anführer mehr unterordnen.\n\nParallel zum Training versucht der reiche Industriemagnat Max Winters mit Hilfe von Shredders Nachfolgerin Karai 13 Monster einzufangen, um ein Ritual durchzuführen, das nur alle 3000 Jahre erfolgen kann. Er hat es schon einmal vor 3000 Jahren durchgeführt, was ihm damals Unsterblichkeit gebracht hat, aber auch seine vier treuen Gefährten in Steinfiguren verwandelte. Darüber hinaus wurden die 13 Monster auf die Welt losgelassen. Max Winters hatte die darauf folgenden 3000 Jahre seine Tat bereut und will mit Hilfe seiner Gefolgsleute das Ritual rückgängig machen. Die zu neuem Leben erwachten Steinfiguren haben aber andere Pläne. Sie wollen aus der anderen Dimension noch mehr Monster auf die Welt transferieren, um die Weltherrschaft an sich zu reißen.\n\nNach einem Kampf zwischen dem rebellischen Raphael und Leonardo wird Leonardo von den Steinfiguren gefangen genommen. Die Steinfiguren wollen Leonardo als falsches Monster dem Ritual opfern, da sie das Ritual manipulieren wollen. Meister Splinter sieht sich gezwungen, die Turtles wieder an die Oberfläche zu lassen. Der anschließende Kampf endet damit, dass die Generäle zusammen mit den 13 Monstern – das letzte wurde inzwischen auch gefunden – in einen Dimensionsriss geschleudert werden, der sich daraufhin wieder schließt. Danach stirbt jedoch auch Winters, der mit der Bannung der 13 Monster auch seine Unsterblichkeit verliert.\n\n\n"}
{"id": "2287968", "url": "https://de.wikipedia.org/wiki?curid=2287968", "title": "Security Identifier", "text": "Security Identifier\n\nEin Security Identifier, kurz SID, ist ein eindeutiger Sicherheits-Identifikator, den Microsoft Windows NT automatisch vergibt, um jedes System, jeden Benutzer und jede Gruppe dauerhaft zu identifizieren. \n\nAn die SID sind die in Access Control Lists festgelegten Zugriffsrechte gebunden. Wenn die Namen von Systemen, Benutzern oder Gruppen geändert werden, bleiben deren SID unverändert. Deshalb bleiben ihnen alle Zugriffsrechte erhalten. SID ermöglichen also, die Namensgebung problemlos zu ändern. \n\nWährend der Installation des Betriebssystems erhält das System selbst seinen SID durch einen Zufallszahlengenerator. Dies ist erforderlich, damit eine eindeutige Kennzeichnung im Netzwerk gewährleistet ist. Anschließend werden sogenannte \"well-known SID\" vergeben, die auf jedem System gleich sind. Zum Beispiel für die Gruppe \"Administratoren\". \n\nDer SID eines Benutzers wird automatisch erstellt, wenn dieser angelegt wird. Der SID eines lokal angelegten Benutzers basiert auf dem SID des Systems. Der SID eines in einer Domäne angelegten Benutzers ändert sich, wenn er von einer Domäne in eine andere verschoben wird, da im SID auch die Domäne des Benutzers hinterlegt wird. \n\nBeispiel:\n\nErläuterung:\n\nErlaubte Werte von 'Identifier Authority':\n\nWenn man von einem fertig installierten System ein Speicherabbild der Festplatte erstellt, werden darin die SID mit abgespeichert. Wenn man andere Computer mit diesem Abbild bestückt, haben mehrere Systeme identische SID. Hiervon wurde in der Vergangenheit dringend abgeraten, da andernfalls Probleme auftreten könnten. Microsoft warnt insbesondere davor, dass andernfalls ein Zugriff auf ein Wechselmedium möglich sein kann, der ausdrücklich verwehrt sein soll. Mittlerweile wurde diese Ansicht jedoch von einem Microsoft-Mitarbeiter relativiert.\n\nMicrosoft unterstützt solche Verwendungen von Speicherabbildern nur, wenn das Programm Sysprep angewendet wird. Es bewirkt, dass beim nächsten Systemstart das Setup ohne erneute Installation nochmals durchlaufen wird und u. a. neue SID vergeben werden. \n\nDas von Winternals entwickelte Programm PsGetSid ermöglicht es, die SID lokal oder übers Netzwerk auszulesen. Bis November 2009 wurde mit NewSID auch ein Programm angeboten, mit dem die SID eines Systems auf eine zufällige SID geändert werden konnte. Der Rückzug des Programms wurde damit begründet, doppelt vergebene SIDs für unterschiedliche Computer seien gar nicht so problematisch wie zuvor angenommen und ein Programm wie NewSID somit überflüssig.\n\nDurch Löschen von Benutzern oder Deinstallieren von Systemen verloren gegangene SID können nur mit hohem administrativem Aufwand wiederhergestellt werden, da das Erstellen eines neuen Objekts mit gleichem Namen zu einer anderen SID führt. Jedoch ist das Ändern einer SID per ADSIEdit möglich. Auch unterstützen Domain Controller unter Windows 2008 und höher das Wiederherstellen von AD-Objekten aus einer Shadow Copy, wenn sich das Domain Functional Level auf Windows Server 2008 oder höher befindet.\n\n"}
{"id": "2292425", "url": "https://de.wikipedia.org/wiki?curid=2292425", "title": "IBM PC Convertible", "text": "IBM PC Convertible\n\nDer „IBM PC Convertible“ oder IBM 5140 war ein tragbarer Rechner mit einem integrierten 640 × 200 Pixel LCD Bildschirm. IBM präsentierte ihn 1986 und ersetzte in ihrer Modellpalette den tragbaren 15 kg Rechner „IBM PC Portable“. Er konnte als ein vollwertiger IBM-PC-kompatibler Computer mit Batterien betrieben werden. Im Gegensatz zum sehr teuren Portable hatte er keine Festplatte, aber zwei 720 kB 3.5\" Disketten-Laufwerke. Im 1987 folgenden Toshiba T1000 wurde das MS-DOS 2.11 aus einem 256 kb ROM (Festwertspeicher) geladen.\n\nDer Prozessor des IBM PC Convertible, ein 8088, der von Intel bereits seit 1978 verkauft wurde, wurde in einer stromsparenden CMOS-Variante verwendet, lief mit einer Taktfrequenz von 4,77 MHz. Der Hauptspeicher war 256 kB groß und erweiterbar auf 640 kB. Der Rechner hatte ein Gewicht von 5,8 kg und einen eingebauten Tragegriff.\n\nWesentliche Mitarbeit am Design des Geräts hatte Richard Sapper.\n\n"}
{"id": "2294204", "url": "https://de.wikipedia.org/wiki?curid=2294204", "title": "Dreamlinux", "text": "Dreamlinux\n\nDreamlinux ist eine ursprünglich von Morphix abgeleitete modulare Debian-Linux-Distribution für die Anwendung im Multimedia-Bereich. Sie stellt mit MKDistro ein Werkzeug zur Verfügung, mit dem Anwender eigene Linux-Distributionen erstellen können. Dreamlinux lässt sich als Live-CD brennen oder auf Festplatten und USB-Massenspeichern betreiben. Die Version 1.0 wurde 2006 veröffentlicht.\nDie letzte Version 5.0 wurde im Januar 2012 veröffentlicht, danach wird die Distribution nicht mehr fortgeführt.\n\nDie Bezeichnung \"Dreamlinux\" soll nicht das beste aller Linuxe ankündigen. Vielmehr möchten die Entwickler mit Dreamlinux und MKDistro dazu beitragen, dass Benutzer sich ihr eigenes „Traumlinux“ zusammenstellen, als ISO-Abbild abspeichern und als Distribution anwenden und verteilen können.\n\nMit MKDistro lassen sich Module innerhalb der Morphix, Knoppix und Dreamlinux-Derivate kombinieren: Linux-Kernel, Installationsroutinen, grafische Benutzeroberflächen und andere Open-Source-Bestandteile. Wenn nötig und vertretbar kann auch Software integriert sein, die nicht unter Open-Source-Lizenzen fällt.\n\nMit jeder Version von Dreamlinux präsentieren die Entwickler ihre bevorzugte Kombination der Module, die sie mit MKDistro aus Open-Source-Software zusammengesetzt haben. Während die Morphix Philosophie beibehalten wird, werden Leistungen von Morphix zunehmend durch andere Software übernommen.\n\nDie Dreamlinux Multimedia Edition 2.2 von 2007 besteht im Wesentlichen aus dem Kernel 2.6.18 mit Morphix-Patch. Die Bootroutine kommt noch aus Morphix, die Pakete aus der Debian GNU/Linux „testing“ Version.\n\nDie Dreamlinux Desktop Edition 3.x verwendet eine neue Architektur, in der beim Booten zwischen Xfce und Gnome-Desktop gewählt werden kann. Die Desktops unterliegen danach den gleichen Benutzereinstellungen und greifen auf die gleichen Anwendungen zu.\n\nDer Xfce-Desktop erinnert durch die Integration von Dock und Menüleiste an macOS. Durch den ab Dreamlinux 2.3 aktivierten Beryl- bzw. Compiz-Fenstermanager kann er dreidimensional eingesetzt werden.\n\nDreamlinux vermeidet oder erleichtert einige der beim Installieren und Booten einer Linux-Distribution früher üblichen Probleme. Für manche Systeme stellt der bis Dreamlinux Version 2.2 enthaltene Knoppix X11-Konfigurator mkxf86config die Bildschirmauflösungen allerdings nicht optimal ein. Das Feststellen der richtigen Auflösungen und die Korrektur per Editor in xorg.conf kann Anfänger überfordern. In neueren Versionen ist die Installation reibungsloser und weniger hardwareabhängig. Die Anpassung an eine breite Hardwarebasis bleibt für das kleine Entwicklerteam jedoch schwierig.\n\nFür ATI Radeon und nvidia-Karten, die 3D-fähige Anwendungsprogramme unterstützen, bietet Dreamlinux Multimedia Edition 2.2 während der Installation Treiber an. Widescreen-Monitore werden automatisch erkannt.\n\nMit dem Easy Install System lassen sich Debian-fremde Programme wie z. B. Google Earth, Picasa, Opera, Skype und Audio- und Multimedia-Anwendungen installieren.\n\nSprachen: Deutsch, Englisch, Französisch, Portugiesisch, Spanisch und Japanisch\n\nBen McGrath testete Dreamlinux Version 2.2 und urteilte überwiegend positiv: \"While much of the software works like a dream, not all is perfect. [...] Nevertheless, the distribution itself looks good and functions well. The Mkdistro tool will be useful for users who want complete control of their systems, and the overall ease of installation and use Dreamlinux offers is good enough that the average user can download and install the distribution and jump right in.\"\n\nJ. A. Watson berichtete über Dreamlinux Version 3.5 auf ZDNet. \"I got interested in the new release of Dream Linux (3.5) because it is supposed to make it easy to create your own customised ISO boot image.\" Er schließt den Bericht mit den Worten: \"In conclusion, though, I would say again, I am just amazed at how well, and how easily, Dream Linux installed on this Mini-Note, after all the struggles with the other distributions I've had. More to come.\"\n\ngolem.de und Netzwelt berichteten über die fünfte Beta der Version 4.0 von Dreamlinux.\n\n"}
{"id": "2298331", "url": "https://de.wikipedia.org/wiki?curid=2298331", "title": "Windows Sysinternals", "text": "Windows Sysinternals\n\nWindows Sysinternals ist eine Abteilung der Firma Microsoft, in der System-Werkzeuge für das Betriebssystem Windows entwickelt und als Freeware im Internet angeboten werden.\n\n„Winternals Software LP“, kurz „Winternals“ genannt, war ein im Jahr 1996 von Mark Russinovich und Bryce Cogswell gegründetes Software-Unternehmen. Winternals hatte sich auf die Entwicklung von Diagnose-Software für das Betriebssystem Microsoft Windows spezialisiert. Die entwickelte Software wurde zum Teil kommerziell unter dem Namen „Winternals“ und zum Teil kostenfrei unter dem Namen „Sysinternals“ im Internet als Freeware angeboten.\n\nAm 18. Juli 2006 wurde die Firma Winternals von Microsoft aufgekauft und später als „Windows Sysinternals“ in den Konzern eingegliedert. Die beiden Gründer von Winternals arbeiten seitdem an der Entwicklung von Windows mit.\n\nDie Produkt-Palette umfasst Dateisystem-, Netzwerk-, Sicherheits- sowie Diagnose-Werkzeuge, welche von Microsoft einzeln und als „Sysinternals Suite“ in einer Werkzeug-Sammlung kostenfrei angeboten werden. Häufig verwendete Programme aus dieser Produkt-Palette sind beispielsweise Process Explorer oder AutoRuns.\n\n"}
{"id": "2302340", "url": "https://de.wikipedia.org/wiki?curid=2302340", "title": "Skimming (Betrug)", "text": "Skimming (Betrug)\n\nSkimming (engl. für „Abschöpfen“) ist ein englischer Begriff für einen Man-in-the-Middle-Angriff, der illegal die Daten von Kreditkarten oder Bankkarten zum Kreditkartenbetrug ausspäht. „Beim Skimming werden illegal Kartendaten erlangt, indem Daten von Magnetstreifen ausgelesen und auf gefälschte Karten kopiert werden.“ Mit der gefälschten Karte erfolgt dann eine Abhebung bzw. Bezahlung zulasten des rechtmäßigen Karteninhabers.\n\nEin typisches Angriffsmuster ist das gleichzeitige Ausspähen von Magnetstreifeninhalt der Kredit- oder EC-Karte zusammen mit der PIN an einem Geldautomaten. Die Daten der EC-Karte werden dann typischerweise auf einen leeren Kartenrohling (sog. \"White-Plastic\") aufgebracht, mit dem die Betrüger dann – zusammen mit der PIN – Bargeld an Geldautomaten abheben können (Kontoplünderung). Da die Karte im Besitz des Eigentümers verbleibt, bemerkt der Inhaber des Kontos diesen Angriff in der Regel erst mit Abholung der Kontoauszüge oder wenn die Bank nach Überziehung des Dispositionskredits einschreitet.\n\nBei Geldautomaten sind inzwischen verschiedene Varianten beschrieben worden, denen gemeinsam ist, dass die fortschreitende Miniaturisierung der Lesegeräte die Manipulation von Automaten enorm vereinfacht. Eine Variante ist es, auf den Einschiebeschacht direkt am Geldautomaten ein Lesegerät in Form eines kleinen Kunststoffrahmens aufzubringen. Die Karte wird dann einfach durch das zusätzliche Lesegerät hindurch in den Automaten gezogen und dabei der Inhalt des Magnetstreifens ausgelesen. Alternativ werden auch Vorfälle berichtet, bei denen ein zusätzliches Lesegerät in den Türöffner der Filiale eingebaut wurde (häufig erfordert schon der Zutritt zum Vorraum mit dem Geldautomaten den Einsatz der Karte).\nBeim \"Deep-Insert-Skimming\" werden äußerst dünne „Kartenlese-Wanzen“ direkt in den Kartenschlitz von Bankautomaten eingeführt. Diese Wanzen bestehen aus einem Metallplättchen mit Leseeinheit, Speicherchip und einer sehr dünnen Batteriezelle.\n\nDie Eingabe der PIN wird meist mit einer kleinen Funk-Kamera gefilmt, die oft oberhalb der Tastatur in einer angeklebten Kunststoffleiste versteckt ist (sogenannte „Kameraleiste“). Diese ist in der Regel selbst für argwöhnische Benutzer kaum erkennbar. Es kommen aber auch ganze Tastenfeld-Attrappen (Skimmer) zum Einsatz, die über das eigentliche Tastenfeld geklebt werden und einfach die Tastendrücke aufzeichnen. Auch mit Wärmebildkameras kann die PIN noch nach der Eingabe von der Tastatur abgelesen werden.\n\nDiese Angriffsmuster sind deshalb möglich, weil der Zugang zu den Kartendaten vom Lesegerät gesteuert wird, nicht wie bei moderneren Smartcards von dem Chip auf der Karte selbst. Die Kartendaten sind auf dem Magnetstreifen ungeschützt und können von jedermann ausgelesen werden. Das ist bei Smartcards anders: Hier kann zum einen nur ein Teil des Inhalts überhaupt ausgelesen werden, zum anderen kontrolliert die Karte selbst die korrekte Eingabe der PIN und sperrt sich selbst nach einer gewissen Zahl von Fehlversuchen. Da viele Geldautomaten im Ausland (noch) nicht für Smartcards ausgelegt sind (zum Beispiel in Nord-, Mittel- und Südamerika), enthalten viele der ausgegebenen Kreditkarten oder Bankkarten weiterhin – auch wenn sie mit einem Chip ausgestattet sind – aus Kompatibilitätsgründen einen Magnetstreifen, der das Skimming begünstigt.\n\nBei Kreditkarten verfahren die Täter ähnlich. Hier wird die Karte des Opfers z. B. beim Bezahlen in einem Restaurant neben dem regulären Kartenlesegerät noch durch ein zweites gezogen.\n\nSofern das Opfer nicht grob fahrlässig gehandelt hat, ersetzt die jeweilige Bank den entstandenen Schaden. Bei einem Verdacht auf Diebstahl der Daten kann eine Karte bei der Zentralen Anlaufstelle zur Sperrung elektronischer Berechtigungen (Notrufnummer 116116) gesperrt werden.\n\nMit \"Antiskimming\"-Modulen kann durch den kombinierten Einsatz mehrerer Abwehrmechanismen das Skimming beinahe unmöglich gemacht werden.\n\n\n"}
