{"id": "5337657", "url": "https://de.wikipedia.org/wiki?curid=5337657", "title": "Please Say Something", "text": "Please Say Something\n\nPlease Say Something () ist ein deutscher computeranimierter Kurzfilm von David O’Reilly aus dem Jahr 2009. In Deutschland feierte der Film am 6. Februar 2009 bei den Internationalen Filmfestspielen in Berlin Premiere.\n\nIn 23 Episoden à 25 Sekunden wird die komplizierte Liebesbeziehung eines Paares erzählt – bestehend aus einer Katze und einer Maus.\n\nInternationale Filmfestspiele Berlin 2009\n\nInternationale Kurzfilmtage Oberhausen 2009\n\nInternationale Kurzfilmtage Winterthur 2009\n\n\n"}
{"id": "5338421", "url": "https://de.wikipedia.org/wiki?curid=5338421", "title": "Pixomondo", "text": "Pixomondo\n\nPixomondo ist ein international tätiges, auf visuelle Effekte spezialisiertes Unternehmen mit Standorten in mehreren Ländern. Gegründet wurde es 2001 von seinem heutigen Geschäftsführer und Executive Producer Thilo Kuther in Pfungstadt bei Darmstadt. Die \"Pixomondo Studios GmbH & Co. KG\" hat derzeit weltweit 13 Standorte.\n\nPixomondo produziert visuelle Effekte für Spielfilme und Fernsehproduktionen wie beispielsweise \"Game of Thrones\", \"2012\", \"Hugo Cabret\", \"Fast & Furious Five\" und \"Hindenburg\".\nAußerdem entwickelt Pixomondo visuelle Medien für Messen und Live Events, Corporate- und Industriefilme, Werbung und Interactive Media sowie Apps. Unternehmen wie Porsche, Mercedes-Benz, Volkswagen, Lufthansa und manroland zählen zu den Kunden von Pixomondo.\n\nDas Unternehmen wurde 2001 von Thilo Kuther zunächst als Designstudio gegründet. Kurz darauf wurde das Leistungsspektrum durch die Erstellung von Motion Graphics für Eventmedien sowie von Animationen für Produktfilme und Commercials ergänzt. Ende 2003 arbeiteten 40 VFX-, CGI und Compositing-Spezialisten am ersten Standort in Pfungstadt bei Darmstadt. 2004 folgten mit den Arbeiten an der Dokumentation \"Atlantropa - Der Traum vom neuen Kontinent\" die ersten digitalen Visualisierungen für das Fernsehen.\n\nIm Jahr 2005 eröffnete das Unternehmen in Ludwigsburg einen Feature-Film Standort. Dort entstanden als erstes Projekt die visuellen Effekte zum Kinofilm \"Der Rote Baron\".\n\n2005 eröffnete PIXOMONDO ein Studio in London. Im Jahr 2007 wurde der Standort in Frankfurt eröffnet und im Juli 2008 in Los Angeles. Im selben Jahr wurde das Unternehmen von Roland Emmerich mit der Produktion von 100 Composites kompletter CG-Environments für den Film 2012 beauftragt.\n\n2009 folgte auf dem asiatischen Kontinent PIXOMONDO Shanghai und Peking. 2010 wurde der Standort London ausgebaut, die Standorte München und Hamburg kamen hinzu. 2011 kam der Standort Toronto hinzu. Bei Pixomondo sind Stand April 2012 etwa 670 Mitarbeiter beschäftigt.\n\nFür die visuellen Effekte in Martin Scorseses \"Hugo Cabret\" erhielten die Pixomondo Mitarbeiter Ben Grossmann (VFX-Supervisor) und Alex Henning (DFX-Supervisor) 2012 den Oscar. Mit 854 Einstellungen, die eine Laufzeit von 62 Minuten im finalen Film haben, erstellte Pixomondo rund 98 Prozent aller visuellen Effekte.\n\nIm Februar 2013 wurde bekanntgegeben, dass die Standorte London und Detroit aus strukturellen Gründen geschlossen werden. Im Mai 2013 musste das Unternehmen aufgrund andauernder Restrukturierungsprozesse und der VFX-Krise den Standort Berlin schließen. Darüber hinaus machte das Unternehmen 2013 Schlagzeilen, als es zahlreiche Honorare von freien Mitarbeitern über mehrere Monate nicht bezahlte und sich einigen Klagen stellen musste.\n\nIm Bereich „Live Media“ betreut das Unternehmen mehrere Automobilmarken bei den wichtigsten Branchenmessen, wie z. B. der Internationalen Automobil-Ausstellung, dem Genfer Auto-Salon und der North American International Auto Show.\n\nDas Unternehmen entwickelt zudem interaktive Medienanwendungen für Touchscreens, Smartphones, Tabletcomputer und Microsites.\n\n\n\n\nDas internationale Studionetzwerk von Pixomondo umfasst Standorte in Europa (Deutschland), Amerika (USA und Kanada) und Asien (China). Alle Standorte sind durch die IT-Pipeline „ITworx 24/7“ vernetzt.\n\n\n\n\n\n"}
{"id": "5338491", "url": "https://de.wikipedia.org/wiki?curid=5338491", "title": "Für immer Shrek", "text": "Für immer Shrek\n\nFür immer Shrek ist ein US-amerikanischer Animationsfilm. Als vierter Teil der \"Shrek\"-Filmreihe nach \"Shrek – Der tollkühne Held\" (2001), \"Shrek 2 – Der tollkühne Held kehrt zurück\" (2004) und \"Shrek der Dritte\" (2007) kam er in den USA am 21. Mai 2010 in die Kinos. Die deutschsprachige Premiere war am 30. Juni 2010.\n\nDie Drehbuchidee \"Shrek Goes Fourth\" stammt von Tim Sullivan, adaptiert wurde diese Geschichte von Darren Lemke und Josh Klausner. Mike Mitchell führte Regie. Am 23. Februar 2009 wurde die Handlung vorgestellt. Wie bei den ersten drei Filmen der \"Shrek\"-Reihe bedient sich auch dieser Film vieler Märchenthemen. Der Film wurde als erster Film der \"Shrek\"-Filmreihe auch in einer 3D-Version veröffentlicht.\n\nNach seinen zahlreichen Abenteuern ist Shrek zu einem gesetzten Familienvater geworden. Anstatt weiterhin Dorfbewohner zu verschrecken, ist Shrek allseits beliebt und verteilt nun Autogramme auf Mistgabeln. Doch aufgrund der Monotonie seines Lebens fühlt er sich unerfüllt und bekommt beim ersten Geburtstag seiner Kinder einen Wutanfall, woraufhin er die Feier im Streit mit seiner Frau Fiona verlässt. Getrieben von der Sehnsucht, sich wieder „wie ein richtiger Oger“ zu fühlen, lässt er sich dazu überreden, einen Pakt mit dem wortgewandten Rumpelstilzchen zu schließen. Für einen Tag als richtiger Oger muss Shrek dem Rumpelstilzchen einen Tag seines eigenen Lebens geben. Während Shrek sich nichts Böses ahnend darauf einlässt und sich einen entspannenden Tag wie in alten Zeiten erhofft, hat sich das schlitzohrige Rumpelstilzchen jedoch genau den Tag ausgesucht, an dem Shrek geboren wurde – mit dem Ergebnis, dass Shrek, nachdem er nie geboren wurde, nie existiert hat. Hierdurch entsteht ein Zeitparadoxon – Shrek findet sich in einer alternativen Parallelwelt des Königreichs \"Weit Weit Weg\" wieder. Dort herrscht Rumpelstilzchen als tyrannischer Diktator gestützt auf eine Armee von Hexen. Artie wurde als König abgesetzt und ist verschwunden. Die Oger werden beinahe bis zum Aussterben gejagt und haben sich im Untergrund organisiert, um eine Revolution zu starten. Der Esel ist ein Intellektueller, der Fuhrwerke ziehen muss, Shrek jedoch noch nie getroffen hat und sich vor ihm fürchtet. Der Lebkuchenmann ist ein Kekse bekämpfender Gladiator. Der gestiefelte Kater ist ein fettes, faules Haustier von Fiona, die sich mittlerweile selbst aus dem Drachenturm befreit hat und eine Widerstandsgruppe der Oger anführt. Tragischerweise kann sie Shrek, den sie ebenfalls vorher nie kennengelernt hat, zunächst nicht ausstehen. In seinem Pakt mit Rumpelstilzchen ist nämlich bestimmt, dass Shrek, wenn er es schafft, bis zum Morgengrauen des nächsten Tages mit Fiona „der wahren Liebe ersten Kuss“ zu teilen, von seinem Schicksal erlöst, Artie wieder zum König und der Pakt mit Rumpelstilzchen ungültig wird. Sollte Shrek das jedoch nicht erreichen, dann wird er, nachdem er nie geboren wurde, verschwinden. Um eine Verbindung zwischen Shrek und Fiona zu verhindern, entsendet Rumpelstilzchen eine Hexenarmee und andere Gefolgsleute, die ihn aufhalten und fangen sollen.\n\nRumpelstilzchen setzt zudem ein Kopfgeld auf Shrek aus. Als Belohnung winkt die Erfüllung eines beliebigen Wunsches. Daraufhin liefert sich Shrek selbst aus, um diesen ausgelobten Wunsch gewährt zu bekommen. Er wünscht sich, dass die gefangenen Oger freigelassen werden, mit dem Hintergedanken, dass auch Fiona dadurch freikommt. Doch wegen des Fluches, der Fiona abwechselnd Mensch und Oger sein lässt, zählt Rumpelstilzchen sie nicht als vollwertigen Oger. Es entwickelt sich im Thronsaal des Schlosses von \"Weit Weit Weg\" ein Kampf zwischen den freigelassenen Ogern und den Hexen von Rumpelstilzchen. Im Laufe des Kampfes wird Rumpelstilzchen von den Ogern gefangen. Doch für Shrek scheint der Sieg über Rumpelstilzchen und die Hexen bereits zu spät zu kommen. Er beginnt sich aufzulösen, da der versprochene „eine Tag als richtiger Oger“ vorbei ist. Fiona hat sich nun allerdings doch in Shrek verliebt und gibt ihm den einen entscheidenden Kuss. In der Folge löst sich die Parallelwelt auf und Shrek findet sich auf der Geburtstagsfeier seiner Kinder wieder, zu dem Zeitpunkt, als er seinen Wutanfall zu bekommen droht. An die Erlebnisse in der Parallelwelt kann er sich noch erinnern und genießt es daher, wieder mit seiner Familie und seinen Freunden beisammen zu sein.\n\n\"Für immer Shrek\" feierte am 21. April 2010 seine Weltpremiere beim Tribeca Film Festival in den USA. Am 16. Mai 2010 wurde er im kalifornischen Universal City gezeigt, bevor er ab dem 21. Mai 2010 in den US-amerikanischen Kinos zu sehen war. Am 30. Juni 2010 lief er in den deutschen und Schweizer Kinos an, einen Tag später in Österreich. Ab dem 25. November 2010 war \"Für immer Shrek\" auf DVD, Blu-ray und Blu-ray 3D erhältlich. Die Free TV-Premiere im deutschsprachigen Raum fand am 27. Oktober 2010 auf ORF eins und Sat 1 statt, der Schweizer Sender SF 2 strahlte den Film bereits am 19. Oktober desselben Jahres aus.\n\nDer letzte Teil der Shrek-Saga war zugleich auch der teuerste mit Produktionskosten von 165 Millionen US-Dollar. Doch trotz der höheren Ticketpreise für 3D-Filme konnte dieser Animationsfilm seine Vorgänger nicht übertrumpfen. In den USA nahm er zwar über 238 Millionen US-Dollar ein, unterbot damit allerdings die Einnahmen aus dem ersten Film, die sich auf knapp 267,7 Millionen US-Dollar beliefen. Insgesamt spielte der vierte Teil weltweit 752,6 Millionen US-Dollar ein, davon umgerechnet rund 25 Millionen US-Dollar in Deutschland, 46,6 Millionen US-Dollar in Frankreich, 51,3 Millionen US-Dollar in Russland und 51,0 Millionen US-Dollar im Vereinigten Königreich. In Deutschland haben etwa 2,5 Millionen Zuschauer den Film in den Kinos gesehen. Das bedeutet, dass auch dieser Teil der Filmreihe erfolgreicher war als sonst ein DreamWorks-Projekt. Die Shrek-Tetralogie hat insgesamt rund 2,9 Milliarden US-Dollar an den Kinokassen eingespielt, davon umgerechnet mehr als 100 Millionen US-Dollar in den deutschen Kinos, und zählt damit zu den erfolgreichsten Filmreihen aller Zeiten.\n\nIn der Liste der weltweit erfolgreichsten Filme aller Zeiten belegt \"Für immer Shrek\" derzeit Platz .\n\nDer vierte Teil ist der erste Film der Filmreihe, in dem Prinz Charming weder zu sehen ist, noch erwähnt wird. Der Rattenfänger von Hameln hingegen tauchte bereits in einer kleinen Nebenrolle in \"Shrek – Der tollkühne Held\" auf. Die Flötensolos, die der Rattenfänger von Hameln spielt, wurden von Jeremy Steig, einem bekannten Jazz-Musiker, eingespielt, dessen Vater William Steig der Autor der \"Shrek\"-Romane ist.\n\nFür die Haupt- und Nebenfiguren konnten fast ausnahmslos wieder die Sprecher der vorherigen Shrek-Filme verpflichtet werden, nur Rumpelstilzchen wurde prominent umbesetzt und man konnte Bernhard Hoëcker für diese Rolle gewinnen. Die deutsche Synchronisation des Films übernahm erneut die Berliner Synchron AG in Berlin unter der Dialogregie von Michael Nowka, der auch für das Dialogbuch verantwortlich war.\n\nWalt Dohrn sprach bei den Treffen zur Besprechung des Storyboards sämtliche Stimmen ein. Da kein anderer Darsteller geeigneter für das Einsprechen der Rolle des Rumpelstilzchens erschien, lieh Dohrn dieser Figur seine Stimme auch im Originalton des endgültigen Films und ersetzte somit Conrad Vernon, der diese Märchenfigur zuvor im dritten Teil \"Shrek der Dritte\" gesprochen hatte. Darin war Rumpelstilzchen nur in einer kleinen Nebenrolle zu sehen und auch sein äußeres Erscheinungsbild wich stark vom Aussehen im vierten Teil ab.\n\nAm 25. Juni 2010 wurde von Alive der Soundtrack veröffentlicht, der 16 Musiktitel der von Harry Gregson-Williams komponierten Filmmusik enthält.\n\nDie Redaktion von TV Spielfilm urteilt: „Während früher spitzzüngige Spielereien mit modernen Popkulturmythen dominierten, hat der vierte Teil nur noch müde Witze vom Oger-Fließband zu bieten. Die von Teil 1 abgekupferte Story wandelt die gleichen Ideen lieblos ab, und die wenigen neuen Figuren – allen voran Rumpelstilzchen, dessen Kampfgans und der tänzelnde Rattenfänger – sind lahme Abziehbilder bereits bekannter Charaktere. Wie gut, dass zumindest auf den leicht aus der Form geratenen gestiefelten Kater Verlass ist.“\n\nCinema schreibt, der Film sei ein „enttäuschender Abschluss der grandiosen Zeichentrickreihe, dem es an witzigen Einfällen und spritzigen Figuren fehlt“.\n\nKino.de resümiert: „Dieses clevere Recycling bringen Witz, die erstmals dreidimensional und auf Cinemascope gestreckten Bilder darüber hinaus einen visuellen Bonus in diese sehr unterhaltsame und temporeiche Fortsetzung ein, die zeigt, dass das Kinoleben des Shrek-lichen längst nicht enden muss. »Für immer Shrek« braucht also ein Ausrufezeichen!“\n\nBei Metacritic erreicht der Film einen Metascore von 58 % bei 35 gewerteten Kritiken. Von den bei Rotten Tomatoes gesammelten Filmkritiken fallen 58 % positiv aus (bei 187 gewerteten Kritiken), während von über 300.000 Usern 64 % den Film positiv werteten.\n\nBei den Teen Choice Awards wurde der Film 2010 als bester computeranimierter Film nominiert. 2011 wurde \"Für immer Shrek\" bei den People's Choice Awards als bester Familienfilm und von der Academy of Science Fiction, Fantasy & Horror Films als bester Animationsfilm nominiert. Andrew Young Kim wurde 2011 bei den Annie Awards mit einer Nominierung für die besten animierten Effekte bedacht und erhielt neben Yancy Lindquist, Jeff Budsberg und Can Yuksel eine weitere Nominierung bei den VES Awards für herausragende Animationseffekte in einem Animationsfilm. Bei den Kids' Choice Awards wurde der Film 2011 als bester Animationsfilm nominiert, während Cameron Diaz eine Nominierung als beste Stimme eines Animationsfilms erhielt und Eddie Murphy in derselben Kategorie gewann.\n\n"}
{"id": "5339106", "url": "https://de.wikipedia.org/wiki?curid=5339106", "title": "MariaDB", "text": "MariaDB\n\nMariaDB ist ein freies, relationales Open-Source-Datenbankmanagementsystem, das durch eine Abspaltung (Fork) aus MySQL entstanden ist. Das Projekt wurde von MySQLs früherem Hauptentwickler Michael Widenius initiiert, der auch die Storage-Engine \"Aria\" entwickelte, auf welcher MariaDB ursprünglich aufbaute (die Software-Schicht, welche die Basisfunktionalität der Datenbank enthält, d. h. das Erstellen, Lesen, Ändern, Löschen von Daten).\n\nDa Oracle die Markenrechte an MySQL hält, mussten neue Namen für das Datenbanksystem und dessen Storage-Engines gefunden werden. Der Name \"MariaDB\" geht auf Widenius’ jüngere Tochter Maria zurück; seine andere Tochter My war bereits die Namensgeberin für MySQL.\n\nSeit Ende 2012 haben einige Linux-Distributionen MySQL durch MariaDB als Standard-Installation ersetzt, dazu gehören Fedora, CentOS, openSUSE, Slackware und Arch Linux. Die Wikimedia Foundation, die unter anderem auch die Server für die Wikipedia bereitstellt, hat ihre Produktivsysteme im April 2013 auf MariaDB umgestellt. Damit hat sich eine der weltweit größten Web-Plattformen von MySQL verabschiedet.\n\nZu den Anwendern von MariaDB gehören:\n\nDie MariaDB Enterprise Version richtet sich an Kunden mit unternehmenskritischen Anwendungen. Diese ist für eine hoch leistungsfähige und sichere Betriebsweise vorkonfiguriert und bietet differenziertes Auditing, schnelle Backups für große Datenbanken sowie Ende-zu-Ende-Verschlüsselung für Daten auf Clustern.<br> Der MariaDB Community Server enthält dagegen auch in Entwicklung befindliche Funktionen.\nBeide Versionen werden unter einer Open-Source-Lizenz vertrieben, wogegen bei Oracle nur die MySQL Community-Version unter einer freien GPL-Variante steht.\nSelbst ohne Supportvertrag darf der MariaDB Server genutzt werden.<br>\nEr ähnelt im Funktionsumfang der MySQL Enterprise-Version, z. B. sind ein Audit- und Thread-Pooling-Plugin enthalten.\n\nBis zur Version MariaDB Server 10.0 gibt es zwei Binärversionen (mit und ohne MariaDB-Galera-Cluster-Unterstützung). Seit MariaDB Server 10.1 ist die Galera-Cluster-Unterstützung als Hochverfügbarkeitslösung integriert.\n\nMit einem neuen ColumnStore bietet MariaDB eine Kombination aus relationaler Datenbank mit Big-Data-Technologien. MariaDB ColumnStore arbeitet als spaltenorientierte Speicher-Engine und unterstützt massive parallele Abfrageverteilung und paralleles Laden von Daten. Die Veröffentlichung erfolgte als Open Source unter der GPL2, ein Fork auf Basis von InfiniDB und Beiträgen der Open-Source-Community.\nMariaDB ColumnStore ist ANSI-SQL-fähig und ermöglicht die gleichen Abfragen, Aggregationen und Funktionen wie herkömmliche SQL-Datenbanken. Zudem kann ColumnStore gemeinsam mit relationalen Engines verwendet werden, so dass eine gemeinsame Verwendung herkömmlicher relationaler Speicherung und der spaltenorientierten Speicherung in einer Datenbank möglich ist.\n\nMariaDB-MaxScale ist ein Anwendung-zu-Datenbank-Gateway, das zwischen Client-Anwendungen und Datenbanken eingesetzt wird. Es soll Datenbankverfügbarkeit, -sicherheit und -skalierbarkeit verbessern, ohne dass die Anwendung geändert werden muss. Die MySQL Community verlieh MaxScale den Preis „Application of the Year 2016“. Die MySQL Community Awards werden jährlich an Personen und Projekte vergeben, die das MySQL-Ökosystem supporten und erweitern.\n\nIm September 2018 wurde bekannt, dass MariaDB Clustrix übernimmt. Mit dem Kauf von Clustrix und der Integration von deren Cluster-Verfahren soll MariaDB in kurzer Zeit für den skalierbaren, verteilten Einsatz bereitgestellt werden. Anstatt die notwendige Technik aufwendig selbst entwickeln zu müssen, sollen Anpassungen an APIs genügen – zumindest sei MariaDB bereits für die Anbindung externe Datenbank-Engines gerüstet.\n\nIm Dezember 2012 wurde von den ehemaligen MySQL-Gründern Michael Widenius, David Axmark und Allan Larsson die unabhängige MariaDB-Foundation gegründet. Die Stiftung soll die Interessen der Nutzer und Entwickler der MariaDB schützen und dafür sorgen, dass die freie Datenbank frei bleibt. Zu den Zielen der Stiftung gehören auch die Verbesserung der Datenbanktechnik, einschließlich der Implementierung von Standards und Sicherstellung der Interoperabilität zu anderen Datenbanken.\n\nHaupt-Entwickler des freien Datenbanksystems ist das Unternehmen MariaDB Corporation. Das Unternehmen wurde von ehemaligen MySQL-Entwicklern unter dem Namen SkySQL gegründet und am 1. Oktober 2014 in MariaDB Corporation umbenannt. Die jüngste Finanzierungsrunde brachte 9 Millionen Dollar, unter anderem von \"Intel Capital\" und \"California Technology Ventures\". Michael Howard trat die Nachfolge des Mitte 2015 ausgeschiedenen CEO Patrick Sallner an. MySQL- und MariaDB-Schöpfer Monty Widenius ist CTO des Unternehmens. Das Unternehmen bietet Support, Schulung und Remote-Administration von MySQL- und MariaDB-Datenbanken. Das Geschäftsmodell des Unternehmens ist, über diese Dienstleistungen die finanziellen Ressourcen zu erlangen, um das Open-Source-System weiterzuentwickeln.\nDas Unternehmen kündigte am 26. Februar 2018 im Rahmen seiner internationalen Anwenderkonferenz M|18 die Gründung von \"MariaDB Labs\" an. Hier soll an innovativen Datenbank-Verfahren geforscht werden. Zunächst ist die Zusammenarbeit mit Intel mit dem Ziel geplant, eine Referenzarchitektur für Datenbanken mit verteilten Speicher- und Server-Landschaften zu entwickeln.\n\nDie MariaDB- und MySQL-Server sind keine monolithischen Datenbankserver wie z. B. PostgreSQL. Diese Server kann man sich als Framework für \"pluggable engines\" vorstellen. Als Standard-Engine verwenden beide seit MariaDB 10.2 die identische InnoDB-Engine, auf die in der Regel auch Applikationen zurückgreifen. Der SQL-Dialekt entspricht dem „Standard-SQL“, und zwischen MySQL und MariaDB gibt es keine essenziellen Unterschiede.\n\nAus Sicht von Applikationen sind zwischen MariaDB Server und MySQL Server keine Inkompatibilitäten bekannt, d. h. man kann MariaDB und MySQL einfach ersetzen. Die Daten-Dateien der InnoDB sind kompatibel und damit austauschbar.\n\nIn der klassischen Speicherung der Passwörter und der klassischen Replikation sind MariaDB und MySQL vollständig kompatibel, so dass man Replikationen zwischen MariaDB und MySQL ohne Probleme einrichten kann. Beim Einsatz neuer Features der MariaDB und MySQL in diesen Bereichen entstehen hingegen Inkompatibilitäten auf Administrationsseite.\n\nDie interne Verarbeitung des Query Optimizer und Planner unterscheiden sich wesentlich, weil Monty Widenius enttäuscht vom Code der MySQL 5.6 war. Aufgrund seines Urteils entschied man sich bei MariaDB, den Query Optimizer, Query Planner und die Replikation neu zu gestalten, um Leistungsgewinne zu erzielen.\n\nAb MariaDB Server 10.3 wird die Kompatibilität zu Oracle-Datenbanken erhöht. Stored Procedures (Oracle PL/SQL) und Sequenzen können nun auch in der SQL-Syntax der Oracle-DB erstellt werden.\n\nMariaDB-Server können auch mit \"MySQL Workbench\" gewartet und administriert werden.\n\nÄhnlich wie für Datenbanksysteme anderer Hersteller bietet auch MariaDB kommerziellen Kundendienst (\"corporation support\") und Beratung sowie entfernte Verwaltung (\"remote administration\") ihrer Datenbanksysteme. Im Kundendienst der MariaDB Corporation sind auch zahlreiche Kernel-Entwickler der beiden freien Datenbanksysteme MySQL und MariaDB tätig.\n\nDie jährliche Konferenz zur Datenbank MariaDB ist die OpenWorks. Sie findet 2019 zum sechsten Mal in New York statt. Es gibt mehr als 60 Keynotes, Workshops und Sessions rund um MariaDB.\n\nGoogle unterstützt die \"MariaDB Foundation\". 2013 erhielt die MariaDB Corporation mehr als 20 Millionen Dollar durch verschiedene Unternehmen. Die EU investierte im Jahr 2017 rund 25 Millionen Euro in MariaDB.\n\nDie MariaDB Foundation garantiert, dass jede Nebenversionsnummer mindestens fünf Jahre Wartung erhält. Das unten angeführte Erscheinungsdatum gibt dabei den Zeitpunkt des ersten Erscheinens wieder und nicht den der allgemeinen Verfügbarkeit (\"General Availability\", GA), welcher einige Wochen oder Monate später lag. Da die Version 5.5 in vielen Linux-Distributionen enthalten ist, deren Wartungsende auf eine Zeit nach 2017 fällt, wurde der Unterstützungszeitraum dieser Version von der MariaDB Foundation um drei Jahre verlängert. Der Versionssprung von 5.5 auf 10.0 soll dem Umstand Rechnung tragen, dass sich MariaDB ab der Version 10 funktional weiter von MySQL entfernen wird.\n\n"}
{"id": "5341707", "url": "https://de.wikipedia.org/wiki?curid=5341707", "title": "Microsoft Windows Home Server 2011", "text": "Microsoft Windows Home Server 2011\n\nWindows Home Server 2011 mit dem Code-Namen Vail ist ein Betriebssystem für Home-Server von Microsoft und der Nachfolger von Windows Home Server. Es basiert auf dem Windows Server 2008 R2 und ist damit ein reines 64-Bit-Betriebssystem.\n\nDie endgültige Version des Betriebssystems ist seit Juni 2011 verfügbar.\n\nWindows Home Server 2011 bietet wie sein Vorgänger bis zu zehn Windows-Rechnern im Heim-Netzwerk regelmäßige Systemsicherungen und einen einfachen und zentralen Zugang zu Daten wie etwa Musik, Bildern und Videos, auf welche auf Wunsch auch aus dem Internet zugegriffen werden kann, sowie zu Geräten wie etwa Druckern und Scannern. Darüber hinaus kann er mit entsprechenden Programmen um Funktionen erweitert werden. Er kann den aus Windows 7 bekannten Heimnetzgruppen beitreten.\n\nNeben Windows-PCs stehen verschiedene Angebote des Windows Home Servers 2011 auch dem Mac und iPhone zur Verfügung, so etwa eine Backup-Funktion für Macs.\n\nDie von der ersten Version des Home Server bekannte Drive-Extender-Technologie wurde aus der aktuellen Version entfernt. Zur Datenduplizierung soll wieder auf klassische RAID-Technologie zurückgegriffen werden.\n\n\nSeit dem 26. April 2010 befand sich der Windows Home Server V2 im öffentlichen Beta-Test (offizielle Seite zum Beta-Test auf Englisch).\nSeit dem 16. August 2010 gab es eine aktualisierte Beta.\n\nSeit dem 3. Februar 2011 stand der Windows Home Server 2011 RC (Release Candidate) zum Download zur Verfügung.\n\nAm 29. März 2011 wurde die zur Veröffentlichung vorgesehene Version fertiggestellt. Seit dem 5. April 2011 steht sie über Technet und MSDN zum Herunterladen zur Verfügung. Ab Juni sollen OEM-Geräte im Handel verfügbar sein. Seit Ende Mai sind System Builder-Versionen für Privatpersonen ab rund 90 € im Handel verfügbar.\nMitte Juni 2011 senkte Microsoft den Preis für eine WHS2011-Lizenz auf rund 50 €, um so den Markt mit Fertigprodukten anzukurbeln.\n\nMit der Vorstellung des Windows Server 2012 erfolgte die Abkündigung des Windows Home Servers.\nDer Verkauf des Windows Home Server 2011 wurde seitens Microsoft zum 31. Dezember 2013 eingestellt.\nDer Support seitens Microsoft endete am 12. April 2016.\n\n"}
{"id": "5341732", "url": "https://de.wikipedia.org/wiki?curid=5341732", "title": "Philips NMS-8250", "text": "Philips NMS-8250\n\nPhilips NMS-8250 war ein MSX-2-Heimcomputer vom Elektronik-Unternehmen Philips und wurde 1986 auf den Markt gebracht. Er gehörte zu den Philips \"New-Media-System\"-Geräten und trug deshalb das Akronym „NMS“ im Namen. Er war damals eine seltene Form von Heimcomputer in einem Desktopgehäuse und der erste MSX-Computer von Philips in dieser Ausführung. \n\nEr war fast gleich ausgestattet wie das Vorgängermodell VG-8235. Nur war bei diesem Gerät bereits ein Diskettenlaufwerk mit zwei Lese-/Schreibköpfen eingebaut, so dass er doppelseitige Disketten (720 kByte) lesen und beschreiben konnte. Bei NMS-8250 war im Desktop-Gehäuse bereits Platz für ein zweites Laufwerk, das aber nicht standardmäßig eingebaut war. Vom Nachfolgemodell NMS-8280 unterschied sich das NMS-8250 in erster Linie durch den fehlenden Genlock.\n\nDer Computer verfügte über eine abgesetzte Tastatur. Der Desktop hatte zwei Cartridge-Slots auf der rechten Seite. Rückseitig hatte er Schnittstellen für einen Kassettenrekorder, einen Drucker, sowie Schnittstellen für Monitor und Fernseher (SCART-, PAL- und Composite-Video-Schnittstelle mit Video-, Luma- und Audio-Schnittstelle), eine Schnittstelle für ein weiteres Laufwerk und zwei Joystick-Ports.\n\nIm Innenleben war er mit einem Z80A-Prozessor mit einer Taktfrequenz von 3,58 MHhz, einem Arbeitsspeicher von 128 kByte und ein Videospeicher von 128 kByte, sowie ein 64 Kbyte großes ROM ausgestattet. Im ROM waren 48 kByte für MSX-DOS und 16 kByte für das MSX-BASIC Version 2.0 wie auch der Befehlssatz zum Ansteuern des Diskettenlaufwerks untergebracht. Der Grafikchip war ein Yamaha V9938 und der Soundchip ein Yamaha YM2149.\n\n\n"}
{"id": "5348885", "url": "https://de.wikipedia.org/wiki?curid=5348885", "title": "SAM Coupé", "text": "SAM Coupé\n\nDer SAM Coupé ist ein 8-Bit-Heimcomputer des britischen Herstellers Miles Gordon Technology (MGT), der von 1989 bis 1992 erhältlich war. Er besitzt einem mit dem Sinclair ZX Spectrum kompatiblen Bildschirmmodus und kann dessen Version mit 48 kB emulieren. Es handelt sich nicht um einen Klon im engeren Sinne, da sich seine Hard- und Software ansonsten deutlich vom ZX Spectrum unterscheidet. \n\nDer Hauptprozessor des SAM Coupé ist ein Z80B mit einer Taktrate von 6 MHz (ZX Spectrum: Z80A mit 3,5 MHz). Daneben kommt eine anwendungsspezifische integrierte Schaltung (ASIC) zum Einsatz, die kompatibel mit dem ULA von Sinclair ist. Der Rechner hat 256 kB Arbeitsspeicher (ZX Spectrum: 16–128 kB), der intern bis 512 KB und extern bis zu 4 MB erweiterbar ist.\n\nAls Massenspeicher diente wie beim ZX Spectrum meist ein Kassettenrekorder, obwohl man auch bis zu zwei 3,5-Zoll-Diskettenlaufwerke an das Gerät anschließen kann. Geräusche und Musik des Rechners werden mit dem 6-stimmigen Soundchip Philips SAA 1099 erzeugt.\n\n"}
{"id": "5351405", "url": "https://de.wikipedia.org/wiki?curid=5351405", "title": "Toshiba HX-10", "text": "Toshiba HX-10\n\nToshiba HX-10 war ein MSX-Heimcomputer von Toshiba, der im Mai 1984 auf den Markt gebracht wurde. Er wurde bereits von Beginn her mit viel Peripherie-Geräten produziert. So wurden gleichzeitig Drucker, Kassettenrekorder, Diskettenlaufwerke, Monitore, Cartridgeslot-Erweiterungen und auch Modems für diesen Computer angeboten. Ebenso wurde von Toshiba produzierte Software angeboten, wie Textverarbeitung, Tabellenkalkulation mit der Möglichkeit, Grafiken wie beispielsweise Tortendiagramme zu erstellen. Damit war der Computer auch für den professionellen Bürobereich geeignet.\n\nAuffallende äußere Merkmale sind die relativ großen Funktionstasten und die kreuzförmige Anordnung der Cursor-Tasten. Die Maße betrugen 370 × 245 × 60 Millimeter und der Computer wog 2,8 Kilogramm. Ausgerüstet war der Computer mit einem Z80A-Prozessor, einen Texas Instruments TMS-9929A-Videochip, 64 KB Arbeitsspeicher (30 KB frei für die eigene Programmierung) und 16 KB Videospeicher. Die Schnittstellen waren ein Cartridge-Steckplatz, zwei Joystick-Anschlüsse, ein Composite-Video- und ein HF-Video-Ausgang, Anschluss für Kassettenrekorder, ein Centronics-Anschluss (Drucker) und ein Ausgang für die Cartridge-Erweiterung.\n\n\nIn der dreiteiligen Fernsehfilmserie Damon and Debbie (Herbst 1987) von Channel 4 stand in der ersten Episode ein Toshiba HX-10 in Debbies Zimmer.\n\n"}
{"id": "5354207", "url": "https://de.wikipedia.org/wiki?curid=5354207", "title": "Western Digital Raptor", "text": "Western Digital Raptor\n\nDer Western Digital Raptor (oft auch einfach WD Raptor genannt) war eine Serie von High-Performance-Festplatten, die von der Firma Western Digital hergestellt wurden. Das Laufwerk nahm den Nischenmarkt für Enthusiasten, Workstations und kleine Server ein. Traditionell ist die Mehrheit der Server-Festplatten aufgrund ihrer Vorteile in Leistung und Zuverlässigkeit mit einer SCSI- bzw. SAS-Schnittstelle angebunden, die Raptor-Festplatten verwendeten hingegen SATA.\n\nObwohl als \"Enterprise-Class-Laufwerk\" erschienen, gewann er die Gunst der Enthusiasten, weil der Raptor in der Lage war, Geschwindigkeiten, die normalerweise nur teurere Server-Laufwerke schafften, zu erreichen. Die Benutzung der SATA-Schnittstelle bedeutete, dass er leicht auf allen zu dieser Zeit modernen Motherboards genutzt werden konnte, ohne separate (und oft teure) Controller-Karten kaufen zu müssen. Außerdem wurde die Integration der ersten Modelle noch einfacher durch die Verwendung eines Standard-4-Pin-Molex-Stromanschlusses zusätzlich zu dem Standard-SATA-Port. \n\nEs wurden mehrere Serien dieser Festplatte vorgestellt, die mit 10.000 min arbeiteten und dabei jeweils größere Kapazitäten boten. Trotz der von 2003 bis 2015 laufenden Produktion und Weiterentwicklung dieser Platte gab es keine vergleichbaren SATA-Laufwerke auf dem Markt. Mit dem Aufkommen von Solid-State-Drives verlor diese Festplatte zunehmend an Bedeutung.\n\nIm Jahr 2003 veröffentlichte Western Digital die erste Inkarnation der Raptor-Serie: Die WD360GD. \n\nVorgestellt mit einer Kapazität von 37 GB auf einer einzigen Platte und einer \"Serial ATA\"-Schnittstelle war er die erste ATA-Festplatte mit einer Spindeldrehzahl von 10.000 Umdrehungen pro Minute. Wie viele frühe SATA-Laufwerke, war der Raptor kein \"echtes\" SATA-Laufwerk, da er in Wirklichkeit ein PATA-Laufwerk war, das ein 88i8030C Interface Bridge-Chip von Marvell verwendete. Allerdings hat diese Tatsache die Leistung nicht verringert. WD360GD-Raptor-Festplatten nutzen die 3,3 V der Serial ATA Netzteilanschlusses. Es besteht keine Notwendigkeit, einen SATA-Stromanschluss zu verwenden, da er nicht voll ausgeschöpft wird.\n\nDie zweite Generation des Raptors wurde Anfang 2004 eingeführt, mit zwei Platten für 74 GB Speicherplatz. Im Gegensatz zu seinem Vorgänger hatte die WD740GD kein Kugellager das die drehenden Platten unterstützte, sondern verwendete fluiddynamische Lager. Dieses erlaubt dem neuen Raptor, auf einen Geräuschpegel vergleichbar mit dem eines ruhigeren Laufwerks mit 7200 min zu kommen.\n\nDie dritte Generation des Raptors von Western Digital wurde im Januar 2006 veröffentlicht. Er verfügte über zwei 75-GB-Platten (für insgesamt 150 GB) und ein erweitertes System des Native Command Queuing. Zur gleichen Zeit wurde der Raptor X mit 150 GB freigegeben. Er hatte die gleiche Spezifikation zum Standard-Raptor, allerdings mit Acrylglas abgedecktem Fenster im Deckel und dem Label auf der Unterseite, wobei das Fenster den Blick auf die Schreib-/Leseköpfe und einen Ausschnitt der Datenscheiben freigibt, sodass man der Festplatte beim Arbeiten zusehen kann.\n\nDie vierte Generation des Raptors von Western Digital wurde im April 2008 angekündigt. Von nun an heißt das Laufwerk VelociRaptor. Der VelociRaptor war im Gegensatz zum Raptor ein 2,5\"-Laufwerk und besaß in der ersten Generation bis zu 2 Platten mit jeweils 150 GB. Montiert war er auf dem IcePack-Kühlkörper, welcher aus dem eigentlichen 2,5\"-Laufwerk ein 3,5\"-Laufwerk machte. Zudem kamen die Lautstärke und der Stromverbrauch einer herkömmlichen Festplatte mit 7200 Umdrehungen pro Minute deutlich näher. Von nun an war kein 4-Pin-Molex-Anschluss mehr vorhanden. Anfangs wurden die Modelle mit der Endung GLFS kritisiert, da der IcePack-Rahmen (siehe Foto) das Laufwerk nicht rückwandplatinenkompatibel machte, sodass das Laufwerk nicht in Hot-Swap-Wechselrahmen eingebaut werden konnte. Deshalb wurde der IcePack-Rahmen überarbeitet und die neuen Modelle hatten die Endung HLFS. Dieser überarbeitete Rahmen blieb in den nachfolgenden Generationen unverändert. Zusätzlich kamen noch die BLFS-Modelle, welche keinen IcePack-Rahmen hatten und für Blade-Server bestimmt waren. Das Entfernen eines IcePack-Rahmens zerstörte ein Garantiesiegel. Zudem sind diese Laufwerke mit 15 mm zu dick für Notebooks und auch der Stromverbrauch ließ den Einsatz nicht zu. Hier gab es kurz nach der Einführung eine Version mit komplettem Plexiglasdeckel, in dieser Ausführung wurden aber nur sehr wenige Modelle produziert.\n\nDie fünfte Generation des Raptors wurde von Western Digital im April 2010 angekündigt. Die Datendichte wurde erhöht und die SATA-Schnittstelle wurde auf 6Gbps erweitert. Wie auch der Vorgänger wurde dieses Laufwerk sowohl als 3,5\"-Version, als auch in der 2,5\"-Version für vermarktet. Die Endungen der Namen dieser Platten waren HLHX (3,5\") und BLHX (2,5\"). Jeder Platter konnte bis zu 200gb fassen, das größte Modell WD6000HLHX dieser Generation besaß 3 dieser Platter. Weitere bekannte Vertreter waren die 2-Plattrige WD3000HLHX und die 1-Plattrige WD1500HLHX. Es wurden aber auch andere Größen gebaut, wie z.B. die WD1600HLHX mit gerade mal 160 GB oder die WD4500HLHX mit 450 GB.\n\nDie sechste Generation WD Raptor (oder 3. Generation VelociRaptor) verfügte über eine erneut gesteigerte Datendichte und einer Kapazität von bis zu 1 TB (WD1000DHTZ). Sie wurde im April 2012 vorgestellt. Das Modell WD1000DHTZ besaß 3 Scheiben, mit jeweils 333 GB. Die anderen Modelle dieser Generation hatten Scheiben mit genau 250 GB verbaut.\n\nEntsprechende Modelle aus dieser Generation (mit der Endung HHTZ) waren: WD5000HHTZ (500 GB) und WD2500HHTZ (250 GB)\n\nDie 2,5\" Versionen trugen die Endung BHTZ für die Modelle mit 250 GB pro Scheibe, und CHTZ für das Modell mit 333 GB pro Scheibe.\nIm Gegensatz zum Vorgänger besaßen alle Modelle dieser Serie einen 64-MB-Puffer anstatt 32 MB wie bei der VR200M und eine Sektorgröße von 4096 bytes, Advanced Format. Zudem konnte die Lautstärke und der Stromverbrauch ebenfalls gesenkt werden, während die Leistung des Laufwerks gesteigert wurde. Die VR333 wurde wie auch alle Vorgänger mit IcePack angeboten, die 2,5\"-Versionen wurden erst gegen Ende des Jahres 2013 freigegeben. Während die Datenübertragungsrate deutlich gesteigert wurde, verbesserte sich die Zugriffszeit nicht nennenswert.\n\nTests \n"}
{"id": "5354223", "url": "https://de.wikipedia.org/wiki?curid=5354223", "title": "Spectravideo SVI-728", "text": "Spectravideo SVI-728\n\nDer Spectravideo SVI-728 war der erste MSX-Heimcomputer des ehemaligen US-amerikanischen Computerherstellers Spectravideo. Er wurde 1984 auf den Markt gebracht. Der SVI-728 war der Nachfolger des SV-328, der aber noch kein vollwertiger MSX-Computer war. Der Computer war sehr professionell und hatte eine ergonomische Tastatur mit einem separaten abgesetzten Ziffernblock und konnte so einerseits als Heimcomputer wie auch als Bürocomputer gebraucht werden. Der SVI-728 war CP/M-fähig und so konnten CP/M-Programme auf diesem Computer genutzt werden.\n\nDas Gehäuse war elfenbeinfarben und hatte graue, für die Fingerkuppe abgerundete Tasten. Der Cartridge-Slot befand sich vorne in der Mitte. Der Computer war mit einem Z80A-Prozessor mit 3,56 MHz, 32 kByte ROM, 64 kByte RAM (erweiterbar bis 265 kByte) und einem Video-RAM von 16 kByte ausgestattet. Der Grafikchip war ein Texas Instruments TMS9918A für NTSC oder TMS9929 für PAL oder SECAM (YPbPr). Als Schnittstellen hatte er einen Kassettenrekorderanschluss, zwei Joystickports, eine Centronics-Drucker-Schnittstelle, einen RGB-Ausgang für den Anschluss eines Monitors und einen Antenne-Ausgang für den Anschluss eines Fernsehers.\n\nVon Spectravideo wurde einiges an Zubehör produziert. Wegen der CP/M-Kompatibilität wurden 5-1/4-Zoll-Floppys (SVI-707) angeboten. Für die Erweiterung des RAMs gab es ein 64-kByte-Steckmodul (SVI-747). Damit kam der freie Arbeitsspeicher auf insgesamt 144 kByte und war so ideal für Textverarbeitung- und Kalkulationsprogramme dimensioniert. Ebenso wurden Modems (SVI-737), Joysticks (SVI-101), Grafiktabletts (SVI-105), Kassettenrekorder (SVI-767), Steckmodule für eine serielle Schnittstelle (SVI-757) wie auch Monitore produziert.\n\n"}
{"id": "5355174", "url": "https://de.wikipedia.org/wiki?curid=5355174", "title": "Spectravideo", "text": "Spectravideo\n\nDas US-amerikanische Unternehmen Spectra-Video, Inc. mit seinem internationalen Ableger Spectravideo International Ltd. war ein Hersteller von Joysticks, Videospielen und Heimcomputern. Größere Bekanntheit erlangte insbesondere der \"Quickshot\", der erste nach ergonomischen Gesichtspunkten gestaltete Joystick der Videospielgeschichte. Die Heimcomputer Spectravideo SV-318 und SV-328 sind ebenso von besonderer technikgeschichtlicher Relevanz, da sie als direkte Vorläufer und damit Wegbereiter des MSX-Standards gelten.\n\nGegründet wurde das Unternehmen 1981 in den USA unter dem Namen „Spectravision“. Die Gründer waren zwei Schweizer Uhrenhersteller \"Harry Fox\" und \"Oscar Jutzeler\", die in den 1950er Jahren nach Nordamerika ausgewandert waren. Das Unternehmen vertrieb zuerst Spiele für die Systeme Atari 2600, Colecovision und Commodore VC 20. 1982 wurde das Unternehmen aufgrund eines Namenskonfliktes mit einem gleichnamigen Fernsehsystems für Hotels in „SpectraVideo“ umbenannt. Ebenfalls in diesem Jahr am 9. November wurde die erste Variante des \"Quickshots\" unter der U.S. Patentnummer 271220 patentiert.\n\nIm Januar 1983 wurde in Las Vegas auf der CES zwei Heimcomputer-Systeme vorgestellt: eine Erweiterung für Atari 2600 \"CompuMate\" und Spectravideo SV-318. Auf der Sommer-CES desselben Jahren in Chicago folgte der Spectravideo SV-328. SV-318 und SV-328 waren Vorläufer des MSX-Standards. Vor allem der SV-328 brachte den ASCII-Präsident Kazuhiko Nishi auf die Idee auf der Basis dieses Heimcomputers einen Heimcomputerstandard zu schaffen.\n\nDie Firma nannte sich 1984 \"SpectraVideo International\" und brachte unter diesem Label den ersten vollwertigen MSX-Computer (Spectravideo SVI-728) auf den Markt und verkaufte den Computer auf dem nordamerikanischen, auf dem europäischen und auf dem australischen Kontinent, sowie in Südafrika und Israel. Erfolg hatten sie vor allem in Europa. Der Absatz in Amerika fiel dagegen bescheiden aus. Deshalb wurde 1985 durch den Hauptaktionär Bondwell der Unternehmenssitz nach Hongkong verschoben und sämtliche Abteilungen in den USA geschlossen.\n\n1985 wurde der MSX \"SVI-738 X'Press\" und 1986 der PC-kompatible MSX-2 \"SVI-838 XPress'16\" produziert. 1986 verließ die Firma endgültig die MSX-Gruppe und produzierte IBM-kompatible PCs (\"Spectravideo SVI-256\" und \"SVI-640FH/FF\"). Das Unternehmen wurde in den Jahren darauf liquidiert und der Name an die britische Firma Ash & Newman (heute Logic3) verkauft.\n"}
{"id": "5357954", "url": "https://de.wikipedia.org/wiki?curid=5357954", "title": "Spectravideo CompuMate", "text": "Spectravideo CompuMate\n\nDer Spectravideo CompuMate SV-010 (übersetzt: „ComputerGefährte“) war eine Erweiterung der Atari-2600-Spielekonsole und ergänzte diese zu einem vollwertigen Heimcomputer. Er wurde von Spectravideo hergestellt und wurde das erste Mal im Januar 1983 in Las Vegas an der Consumer Electronics Show vorgestellt.\n\nEr bestand aus einem Steckmodul mit Joystickkabeln und einer mit einem Kabel verbundenen Membrantastatur, die an die Tastatur der Spielekonsole G7000 erinnerte. Die Tastatur konnte mit dem Atari zusammengesteckt werden und so wurde das Ganze zu einer stabilen Einheit. Dies funktionierte beim Atari 2600 Junior nicht, da dieser ein kleineres Gehäuse hatte. Das Steckmodul passte in den Cartridge-Slot des Ataris. Aus diesem Modul gingen zwei Kabel mit Joystickstecker hervor, die an die Joystickports angeschlossen werden mussten. CompuMate hatte eine Schnittstelle für einen Kassettenrekorder, um Programme und Daten laden und speichern zu können.\n\nDurch den Atari 2600 war der Heimcomputer mit einem 6507-Prozessor mit einer Taktfrequenz von 1,18 MHz ausgestattet. Im Steckmodul standen etwa 1,75 kByte freier Arbeitsspeicher für die Programmierung und für die Anwendungsdaten der internen Programme zur Verfügung. Der beschränkte Speicher reichte etwa für 100 BASIC-Zeilen, was ernsthafte Programme unmöglich machte.\n\nDas 16-KB-ROM wurde mit einem rudimentären BASIC ausgestattet. Es kannte Kurzbefehle, die über einen Tastendruck eingegeben werden konnten (Basic-Tokens). Der Textmodus war auf 10 Zeilen mit je 12 Zeichen beschränkt. Integriert waren ein Zeichenprogramm und ein Musikprogramm. Mit dem Zeichenprogramm konnte der Benutzer Bilder in einer Auflösung von 40 × 40 Pixel zeichnen und mehrere Bilder zu einer Animation zusammensetzen. Das Musikprogramm erlaubte das Komponieren von Melodien. Dazu musste die Tonhöhe und Tondauer jedes Tons in eine Liste eingegeben werden, die dann das System sequentiell abarbeitete.\n\nZusätzlich sollten im Oktober 1983 noch einige Hardwareerweiterungen erscheinen, die am Compumate angeschlossen werden konnten, wie Micro Disk, Modem, Speicherweiterungen. Jedoch aus Sorge, den hauseigenen Heimcomputern Atari 600 XL und Atari 800 XL Konkurrenz zu machen, wurden die zusätzlichen Hardwareerweiterungen nicht veröffentlicht.\n\nDer CompuMate wurde in Deutschland vom Quelle-Versand unter der Hausmarke „Universum“ angeboten.\n\nVon Atari selbst wurde das Modul Atari 2600 Basic Programming angeboten, das in Art und Umfang weit hinter dem CompuMate zurück blieb.\n\nDie CompuMate Heimcomputer-Erweiterung gilt heute als begehrtes und teures Sammlerstück.\n"}
{"id": "5358136", "url": "https://de.wikipedia.org/wiki?curid=5358136", "title": "Native Transparenz", "text": "Native Transparenz\n\nNative Transparenz ist ein Begriff aus der Druckvorstufentechnologie. Er bezeichnet Grafikdateien (insbesondere PDF-Dateien), in denen transparente Bild- oder Textelemente in mehreren Ebenen übereinander angeordnet sind.\n\nIm traditionellen PostScript-Workflow ist es nicht möglich, transparente Objekte einzubinden. Werden in einem Grafik- oder DTP-Programm Transparenzen erzeugt, mussten diese bei der Ausgabe „verflacht“, das heißt die übereinander liegenden transparenten Objekte zu einer Bilddatei verschmolzen werden. Nachträgliche Änderung an Texten oder den Einstellungen zum Überdrucken sind dann nicht mehr möglich und die Auflösung auf die gewählte Rasterbildauflösung begrenzt.\n\nZur Unterscheidung von solchen verflachten Transparenzen werden die (vom Druckergebnis theoretisch nicht zu unterscheidenden) Dateien mit noch vorhandenen Transparenzen als \"nativ\" bezeichnet, die zur Ausgabe nötige Transparenzreduzierung erfolgt hier erst im Ausgabegerät (Raster Image Processor oder Drucker).\n\nDas Portable-Document-Format unterstützt native Transparenzen ab Version 1.4. In den PDF/X-Spezifikationen sind Transparenzen in der PDF 1.3-Version und bislang (2018) weitgehend verbreiteten PDF/X-1a:2001/2003 oder PDF/X-3:2002/2003-Standard nicht zulässig, sie werden jedoch ab PDF/X-4:2010 unterstützt. Ebenfalls unterstützt werden sie durch die Adobe PDF Print Engine.\n"}
{"id": "5360816", "url": "https://de.wikipedia.org/wiki?curid=5360816", "title": "JooJoo", "text": "JooJoo\n\nJooJoo ist ein auf Linux basierender Tablet-PC, der für das Surfen im Internet konzipiert ist. Er wurde von Singapore Development Studio Fusion Garage hergestellt und wurde auch nach Deutschland geliefert.\nAllerdings enttäuschte das als iPad-Konkurrent gehandelte Tablet, heise bemängelte das unfertige System, den benutzerunfreundlichen Touchscreen und den langsamen Prozessor.\nDer Hersteller kündigte im August 2011 einen indirekten Nachfolger, das \"Grid10\", an. Es basiert auf dem OpenSource-Betriebssystem Android und wurde ab Mitte September 2011 ausgeliefert.\n\nAufgrund der geringen Nachfrage nach dem Grid 10 und massiven Preisnachlässen um diese zu erhöhen, benötigte das Unternehmen laut Gründer und CEO Chandra Rathakrishnan Ende 2011 mehr Kapital von Investoren. Am 5. Januar 2012 musste Fusion Garage schließlich Konkurs anmelden.\n\nDas Joojoo verfügt über einen 1,6 GHz Intel Atom N270 Prozessor und einen NAND-Flash-Speicher mit 4 GB. Die Bildschirmoberfläche besteht aus einem 12,1-Zoll-Touchscreen mit 1366 × 768 Pixel. Neben integrierten USB-Anschlüssen und Mikrofoneingang gibt es zusätzlich eine 1,3-Megapixel-Webcam. JooJoo verfügt zudem über Bluetooth 2.1 und WLAN.\n\n"}
{"id": "5363380", "url": "https://de.wikipedia.org/wiki?curid=5363380", "title": "Zigby, das Zebra", "text": "Zigby, das Zebra\n\nZigby, das Zebra ist eine australisch-kanadisch-singapurische Computeranimationsserie um ein anthropomorphes Zebra. Die Serie basiert auf Büchern des schottischen Schriftstellers Brian Paterson. Das Zebra Zigby lebt in einem Baumhaus auf einer tropischen Insel und erlebt mit seinen Freunden, dem Perlhuhn Bertie und das Erdmännchen Matze (engl. ), verschiedene Abenteuer.\n\nBei der Produktion der kanadischen Firma Zebra Productions führte Mark Barnard Regie. Für den Schnitt war Simon Klaebe verantwortlich, künstlerischer Leiter war Robert Gandell. \n\nInternational wird die Serie von Thunderbird Films verliehen. Die deutsche Fassung wurde erstmals ab dem 19. Oktober 2009 werktags bei KiKA ausgestrahlt. Am 23. November 2009 wurde die 52. Folge gesendet, es folgten Wiederholungen bei KiKA und dem ZDF.\n\n"}
{"id": "5366006", "url": "https://de.wikipedia.org/wiki?curid=5366006", "title": "World Wide Telescope", "text": "World Wide Telescope\n\nWorld Wide Telescope ist ein von Microsoft entwickeltes Programm, das den Nachthimmel mit Hilfe von Satellitenbildern darstellt. Es ähnelt dem von Google entwickelten Google Sky. Daneben ist es möglich, ähnlich wie bei Google Earth, Satellitenbilder der Planeten zu betrachten.\n\n"}
{"id": "5370761", "url": "https://de.wikipedia.org/wiki?curid=5370761", "title": "Anki", "text": "Anki\n\nAnki (basierend auf dem japanischen Wort \"anki\" für „Auswendiglernen“) ist eine quelloffene Lernkartei-Software, ursprünglich vorrangig gedacht zum Erlernen von Fremdsprachen, wegen ihrer vielfältigen Einstellmöglichkeiten allerdings für das Einüben unterschiedlichster Inhalte geeignet. Für die Übungen benutzt Anki einen Algorithmus, dessen Wiederholungsintervall für einzelne Fakten gezielt für den Einbau in das Langzeitgedächtnis konzipiert ist.\n\nNeben dem Import öffentlich zugänglicher oder eigener Dateien mit Kartenstapeln können auch Stapel selbst angelegt oder bestehende erweitert werden. Hierzu werden keine Karten angelegt, sondern in Notizen die vorgefertigten Felder ausgefüllt. Anki formatiert diese Informationen anhand des Notiz-Typs und erstellt Karten, mit welchen anschließend gelernt werden kann. Dadurch ist es möglich, mehrere Karten mit den gleichen Feldern zu verbinden. Die Karten können außerdem mit Schlagwörtern markiert werden, um später nur einen Teil des Stapels wiederholen zu müssen.\n\nZum Sprachenlernen können die Daten (Fakten) z. B. wie folgt eingegeben werden:\n\nAnschließend wird basierend auf einem Notiz-Typ eine Karte erstellt. Die Kartenvorlage arbeitet mit Platzhaltern, und kann folgendermaßen aussehen:\n\nDie Platzhalter werden danach durch die eingegebenen Inhalte ersetzt, wodurch eine Karte erzeugt wird. Diese hat nun das folgende Format:\n\nEs lassen sich gleichzeitig mehrere Notiz-Typen erstellen, um sofort mehrere Karten zu erstellen. Beispielsweise kann in einem anderen Modell das französische Wort oder nur die Audio-Datei auf der Vorderseite erscheinen.\n\nIm Lernmodus werden, wie bei vergleichbaren Programmen auch, Karten mit dem zu lernenden Begriff und der Erklärung gleichzeitig angezeigt. Bei der Abfrage von Wissen wird nur das zu beantwortende Muster angezeigt. Die Antwort kann aufgedeckt oder auf Wunsch auch eingegeben werden, sodass Anki diese mit der korrekten vergleichen kann. Bei beiden Modi kommt der spezielle Wiederholungsalgorithmus von Anki zum Einsatz. Bearbeitete Karten können markiert werden, um sie innerhalb der gleichen Sitzung oder nach einem bestimmten Intervall wiederholen zu lassen. Das Intervall richtet sich nach dem Schwierigkeitsgrad, mit dem sich der Benutzer den zu lernenden Fakt einprägen kann. Leicht einzuprägende Notizen werden nach einem längeren Zeitraum wiederholt, schwere nach einem kürzeren. Allerdings können mit Schlagwörtern markierte Themenbereiche ausgewählt werden (im obigen Beispiel „Essen“), um so mit einem \"Auswahlstapel\" gesondert zu lernen, oder bestimmte Themenbereiche kurzzeitig auszublenden. Beim Lernen oder Abfragen kann immer nur ein Stapel zur Zeit genutzt werden. Der Nutzer kann für diesen aber unter anderem die pro Tag abzuarbeitende Menge an Karten bzw. die dafür zur Verfügung stehende Zeit selbst einstellen.\n\n\nSinn der von Anki verwendeten Methode des \"Wiederholens mit Lücken\" („spaced repetition“) ist es, Informationen aus dem Gedächtnis kurz vor deren Vergessen abzurufen und somit eine maximale Wirkung beim Training des Langzeitgedächtnisses zu erreichen.\nAnki nutzte ursprünglich den \"SuperMemo-5-Algorithmus (SM5)\", um die Wiederholungsintervalle für die Abfragen zu berechnen. Dieser Algorithmus erwies sich aber – laut den Angaben des Anki-Autors – als problematisch, da die Wiederholungsintervalle nicht unabhängig für jede einzelne Karte erzeugt werden. Stattdessen berücksichtigen die SuperMemo-Algorithmen ab Version SM3 Ähnlichkeiten zu anderen Lernkarten, was teilweise zu Ungereimtheiten führen kann (besonders wenn die Lernkarten unterschiedlich schwierig sind und nur unregelmäßig gelernt wird). Der Entwickler hat sich deshalb für einen verbesserten SM2-Algorithmus entschieden, der für SuperMemo in den späten 1980er Jahren implementiert wurde, welcher eine größere Flexibilität ermöglicht.\n\nEs existieren mittlerweile mehrere Smartphone-Clients, mit denen Anki-Stapel auch unterwegs gelernt werden können.\nHierbei können die Lernkarten und Lernfortschritte in beide Richtungen über AnkiWeb mit Anki synchronisiert werden.\n\nAnkiDroid ist eine kompatible Anki-Implementierung eines anderen Anbieters für das mobile Betriebssystem Android. Es unterstützt die von Anki erstellten Dateien, die entweder über das Internet mit AnkiWeb oder durch einfaches Kopieren der Anki-Datei auf das Smartphone synchronisiert werden können.\n\nDie Software zeigt die Karten mit Bilder- und Audio-Unterstützung an, und bietet auch die grundlegenden Funktionen zum Erstellen und Bearbeiten von Karten. Beim Hinzufügen neuer Notizen besteht die Möglichkeit, Bilder aus der Galerie einzufügen, sowie mit der Kamera Fotos aufzunehmen. Zudem lässt sich eine mithilfe des internen Mikrofons des Smartphones aufgezeichnete Aussprache direkt der Karte anfügen. Über einen erweiterten Editor lassen sich Wörter direkt übersetzen und die Aussprache eines Wortes als Audiodatei hinzufügen. Formatierungen werden angezeigt, können aber nicht bearbeitet werden (mit Ausnahme von direkter HTML-Schreibung).\n\nEine Besonderheit ist die Unterstützung von benutzerdefinierten Schriftarten. So muss man sich nicht auf die Android-Schriftarten verlassen, sondern kann auch jede beliebige Schriftart benutzen. Dies ist besonders nützlich, wenn man Sprachen lernen möchte, deren Schrift von Android noch nicht, oder nur unzureichend unterstützt wird.\n\nWeiterhin gibt es einen Nachtmodus, bei dem weiße Schrift auf schwarzem Hintergrund benutzt wird. Dieser Modus kann die Akkulaufzeit erhöhen und ist angenehmer in der Dunkelheit zu lesen. Durch ein Whiteboard können durch einfaches Schreiben direkt Notizen auf dem Bildschirm gemacht werden. Dies bietet sich beispielsweise beim Erlernen chinesischer Schriftzeichen an. Außerdem kann, wie auch bei Anki, ein Eingabefeld für die Antwort benutzt werden, so dass Ankidroid die Antwort vergleichen kann.\n\nEs besteht auch die Möglichkeit, sich die Karten in verschiedenen Sprachen beim Lernen mittels eines Text-to-Speech-Systems (TTS) vorlesen zu lassen. Hierzu kann die vorhandene Google-TTS-Engine verwendet werden. Sofern eine Sprache nicht vorhanden ist (wie z. B. Russisch in der Android-Version Ice Cream Sandwich), kann auch eine andere Text-To-Speech-Ausgabe wie z. B. SVOX Classic TTS verwendet werden.\n\n"}
{"id": "5372189", "url": "https://de.wikipedia.org/wiki?curid=5372189", "title": "Code Aster", "text": "Code Aster\n\nCode_Aster ist eine freie FEM-Simulations-Software.\n\nSie wurde von Électricité de France (EDF) zunächst für den internen Gebrauch entwickelt, 1999 jedoch unter den Bedingungen der GPL freigegeben. Im deutschen Sprachraum aufgrund zunächst rein französischer Dokumentation weitgehend unbekannt, erfreut sich die Software im frankophonen Sprachraum und zunehmend auch im angloamerikanischen Raum zunehmender Beliebtheit. Eine englischsprachige Dokumentation der Software steht seit September 2011 offiziell zu Verfügung.\nIn direkten Vergleichen im Rahmen von Simulationsprojekten zur Reaktorsicherheit zeigte sich die Software kommerziellen Alternativen zumindest ebenbürtig. Sie stellt eine der Kernkomponenten von CAE Linux dar.\nMaßgeblich eingesetzt wurde Code_Aster unter anderem in der Entwicklung des (EPR).\nDer Quellcode umfasst derzeit 1,2 Millionen Zeilen und trägt die Freigabe der EDF Nuclear Structures Safety Authority. Die Dokumentation umfasst 13.000 Seiten. 2.000 Testbeispiele sind verfügbar, anhand derer die Funktionalität des Programmes getestet werden kann.\n\nDie Software bietet Finite-Elemente-Analyse und Numerische Simulation zur Berechnung mechanischer und thermischer, statischer und dynamischer Effekte für feste und flüssige Stoffe. Dabei können auch akustische und materialspezifische Einflüsse (u. a. Ermüdung, Korrosion) berücksichtigt werden. Es bestehen Schnittstellen zu anderen Programmen, darunter beispielsweise auch zu Salome. Die Software ist unter Linux und verschiedenen Unix-Derivaten einsetzbar, es bestehen aber auch nicht-offizielle Portierungen für Windows, z. B. als FEM-Erweiterung zu dem Zahnradprogramm KissSoft (Version 10.3) oder als kommerzielle Windows-Version (11.x) der Firma Alneos.\n\n"}
{"id": "5373096", "url": "https://de.wikipedia.org/wiki?curid=5373096", "title": "Roland CR-78", "text": "Roland CR-78\n\nRoland CR-78 ist ein Drumcomputer, der 1978 auf den Markt kam. Nach den Standards moderner elektronischer Musik wirkt das Gerät sehr einfach, für die damalige Zeit stellte es aber eine enorme Verbesserung der Drumcomputertechnologie dar: Der \"CR-78\" war der erste programmierbare Drumcomputer auf dem Markt.\n\nWenn man das hölzerne Gehäuse und die eingespeicherten Rhythmen wie Walzer, Rock, Tango, Bossa Nova oder Rumba betrachtet, ist es naheliegend, dass die Designer den CR-78 im Wesentlichen als ein Begleitinstrument für Orgeln gesehen haben. Er wurde jedoch ein beliebtes Instrument bei New-Wave- und Elektronikmusikern in den späten 1970er- und den frühen 1980er-Jahren. Die Maschine ist auch auf einigen bekannten Liedern zu hören, wie zum Beispiel \"Heart of Glass\" von Blondie oder \"In the Air Tonight\" von Phil Collins.\n\nDie Klangerzeugung des \"CR-78\" ist analog. Ein früher Intel-Mikroprozessor wurde zur digitalen Steuerung der Bearbeitungsmöglichkeiten eingebaut. Die Instrumente, die simuliert werden sollen, klingen nicht natürlich, sondern haben einen eigenen Klang. Der \"CR-78\" ebnete Roland den Weg zum Erfolg der späteren TR-808.\n\n"}
{"id": "5373159", "url": "https://de.wikipedia.org/wiki?curid=5373159", "title": "Mnemosyne (Software)", "text": "Mnemosyne (Software)\n\nMnemosyne ist ein von Peter Bienstman entwickelter freier und kostenloser Vokabeltrainer. Inspiriert war Mnemosyne ursprünglich vom kommerziellen Programm SuperMemo, hat sich jedoch weit darüber hinaus entwickelt. Mnemosyne verwendet eine leicht modifizierte Variante einer älteren, aber robusteren Version des SuperMemo-Algorithmus SM2.\n\n\nMnemosyne wurde in Python geschrieben und kann deshalb auf einer Vielzahl von Betriebssystemen eingesetzt werden.\n\n"}
{"id": "5377608", "url": "https://de.wikipedia.org/wiki?curid=5377608", "title": "TRICAD MS", "text": "TRICAD MS\n\nTRICAD MS ist ein CAD/CAE-Planungswerkzeug mit 3D-Branchenlösungen für die Technische Gebäudeausrüstung, die Digitale Fabrikplanung, den Anlagenbau sowie die Berechnung von Hüllkurven in der Verkehrsplanung. Das Software-Werkzeug basiert auf dem CAD-Kernsystem MicroStation von Bentley Systems.\n\nBegonnen hat die Entwicklung von TRICAD MS im Jahre 1967, als der Ingenieur Reinhard Meier sich mit der Triplan GmbH selbständig machte. In den 1960er Jahren gehörte Meier zu den Pionieren, die das maßstäbliche Industriemodell als Planungshilfsmittel einsetzten. \n\n1979 entschloss sich Meier, als weiteres Planungshilfsmittel in ein CAD-System zu investieren. Mit TRICAD stand schon bald eine ganze Produktfamilie von der Rohrleitungs- und Anlagenplanung bis zu einer Lösung für alle Gewerke der Gebäudetechnik zur Verfügung. \n\n1995 fiel die strategische Entscheidung, TRICAD auf die MicroStation-Plattform zu portieren. Ab 1998 war TRICAD MS dann auch kommerziell verfügbar.\n\nTRICAD MS bietet als einziges CAD/CAE-Planungswerkzeug für alle Gewerke der Gebäudetechnik- und Fabrikplanung spezifische Module (Heizung, Lüftung, Sanitär, Elektro, Sprinkler, Fördertechnik, Anlagenbau, Stahlbau, Lacktechnik, Schleppkurven, Layout etc.). In allen Modulen arbeitet der Planer mit einer einheitlichen Bedienoberfläche.\n\nEin wesentliches Merkmal von TRICAD MS ist somit die Möglichkeit der integrierten, gewerkeübergreifenden Planung. Auch die Integration von Berechnungs-Algorithmen ist möglich (Kanalnetze, Rohrnetze, Abwasser und Heizkörper; VDS/FM-Sprinklerberechnung über IDAT).\n\nDie ‚Intelligenz’ der Software steckt in ASCII-Files (DGN-Files mit allen technischen Informationen); eine komplexe Datenbank entfällt. So bildet das generierte 3D-Modell das komplette Gebäude, die komplette Fabrik ab – alle Bauteile liegen in einer parametrierbaren Geometrie vor, sind beliebig konfigurierbar. Über einen Infoknopf sind alle technischen Informationen abrufbar, ohne TRICAD MS selbst im Einsatz zu haben.\n\nTRICAD MS ist zur Planung der technischen Gewerke im Bereich Automotive seit Jahren Branchen-Standard. Im Auftrag des VDA (Verband der Automobilindustrie) hat der Anbieter VenturisIT eine Reihe von Modulen zur Planung der Technischen Gebäudeausrüstung unter anderem der Produktionshallen von Fahrzeugen entwickelt.\n\nNamhafte Hersteller wie Daimler AG, Volkswagen AG, Audi AG, BMW AG, Skoda Auto Deutschland GmbH und SEAT Deutschland GmbH schreiben den Einsatz dieser Software internen wie externen Planern zur Fabrikplanung explizit vor.\n\nDazu kann in TRICAD MS eine firmenspezifische Umgebung erstellt werden (beispielsweise vorhanden bei Audi, BMW, Daimler, Fraport, VW, Bayer etc.). Darin sind alle Vorgaben für Stricharten, Strichstärken und Layer definiert. Die Medienarten wie beispielsweise Zuluft, Abluft etc. sind ebenfalls definiert, ebenso die Rohrmaterialien und Bauteile. Über ein spezielles Quali-Tool kann die Übereinstimmung mit den Planungsvorgaben überprüft und gegebenenfalls sichergestellt werden.\n\n\n"}
{"id": "5377965", "url": "https://de.wikipedia.org/wiki?curid=5377965", "title": "Tabletcomputer", "text": "Tabletcomputer\n\nEin Tablet () (, US-engl. „Notizblock“) oder Tabletcomputer, Tablet-PC, selten auch Flachrechner, ist ein tragbarer, flacher Computer in besonders leichter Ausführung mit einem Touchscreen, aber, anders als bei Notebooks, ohne ausklappbare mechanische Tastatur. Ein Tablet ist eine spezielle Bauform eines Personal Computers, die zu den Handheld-Geräten zählt.\n\nAufgrund der leichten Bauart und des berührungsempfindlichen Bildschirms zeichnen sich Tablets durch eine einfache Handhabung aus. Die Geräte ähneln in Leistungsumfang, Bedienung und Design modernen Smartphones und verwenden meist ursprünglich für Smartphones entwickelte Betriebssysteme. Wegen der Bildschirmtastatur, die nur bei Bedarf eingeblendet wird, eignen sich Tablets weniger gut für das Schreiben größerer Textmengen. Tablets sind meist mit nicht wechselbaren Akkus ausgestattet.\n\nBluetooth und WLAN gehören beim Tablet zum Standard. Darüber hinaus werden viele Geräte auch mit einem integrierten Modem (u. a. UMTS oder LTE als Datenfunk) angeboten, sind dann also mobil telefonisch nutzbar, ohne auf ein externes mobiles Modem (etwa über einen USB-Port) angewiesen zu sein.\n\nDie verkabelte Anbindung an externe Geräte ist für die meisten Tablet-PCs nicht vorgesehen.\n\nTabletcomputer werden zunehmend auch für die Fernsteuerung digitaler Geräte eingesetzt, wie zum Beispiel Kameras, AV-Receivern, Fernsehgeräten oder Quadrocoptern.\n\nDer Funktionsumfang eines Tablets kann durch Zusatzprogramme (genannt \"\", von ) erweitert werden. Einen immer größeren Stellenwert bekommt der Tablet-Journalismus, wobei das Tablet als Informationsmedium benutzt wird, um journalistisch aufbereitete Medieninhalte zu konsumieren oder zum Teil auch selbst zu schaffen.\n\nKonzepte und Designstudien für diese Gerätegattung existieren bereits seit Ende der 1980er Jahre. Eines der ersten Geräte dieser Art war 1989 das GRiDPad von GRiD Systems, das allerdings keine große Marktbedeutung erringen konnte. Die als Personal Digital Assistant (PDA) bezeichneten Geräte waren zu Beginn der Entwicklung aufgrund der technischen Möglichkeiten und des fehlenden breitbandigen mobilen Internetzugangs hauptsächlich auf Kalender-, Adress- und Aufgabenverwaltung beschränkt. Lange Zeit in den 1990ern marktdominierend waren die PDAs bzw. Organizer der Firma Palm (etwa der \"Palm Pilot\"), die über einen Stift und Handschrifterkennung bedient wurden.\n\nUnter dem Begriff \"Surfpad\" wurde im Jahr 2001 das SIMpad, ein vom deutschen Hersteller Siemens in der Schweiz auf den Markt eingeführter Microsoft Tablet-PC, vermarktet. In Deutschland eingeführt wurde dieses Gerät vom Netzbetreiber Telekom unter dem Namen \"T-Sinus Pad\". Der Name wurde gewählt, um sich von mobilen Internetgeräten ohne bzw. mit eingeschränkter Multimediafähigkeit, z. B. Mobiltelefonen mit WAP-Unterstützung, abzugrenzen. Das des Betriebssystems endet in einem Webbrowser und lädt schon während des Systemstarts benutzerspezifische Webinhalte in die für das Surfen im Internet angepasste Benutzeroberfläche. Doch keines dieser Geräte konnte sich auf dem Markt behaupten.\n\nIm Jahr 2010 brachte der US-amerikanische Hersteller Apple das iPad heraus und erzielte mit einem großen Verkaufserfolg den Durchbruch für diese Produktkategorie. Zahlreiche andere Hersteller folgten daraufhin mit ähnlichen Geräten, was letztendlich erhebliche Marktveränderungen im Bereich der tragbaren Computer nach sich zog. Insbesondere ging der Absatz von Notebook-PCs und Netbooks zugunsten der Tablets deutlich zurück.\n\nDie Bauform wird teilweise auch als \"Pad\" oder \"Surfpad\" bezeichnet. In dieser Geräteklasse findet man oft Ein-Chip-Systeme mit Embedded-Betriebssystemen. Das Gerät besteht dabei aus einem monolithischen Block, welcher das Display und sämtliche anderen Bauteile enthält. Dabei sind nur wenige Schnittstellen für Peripheriegeräte vorhanden. Teilweise existiert nur eine einzelne Schnittstelle, die über Adapter Standardschnittstellen wie USB oder VGA bereitstellt. Die Displays sind häufig kapazitive Touchscreens, weshalb die Geräte nur mit den Fingern oder speziellen Eingabestiften bedient werden können. Der Hersteller Lenovo setzt bei dem Modell Yoga Tablet 2 Pro als zusätzliches Ausgabegerät auf einen integrierten Beamer.\n\nSeit etwa 2013 bieten Hersteller auch Geräte an, die eine Tastatur besitzen und somit ein klassisches Notebook ersetzen sollen. Hierunter findet man zwei unterschiedliche Bauformen: zum einen die \"Convertibles\" (von ) und zum anderen die \"Detachables\" (von ).\n\nBei der Gerätebauform der \"Convertibles\" ist die Tastatur fest mit dem Display verbunden und lässt sich zusammenklappen wie ein Notebook. Die Besonderheit liegt darin, dass das Scharnier eine 360-Grad-Drehung zulässt, sodass die Tastatur bis auf den Rücken des Displays aufgeklappt werden kann. Die Tastatur ist so nicht mehr sichtbar und das Gerät lässt sich nun bedienen wie ein ganz normaler Tablet-Computer. Nachteil dieser Bauform: das zusätzliche Gewicht der Tastatur macht das Tablet etwas schwerer und unhandlicher – und verschlechtert damit ein wenig seine Haupteigenschaften.\n\nBei \"Detachables\" lässt sich das Display von der Tastatur abnehmen. Somit kann man selbst entscheiden, ob man die Tastatur unterwegs dabei haben möchte oder nicht. Das Gerät lässt sich als normales Tablet nutzen und wenn man längere Texte schreiben möchte, kann die Tastatur einfach angedockt werden. Es gibt unterschiedliche Ausführungen der mechanischen Verbindung. Einige Geräte lassen sich mit einem mechanischen Verschlussriegel sehr sicher und fest verbinden, andere hingegen werden nur magnetisch aneinander gehalten. Auch die Ausführung der Datenverbindung ist höchst unterschiedlich. Einige verbinden sich mittels Steckkontakten, andere bauen lediglich eine Bluetooth-Verbindung auf. Nachteil ist in der Regel, dass die Displayeinheit schwerer ist als die Tastatur. Somit kippt das Gerät nach hinten um, wenn man das Display zu weit öffnet. Damit das nicht passiert, ist bei den meisten Geräten der Öffnungswinkel konstruktionsbedingt klein gehalten – was oft zu Blickwinkelproblemen in heller Umgebung führt. Es gibt sogar Geräte (bspw. Lenovo Miix 2), bei denen sich der Winkel des Displays zur Tastatur überhaupt nicht verstellen lässt.\n\nDer berührungsempfindliche Bildschirm eines Tablets wird mit dem Finger oder einem Eingabestift bedient. Zur Eingabe von Text erscheint, wenn notwendig, eine virtuelle Tastatur auf dem Display. Bei einigen Geräten ist alternativ auch der Anschluss einer externen, mechanischen Tastatur und weiterer Geräte mittels Funk, z. B. Bluetooth möglich. Spracheingabe und Gesten-Erkennung sind nach Einsatzgebiet gut einsetzbar.\n\nSehr verbreitet sind tragbare Tabletcomputer mit Displays 8 bis 12 Zoll. Tabletcomputer werden mit Displays bis 84 Zoll Bilddiagonale in Serie gefertigt. Ab 42 Zoll werden sie als InfoPoint, digitale Tafel oder Zeichenbrett eingesetzt.\n\nIm Gegensatz zu Notebooks, Servern, Workstations und regulären PCs, bei denen x86-kompatible Mikroprozessoren dominieren, bilden diese bei Tablets eine Minderheit, wie beispielsweise der Microsoft Tablet-PC. Äquivalent zu den Smartphones dominieren im Tablet-Markt derzeit (2016) Prozessoren mit ARM-Architektur.\n\nAnstelle einer Festplatte wird bei Tablet-PCs in der Regel Flash-Speicher als Massenspeicher verwendet. Einige Tablets der Firmen Archos und Sony sind jedoch mit einer Festplatte bzw. SSD-Platte ausgestattet.\n\nAls Betriebssysteme werden Android, iOS oder Windows 10 eingesetzt.\n\nGeräte mit Android-Betriebssystem hatten 2013 einen Marktanteil von 62 % (2. Quartal 2016: 65 %), während Geräte mit iOS einen Anteil von 36 % hielten (2. Quartal 2016: 26 %). Der Windows-Marktanteil stieg von 1 % auf 9 % (2. Quartal 2016).\n\nLaut einer vom Bitkom in Auftrag gegebenen Umfrage aus dem Jahr 2015 werden Tabletcomputer in Deutschland vor allem zu Hause genutzt: Jeder dritte Tablet-Nutzer (30 %) gibt an, sein Gerät ausschließlich daheim zu nutzen. Und ein weiteres Drittel (31 %) setzt den Tabletcomputer überwiegend zu Hause ein. Nur 6 % gebrauchen ihr Gerät ausschließlich oder überwiegend unterwegs. Daheim sind die beliebtesten Einsatzorte für den Tabletcomputer das Sofa (82 %), das Bett beziehungsweise der Balkon oder Garten (jeweils 50 %), der Schreibtisch (47 %) und die Küche (39 %). 7 % nehmen ihr Gerät mit ins Bad.\n\n\n"}
{"id": "5380463", "url": "https://de.wikipedia.org/wiki?curid=5380463", "title": "VT180", "text": "VT180\n\nVT180, Codename „Robin“, war ein ASCII-Computer-Terminal und Mikrocomputer, gebaut von Digital Equipment Corporation (DEC) in den Jahren 1982 bis 1983. Er basierte auf dem VT100-Terminal und beinhaltete zusätzlich eine Platine mit Z80-CPU und 64 kB RAM. Außerdem verfügte er über zwei oder vier externe Diskettenlaufwerke für einseitige Disketten mit 180 kB sowie drei programmierbare serielle Schnittstellen für Kommunikation, Drucker und allgemeinen Bedarf. Somit konnte er wahlweise als Terminal oder als Computer verwendet werden.\n\nDer Computer lief unter dem Betriebssystem CP/M, Version 2.2, und war daher in der Lage, die damals verbreitete Software (ggf. nach Adaption) zu verarbeiten, beispielsweise WordStar, SuperCalc, MBASIC oder dBASE.\n\nMit dem Ende der VT100-Serie wurde auch das Modell VT180 eingestellt. Ein direktes Nachfolgemodell für diesen Computer kam nicht auf den Markt. Mittlerweile waren leistungsfähigere Computer auf Basis der 16-Bit-Mikroprozessoren Intel 8088 oder Intel 8086 verfügbar. Jedoch beinhaltete der danach hergestellte DEC-Computer „Rainbow 100“ mit Z80- und 8088-CPU die meisten VT180-Funktionalitäten als Untermenge.\n\nDas VT180/Robin-Diskettenformat konnte nicht nur vom Rainbow 100 verarbeitet werden, sondern auch von einigen anderen Computersystemen, wie den ersten tragbaren Computern Osborne 1 und Kaypro II oder später auch dem IBM-PC unter dem Betriebssystem MS-DOS mit Zusatzsoftware.\n\n"}
{"id": "5381078", "url": "https://de.wikipedia.org/wiki?curid=5381078", "title": "Liste der Röhrencomputer", "text": "Liste der Röhrencomputer\n\nRöhrencomputer wurden in der Zeit der 1940er bis Anfang der 1960er Jahre gebaut und haben heute ausschließlich museale Bedeutung.\n\n"}
{"id": "5381141", "url": "https://de.wikipedia.org/wiki?curid=5381141", "title": "Röhrencomputer", "text": "Röhrencomputer\n\nRöhrencomputer (auch bezeichnet als Röhrenrechner, Elektronenrechner oder veraltet als Elektronenhirn oder Elektronengehirn) auch als \"Computer der ersten Generation\" bezeichnet, wurden von den 1940er bis Anfang der 1960er Jahre gebaut und bestehen bei den zentralen Schaltelementen aus Elektronenröhren. Als bekannteste Röhrenrechner gelten der ENIAC (USA) und der Colossus (Großbritannien). Für Deutschland relevant waren insbesondere der Zuse Z22, die PERM sowie der D1 und der D2 aus der DDR.\n\nCharakteristisch für diesen historischen Computertyp waren im Vergleich zu den folgenden Rechneranlagen große Ausmaße von einigen Metern bis zu einigen 10 m, ein hoher Leistungsbedarf im Bereich von einigen 10 kW aufwärts und eine latente Störanfälligkeit. Röhrenrechner stellen den Übergang zwischen den Analogrechnern zu den auf Halbleitertechnik basierenden Minirechnern dar.\n\n"}
{"id": "5384981", "url": "https://de.wikipedia.org/wiki?curid=5384981", "title": "Visual Studio One", "text": "Visual Studio One\n\nVisual Studio One (\"Die Zeitung für die Microsoft Developer Community\") war eine Fachzeitschrift für Softwareentwickler. Sie erschien seit der Erstausgabe 06/2005 (Oktober) regelmäßig alle zwei Monate und präsentierte Artikel zu Development mit Microsoft-Technologien. Herausgeber war der im oberbayerischen Burghausen ansässige IT-Schulungsanbieter ppedv.\n\nVisual Studio One war ein Formathybrid aus Zeitung und Zeitschrift. Seit der Erstausgabe Ende 2005 hatte das Heft zwei Redesigns erfahren, durch die es seine Magazineigenschaften immer mehr durch typische Zeitungsfeatures ergänzte.\n\nSeit Erscheinen der letzten Ausgabe Nummer 67 im Oktober 2017 ist es nicht mehr möglich, die Zeitschrift im Abo zu beziehen.\n\nVon der Erstausgabe 06/2005 bis zur letzten des Jahrgangs 2007 erschien die Zeitschrift im herkömmlichen Magazinformat DIN A4 mit Glanzumschlag.\n\nMit Ausgabe 01/2008 ging der Verlag dazu über, das Heft im Überformat und neuem Layout herauszugeben. Hier zeigten sich zum ersten Mal Einflüsse des Zeitungsformates: Das Cover präsentierte statt eines seitenfüllenden Titelbildes zusätzlich zu den Headlines Artikelteaser im Zeitungsstil. Das Innenlayout wurde von drei auf zwei Texspalten reduziert.\n\nZum Jahresanfang 2010 erfuhr Visual Studio One sein bis dato letztes Redesign. Das Überformat blieb bestehen. Das Innenlayout wurde zeitungstypisch in Umbrüchen flexibler und farblich aufgelockert. Die deutlichsten Änderungen erfuhr das Cover: Der Logobalken wurde von nun an vertikal an der linken Seite platziert, die Headlines und Teaser dreispaltig verteilt und durch eine Vorschau auf den am Inhaltsverzeichnis folgenden Comic ergänzt.\n\nDas Themenspektrum umfasste Software-Entwicklung mit Microsoft-Technologien. Laut Cover befanden sich darunter „.NET, Microsoft Visual Studio, C#, Team System, Visual Basic, Phone, Windows Presentation Foundation, SharePoint, Internet Explorer, Microsoft SQL Server, Microsoft Silverlight und Windows Communication Foundation“. Themenübersichten zur aktuellen sowie zur kommenden Ausgabe fanden sich regelmäßig auf der Homepage.\n\nSeit Ausgabe 01/2010 führte Visual Studio One als einzige Developer-Zeitschrift im deutschsprachigen Raum einen Comic. Hauptcharakter des Comics war das Maskottchen der Zeitschrift, der „DOT.NERD“. Dieser traf in den verschiedenen Ausgaben auf Persönlichkeiten aus der Entwicklerszene. Dabei waren Ralf Westphal und Stefan Lieser von der Clean Code Developer-Initiative sowie Jan Schenk und Cortessa Kostis von msdn tv.\n\n"}
{"id": "5386691", "url": "https://de.wikipedia.org/wiki?curid=5386691", "title": "Ural (Computer)", "text": "Ural (Computer)\n\nUral ist die zahlenmäßig bedeutendste Serie von Computern der ersten Generation, die in Pensa, Sowjetunion zwischen 1956 und 1964 gebaut wurden. Von diesen Röhrencomputern (Modell \"Ural-1\" bis \"Ural-4\") wurden in Pensa insgesamt 139 Anlagen produziert. Als Speicher dienten Kernspeicher. Lochkarten waren als Ein- und Ausgabemedien in Gebrauch. Die Stellfläche betrug knapp 100 Quadratmeter. Mit ca. 12.000 Fließkommaberechnungen pro Sekunde lag die Serie Ural leistungsmäßig deutlich hinter zeitgenössischen westlichen Rechnern. Der Chefkonstrukteur des Computersystems war Baschir Iskandarowitsch Ramejew. Eine Nachfolgeserie, die von 1964 bis 1971 gebaut wurde, hatte die Modellnummern \"Ural-11\" bis \"Ural-14\" und arbeitete auf modernerer Halbleiterbasis.\n\n"}
{"id": "5388939", "url": "https://de.wikipedia.org/wiki?curid=5388939", "title": "IBM 7070", "text": "IBM 7070\n\nDie IBM 7070 war ein Datenverarbeitungsrechner der Firma IBM, welcher von IBM im Juni 1960 vorgestellt wurde. Die 7070 Serie war der erste transistorbasierte, speicherprogrammierbare Rechner der 700/7000 series der Firma IBM.\n\nDie 7070 wurde als transistorisierte Nachfolgerin der IBM 650 entwickelt, dabei wurde der Trommelspeicher der 650 mit sehr viel schnellerem Kernspeicher ersetzt. Die 7070 war nicht befehlskompatibel zur 650, die die Möglichkeit besaß, bei jedem Befehl zusätzlich eine Sprungadresse zur optimalen Nutzung des Trommelspeichers anzugeben, was für einen Computer mit wahlfreiem Kernspeicherzugriff unnötig und verschwenderisch gewesen wäre. Deshalb war ein Emulator nötig, um alte Programme laufen zu lassen.\n\nDie 7070 wurde auch als Nachfolger für die IBM 705 vermarktet. Die dabei aufgetretenen gravierenden Inkompatibilitäten, einschließlich der Unmöglichkeit, den Zeichenvorrat der 705 vollständig abzubilden, zwangen die IBM, die IBM 7080 als vollständig kompatible \"transistorisierte IBM 705\" zu entwickeln.\n\nDas verwendete Datenformat bestand aus Worten aus 10 Dezimalziffern plus Vorzeichen. Die Ziffern wurden im Zwei aus Fünf Code gespeichert. Die Kernspeichergröße der ausgelieferten Maschinen konnte zwischen 5.000 und 9.990 Worten liegen. Die Rechengeschwindigkeit der CPU lag bei 27 kIPS. Der monatliche Mietpreis eines typisch ausgestatteten Systems betrug 17.400 US-Dollar, der Kaufpreis 813.000 US-Dollar.\n\nSpäter vorgestellte Rechner dieser Baureihe waren die IBM 7072, eingeführt im November 1962, und die IBM 7074 (November 1961), von der heute eine im Deutschen Museum München ausgestellt ist.\n\nNachfolger war das System/360, das von IBM 1964 vorgestellt wurde.\n\n"}
{"id": "5396218", "url": "https://de.wikipedia.org/wiki?curid=5396218", "title": "TortoiseHg", "text": "TortoiseHg\n\nTortoiseHg ist ein freier Client für den Versionsverwaltungs-Dienst Mercurial. Es steht unter der GNU General Public License (GPL).\n\nTortoiseHg ist als Shell-Erweiterung implementiert. Es integriert sich in den Windows-Explorer und Gnome/Nautilus und ist daher außerhalb und unabhängig von einer integrierten Entwicklungsumgebung verwendbar.\n\nAls Kernaufgabe der Software wird die Versions-, Revisions- und Sourcekontrolle beschrieben. Um Mercurial unter Windows und Linux ähnlich einfach benutzbar wie Subversion zu gestalten, ließ man sich von den erfolgreichen Tortoise-Plugins für Subversion und CVS inspirieren und leiten. So wurde z. B. das \"Iconset\" teilweise aus TortoiseSVN übernommen.\n\n\n"}
{"id": "5432489", "url": "https://de.wikipedia.org/wiki?curid=5432489", "title": "CoreExpress", "text": "CoreExpress\n\nCoreExpress-Module sind vollständige Computer-on-Module (COM). Dies sind hochintegrierte, kleine und kompakte PCs, die in einem Embedded-Computer-Board-Design genutzt werden können, ähnlich wie eine integrierte Schaltung. CoMs integrieren Prozessor, Speicher, Grafik und BIOS sowie allgemeine I/O-Schnittstellen. Diese Schnittstellen sind legacy-free und verwenden nur digitale Busse, wie PCI Express, Serial ATA, Ethernet, USB und HD Audio. Alle Signale sind auf einem high-speed, 220-Pin-Steckverbinder verfügbar. Dieser Typ wird auch bei COM Express eingesetzt, ist jedoch zu CoreExpress elektrisch nicht kompatibel. Obwohl derzeit verfügbare Implementierungen Intel-Prozessoren verwenden, ist die Spezifikation auch offen für andere CPU-COM-Lösungen.\n\nCoreExpress Module werden auf einem Trägerboard (Carrier) montiert, das die für die jeweilige Anwendung erforderlichen Peripherie enthält. Auf diese Weise können kleine, hochspezialisierte Embedded-Computer-Systeme aufgebaut werden.\n\nDer CoreExpress-Formfaktor wurde ursprünglich von LiPPERT Embedded Computers entwickelt, und 2010 durch die Small Form Factors Special Interest Group (SFF-SIG) standardisiert.\n\nDie CoreExpress-Spezifikation wird von der SFF-SIG betreut und kann von deren Website heruntergeladen werden.\nDie aktuelle Version 2.1 stammt vom 23. Februar 2010.\n\nDie Spezifikation definiert die Modulgröße mit 58 mm × 65 mm.\n\n\n"}
{"id": "5433353", "url": "https://de.wikipedia.org/wiki?curid=5433353", "title": "Imagine (Viewer)", "text": "Imagine (Viewer)\n\nImagine ist ein kostenloses Bildbetrachtungs-Programm des südkoreanischen Programmierers Chun Sejin. Es läuft unter Windows und zeichnet sich vor allem durch seine Geschwindigkeit und geringe Größe aus.\n\nWie die meisten Bildbetrachter hat Imagine einen Vorschau- und einen Betrachtungsmodus. Das Programm unterstützt viele Bildformate, auch gepackte Archive und verschiedene Sprachen. Verschiedene Funktionen zur Bildbearbeitung sind integriert, z. B. Drehen, Größe ändern, Farbmanipulationen, Effektfilter. Weiterhin verfügt Imagine über eine Plug-in-Schnittstelle, Exif-Anzeige, Animations-Bearbeitung und einen Batch-Converter. Die Tastenkombinationen für sämtliche Bedienfunktionen können beliebig editiert werden.\n\nDie erste Version erschien im Jahr 2003. Zum Download angeboten wird eine ANSI-, Unicode- und 64-Bit-Version des Programmes, jeweils als Installationsdatei oder als Stand-Alone-Archiv. Die Archive sind jeweils ca. 1 MB groß (Version 1.0.7). Als Hardwareanforderungen werden eine Pentium-CPU und 32 MB RAM angegeben. Das Programm ist Freeware (Donationware), es kann ohne jede Einschränkung benutzt werden. Für eine Spende ist der Autor dankbar.\n\n"}
{"id": "5435804", "url": "https://de.wikipedia.org/wiki?curid=5435804", "title": "Anlagensimulation", "text": "Anlagensimulation\n\nUnter Anlagensimulation versteht man die \"virtuelle Inbetriebnahme\" von Automatisierungsanlagen an in Echtzeit simulierten Anlagenmodellen (Hardware in the Loop).\n\nOftmals trennt man die Automatisierungshardware (z. B. eine Speicherprogrammierbare Steuerung) am Feldbus auf und simuliert die Eingabe- und Ausgabebaugruppen sowie das dynamische Verhalten des Prozesses (siehe auch Dynamisches System). Das exakte dynamische Verhalten des Prozessmodells ist hierbei kein Schwerpunkt. Wichtig bei der virtuellen Inbetriebnahme sind das Finden von Vorzeichenfehlern in der Anwendersoftware der Automatisierungsgeräte und die Austestung von kritischen Prozesszuständen, die in der realen Anlage nicht bzw. nur mit erheblichem Aufwand erprobt werden können. Das Finden von Fehlern in der Logik (z. B. fehlende oder fehlerhafte Verknüpfungen) ist ein weiterer Schwerpunkt der Anlagensimulation.\n\nDie Simulation soll den zeitlichen und finanziellen Aufwand für die Inbetriebnahme reduzieren und die Qualität der Anwendersoftware verbessern. Außerdem ist es somit dem Automatisierungsunternehmen möglich, die durchgeführten Vortests lückenlos durch Archivierung der Testdaten zu dokumentieren.\n\n"}
{"id": "5435945", "url": "https://de.wikipedia.org/wiki?curid=5435945", "title": "SYSCAD", "text": "SYSCAD\n\nSYSCAD ist eine 2D-CAD-Zusatzsoftware für Autodesk AutoCAD und wird von der deutschen Firma SYSCAD TEAM GmbH entwickelt.\n\nMit der Zusatzprodukt SYSCAD werden im AutoCAD sehr einfach Fenster, Türen und Fassaden aller führenden europäischen Profilsystemlieferanten gezeichnet und mit Stücklisten ausgewertet. \n\nSYSCAD wird bei Fassadenplanern und Metallbauern eingesetzt. Im Bereich Schlosserei und Metallbau wird SYSCAD in Verbindung mit dem kostenlosen Profilsystem STAHL/ALU/HOLZ für das Konstruieren von Geländern, Podesten oder Unterkonstruktionen für Aufsatzfassaden verwendet. Hier sind ebenfalls Stücklisten möglich.\n\nDie Software ist europaweit im Einsatz und wird über örtliche Fachhändler verkauft, die zusätzlich auch die Schulung und die Betreuung der Anwender übernehmen. \nIn diversen Fachzeitschriften für die Metallbau/Holzbau-Branche wird regelmäßig über die Software berichtet.\n\nVerfügbar für:\n\nDie erste Version der Software wurde im Jahr 1989 im Hause des Profilsystem-Lieferanten W. HARTMANN & Co. fertiggestellt. Das Entwicklungszentrum dieser Firma war in Nürnberg angesiedelt. SYSCAD war bis 2001 nur für die Profilsysteme der Fa. W. HARTMANN & Co. verfügbar. Durch die Fusion von Hueck und W. HARTMANN & Co. ab diesem Zeitpunkt auch für die Profilsysteme beider Firmen. Nach der Schließung des Entwicklungszentrums im Jahre 2003 konnten die Entwickler alle Rechte an dem Programm übernehmen und für alle anderen Profilsysteme öffnen.\n"}
{"id": "5437863", "url": "https://de.wikipedia.org/wiki?curid=5437863", "title": "Boundin’ – Ein Schaf ist von der Wolle", "text": "Boundin’ – Ein Schaf ist von der Wolle\n\nBoundin’ – Ein Schaf ist von der Wolle ist ein fünfminütiger animierter Kurzfilm aus dem Jahr 2003, der von den Pixar Animation Studios produziert wurde und als Vorfilm der Pixar-Produktion \"Die Unglaublichen – The Incredibles\" in die Kinos kam.\n\nDer Film handelt von einem Schaf, das im amerikanischen Westen lebt. Es hat ein wunderschönes Fell und kann durch seinen Tanz alle anderen Tiere begeistert zum Tanzen mitreißen. Als eines Tages der Schafhirte kommt, nimmt er das Schaf, schert es und lässt es anschließend nackt zurück. Es schämt sich nun und verliert dadurch seine Fähigkeit, die anderen Tiere durch seinen Tanz zu begeistern. Zudem lachen ihn die anderen auch noch aus.\nAls es sich weinend zurückgezogen hat, kommt ein Jackalope vorbei und nimmt sich seiner an. Er lehrt das Schaf durch ein Lied, wie es dem ewigen Auf und Ab des Lebens begegnen muss. Das Schaf nimmt sich diese Worte zu Herzen und sein Lebensmut kehrt zurück, ebenso seine Fähigkeit zu tanzen. Als seine Wolle nachgewachsen ist und der Schäfer erneut kommt, begegnet ihm das Schaf mit Gleichmut und lässt sich von der Schur und dem Zustand der Nacktheit anschließend nicht mehr beeindrucken und tanzt einfach weiter.\n\n\n"}
{"id": "5438856", "url": "https://de.wikipedia.org/wiki?curid=5438856", "title": "1984 (Werbespot)", "text": "1984 (Werbespot)\n\n1984 ist der Titel eines US-amerikanischen Werbespots des Computerherstellers Apple und der Werbeagentur TBWA. Er wurde 1984 während des Super Bowl XVIII aufgeführt und bewarb den zu dieser Zeit erstmals produzierten Macintosh. Der mehrfach ausgezeichnete Spot gilt als Meilenstein der Werbebranche. Regisseur des einminütigen Werbefilms war Ridley Scott.\n\n\"1984\" ist an den gleichnamigen Roman von George Orwell angelehnt. In dem Spot befreit sich eine junge Frau vom Großen Bruder. Er endet mit einem Hinweis auf den Apple Macintosh, und dass das Jahr 1984 nicht wie der Roman \"1984\" werde.\n\nIn einer farblosen und düsteren Welt betreten ausdruckslose Arbeiter im Gleichschritt eine Halle mit einem riesigen Bildschirm (\"Teleschirm\"). Der „Große Bruder“ spricht zu ihnen und preist die „Vereinigung der Gedanken“ an. Ebenfalls zu sehen ist eine junge Frau in Sportkleidung, die auf den Bildschirm zurennt. In der Hand trägt sie einen großen Vorschlaghammer; sie wird von mehreren Personen (der Gedankenpolizei) verfolgt. Die Frau holt zum Befreiungsschlag aus und schleudert ihren Hammer gegen den Schirm, der zerbricht und die Zuschauer mit grellem Licht anstrahlt.\n\nEine Off-Stimme verkündet:\n\nDie namenlose Heldin des Spots trägt ein Top, auf dem schemenhaft ein Macintosh zu sehen ist – die einzige Abbildung des beworbenen Produktes im Film. Sie steht somit für das Unternehmen Apple. Verkörpert wird sie durch die Hammerwerferin Anya Major.\n\nBezüglich des Symbols des Großen Bruders gibt es verschiedene Interpretationen: Eine Rede von Steve Jobs weist darauf hin, dass dadurch der Konkurrent IBM symbolisiert wird, für die Macher des Werbespots verkörpert er die Konformität an sich und beschränkt sich nicht nur auf IBM.\n\nDer Film hatte ein Budget von 900.000 US-Dollar (entspräche heute etwa US-Dollar, bzw. Euro).\n\nSteve Jobs und John Sculley waren von seiner Wirkung begeistert und kauften eine Minute und dreißig Sekunden Werbezeit beim Super Bowl. Der Verwaltungsrat war jedoch nicht überzeugt und wollte daher die schon gekauften 90 Sekunden wieder verkaufen. Da aber nur 30 Sekunden verkauft werden konnten, entstand daraus die bekannte einminütige Fassung.\n\n\n2013, knapp 30 Jahre später, fragte im Rahmen der Überwachungs- und Spionageaffäre 2013 eine interne NSA-Präsentation, .\n\n"}
{"id": "5448639", "url": "https://de.wikipedia.org/wiki?curid=5448639", "title": "IOS (Betriebssystem)", "text": "IOS (Betriebssystem)\n\niOS ist ein von Apple entwickeltes mobiles Betriebssystem für das iPhone, das iPad und den iPod touch. Bis Anfang 2010 hieß es iPhone OS (unter iTunes \"iPhone Software\") auf dem iPhone und iPad OS auf dem iPad, bis es nach dem Lizenzieren des Markennamens \"IOS\" von Cisco Systems ab Version 4 im Juni 2010 in iOS umbenannt wurde und die beiden nur leicht unterschiedlichen Versionen für iPhone und iPad vereint wurden.\n\nAuf iOS basieren ebenfalls ab Version 4 die Apple-TV-Software, die auf der zweiten und dritten Generation des Apple TV läuft und mit der vierten Generation des Apple TV in tvOS umbenannt wurde, sowie watchOS für die Apple Watch.\n\nIm Gegensatz zu Apples Konkurrenten, die ihr eigenes mobiles Betriebssystem oft auch an andere Hardwarehersteller lizenzieren, wird iOS nur auf eigener Hardware von Apple eingesetzt. iOS ist ein macOS-Derivat und basiert auf Darwin, das wiederum auf das ab 1986 entwickelte NeXTStep zurückgeht, ein BSD-Unix mit Mach-Kernel und damals neuartiger grafischer Oberfläche.\n\nDie Entwicklung an iOS begann 2005. Damals war die Idee, einen Tablet-Computer zu entwickeln, von Steve Jobs vorübergehend abgelehnt worden und entschieden worden, dass ein Telefon entwickelt werden sollte. Nach einem ersten „'“ genannten Prototyp, der ein iPod-Clickwheel besaß, übernahm Scott Forstall, damaliger Leiter der Mac-Softwareabteilung bei Apple, die Leitung der Softwareentwicklung des späteren iPhones. Forstalls Plan war es, ein Telefon mit Mac OS X zu entwickeln. Der daraufhin entstandene Prototyp wurde „'“ oder nur „\"P2\"“ genannt. Daraus hervorgegangen sind die Programme „'“ zur Installation von iPhone-Prototypen und „'“, der Einrichtungsassistent des iPhones seit iOS 5. Die Software des Prototyps „P2“ – das spätere iOS – wurde auf einem Power Mac G5 entwickelt und später auf einen schwächeren Power Mac G3 übertragen, um die Leistungsfähigkeit eines Smartphones zu simulieren. Die Entwicklungsmannschaft hatte bald darauf den ersten richtigen iPhone-Prototyp fertiggestellt, der im Gegensatz zum fertigen iPhone ein Freescale MX31-SoC anstatt eines Samsung-S5L-SoCs verwendete. An diesen waren sämtliche für den Betrieb des iPhones notwendigen Komponenten wie Modem per Kabel angeschlossen. Um die Geheimhaltung des Projekts zu gewährleisten, wurden nur wenige Mitarbeiter in die Softwareentwicklung eingeweiht. Parallel zum SpringBoard, der allgemein bekannten Benutzeroberfläche von iOS, wurde die Oberfläche ' entwickelt, von der sich mehrere Diagnoseprogramme starten lassen, und „'“ zur primären Benutzung des iPhones als Telefon. Viele Mitarbeiter am iPhone bekamen das \"\" erst bei der Vorstellung auf der MacWorld zu Gesicht.\n\nDas ursprüngliche Betriebssystem wurde am 9. Januar 2007 zusammen mit dem iPhone auf der \"MacWorld Conference and Expo\" vorgestellt. Damals sagte Steve Jobs „auf dem iPhone läuft OS X“. Der Funktionsumfang fiel verglichen zu heute recht spärlich aus, da das iPhone fast nur die Funktionen eines zur damaligen Zeit herkömmlichen GSM-Telefons unterstützte und bis auf die Bedienung per Touchscreen sowie einige der bekannten vorinstallierten Apps keine Funktionen eines modernen Smartphones bot. Es fehlten sogar essentielle Komponenten, wie etwa die Tastatureingabe von Umlauten oder die Unterstützung der deutschen Sprache. iPhone OS (iOS) unterstützte zu diesem Zeitpunkt ebenfalls noch keine Apps von externen Entwicklern. Steve Jobs war für ein geschlossenes Betriebs- und Anwendungssystem und meinte, Webapps würden den Dienst von nativ installierten Anwendungen genauso zuverlässig und schnell erledigen. Dennoch verkündete Apple am 17. Oktober 2007 auf Drängen des Vorstands und der Medien, im Februar 2008 ein Software Development Kit (SDK) für Entwickler freizugeben.\n\nAm 6. März 2008 veröffentlichte Apple dann das SDK für iOS, um Drittentwicklern die Möglichkeit zu geben, Apps für iOS zu entwickeln. Die damit entwickelten Apps lassen sich ausschließlich im ebenfalls mit iPhone OS 2.0 neu eingeführten App Store veröffentlichen. Die direkte Installation von Apps (ohne Einbeziehung des App Stores) ist von Apple nur im Rahmen des Developer Enterprise Program vorgesehen. Hiermit können Firmen unternehmensinterne Apps erstellen und auf den Geräten des Unternehmens installieren. Seit 2015 ist auch ein Entwicklungspaket (SDK) für den AppleTV (tvOS) verfügbar.\n\nZunächst wurden das iOS des iPhones und das des iPads als unterschiedliche Versionen betrieben (\"iPhone OS\" und „iPad OS“). Technisch gesehen waren die Unterschiede aber gering, daher kann das iPad sämtliche für das iPhone entwickelten Apps ausführen. Dabei gibt es die Option, die App entweder zugunsten einer besseren Sichtbarkeit auf die Bildschirmgröße des iPads anzupassen (sogenanntes \"Upscaling\") oder sie in einem kleinen Fenster anzuzeigen.\n\nIm Juni 2010 benannte Apple dann sein \"iPhone OS\" in \"iOS\" um. Die nötigen Markenrechte lizenzierte Apple von Cisco Systems, die bereits ein Router-Betriebssystem namens „IOS“ vertrieben. Cisco betont, dass ausschließlich Namensrechte lizenziert wurden.\n\nSchließlich führte Apple Ende November 2010 die Betriebssysteme des iPhones und des iPads zusammen. Die erste gemeinsame Version war iOS 4.2.1.\n\nNach der Umstrukturierung der iOS-Softwareentwicklung und der Entlassung von Scott Forstall im November 2012 erfolgte eine komplette Neuausrichtung des iOS-Designs durch den Chef-Designer Jonathan Ive. Das Ergebnis war iOS 7, ein bunteres Betriebssystem, das sich sehr am Flat Design (nicht wie bisher am Skeuomorphismus) orientierte. Visuelle Ebenen (Unschärfen und Transparenz) wurden in vielen der neu designten Standard-Apps hinzugefügt.\n\nAm 9. September 2014 wurde die Apple Watch mit dem dazugehörigen Betriebssystem watchOS (ursprünglich Watch OS), welches auf iOS basiert, vorgestellt. Es besitzt eine angepasste Benutzeroberfläche für das kleinere Display der Apple Watch. Am 24. April 2015 wurde es zusammen mit der Apple Watch veröffentlicht. Die dazugehörige API heißt \"WatchKit\". watchOS 2 wurde auf der WWDC 2015 mit großen Verbesserungen, wie z. B. der nativen Unterstützung für Drittanbieter-Apps, vorgestellt und am 21. September 2015 veröffentlicht.\n\nDas Bedienkonzept von iOS soll möglichst einfach gehalten sein. Somit beschränkt es sich fast ausschließlich auf den Home-Bildschirm – auch \"Springboard\" genannt – und die Synchronisierung mit der iCloud bzw. iTunes. iOS wird fast ausschließlich über den Multitouchbildschirm gesteuert, nur das Sperren und Ausschalten des Geräts wird mit dem \"Lockbutton\" ausgelöst und das Beenden von Anwendungen (genannt \"Apps\") mit dem \"Homebutton\". Dieser kann das Gerät ebenso wie der Lockbutton aus dem Standby-Modus aufwecken. iOS ist darauf ausgelegt, mit allen anderen Apple-Produkten zusammenzuarbeiten. Es unterstützt Mehrfingergesten („Multi Touch“) mit bis zu fünf Fingern.\n\nDer Home-Bildschirm, auch SpringBoard genannt, stellt die eigentliche Benutzeroberfläche von iOS dar. Kennzeichnend für diesen sind die auf einzelnen Seiten als Icons dargestellten Apps, von denen vier im \"Dock\" abgelegt werden können, die Statusleiste am oberen Bildschirmrand mit der Uhrzeit, dem Akkuladestand und gegebenenfalls Signalstärken sowie der Sperrbildschirm mit dem \"Entriegeln\"-Regler und einer Digitaluhr.\n\nErst mit der Softwareaktualisierung 1.1.2 war es möglich, Apps zu verschieben und nach Belieben zu ordnen, zu löschen oder mehrere Seiten mit Apps zu erstellen. Ab Version 2.0 ließen sich weitere Apps von Drittanbietern aus dem App Store installieren. Mit iPhone OS 3.0 kam die aus OS X bekannte Spotlight-Suche hinzu, mit der sich nach Inhalten auf dem iOS-Gerät suchen lässt. Im gleichen Zuge fügte Apple auch eine Copy-Paste-Funktion ein. Ebenso kamen mit iPhone OS 3.0 \"Push-Nachrichten\" hinzu. Push-Nachrichten werden von Apps an das iOS-Gerät geschickt. Es handelt sich dabei um Textnachrichten, die beispielsweise von Nachrichten- oder Instant-Messaging-Apps stammen können.\n\nMit iOS 4.0 war es erstmals möglich, Apps in Ordnern zu ordnen. Außerdem konnte man den bis dahin nicht individualisierbaren schwarzen Hintergrund des Home-Bildschirms mit einem eigenen Hintergrundbild versehen. Zudem wurde mit iOS 4 eine Taskleiste eingeführt, die seitdem mit einem Doppelklick auf den Homebutton aufrufbar ist. In dieser Leiste werden die aktuell verwendeten Apps angezeigt und können direkt von dort aufgerufen werden. Seit iOS 4 werden Apps nicht mehr durch den Homebutton beendet, sondern pausiert, sodass sie schneller geladen werden können. Bei Bedarf werden Apps beendet, um Arbeitsspeicher freizugeben; nach zehn Minuten werden jedoch alle Apps, die keine aktive Aufgabe haben, automatisch beendet.\n\nMit iOS 5 kamen das \"Notification Center\" und Siri hinzu. Das Notification-Center zeigt die letzten Push-Nachrichten an und lässt sich mit einem Wisch von der Statusleiste nach unten aufrufen. Siri ist ein Assistent, der auf Sprachbefehle reagiert und diverse Aufgaben, wie das Erstellen und Absenden von SMS-Nachrichten, ausführen kann.\n\nMit iOS 6 wurde das bis dahin vorinstallierte Google Maps durch Apples eigene, anfangs umstrittene Kartenanwendung Apple Maps ersetzt. Im gleichen Schritt wurde auch die YouTube-App entfernt. Google bietet seitdem für iOS eine kostenlose YouTube-App in Apples hauseigenem App Store an.\n\nSeit iOS 7 ist das sogenannte \"Control Center\" mit einem Wisch vom unteren zum oberen Bildschirmrand aufrufbar. Im Control Center lassen sich zum Beispiel WLAN und Bluetooth aktivieren oder deaktivieren.\n\niOS 8 veränderte nur wenige Dinge am Homebildschirm. Laut Apple bietet iOS 8 vor allem für Entwickler mehr Möglichkeiten.\n\nMit iOS 9 wurden vor allem für die neueren Gerätegenerationen Veränderungen an der Bedienung vorgenommen. Ab dem iPhone 6s und 6s Plus unterstützt iOS 9 eine \"3D Touch\" genannte Technik, mit der sich Untermenüs auf dem Home-Bildschirm und in Anwendungen durch stärkeres \"Drücken\" auf den Bildschirm öffnen lassen. Die aus Vorgängerversionen von iOS bekannte Bedienung durch \"Berühren\" funktioniert weiterhin. Bei den iPad-Modellen ab dem iPad Air sind die Funktionen \"Slide Over\" und \"Picture in Picture\" verfügbar. Damit lassen sich Anwendungen im selben Fenster ausführen, jedoch nicht zeitgleich. Eine Anwendung wird vom Bildschirmrand in das aktive Anwendungsfenster gezogen und wird in diesem Moment aktiv; die zuvor laufende Anwendung wird dabei pausiert. Beim Zurückwischen wird die ursprüngliche Anwendung wieder aktiv. Bei Videodarstellung (etwa durch Videotelefonie oder YouTube-Videos) kann das Videoausgabefeld in der aktiven Anwendung an eine beliebige Stelle gezogen werden und bleibt dabei permanent im Vordergrund. Ab dem iPad Air 2 steht des Weiteren die Funktion \"Split View\" zur Verfügung, bei der zwei separate Anwendungen auf demselben Bildschirm gleichzeitig nebeneinander laufen.\n\nDie Apple-TV-Software der zweiten und dritten Generation des Apple TV verwendet den gleichen Kernel wie das iOS von iPhone, iPod touch und iPad, wird jedoch über eine Fernbedienung mit sieben Tasten gesteuert und besitzt eine eigene Oberfläche, die sich vom iPhone-Home-Bildschirm deutlich unterscheidet. Apple TV ist primär auf Multimediainhalte ausgelegt, nicht auf das Nutzen von Apps.\n\niOS ermöglicht keinen direkten Zugriff des Nutzers auf das Dateisystem oder die Kommandozeile. Apps laufen in einer Sandbox und können nur innerhalb dieser Sandbox lokale Dateien auf dem Gerät lesen und speichern. Apps können nur aus dem App Store geladen oder über einen Entwicklerzugang installiert werden.\n\nDiese Beschränkungen lassen sich durch einen von Apple nicht autorisierten sogenannten Jailbreak umgehen. Danach hat der Nutzer Vollzugriff auf das Dateisystem und die Kommandozeile des Unix-artigen Betriebssystems, zudem kann er Software aus beliebigen Quellen installieren, etwa über Cydia. Durch einen Jailbreak verliert man jedoch die Garantie.\nBis zum 17. September 2013 war es Nutzern älterer Geräte nicht möglich, Apps über den App Store zu installieren, für die eine neuere iOS-Version erforderlich war. Mittlerweile lassen sich jedoch auch mit älteren Geräten noch kompatible Versionen von Apps über den App Store herunterladen, womit diese Restriktion heute obsolet ist.\n\nEs ist nicht möglich, unter iOS einen Webbrowser zu installieren, der eine eigene Rendering-Engine nutzt. Alle Webbrowser für iOS sind damit lediglich andere Oberflächen für die WebKit-Rendering-Engine. Bis einschließlich iOS 7 wurden alternativen Webbrowsern zudem Geschwindigkeitsverbesserungen an der JavaScript-Engine vorenthalten.\n\nMit iOS 9 begann Apple ältere, jedoch kompatible Geräte mit 32-Bit-Prozessor (dazu zählen der iPod touch der fünften Generation, die iPhones 4s, 5 und 5c sowie die iPads 2 bis 4 und das iPad mini 1) von einzelnen Funktionen auszuschließen. Für Entwickler hat Apple die Möglichkeit eingeführt, nun Apps zu entwickeln, die unter diesen Geräten nicht kompatibel sind (stattdessen kommt beim Versuch des Herunterladens betreffender Apps aus dem App Store nun die Meldung „Diese App ist nicht mit ihrem Gerät kompatibel“). Auch die mit diesem Update eingeführte Möglichkeit der Installation von Erweiterungen für den Safari-Browser (wie bspw. Werbeblockern) hat Apple für diese Geräte ausgeschlossen. Der mit iOS 9.3 eingeführte Night-Shift-Modus, mit dem die Farbtemperatur des Displays geändert werden kann, ist auf diesen Geräten ebenfalls nicht verfügbar.\n\niOS verwendet seit iOS 10.3 das Apple File System (APFS) als Dateisystem. Es ist für Flash-Speicher optimiert und beinhaltet Funktionen wie Snapshots und Copy-on-Write. Davor wurde HFSX (HFS+ Extended) verwendet, einer Variante des HFS+-Dateisystems. Beim Starten von iOS werden zwei Partitionen eingebunden.\n\nDie Systempartition enthält das sogenannte root-Verzeichnis von iOS, dort befinden sich alle Systemkomponenten wie zum Beispiel das \"Springboard\" und die Hintergrunddienste von iOS. Der Benutzer hat keinen Zugriff auf die root-Partition, ohne einen Jailbreak durchzuführen. Die Größe der Partition wird in fast jeder neuen iOS-Version vergrößert. In iOS 6.1 ist diese Partition ca. 1,3 GB groß. Eine manuelle Änderung der Größe ist normalerweise nicht nötig, kann jedoch mit einer modifizierten iOS-Firmware-Datei mittels Jailbreak vollzogen werden. Die maximale Größe der Partition beträgt 4 GB. Die Systempartition ist nur lesbar, und das System kann hier keine Daten verändern.\n\nDie Datenpartition ist unter codice_1 sichtbar und enthält den Ordner \"mobile\", das sogenannte \"User\"-Verzeichnis. In diesem Verzeichnis werden alle Medien und Einstellungen gespeichert. Die Größe des \"User\"-Verzeichnisses hängt von der Speicherkapazität des iOS-Gerätes ab. Die Größe des \"User\"-Verzeichnisses wird von iOS als Gesamtgröße des Flash-Speichers angegeben. Dadurch, dass die Systempartition in fast jeder iOS-Version vergrößert wird, verringert sich der nutzbare Speicher des iOS-Geräts nach einer Hauptversions- oder „Major“-Aktualisierung. Die Größe der root-Partition hat sich im Laufe der iOS-Entwicklung mehr als verzwanzigfacht. Das \"User\"-Verzeichnis enthält einige Unterverzeichnisse, die wichtigsten davon sind:\n\n\n\"Diese Auflistung beinhaltet nur die primären Aktualisierungen („Major Updates“) und deren wichtigste Neuerungen.\" Auch das iOS des Apple TVs wird, da es andere Versionsbezeichnungen trägt, hier nicht aufgeführt; Gleiches gilt für dessen mitgelieferte Applikationen.\n\nEine Reihe von Apps werden mit den iOS-basierten Geräten mitgeliefert. Trotz der Namensgleichheit mit entsprechenden Programmen für Mac OS X sind die Apps für iOS an die jeweilige Benutzeroberfläche angepasst und im Funktionsumfang verändert. Die Applikationen Nike+iPod und iCloud Drive sind standardmäßig ausgeblendet und müssen vom Nutzer erst aktiviert werden. Ab iOS 10 lässt sich der größte Teil der vorinstallierten Apps ausblenden, ab iOS 11 auch deinstallieren. Diese können dann wieder im App Store heruntergeladen werden.\n\nDie folgenden Listen zeigen alle Applikationen, die in der aktuellen Version des Betriebssystems vorinstalliert sind.\n\nBis iOS 5.x war eine von Apple designte App zum Anschauen von Videos auf YouTube vorinstalliert. Wegen einer abgelaufenen Lizenz wurde die App ab iOS 6.0 nicht mehr in das OS eingebunden. Kurz darauf stellte Google eine überarbeitete YouTube-App im App Store für iOS-6-Nutzer bereit. Eine Alternative zu der App, die eine Apple-ID erfordert, ist die mobile Webseite von YouTube, die in einem Webbrowser aufgerufen werden kann. Google hat die Unterstützung der YouTube-App auf älteren iOS-Geräten serverseitig größtenteils abgeschaltet.\n\nDie standardmäßige Installation der Apple Watch App in iOS 8.2, die zur Konfiguration der Uhr verwendet werden soll, sorgte für Kritik, da die App schon vor Erscheinen der Uhr installiert wurde und sich nicht entfernen ließ.\n\nSeit Herbst 2013 können die sogenannten iLife- (iPhoto [ersetzt durch vorinstallierte Fotos-App], iMovie und GarageBand) und iWork-Apps (Pages, Numbers und Keynote) für iOS kostenlos heruntergeladen werden. Dies gilt allerdings nur für iOS-Geräte, die nach dem 10. September 2013 gekauft wurden und auch nur für den Erstbenutzer. Wird das Gerät weiterverkauft, verschenkt oder vom selben Nutzer mit einer anderen ID verwendet, erlischt der Gratis-Anspruch und man muss für die Apps den regulären Preis bezahlen.\n\nSeit April 2017 sind die Apps für alle iOS-Nutzer kostenlos.\n\nAuf Geräten mit 64 GB bzw. 128 GB internem Speicher sind diese Apps seit Herbst 2014 standardmäßig installiert.\n\nNeben den mitgelieferten Standard-Programmen sind im App Store weitere Anwendungen verfügbar. Bis Mai 2013 wurden von dort weltweit mehr als 50 Milliarden Apps heruntergeladen. Sämtliche Apps im App Store werden von Apple kontrolliert, was Sicherheit, aber auch Einschränkungen für den Nutzer bedeutet.\n\nIn der ersten Betaversion von iOS 8 wurde die App \"Bug Reporter\" eingeführt, welche mittlerweile \"Feedback\" heißt. Sie dient dazu, gefundene Fehler der iOS-Entwickler an Apple zu schicken.\n\nApples zentralisierter Prozess rund um die Veröffentlichung von Apps wird oft skeptisch gesehen. Da es Nutzern schwer möglich ist, aus anderen Quellen als dem App Store Programme zu beziehen, sehen Kritiker in der Nichtzulassung von Programmen eine Zensur. Die Electronic Frontier Foundation kritisiert außerdem, dass Entwickler gezwungen seien, deutliche Einschränkungen hinzunehmen, wenn sie für iOS entwickeln wollten; unter anderem müssten sie ein Geheimhaltungsabkommen unterzeichnen und einen Mitgliedsbeitrag entrichten. Langfristig könne dies demnach innovationshemmend wirken.\nAndere Autoren sehen die Kontrolle des App Store dagegen als einen Vorteil an:\n\nAuch die abgeschlossene Natur der Plattform wird kritisiert. Vor allem Entwickler befürchten, dass zukünftige Generationen weniger intensiv an den Geräten herumbasteln können und sich daher nicht für Informatik begeistern werden. Auch einige Nutzer fühlen sich durch die von Apple getroffenen Einschränkungen bevormundet und stören sich an der zu starken Kontrolle, die Apple über die Plattform hat. So kann Apple beispielsweise Programme mithilfe des \"Apple-Killswitch\" vom iPhone des Nutzers löschen. Der ehemalige Apple-Chef Steve Jobs erklärte, dass diese Möglichkeit nur auf Schadsoftware abziele.\n\nVon vielen Benutzern wird kritisiert, dass die vorinstallierten Apps wie Aktien, Wetter oder Zeitungskiosk sich nur mit einem Jailbreak entfernen lassen. Das gilt selbst für solche Apps, die keinerlei kritischen Einfluss auf den grundsätzlichen einwandfreien Betrieb des Gerätes haben. Seit iOS 10 ist es möglich, verschiedene dieser Apps wie Aktien, Wetter und Erinnerungen zu entfernen und sie bei Bedarf erneut aus dem App Store zu laden.\n\nViel Kritik erhielt Apple dafür, dass es für iOS keinen Flash Player gab. Nach Darstellung von Apple sei dessen Hersteller Adobe nicht willens oder nicht in der Lage gewesen, eine funktionierende Lösung für iOS zu entwickeln. Steve Jobs äußerte sich im April 2010 in einem offenen Brief zu der Debatte um Flash. Im November 2011 stellte Adobe die Entwicklung des Flash Players für alle mobilen Endgeräte ein, ab August 2012 konnte man das Programm auch nicht mehr herunterladen, womit dieser Kritikpunkt heute obsolet ist.\n\nUnter iOS 6 wurde ein eigener Kartendienst eingeführt, der wegen gravierender Fehler im Kartenmaterial stark kritisiert wurde. So war das Satellitenmaterial in einigen Fällen schlecht aufgelöst oder nur schwarz-weiß. Apples CEO Tim Cook hat sich in einem offenen Brief entschuldigt und versichert, dass das Kartenmaterial verbessert werden soll. Im Sommer 2013 sagte er diesbezüglich in einem Interview “we screwed up” („Wir haben versagt“).\n\nApple wird vorgeworfen, Funktionen von iOS nicht selbst entwickelt, sondern lediglich kopiert zu haben. Der britische Entwickler Greg Hughes entwickelte die App WiFi-Sync für iOS 4, die es ermöglichte, iOS-Geräte drahtlos mit iTunes zu synchronisieren. Im iTunes Store wurde diese App abgelehnt, woraufhin Hughes seine Anwendung im Cydia Store einreichte. Apple implementierte die Funktionen von WiFi-Sync anschließend mit identischem Namen und ähnlichem Logo in iOS 5. Teile des Mitteilungssystems auf dem Sperrbildschirm von iOS sollen ebenfalls Kopien einiger Anwendungen aus Cydia sein. In iOS 7 wurde das \"Control Center\" eingeführt, mit dem Funktionen wie WLAN oder Bluetooth aktiviert und deaktiviert werden können. Laut \"Chip Online\" sei die Vorlage eindeutig das 2008 erschienene \"SB-Settings\", eine Anwendung ebenfalls aus dem Cydia Store, von der viele Elemente übernommen worden sein könnten.\n\nAufsehen erregte zudem iOS 6 für das iPad, mit dem eine zuvor fehlende Uhr-Anwendung auf dem iPad installiert wurde. Apple stahl das Design der Uhr von Hans Hilfiker, woran die Schweizerischen Bundesbahnen (SBB) die Rechte halten.\n\nDie Tabübersicht des Browsers Safari weise so gravierende Ähnlichkeiten mit Google Chrome auf, dass die beiden Anwendungen kaum voneinander zu unterscheiden seien. In einem Fazit meint Chip Online, dass viele Ähnlichkeiten der Systeme zu offensichtlich seien, um Zufall sein zu können. Direkte Parallelen können offenbar auch zu WebOS gezogen werden, dessen Multitasking-Menü in iOS übernommen wurde.\n\nImmer wieder steht der Sperrbildschirm von iOS in der Kritik, da mehrfach Sicherheitslücken aufgefallen sind, die unautorisierten Zugriff auf die Telefon-App gestatteten.\n\nJedes iOS-Gerät bis einschließlich zum iPhone 4 hat einen Hardwarefehler, der es gestattet, unautorisierten Code auszuführen. Bis zur iOS-Version 3.1.3 lässt sich so durch einen Löschbefehl der Schlüsselbund von iOS löschen, wodurch die Codesperre verschwindet. Mit iOS 4 hat Apple eine zusätzliche Verschlüsselung namens \"Data Protection\" eingeführt, die bestimmte Daten zusätzlich mit dem gesetzten Code verschlüsselt. Dies verhindert, dass geschützte Daten ohne Kenntnis des Codes auch bei physischem Zugriff auf dem Gerät lesbar sind.\n\nDer genannte Hardwarefehler lässt sich ebenfalls dazu ausnutzen, auch ab iOS 4 noch unzureichend geschützte Daten auszulesen, ohne den Code einzugeben. Aufgrund der reinen Verschlüsselung über einen Hardwareschlüssel sind ohne \"Data Protection\" geschützte Daten auf diesem Weg weiter lesbar. Ab iOS 7 ist die Verschlüsselung zwangsweise, weist jedoch auch noch Lücken auf.\n\nDes Weiteren lässt sich mithilfe des erwähnten Hardwarefehlers auch ein Bruteforce-Angriff gegen die Code-Sperre starten. Wenn nur ein vierstelliger Code genutzt wird, kann er unabhängig von der verwendeten iOS-Version in der Regel nach etwa fünf bis zehn Minuten entschlüsselt werden. In diesem Fall sind die Code-Sperre und Verschlüsselung durch \"Data Protection\" bei älteren Geräten wirkungslos.\n\nBis iOS 7 war es Apple möglich, über ein „proprietäres Verfahren“ die Daten von gesperrten Geräten auszulesen.\n\nMit der Einführung von iOS 8 im September 2014 gibt es laut Apple keine Möglichkeit mehr, den eingegebenen Passcode zu umgehen, ohne den künftig nicht mehr auf die Daten auf mobilen Geräten zugegriffen werden kann. Durchsuchungsbefehlen von Strafverfolgungsbehörden könne somit nicht mehr nachgekommen werden. Das bestätigt ein Bericht der New Yorker Staatsanwaltschaft. Damit seien Fotos, Nachrichten samt Anhängen, E-Mails, Kontaktdaten, Verbindungsverläufe, iTunes-Inhalte, Notizen und Erinnerungen geschützt. Ein FBI-Mitarbeiter äußerte sich dahingehend, dass Apples Schritt zu der zunehmenden Verdunklung beitrage, die mit der verbreiteten Verwendung von Verschlüsselung einhergehe.\n\nIm Juni 2015 wurde eine Studie veröffentlicht, die gravierende Sicherheitslücken in iOS und OS X beschreibt, mit deren Hilfe sich Passwörter und Daten auslesen lassen; die Forscher nutzten dabei fehlende Sicherheitsmechanismen bei der Kommunikation von Apps untereinander (\"Cross-App Resource Access\", kurz \"Xara\") aus. Entsprechend manipulierte Apps konnten sowohl im iOS- als auch im Mac App Store platziert werden. Apple wurde im Oktober 2014 über die Probleme informiert und erbat sich einen – branchenüblichen – Zeitraum von sechs Monaten für die Fehlerbehebung aus. Bis Juni 2015 hatte Apple den Fehler noch nicht behoben.\n\nBis zur iOS-Version 9.3.4 klafften drei kritische Sicherheitslücken, die von dem Spyware-Tool Pegasus des Unternehmens NSO Group ausgenutzt wurden und mit Veröffentlichung von Version 9.3.5 von Apple geschlossen wurden.\n\nVereinzelt steht iOS wegen Problemen mit der Akkulaufzeit in der Kritik. Das im März 2014 veröffentlichte iOS 7.1 soll die mögliche Laufzeit der iOS-Geräte stark beeinträchtigen. Ähnliche Probleme gab es auch schon bei Vorgängerversionen von iOS, bei iOS 5 war vom sogenannten \"Battery Gate\" die Rede, in Anlehnung an den \"Antenna-Gate\"-Konstruktionsfehler des iPhone 4. Abhilfe gegen die magere Akkulaufzeit unter iOS schafft in den meisten Fällen das Wiederherstellen von iOS aus dem DFU-Modus heraus, \"ohne\" das anschließende Installieren eines Backups.\n\nIn der Vergangenheit stand nach der Veröffentlichung neuer iOS-Versionen die Kritik im Raum, dass die Geschwindigkeit einiger Geräte nach den Aktualisierungen nachlasse. So klagten etwa Nutzer über Geschwindigkeitsprobleme des iPhone 4 unter iOS 7 oder des iPhone 4s unter iOS 8. Apple reichte mit iOS 7.1 und iOS 8.1.1 Aktualisierungen nach, um die Stabilität und Geschwindigkeit der Geräte zu verbessern. Weiterhin liegen Berichte vor, dass sich mit weiteren Aktualisierungen die Geschwindigkeit erneut verbessere.\n\nIn den Vereinigten Staaten wird gegen Apple von über 100 Klägern eine Sammelklage angestrebt. Apple wird vorgeworfen, Benutzer wissentlich durch falsche Werbeversprechen getäuscht zu haben. So solle die iOS-9-Softwareaktualisierung bei appleinternen Tests die Nutzbarkeit des iPhone 4s massiv eingeschränkt haben, Apple solle in der Werbung jedoch wider besseres Wissen Leistungssteigerung und Akkulaufzeitverbesserungen versprochen haben. Die Kläger halten Apple vor, dass zumindest darauf hingewiesen hätte werden sollen, dass durch eine Aktualisierung auf iOS 9 die Benutzbarkeit der Geräte eingeschränkt werden könne. Bei den Klägern sei durch iOS 9 ein finanzieller Schaden entstanden, da ein Zurückspielen von älteren iOS-Versionen nicht möglich ist. Weiters solle Apple vorsätzlich die Benutzbarkeit der Geräte durch Softwareaktualisierungen einschränken, um Kunden zum Kauf eines neuen Geräts zu bewegen.\n\nIm Dezember 2017 deckte Geekbenchentwickler John Poole eine Funktion in iOS auf, die die Systemleistung älterer Geräte durch Reduktion der Prozessortaktfrequenz permanent künstlich senkt, wenn die Ladungsträgerkapazität des eingebauten Lithiumpolymerakkumulators durch natürlichen Verschleiß geringer geworden ist. Betroffen sind iPhone SE, iPhone 6, iPhone 6s und iPhone 7 mit iOS 10.2.1 bzw. 11.2.0 oder neuer. Apple bestätigte auf Anfrage, dass die Leistung älterer Geräte künstlich gedrosselt werde und kündigte an, diese Praxis zukünftig auch bei weiteren Geräten anzuwenden. Als Grund gibt Apple an, dass die im iPhone verwendeten Lithiumionenakkumulatoren in Lastsituationen nicht mehr die benötigte Leistung liefern können, weil sie im Laufe der Zeit verschleißen oder kalten Temperaturen ausgesetzt werden. Dadurch sei es in der Vergangenheit öfter zur Notabschaltung der Geräte gekommen, was Apple im Rahmen einer positiven Benutzererfahrung und Verlängerung der Produktlebenszeit vermeiden möchte. Französische Verbraucherschützer reichten Ende Dezember 2017 Klage gegen Apple ein, da geplantete Obsoleszenz in Frankreich gesetzeswidrig ist. Im Januar 2018 wurde bekannt, dass die französische Justiz Ermittlungen gegen Apple aufgenommen hat. Apple reagierte darauf mit einer Vergünstigung des Akkutausches bei betroffenen Geräten. Kunden können bis Dezember 2018 ihre Akkumulatoren bei Apple oder Vertragshändlern um 30 € statt 90 € tauschen lassen.\n\nVermehrt traten nach Aktualisierungen von iOS schwere Probleme mit den aktualisierten Geräten auf, die zur Unbenutzbarkeit führten.\n\nNach der Installation von iOS 7 funktionierte offenbar bei einigen iPhone 4s der WLAN- und Bluetooth-Chip nicht mehr ordnungsgemäß. Ursache des Problems ist kein Fehler in iOS, sondern ein Produktionsmangel an den Lötstellen des WLAN-Chips. Beim Herunterladen des großen Aktualisierungspakets wird der WLAN-Chip über einen längeren Zeitraum thermisch belastet, wodurch die Lötverbindungen zur Hauptplatine \"(logicboard)\" schmelzen und anschließend „kalt werden“.\n\nSofern der Fingerabdrucksensor des iPhone 6 durch einen Austauschsensor (etwa bei der Reparatur des Bildschirmglases) ersetzt worden war, ließen sich betroffene Geräte nach einer versuchten Aktualisierung des Betriebssystems nicht mehr benutzen, da die Installation nicht abgeschlossen werden konnte und die Fehlermeldung 53 angezeigt wurde. Apple reagierte darauf mit dem iOS-Update 9.3, durch dessen Installation der Fehler behoben werden soll.\n\nDurch die Aktualisierung iOS 9.3 ließen sich offenbar ältere Geräte, insbesondere das iPad 2 nicht mehr aktivieren. Nach der Installation von iOS ist eine Aktivierung erforderlich, damit der Benutzer zum SpringBoard gelangt. Apple veröffentlichte daraufhin eine überarbeitete Version von iOS 9.3, bei der dieser Fehler behoben wurde.\n\nOffenbar scheinen einige iPad Pros mit 9,7-Zoll-Bildschirm durch eine Aktualisierung auf Version 9.3.2 nicht mehr benutzbar zu sein, auch eine Wiederherstellung soll unmöglich sein. Die Betriebssystemversion 9.3.2 wurde daraufhin für die 9,7-Zoll-iPad-Pro-Modelle vorzeitig zurückgezogen.\n\nEs wird immer wieder kritisiert, dass Apple offene Standards nur sehr halbherzig unterstützt. So wurde im Oktober 2016 in Frankreich eine Klage gegen Apple eingereicht, da im Webbrowser Safari die Unterstützung für HTML5 sehr weit hinter dessen aktuellem Stand zurückhängt. In iOS ist dieses Problem besonders eklatant, da die Anbieter anderer Webbrowser nicht ihre eigenen Render-Engines verwenden dürfen, sondern nur auf Apples eigene Render-Engine WebKit und deren eingeschränkte Unterstützung offener Webstandards Zugriff haben.\n\nAusgeliefert wird iOS in den Sprachen .\n\n\n\n"}
{"id": "5451442", "url": "https://de.wikipedia.org/wiki?curid=5451442", "title": "Acorn Electron", "text": "Acorn Electron\n\nDer Acorn Electron war eine preisgünstige Version des BBC Micro Lern- und Heimcomputers, die von Acorn hergestellt wurde. Er war mit 32 KB RAM ausgestattet und sein ROM enthielt BBC BASIC und das Betriebssystem.\n\nDer Electron nutzte Audiokassetten um Programme zu laden und zu speichern. Dazu wurde ein Konverterkabel beigefügt, das bei passenden Buchsen den Anschluss an einen Standard-Kassettenrekorder ermöglichte. Er konnte einfache Grafik auf einem Fernsehgerät, einem RGB-Monitor oder einem Grünmonitor ausgeben.\n\nIn seiner Hochzeit war der Electron der dritthäufigste Mikrocomputer im Vereinigten Königreich, und es wurden insgesamt mehr Spiele verkauft als für den BBC Micro. Es gibt mindestens 500 bekannte Spiele für den Electron.\n\nDie Hardware des BBC Micro wurde im Wesentlichen in einem einzigen Chip integriert, der von Acorn entwickelt wurde und auf Basis eines angepassten ULA realisiert wurde. Wegen des Designs ergaben sich Einschränkungen bei den Fähigkeiten, wie zum Beispiel bei der Beschränkung der Tonausgabe auf einen Kanal, während dem BBC Micro drei Kanäle (und einer für Rauschen) zur Verfügung standen. Darüber hinaus konnte er keinen Teletext-Modus bieten.\n\nDas ULA steuerte den Speicherzugriff und konnte 32K × 8 Bits RAM adressieren, wobei 4 Stück 64K × 1-Bit RAM-Chips vom Typ 4164 verwendet wurden. Dadurch, dass zwei Zugriffe auf jeden Chip (statt nur einem) notwendig waren, und weil die Video-Hardware ebenfalls auf den Speicher zugreifen musste, war das Lesen und Schreiben im RAM langsamer als beim BBC Micro. Während reine ROM-Anwendungen gleich schnell liefen, gab es bei Anwendungen mit RAM-Zugriff deutliche Geschwindigkeitseinbußen.\n\nDer Electron wurde im Laufe des Jahres 1983 als kleiner kostengünstiger Bruder des BBC Micro entworfen. Ziel war es, das Niedrigpreissegment für das Weihnachtsgeschäft zu sichern. Auch wenn es Acorn gelungen war, praktisch den gleichen Funktionsumfang des BBC Micro in nur einem Chip anzubieten, waren aufgrund von Herstellungsproblemen nur wenige Einheiten für das Weihnachtsgeschäft verfügbar.\n\nVon diesem Rückschlag erholten sich die Verkäufe nie vollständig, auch wenn letztendlich mehr Spiele für den Electron als für den BBC Micro verkauft wurden. Nach der Beteiligung von Olivetti im Jahr 1985 an Acorn wurde der Electron praktisch kaltgestellt.\n\nIm Nachhinein wird deutlich, dass der Speicher des Electron zu klein war. Einem Programm standen nur etwa 20 kB zur Verfügung, nachdem der Grafikspeicher abgezogen wurde. Auch konnte es der Electron nicht mit der Verarbeitungsgeschwindigkeit eines Sinclair ZX Spectrum oder Commodore 64 aufnehmen. Dennoch wurden viele Funktionen, die später mit dem BBC Master und Archimedes verbunden wurden, erstmals durch Erweiterungsmodule für den Electron geboten. Beispiele dafür sind ROM-Steckmodule und das Advanced Disc Filing System, das eine Weiterentwicklung des Disc Filing System für den BBC Micro war.\n\nAuch wenn der Electron im Vergleich zu seinen Konkurrenten wie Spectrum, Commodore 64, Amstrad CPC oder dem BBC Micro für wenig erfolgreich gehalten wird, waren die Verkaufszahlen so gut, dass neue Software bis in die frühen 1990er erhältlich war. Das bedeutet, dass der Electron eine Lebensspanne hatte, die nicht kleiner als die von beliebtereren Mikrocomputern war.\n\nMit der Ausführung Acorn Plus 1 wurden zwei ROM-Slots, ein Analoginterface und ein Parallelport verfügbar. Das Analoginterface wurde meist zum Anschluss von Joysticks genutzt, der Parallelport üblicherweise für Drucker.\n\nDer Zugriff auf den ROM-Speicher war unabhängig vom Grafikmodus mit 2 MHz getaktet. Dadurch konnten Programme, die auf ROM verfügbar waren, theoretisch doppelt so schnell ausgeführt werden wie Programme, die auf Band oder Diskette verbreitet wurden. Dennoch wurden alle Spiele, die auf ROM veröffentlicht wurden, als 'serielle ROMs' geliefert, von denen der Rechner die Programme wie von Band las. Dies hatte zwar den Vorteil, dass Programme nicht an ihre neue Speicheradresse angepasst werden mussten, brachte allerdings auch keine Erhöhung der Geschwindigkeit.\n\nDas Acorn Plus 3 war ein Hardwaremodul, das unabhängig vom Plus 1 verbunden wurde und eine Anschlussmöglichkeit für ein 3½”-Diskettenlaufwerk bot. Das Laufwerk wurde über einen WD1770-Controller von Western Digital sowie über ein ROM für das ADFS ermöglicht. Weil der Controller auch mit einfacher Speicherdichte umgehen konnte und dasselbe vom IBM360 abgeleitete Diskettenformat wie der Intel 8271 im BBC Micro nutzte, war es mit einem Austausch-ROM möglich, das Dateisystem DFS zu nutzen.\n\nAls Spielcomputer war der Electron so wie der Sinclair Spectrum zunächst wenig tauglich, da ihm ein Joystick-Port fehlte. Daher bot die Firma First Byte Computers eine bald sehr beliebte Schnittstelle einschließlich Software an, die es erlaubte, einen Joystick mit einer Mehrzahl der verfügbaren Programme zu nutzen.\n\nDas Advanced Plus 3 war dem Acorn Plus 3 sehr ähnlich wurde aber als ROM-Steckmodul für den Plus 1 mit einem angeschlossenen Verbindungsstecker für ein Diskettenlaufwerk angeboten. So war es möglich, ein 5¼”-Diskettenlaufwerk anzuschließen, wie es von Nutzern des BBC Micro eingesetzt wurde, oder eines der eher üblichen 3½”-Laufwerke.\n\nDie Slogger und Elektuur Turbo Boards entstanden aus einem Hack, der von Acorn erdacht wurde. Indem die unteren 8 kB RAM außerhalb des Zugriffs des ULA gelegt wurden, lag die Zugriffsgeschwindigkeit der CPU auf diesen Bereich immer bei 2 MHz. Der Grafikspeicher konnte jedoch nicht in diese 8 kB gelegt werden. Meist legten die Betriebssystem-ROMs den Grafikspeicher in die oberen 24 kB, so dass lediglich 2 % der Software inkompatibel waren.\n\nDas Slogger Turbo Board war ein professionell hergestelltes Aufrüstungsmodul. Die Anpassungen für das Elektuur-Board wurden in der niederländischen Elektronikzeitschrift Elektuur (der niederländischen Mutterausgabe der Elektor) beschrieben und konnten von Lesern nachgebaut werden.\n\nFür Rechner, die vom 6502 abgeleitet sind, war die Beschleunigung des Zugriffs auf den unteren Speicherbereich besonders vorteilhaft, da der Prozessor eine schnellere Adressierungsart für die ersten 256 Bytes bietet. Daher wurden Variablen, die für zeitkritische Operationen benötigt wurden, üblicherweise in diesen Bereich gelegt.\n\nDas Slogger Master RAM Board war eine Weiterentwicklung des Turbo Boards und bot als zusätzliche Funktion die Möglichkeit, den Electron mit 32 kB Shadow-RAM zuzüglich zu den bereits vorhandenen 32 kB zu betreiben.\n\nDurch geschickte Manipulation des Befehlszählers war es möglich, dass die normalen System ROMs und Software, die die Betriebssystemaufrufe nutze, ohne umfangreiche Änderungen eingesetzt werden konnten. Dadurch war mehr Speicher für BASIC, View, Viewsheet und andere Geschäftsanwendung verfügbar. Die Modifikation stellte zusätzlichen Speicher bereit, so dass auch einige Spiele und Anwendungen für den BBC Micro lauffähig waren, auch wenn dem Electron ein nativer Mode 7 zur Darstellung fehlte.\n\nAnwendungen konnten auf den Grafikspeicher nicht ohne Änderungen des Programmcodes zugreifen. Daher war die Erweiterung mit den meisten Spielen inkompatibel, auch wenn es keinen Grund gab, ein Spiel zu so programmieren, dass es im Shadow-Modus funktioniert.\n\nIn der Phase des Abschwungs wurden jedem Electron Master RAM Boards beigelegt um die Verkaufszahlen zu erhöhen.\n\nEine der Eigenschaften des BBC Micro, die dem Electron fehlte, war der Teletext \"Mode 7\". Das Fehlen dieses Modus verwundert angesichts der geringen Speicherbelegung von unter 1 kB in diesem Modus und der großen Zahl der BBC-Micro-Programme, die diesen Modus nutzten. Die Firma Jafa Systems bot einige Lösungen an, um den fehlenden Modus nachzurüsten oder wenigstens zu emulieren.\n\nDie einfachste Lösung war ein reines Softwaresystem, das als ROM-Modul ausgeliefert wurde und im Grafikmodus eine Näherung des Mode 7 zeichnete – wenn auch in niedriger Auflösung. Auch wenn dieser Ansatz preiswert und effektiv war, um einigen Programmen die Textausgabe im Mode 7 über offizielle Einsprungpunkte zu ermöglichen, war diese Lösung auch sehr langsam. Dies lag unter anderem daran, dass die Näherung durch die CPU des Electron berechnet werden musste, was bei einem nativen Modus wie beim BBC Micro entfällt. Auch war der notwendige Speicher mit 20 kB deutlich größer.\n\nEs gab auch zwei Lösungen mit zusätzlicher Hardware. Die erste basierte auf dem Grafikprozessor SAA5050, den der BBC Micro im Mode 7 einsetzte. Die Lösung bestand zudem aus einem Softwareteil, der sicherstellte, dass der Prozessor mit den notwendigen Grafikdaten versorgt wurde. Das ULA griff dabei weiterhin auf den Grafikspeicher zu während der SAA5050 diese Daten auslas und eine Mode-7-Interpretation der Daten lieferte. Der Hardwareteil schaltete bei Bedarf zwischen der Grafikausgabe des Electron und des Moduls um.\n\nDer Nachteil dieses Systems bestand darin, dass der SAA5050 wiederholt mit denselben 40 Byte Daten pro Bildzeile und Zeichenzeile versorgt werden musste, während das ULA einen anderen Satz von 40 Bytes pro Bildzeile las um die Darstellung im nativen Modus zu ermöglichen. Der Softwareteil umging dieses Problem, indem die Daten für die Mode-7-Darstellung im Speicher dupliziert wurden. Es gab dadurch kaum Leistungseinbußen bei der Darstellung im Mode 7, die qualitativ mit der des BBC Micro identisch war. Die Lösung benötigte aber 10 kB Speicher und war nur kompatibel zu Programmen, die die ROM-Routinen zur Ausgabe von Text und Grafik nutzten.\n\nEine zweite Version der Hardwarelösung beseitigte diese Probleme. Dazu wurde ein Motorola 6845 (CRTC)\nhinzugefügt. Die Lösung basierte damit vollständig auf Hardware, hatte keinen negativen Einfluss auf die Ausführungsgeschwindigkeit und nutzte nur 1 kB Speicher für die Grafikausgabe. Es gab zwar weiterhin ein Software-ROM, das aber lediglich das Hardware-ROM so erweiterte, dass es in den Mode 7 wechseln konnte.\n\nEine ungewöhnliche Variante des Electron wurde von \"British Telecom Business Systems\" als \"BT Merlin M2105 Communications Terminal\" angeboten. Dabei handelte es sich um einen Electron, bei dem das Typenschild entfernt und der mit einem umfangreichen Erweiterungsmodul versehen wurde. Diese Erweiterung bestand aus zusätzlichen 32 kB RAM und 48 kB ROM, einem Centronics-Anschluss für Drucker und einem Modem. Die Firmware des ROM ermöglichte die Kommunikation über das Modem. Die Terminals wurden mehr als zehn Jahre lang vom Interflora Floristen-Netzwerk im Vereinigten Königreich eingesetzt.\n\n\nWie der BBC Micro wurde der Electron wegen der geringen Speicherkapazität eingeschränkt. Von den 32 kB RAM wurden beim Start 3,5 kB für das Betriebssystem reserviert und mindestens 10 kB wurde als Puffer für den Grafikspeicher belegt.\n\nDurch das Timing von Interrupts war es möglich, entweder die oberen 100 oder die unteren 156 Zeilen der Darstellung auszuschalten. Viele Spiele nutzten dies und speicherten nichtgrafische Daten in den ausgeschalteten Bereich, um den zusätzlichen Platz anders belegen zu können. Andere Spiele luden nichtgrafische Daten in den Bildschirmspeicher, so dass sie als Pixel mit scheinbar zufälligen Farben angezeigt wurden.\n\nDie Hardware erlaubte Page-Flipping zur Erzeugung flüssiger Animationen. Der beschränkte Speicher zwang die meisten Anwendungen jedoch, ihre Ausgabe direkt in den Bildschirmspeicher zu schreiben, so dass es zu Flackern oder sichtbarem Neuzeichnen kam. Eine Ausnahme ist die \"Joe Blade\"-Serie von Players.\n\nDer Electron genoss im Gegensatz zum Commodore 64 oder dem Sinclair ZX Spectrum nicht die breite Unterstützung der großen Spielehersteller. Dennoch wurden viele Spiele für den Electron herausgegeben, besonders durch Hersteller von Spielen für den BBC Micro wie \"Acornsoft\", \"Superior Software\" und \"Micro Power\". Beliebte Spiele, die besonders mit dem Electron verbunden werden sind:\n\n\nViele beliebte Spiele wurden auch offiziell von Arcade-Automaten konvertiert. Dazu zählten \"Crystal Castles\", \"Tempest\", \"Commando\", \"Paperboy\" und \"Yie Ar Kung-Fu\". Spiele, die von anderen Heimcomputern konvertiert wurden waren u. a. \"Impossible Mission\", \"Jet Set Willy\", \"The Way of the Exploding Fist\", \"Tetris\", \"The Last Ninja\", \"Barbarian\" und \"SimCity\".\n\nObwohl Acorn den Electron in 1985 faktisch einstellte, wurden bis zum Jahr 1991 weiterhin Spiele für den Electron entwickelt und veröffentlicht. Zu den etwa 1400 Spielen, die für den Acorn Electron veröffentlicht wurden (davon 99 % auf Kassette) kamen noch tausende Programme, die als Public domain auf Diskette veröffentlicht wurden. Diese Disketten wurden unter anderem vom \"BBC PD\", der \"Electron User Group\" und \"HeadFirst PD\" vertrieben.\n\nEs gibt drei Emulatoren für den Rechner: ElectrEm für Windows/Linux/Mac OS X, Elkulator für Windows/DOS und den Multisystem-Emulator M.E.S.S. Software für den Electron wird überwiegend im UEF-Dateiformat archiviert.\n\n"}
{"id": "5459549", "url": "https://de.wikipedia.org/wiki?curid=5459549", "title": "ARIS MashZone", "text": "ARIS MashZone\n\nARIS MashZone ist eine Freeware zur Erstellung von flexiblen und interaktiven Management Dashboards (Mashups). Das Tool ermöglicht den Import von Daten aus internen Datenquellen wie CRM-Systemen, ERP-Berichten oder Data Warehouses, externen Daten aus Webservices sowie einfachen Excel-Tabellen.\nARIS MashZone wurde von IDS Scheer/Software AG entwickelt.\n\nARIS MashZone wurde erstmals im Februar 2009 in einer Presseinformation der IDS Scheer AG erwähnt. Die erste Veröffentlichung fand am 22. September 2009 in einem öffentlichen Beta-Test in der ARIS Community statt. Personen, die sich zuvor für den Beta-Test registriert hatten, war es möglich, diese Beta-Version herunterzuladen und zu testen.\nDas offizielle Release war am 18. Januar 2010. Am 31. März 2010 folgte dann das erste Service Release. Neuerungen gegenüber der ersten Version umfassten dynamische Datenquellen-Parameter, Real-Time Dashboards, Kreuztabellen und dynamische URL‘s.\nMitte Juni 2010 gab USU Software eine Kooperation mit IDS Scheer bekannt, in deren Rahmen USU als Vertriebspartner von ARIS MashZone auftritt.\n\nARIS MashZone ist eine client/server-Applikation. Die Applikation besteht aus dem Home Screen, einem virtuellen Composer und einem Feed Editor. Der Home Screen bietet einen Überblick über die vorhandenen Mashups. Im Visual Composer kann man Mashups erstellen und bearbeiten. Im Feed Editor können die Datenquellen für die Mashups verwaltet werden.\n\nDie folgenden Datenformate werden durch ARIS MashZone unterstützt. Um ein Mashup zu erstellen, kann der Benutzer Daten aus den folgenden Quellen miteinander kombinieren:\n\n\nJedes der oben erwähnten Datenformate kann über ein Dateiverwaltungssystem oder eine URL importiert werden.\n\nDer Home Screen gibt dem Nutzer die Möglichkeit, seine Mashups durch zu blättern, zu suchen und zu bewerten. Da MashZone auf einem client-server-Modell basiert, sind auch Mashups von anderen Nutzern gelistet. Mit der Tag Cloud Funktion können Mashups nach bestimmten Schlagworten sortiert werden.\n\nDer Visual Composer ist ein WYSIWYG-Editor zur Erstellung von Mashup Dashboards, die auf Datenfeeds basieren. Als Operatoren werden eine Vielzahl an Tabellen, Diagrammen und Eingabefeldern zur Visualisierung von Daten angeboten. Jede einzelne Komponente kann vom Benutzer bezüglich Erscheinungsbild und Verhalten angepasst werden. In der Datenzuordnungssicht können die Komponenten mit Datenfeeds verbunden werden. Diese Datenfeeds liefern die Werte, welche später im Dashboard visualisiert werden sollen.\n\nDer grafische Datenfeed-Editor von MashZone ermöglicht es, die visuellen Komponenten mit den entsprechenden Datenquellen zu verbinden. Im Editor beschreibt eine Hierarchiestruktur, wie die Daten aus den verschiedenen Quellen gewonnen werden und wie sie später umgewandelt werden.\nDie Datenquellen umfassen Daten, die außerhalb von MashZone gespeichert werden. Man kann Operatoren benutzen um festzulegen, welche Daten von MashZone in welcher Weise verarbeitet werden sollen.\nJeder Datenfeed hat eine Tabellenstruktur als Ergebnis. In Ergänzung zu den verschiedenen Datenquellen bietet die Palette auf der linken Seite verschiedene Operatoren wie \"kombinieren, verknüpfen\" und \"berechnen\". Zusätzlich stehen verschiedene grundlegende Text- und Berechnungsfunktionen zur Verfügung, um die Ergebnisse des Feeds zu beeinflussen.\nDie Operatoren können mittels Ziehen & Ablegen in jeglicher Richtung angeordnet und miteinander verbunden werden.\n\nARIS MashZone ist eine client/server-basierte Anwendung. Diese besteht aus einer auf Java basierenden Webapplikation und einem auf Flash basierenden User Interface – einer Rich Internet Application. MashZone spricht Business Anwender an, die an selbst zu bedienenden Business Intelligence Lösungen interessiert sind. Dazu besteht der Aufbau von MashZone aus zwei Teilen: einer \"Java Laufzeitumgebung\" und einer \"Web-Anwendung\". Das Aufbau-Verfahren versteckt die technischen Details zum Aufbau der Web-Anwendung, Starten der Services oder Auswahl der Ports. Nachdem das Produkt installiert wurde, kann jeder Flash-fähige Browser zum Starten von MashZone benutzt werden. Obwohl die Applikation kostenlos zu erwerben ist, wird ein Lizenz-Schlüssel benötigt, wenn der \"Datenfeed-Editor\" oder der \"Visual Composer\" geöffnet wird. Diesen Schlüssel erhält man kostenlos, nachdem man sich in der ARIS Community registriert hat.\n\nIn der ARIS Community gibt es eine Gruppe speziell für MashZone Nutzer.\nEin Personas for Firefox ist für ARIS MashZone erhältlich.\n\nAuf der Webseite findet man eine Galerie, die man sich anschauen kann, ohne das Produkt installieren zu müssen.\n\n"}
{"id": "5463855", "url": "https://de.wikipedia.org/wiki?curid=5463855", "title": "LinuxPPC", "text": "LinuxPPC\n\nDie ersten CD-ROMs von LinuxPPC wurden im Jahre 1996 an Entwickler und andere interessierte Personen verkauft. LinuxPPC basierte auf Red Hat Linux und der Linux-Kernel Portierung Linux/PPC. Viele Teile des Systems wurden von Red Hat Linux ohne große Veränderungen übernommen. Die im Juni 1998 veröffentlichte Version R4 war sehr erfolgreich, da sie neben Yellow Dog Linux damals die einzige Linux-Distribution war, die sich einfach auf Macintosh-Computern installieren ließ. Nach der Version 4.1 folgte im Jahr 1999 die Version 5.0 und 5.5.\n\nAm 9. November 2000 stellte LinuxPPC Inc. die Version 6.0 seiner gleichnamigen Distribution vor. Sie enthielt erstmals gegenüber Red Hat Linux diverse Optimierungen der Installation und Oberfläche, weshalb dieses Release \"LinuxPPC 2000\" genannt wurde. \"LinuxPPC 2000\" basierte auf Red Hat Linux 6.2. Das Installationsprogramm installierte Gnome als Arbeitsoberfläche. Es war aber möglich nachträglich KDE von der CD-ROM einzuspielen. Neben der bootbaren CD-ROM mit den kompilierten RPM-Paketen der Distribution darauf, lag zusätzlich eine zweite CD-ROM bei, die alle Quellcode-Packete enthielt. Alternativ konnte gratis ein für die damalige Zeit sehr großes (170 MB) Image aus dem Internet heruntergeladen werden. Dieses Image enthielt die Demoversion \"LinuxPPC 2000 lite\" und bot auch ein Live-System.\n\nDie letzte Version von LinuxPPC war 6.0. Bis Anfang 2003 wurden noch Updates für LinuxPPC 2000 angeboten. Im Mai 2003 wurden die LinuxPPC Inc. aufgelöst und alle Entwicklungsarbeiten eingestellt. Da die PPC-Plattform etwa ab dem Jahr 2004 von diversen anderen Distributionen unterstützt wurde, gab es zahlreiche mindestens ebenbürtige Nachfolger für LinuxPPC.\n"}
{"id": "5469815", "url": "https://de.wikipedia.org/wiki?curid=5469815", "title": "Apple Wireless Keyboard", "text": "Apple Wireless Keyboard\n\nDas Apple Wireless Keyboard ist eine kabellose Tastatur, die für Macintosh-Computer hergestellt wurde. Sie kann auch mit dem iPad sowie dem iPod touch und iPhone benutzt werden und verbindet sich über Bluetooth und verfügt, im Gegensatz zur kabelgebundenen Version, über keine USB-Anschlüsse.\n\nAm 16. September 2003 wurde das erste \"Apple Wireless Keyboard\" bei der Apple Expo vorgestellt. Das Gerät brauchte 4 AA-Batterien, und hatte einen Schalter zum Ein- und Ausschalten auf der Rückseite. Es fehlten Kabel und USB-Anschlüsse, das Aussehen glich aber der kabelgebundenen Version.\n\nAm 7. August 2007 brachte Apple ein völlig überarbeitetes Modell des Apple Wireless Keyboards heraus. Wie das kabelgebundene Apple Keyboard war das Modell dünner als sein Vorgänger und hatte ein Aluminiumgehäuse. Eine andere Neuerung waren die neuen Funktionstasten, sowie Media- und Dashboard-Steuerung. Im Gegensatz zu der vorigen Version hatte die neue Tastatur ein Layout passend zum MacBook. Der An/Aus-Knopf wurde auf die rechte Seite der Tastatur gelegt und das neue Layout beinhaltete nicht mehr den Ziffernblock. Die neue Tastatur brauchte auch nur noch 3 AA-Akkus, einen weniger als ihr Vorgänger. Das war vorteilhaft, weil man bei 4er-Packs die letzte Batterie für die Apple Magic Mouse benutzen konnte, die nur ein oder zwei AA-Akkus braucht. Im Oktober 2009 kam eine leicht modifizierte Version heraus. Das neue Modell A1314 ersetzte Modell A1255, zwei Jahre nachdem diese veröffentlicht wurde. Das neue Modell brauchte nur noch zwei AA-Batterien anstelle von drei, benötigte jedoch nun mindestens Mac OS X 10.5.8 anstelle von Mac OS X 10.4.10.\n\nAm 13. Oktober 2015 wurde eine neue Version des Wireless Keyboards mit dem Namen „Magic Keyboard“, passend zur Magic Mouse 2 und dem Magic Trackpad 2, vorgestellt. Es wird nun nicht mehr über zwei AA-Batterien, sondern über einen integrierten Lithium-Ionen-Akkumulator betrieben. Dieser lässt sich über den vom iPhone und iPad bekannten Lightning-Anschluss aufladen, welcher mittig auf der hinteren Kante platziert ist. Durch Verwendung eines integrierten Akkus anstelle von Batterien konnte die Dicke von 1,8 cm auf 1,1 cm verringert werden. Damit einhergehend wurde die Rückseite neuentworfen. Sie hat nun eine einzige Linie anstatt des „aufgerollten“ Designs der zweiten Generation. Wie die vorherigen Generationen besitzt das Magic Keyboard eine Front und Seite aus Aluminium, auf der die Tasten sitzen. Deren Aufschriften sind nun in einem helleren Grau. Die Rückseite besteht nach wie vor aus Kunststoff. Weiterhin wurde der Tastenhub minimiert, dadurch erhält die Tastatur ein völlig anderes Schreibgefühl. Auch wurden die F- sowie Pfeil Links & Rechts-Tasten vergrößert und die Außenmaße reduziert. Es ist nun 27,9 × 11,49 cm groß. Im Vergleich hierzu hatte die zweite Generation Abmessungen von 28,1 × 13 cm. Das Gewicht hat sich jedoch von 73 g (ohne Batterien) auf 231 g erhöht. Laut Apple sind die Tasten nun 33 % stabiler und das Gerät insgesamt habe durch den Wegfall der AA-Batterien eine stabilere innere Struktur. Die Bluetooth-Version wurde von 2.1 auf 4.2 angepasst und der Preis ist um 40 € auf 119 € bzw. um 30 CHF auf 109 CHF gestiegen. Zur Verwendung des Magic Keyboards wird mindestens OS X El Capitan vorausgesetzt.\n\nIm Modus Boot Camp hat Apple die fehlenden Tasten bei Windows-PCs wie die PrintScreen-Taste durch alternative Tastenkombinationen verfügbar gemacht.\n\n\nObwohl Apple hauptsächlich Macintosh-Computer unterstützt, kann sie nun auch mit einem Windows-PC betrieben werden, welcher ein Bluetooth-Gerät und ein passendes Bluetooth-Stack vorweisen kann. Das Aktivieren der „Fn“- und „Eject“-Tasten benötigt die zusätzliche Installation eines „WinA1314 driver“. Das Aktivieren der Multimedia-Tasten und die Neubelegung der Tasten sowie die Zuteilung der Tasten bis ist auch möglich.\n\nEin Tastatur-Layout mit einer verlängerten Enter-Taste ist im US-English- und Japanisch-Layout verfügbar.\n\nTastaturen mit einer L-förmigen Entertaste sind verfügbar für:\n\n"}
{"id": "5471160", "url": "https://de.wikipedia.org/wiki?curid=5471160", "title": "Prime95", "text": "Prime95\n\nPrime95 (prime95.exe) ist ein Programm für Windows und Mac OS X zum Testen der Primalität einer Mersenne-Zahl mithilfe des sogenannten Lucas-Lehmer-Tests. Es wird von GIMPS angeboten und von George Woltman als Software für Volunteer-Computing entwickelt. Die Softwareversionen für GNU/Linux und FreeBSD werden MPrime genannt und besitzen im Gegensatz zu Prime95 keine grafische Benutzeroberfläche.\n\nDas Programm verfügt über eine der schnellsten bekannten Implementierungen für Multiplikationen, in dem es hochoptimierten Prozessor-Code zur Durchführung von schnellen Fourier-Transformationen verwendet. Die zugehörigen Routinen stehen als \"gwnum\"-Bibliothek in der Programmiersprache C zur Verfügung und werden von einigen anderen Programmen eingesetzt. Die \"gwnum\" ist frei nutzbar, jedoch müssen bei der Suche nach Mersenne-Primzahlen die Projektbedingungen (\"Software End User License Agreements „EULA“\") eingehalten werden.\n\nDer Code für die Generierung von Prüfsummen ist aus Sicherheitsgründen nicht öffentlich vorhanden.\n\nDas Programm kann als Software-Client für das \"PrimeNet\", einer von GIMPS betriebenen zentralen Datenbank für Mersenne-Primzahlen, betrieben werden. Es verbindet sich dann in regelmäßigen Abständen mit dem PrimeNet-Server, um neue Arbeit anzufordern und fertige Ergebnisse abzuliefern. Die Berechnung erfolgt auf der CPU, während diese ungenutzt ist. Eine offizielle Unterstützung für GPUs existiert noch nicht. Mit \"CUDALucas\" (Lucas-Lehmer-Test) und \"mfaktc\" (Probedivision) existieren allerdings zwei CUDA-fähige Programme, deren Ergebnisse vom Server ebenfalls akzeptiert werden. Das PrimeNet verfügt Mitte 2011 über rund 62 Teraflops Rechenleistung.\n\nVon PC-Enthusiasten wird Prime95 gerne beim CPU-Übertakten als Stabilitätstest eingesetzt, da das Programm die CPU relativ stark auslastet, woraus eine starke Wärmebelastung resultiert, die oft den kritischen Faktor darstellt. Programminterne Plausibilitätsprüfungen der Rechenergebnisse liefern eine Qualitätskontrolle, die hardwarebedingte Rechenfehler des übertakteten Computersystems offenbaren.\n\nDas Programm kann als Benchmark verwendet werden. Die Ergebnisse können der Öffentlichkeit automatisch durch den \"PrimeNet-Server\" zum Vergleich dargestellt werden.\n1) Durchsatz pro Zeiteinheit, welche Zeiteinheit das ist (Sekunde, Tag oder Jahr), ist irrelevant.\n2) Durchsatz geteilt durch die Taktfrequenz in GHz, keine Messungen bei 1 GHz Taktfrequenz (ergibt andere Werte)\n3) Durchsatz geteilt durch die Taktfrequenz in GHz und die TDP in Watt, multipliziert mit der Kernanzahl. Dieser Wert ist Unsinn, da höhere Taktfrequenzen zweimal \"weggerechnet\" werden, einmal durch Division durch den Takt, ein zweites Mal durch Division der TDP bei diesem Takt. TDP ist weiterhin nicht die Leistungsaufnahme bei Prime95.\n\nPrime95 kann zur Faktorisierung von Zahlen der Form formula_1 benutzt werden. Im Normalfall sucht es jedoch nur nach Mersenne-Primzahlen, für die a = 1, b = 2, c = Primzahl und d = −1 gilt.\n\nDas Programm unterstützt die Faktorisierungsmethoden:\n\n\nBezüglich der Menge aller zu testenden Zahlen, wird die Faktorisierungsmethode Probedivision dem eigentlichen Lucas-Lehmer-Primzahltest vorgeschaltet, um vergleichsweise schnell kleine Faktoren q in einzelnen Zahlen zu finden. Die Faktorisierungsmethode Probedivision zeigt Zahlen auf, die zusammengesetzt sind und deshalb keine Mersenne-Primzahlen sind. Diese Zahlen werden mit Hilfe des PrimeNet-Servers administriert. Auf sie kann der ECM-Test angewendet werden, der mögliche weitere Faktoren mit einer Länge bis etwa 60 Dezimalstellen effektiv findet. Hiernach wird mit jenen Zahlen, welche diesen ECM-Test durchlaufen, bei Bedarf zum Zahlkörpersieb übergegangen, das vom BOINC-Projekt \"NFS@Home\" angeboten wird.\n\nSeit den Anfängen der programmierbaren Grafikprozessoren im Jahr 2000 besteht die Möglichkeit, die Rechenleistung von Grafikkarten zur Berechnung von parallelisierbaren Rechenoperationen zu nutzen (GPGPU). In Zusammenarbeit der Firmen AMD, IBM, Intel und Nvidia wurde der erste Entwurf für OpenCL, eine Programmierschnittstelle u. a. für Grafikprozessoren, ausgearbeitet und schließlich bei der Khronos Group eingereicht.\n\nDurch den derzeitigen Überschuss an GIMPS-Rechenkapazität im Bereich Probedivision durch GPGPU-Unterstützung leistungsfähiger Grafikkarten mittels der \"mfaktc\" Software und OpenCL, werden seit August 2011 höhere Obergrenzen verwendet. Da der Aufwand der Probedivision bei \"mfaktc\" proportional zur Faktorgröße ist, d. h. nur von der Größe des Faktors abhängt, wird diese Software für größere Faktoren zunehmend ungeeignet. Es wird im Vergleich zu den beiden anderen Faktorisierungsmethoden Probedivision und P1 Test jedoch kaum Arbeitsspeicher benötigt, d. h. geeignete Grafikkarten mit vergleichsweise geringem Grafikarbeitsspeicher reichen aus.\n\nBezüglich der Menge aller zu testenden Zahlen, wird der P-1-Test dem eigentlichen Lucas-Lehmer-Primzahltest vorgeschaltet, um effektiv mittelgroße Faktoren q in einzelnen Zahlen zu finden. Er erfolgt im Anschluss an die Probedivision und findet Faktoren, die stark zusammengesetzt sind. Man weiß, dass mögliche Faktoren q von formula_2 den Aufbau formula_3 haben müssen. Der Teil k ist hierbei meist selbst zusammengesetzt. Das Verfahren findet den Faktor q, solange alle Faktoren von k kleiner als die sogenannte B1-Grenze sind (Stufe 1) oder alle bis auf einen kleiner als B1 und der verbleibende letzte Teilfaktor von k kleiner als die sogenannte B2-Grenze ist (Stufe 2, mit B2 ≈ 30*B1). In seltenen Fällen können durch die sogenannte Brent-Suyama-Erweiterung aber auch Faktoren gefunden werden, die das B2-Kriterium eigentlich nicht erfüllen. Der Berechnungsaufwand ist abhängig von der Größe des Exponenten sowie der Wahl von B1 und B2. Stufe B2 benötigt viel Arbeitsspeicher.\n\nDer rechenaufwändige Lucas-Lehmer-Primzahltest wird dann nur noch auf die Untermenge alle Zahlen angewendet, für die obige Faktorisierungsmethode ergebnislos blieben. Im Normalfall erfolgt die Zuweisung von zu testenden Zahlen automatisch durch PrimeNet. Die Grenze, bis zu der Faktoren im Rahmen der Probedivision gesucht werden, ist abhängig von der zu testenden Zahl und steigt mit ihrer Größe an. Die aufwandsoptimalen Obergrenzen sind in der Tabelle \"Probedivision\" genannt. Sie werden empirisch ermittelt.\n\nDie „Elliptic Curve Method“ (ECM) wird auf Zahlen angewendet, die vom PrimeNet-Server zugewiesen werden. Der ECM-Test findet große Faktoren q mit einer Länge bis etwa 60 Dezimalstellen effektiv. Die Exponenten aus der automatischen ECM-Zuweisung des PrimeNet-Servers sind derzeit siebenstellig. Eine Zuweisung erfolgt nur nach entsprechender Einstellung in Prime95 oder manueller Anforderung über die Projekt-Webseite. Es verfügt ebenfalls über eine B1- und B2-Grenze (B2 = 100*B1). Auch hier benötigt Stufe B2 viel Arbeitsspeicher.\n\nAuf der Projekt-Webseite kann in den \"Worker Windows (Prime95)\" bzw. \"Workers (MPrime)\" festgelegt werden, welche Art von Arbeit man erhalten möchte, zum Beispiel ein Faktorisierungsverfahren oder den Lucas-Lehmer-Test. Dies kann auch im Programm selbst vorgenommen werden. Unter \"Status\" sieht man die Arbeiten, die man erhalten hat, sowie die erwarteten Vervollständigungsdaten. Die Arbeiten werden in der Datei worktodo.txt gespeichert. Bei \"Unreserve Exponent\" kann man einen Exponenten freigeben. Die Prozentzahl einer erledigten Arbeit wird automatisch an GIMPS weitergeleitet, man kann sie jedoch auch im Programm bei \"Manual PrimeNet Communication\" (Advanced → Manual Communication…) manuell zur Website schicken, indem man ein Häkchen bei \"Send new expected completion dates to server\" setzt. Dabei werden die neuen Vervollständigungsdaten zum Server geschickt.\n\nMan kann mit dem Programm anonym oder mit einem GIMPS-Nutzerkonto arbeiten. Das Nutzerkonto sowie der Computername müssen im Fenster \"Configure PrimeNet\" (Test → PrimeNet…) eingegeben werden. Will man anonym arbeiten, muss man die Felder leer lassen. Die Ergebnisse sind in der Datei results.txt ersichtlich, die Erneuerungen in Versionen in der Datei whatsnew.txt.\n\nAusgewählte Haupt-Versionen:\n\n\n"}
{"id": "5472124", "url": "https://de.wikipedia.org/wiki?curid=5472124", "title": "GreenBrowser", "text": "GreenBrowser\n\nGreenBrowser ist ein kostenfreier Webbrowser auf der Basis des Internet Explorers.\n\nEr ist ein Browser mit vollem Funktionsumfang, trotzdem ist er sehr kompakt und benötigt nur wenig Festplattenspeicher.\nGreenBrowser wird von der chinesischen Firma morequick entwickelt.\n\nEr bietet einen eigenen Download-Manager, einen Werbeblocker sowie Unterstützung von Tabbed Browsing und Mausgesten. Das Aussehen kann durch Skins, die von der Webseite heruntergeladen werden können, verändert werden. Ebenso gibt es Plug-ins, um den Funktionsumfang zu erweitern.\n\nDer Browser besitzt viele Symbolleisten; die Standardsuchmaschine ist Google.\n\nGreenBrowser war einer der elf Browser, die von Microsoft infolge eines Gerichtsverfahrens mit der EU unter BrowserChoice.eu als Alternative zum Internet Explorer angeboten werden. Im August 2010 wurden GreenBrowser und Sleipnir aus der Liste entfernt und durch Lunascape und SRWare Iron ersetzt.\n"}
{"id": "5476591", "url": "https://de.wikipedia.org/wiki?curid=5476591", "title": "Sony Vaio UX Micro PC", "text": "Sony Vaio UX Micro PC\n\nDer Sony Vaio UX Micro PC ist ein Ultra-Mobile Portable Computer (UMPC). Die Produktion der VGN-UX-Reihe wurde von Sony Mitte 2008 ohne direkten Nachfolger eingestellt. Obwohl ein Nischenprodukt, war der VGN UX als Hollywood-Requisite sehr beliebt; er stellt dabei meist ein futuristisches High-Tech-Gadget dar, das die technische Versiertheit bestimmter Charaktere unterstreichen soll.\n\nIn der UX-Reihe wurden verschiedene Modelle produziert, die aber gemeinsame Leistungsmerkmale hatten:\n\n\nAmerikanische Modelle nutzen 400 MHz RAM, während alle anderen 533 MHz RAM nutzen.\n\nTrotz Intel Core Solo U1x00 CPU läuft der Sony Vaio UX mit Windows Vista nicht ganz flüssig. Die fest eingelötete CPU kann von spezialisierten Werkstätten gegen eine Intel Core 2 Duo U7700 CPU ausgewechselt werden. Die doppelt so hohe thermische Designleistung wird durch das bessere Leistungsmanagement des U7700 ausgeglichen.\n\n"}
{"id": "5479542", "url": "https://de.wikipedia.org/wiki?curid=5479542", "title": "Ventuz", "text": "Ventuz\n\nVentuz ist eine 3D-Echtzeit-Authoring-Software. Die zentralen Anwendungsgebiete sind große Präsentationen, Events, interaktive Applikationen und TV-Grafiken. Ventuz zielt darauf, neueste technologische Entwicklungen und qualitativ hochwertiges Design in einer zuverlässigen Entwicklungsumgebung zu verbinden. Ventuz wird von der Ventuz Technology AG mit Sitz in Hamburg und München entwickelt. \n\nVentuz wurde entwickelt, um alle Bedürfnisse bei der Erstellung professioneller, hochwertiger Präsentationen jeder Art zu befriedigen. Eine Besonderheit von Ventuz ist seine Offenheit in Bezug auf Software- und Hardware-Setups. Es lässt sich flexibel in die verschiedensten Umgebungen integrieren. Dies erlaubt es, komplexe und visuell ansprechende 3D Animationen und Designs mit den neuesten technologischen Entwicklungen zu kombinieren und so neuartige audiovisuelle Präsentationen und Installationen herzustellen. \n\nVentuz ist eine .NET-basierte Software für Echtzeit-3D-Grafik. Sie hat ein grafisches User-Interface, das auf einer Node-Struktur basiert. Dies erlaubt es, 3D-Inhalte und Animationen herzustellen, ohne programmieren zu müssen. Ventuz ist ein Authoring Tool und kann daher nur für das Erstellen einfacher 3D-Objekte genutzt werden. Komplexere 3D-Objekte können aber aus allen gängigen Modelling-Tools importiert werden. Ventuz hat einen Key-Frame-Animationseditor und eine sogenannte State Engine. Letztere ermöglicht vor allem Animationen, die sich an interaktiven Inputs orientieren, wie dem Drücken eines Knopfes und Ähnlichem. Zudem kann man komplexe Logik und maßgeschneiderte Scripts einfach einfügen.\n\nEin Vorteil der offenen Architektur von Ventuz ist die Fähigkeit, Befehle von den verschiedensten Quellen empfangen und verarbeiten zu können. Dies macht Ventuz zu einem mächtigen Tool für interaktive Applikationen. Gängige Anwendungsgebiete sind unter anderem die Navigation durch eine Präsentation via Lichtschranken oder Motion Tracking sowie Informations-Terminals mit Touchscreens. Mit Ventuz lassen sich die verschiedensten Geräte nahtlos einbinden. Auch Multi-Touch-Anwendungen sind möglich.\n\nVentuz-Projekte können in jedem beliebigen Format und jeder Auflösung hergestellt werden. Mehrere Ventuz-Computer können in einem Cluster arrangiert werden und spielen die Präsentation dabei synchron ab, sodass eine einheitliche und fehlerfreie Darstellung garantiert ist. Ventuz beinhaltet außerdem Anwendungen zur Projektion einer Präsentation auf unebene Flächen. Da Ventuz eine 3D-Software ist, ist es auch ein Leichtes, ein Projekt in Stereo3D darzustellen. \n\nVentuz ist zudem eine flexible Lösung für Infomedia und Digital Signage. Daten können aus vielen externen Quellen bezogen werden, so auch aus dem Internet, aus Excel- oder Text-Dateien sowie aus Datenbanken. Sobald die Daten an der Quelle geändert werden, werden auch die Grafiken in der Ventuz-Präsentation angepasst, so dass immer die neusten Informationen dargestellt werden. \n\nViele Firmen weltweit benutzen Ventuz für die Präsentationen der eigenen Produkte, so zum Beispiel Porsche, Volkswagen, Audi, Microsoft, und viele mehr. \n\nZudem wird Ventuz im Bereich der TV-Grafik verwendet. Zu den Sendern, die mit Ventuz arbeiten, gehören RTL, ZDF, National Geographic, WDR, ERTU, mbc und viele andere. Zu den Shows, die mit Ventuz gemacht wurden, gehören DSDS, Wie schlau ist Deutschland?, 5 gegen Jauch, Schlag den Star und das amerikanische Who Wants to Be a Millionaire?. Im Jahr 2009 hat der US-amerikanische Fernsehsender Fox Sport Ventuz für seine on-air-Grafik eingeführt. \n\nDie aktuelle Version ist Ventuz 6 (Stand August 2018).\n\nGrundsätzlich gibt es folgende Ventuz-Editionen:\n\n"}
{"id": "5481914", "url": "https://de.wikipedia.org/wiki?curid=5481914", "title": "Toy Story 3", "text": "Toy Story 3\n\nToy Story 3 aus dem Jahr 2010 ist die Fortsetzung zu \"Toy Story\" aus dem Jahre 1995 und \"Toy Story 2\" aus dem Jahre 1999. Wie seine Vorgänger ist er ein komplett computeranimierter Trickfilm der Pixar Animation Studios. Der Kinostart erfolgte am 18. Juni 2010 in den USA, am 29. Juli 2010 kam er auch in Deutschland in die Kinos. Er wurde in Disney Digital 3-D gerendert. Der Vorfilm zu diesem Film ist Day & Night.\n\nDer mittlerweile 17 Jahre alte Andy bereitet sich auf das College vor. Seine ehemaligen Lieblingsspielzeuge braucht er nicht mehr. Daher plant er, alle bis auf Cowboy Woody, den er mit aufs College nehmen will, auf den Speicher zu stellen. Allerdings lässt er den Beutel mit den Spielzeugen vor der Speichertreppe liegen, woraufhin ihn seine Mutter unter der Annahme, dass sich darin Müll befinde, auf die Straße stellt.\n\nWoody versucht, seine Spielzeug-Freunde zu retten. Aber diese haben sich bereits aus dem Beutel befreit und verstecken sich in einer Kiste mit Spielsachen, die an die Kindertagesstätte \"Sunnyside\" gespendet werden sollen. Irrtümlicherweise wird auch Woody weggebracht. Sunnyside ist auf den ersten Blick ein Spielzeug-Paradies, doch Woody lässt sich nicht täuschen und verlässt seine Freunde, um zu Andy zurückzukehren.\n\nDie Kindertagesstätte entpuppt sich schon bald als Hölle, als Andys restliche Spielzeuge von den jüngsten Kindern der Kindertagesstätte stark ramponiert werden. Daher wollen sie das Spielzeug-Oberhaupt von Sunnyside, Lotso Knuddelbär, überreden, sie in den ruhigeren Teil wechseln zu lassen. Nachdem der Space-Ranger Buzz Lightyear aus dem Raum entkommt, erkennt er, dass Lotso ein grausamer Diktator ist. Lotsos Schergen nehmen Buzz gefangen und löschen sein Gedächtnis mit Hilfe seiner Bedienungsanleitung. Fortan arbeitet Buzz als Lotsos Wächter und hilft mit, die anderen Spielsachen einzusperren.\n\nWoody wird währenddessen auf dem Weg zu Andy von dem kleinen Mädchen Bonnie gefunden, die ihn mit nach Hause nimmt. Bei ihr lebt ein Clown, der früher ein Freund von Lotso war. Er erklärt, wie Lotso zu dem Diktator geworden ist, der er heute ist. Woody kehrt daraufhin nach Sunnyside zurück, um seine Freunde zu retten. Als man versucht, Buzz wieder richtig zu polen, wird er versehentlich auf die spanische Sprache umgestellt. Kurz darauf verliebt Buzz sich in das Cowgirl Jessie.\n\nNun versuchen Andys Spielzeuge, aus Sunnyside zu entkommen, nachdem Mrs. Naseweis mit ihrem in Andys Zimmer verlorenen Auge gesehen hat, dass dieser nach ihnen sucht. Kurz vor dem Ziel werden sie jedoch von Lotso und seinen Schergen gestellt. Es gelingt Woody, die Schergen auf seine Seite zu ziehen, woraufhin Lotsos einstiges Bandenmitglied „Big Baby“ Lotso nach einem Streit in einen Müllcontainer schubst und Lotso Woody in ebendiesen mit hineinzieht. Andys Spielzeuge versuchen, ihn zu retten, landen jedoch nun alle in dem Müllwagen. Dieser lädt sie in einer Müllverbrennungsanlage ab. Buzz wird unterwegs durch einen auf ihn fallenden alten Fernseher wieder richtig gepolt. In der Anlage geraten die Spielzeuge auf ein Förderband, wo sie zunächst einer Zerstückelung entkommen können. Woody rettet den eingeklemmten Lotso, der daraufhin vom Förderband klettert. Er hätte nun die Chance, die Spielzeuge durch das Abschalten der Anlage vor dem Feuer zu bewahren, doch er lässt sie im Stich und trennt sich von der Gruppe. Diese ist nun im Feuerraum gefangen und kurz vor der Verbrennung. Da die Lage aussichtslos erscheint, fassen sich alle Spielzeuge an den Händen, um gemeinsam dem drohenden „Tode“ entgegenzutreten. In letzter Sekunde werden sie jedoch von den drei „Außerirdischen“ via Kran gerettet. Lotso hingegen wird von einem Lastwagenfahrer gefunden und von ihm an den Kühlergrill seines Lastwagens gebunden.\n\nDie Spielzeuge kehren mit dem Müllwagen wieder zu Andy zurück und bereiten sich auf das Dasein auf dem Speicher vor. Woody empfindet dies jedoch als ungerecht und hinterlässt Andy eine Nachricht: Er soll seine Spielsachen dem Mädchen Bonnie schenken. Am Schluss des Films nimmt Andy Abschied von seinen Spielsachen und spielt sogar gemeinsam mit Bonnie ein letztes Mal mit ihnen. Im Abspann ist weiter zu sehen, dass in Sunnyside wieder angenehmere Zustände herrschen.\n\nBevor die Disney Studios Pixar im Januar 2006 kauften, sah es ganz nach einer Spaltung der beiden Studios aus. Disney hatte die Rechte an allen bisherigen Pixar-Filmen und Figuren und gab somit eigenständig eine zweite Fortsetzung zu Toy Story in Auftrag. Das \"Circle 7 Animation Studio\", eigenständig von Disney gegründet, sollte den dritten Teil entwickeln, die Story dazu schrieb Jim Herzfeld. Es sollte ursprünglich darum gehen, dass Buzz einige Fehlfunktionen erlitten hat und in Aussicht auf eine Reparatur von den anderen Spielzeugen nach Taiwan geschickt wird. Im Internet finden die Spielzeuge dann allerdings heraus, dass es weltweit einen Rückruf von defekten Spielsachen gab. Aus Angst, Buzz könnte „entsorgt“ werden, reisen die Spielzeuge ihrem Freund hinterher, um ihn zu retten. Derweil ist Buzz auf andere Spielzeuge aus aller Welt getroffen, die auch „aussortiert“ wurden.\n\nNachdem Disney Pixar gekauft und man sich darauf geeinigt hatte, dass Pixar selbst die Fortsetzung entwickeln würde, verwarf man alle Pläne wieder. An nur einem Wochenende entstand bei einem Brainstorming von John Lasseter, Andrew Stanton, Pete Docter und Lee Unkrich die Geschichte für den Film. Stanton schrieb ein Treatment und Oscar-Preisträger Michael Arndt (Little Miss Sunshine) machte sich daran, das Drehbuch zu schreiben.\n\nNach einer ersten Vorführung der Handlung anhand von Storyboards, ersten Sprachaufnahmen, Soundeffekten und Musik unterschrieben Tom Hanks, Tim Allen und John Ratzenberger für den Film. Im April 2009 begann die Animation. Regisseur Unkrich und das Animationsteam rasierten sich alle zu Produktionsstart die Köpfe kahl. Unkrich dazu: „Jetzt, wo wir alle kahlköpfig sind, der Plan: Mal sehen, wer am längsten ohne Haarschnitt und Rasur auskommt.“\n\nIm Rahmen des Kinostarts von Pixars Film Oben wurde der erste Teaser veröffentlicht. Darin sieht man die Spielzeuge unter Anweisung von Woody den Schriftzug „Toy Story 3“ aufbauen. Buzz dagegen hat ein hochmodernes, elektrisch beleuchtetes Gegenstück vorzuweisen, was alle außer Woody wieder viel interessanter finden.\n\n\"Toy Story\" und \"Toy Story 2\" wurden in den USA am 2. Oktober 2009 als 3D-Film wiederveröffentlicht. In Deutschland wurden die beiden Filme am 27. Mai 2010 wiederaufgeführt, ebenfalls in 3D.\n\nMattel und Lego stellten Spielzeuge zum Film her.\n\nWie im ersten Teil war Pierre Peters-Arnolds, der auch die Rolle eines Spielzeugtelefons übernahm, Dialogautor und -regisseur. Die zuständige Synchronfirma war die FFS Film- & Fernseh-Synchron GmbH.\n\nDer englische Sprecher von Slinky Dog, Jim Varney, starb 2000 an Lungenkrebs. Ein sehr enger Freund von ihm übernahm seine Sprechrolle. Peter Thom, der deutsche Sprecher von Slinky Dog, starb 2005. Die deutschen Synchronstimmen für Woody und Rex werden nicht von den Sprechern der ersten beiden Teile gesprochen.\n\nDer Film kam am 18. Juni 2010 in den USA und Brasilien in die Kinos. Eine Woche später wurde er in Australien gezeigt. Am 23. Juli lief der Film in Großbritannien an, am 28. Juli in Frankreich. Am 29. Juli 2010 startete er in Deutschland und Österreich.\n\nToy Story 3 spielte am ersten Wochenende allein in den nordamerikanischen Kinos 109 Millionen Dollar ein, mehr als jeder andere Pixarfilm zuvor. Er ist der erste Animationsfilm, der über eine Milliarde einnahm. Er liegt auf Platz der kommerziell erfolgreichsten Filme und löste damals Shrek 2 – Der tollkühne Held kehrt zurück als erfolgreichsten Animationsfilm ab, bis ihn Die Eiskönigin – Völlig unverfroren aus dem Jahr 2013 überholte. Aktuell liegt Toy Story 3 auf Platz drei der erfolgreichsten Animationsfilme, ist aber mit 1,063 Milliarden US-Dollar an weltweiten Einnahmen nach wie vor der erfolgreichste Film aus dem Hause Pixar.\n\nDie Free-TV Premiere im deutschsprachigen Raum fand am 29. September 2012 um 20:15 Uhr auf ORF eins, einen Tag später zur gleichen Uhrzeit auf RTL statt.\n\n\"Toy Story 3\" erhielt fast ausnahmslos positive Kritiken. Bei Rotten Tomatoes fielen 99 % von 290 Kritiken positiv aus. So erhielt der Film eine hohe Wertung von 8,9 von 10 Punkten. Auch in der IMDb wurde der Film (mit 8,3/10) sehr gut bewertet. Bei Metacritic liegt die Durchschnittswertung bei 92 % basierend auf 39 Kritiken.\n\nDer Film gewann unter anderem den US-amerikanischen National Board of Review Award als bester Animationsfilm sowie den Golden Globe Award und den British Academy Film Award in dieser Kategorie. Bei der Verleihung der Annie Awards 2011 folgte eine Nominierung in der Kategorie „bester Animationsfilm“, wo sich aber \"Drachenzähmen leicht gemacht\" in dieser (sowie neun weiteren) Kategorie(n) durchsetzen konnte. \n\n\"Toy Story 3\" gewann bei der Oscarverleihung 2011 die begehrte Auszeichnung in den Kategorien „bester Animationsfilm“ und „bester Filmsong“ (\"We Belong Together\"). Darüber hinaus war er in drei weiteren Kategorien nominiert („bester Film“, „bestes adaptiertes Drehbuch“ und „bester Tonschnitt“).\n\nZum Film erschien auch ein Videospiel für Wii, PlayStation 3, Xbox 360, Nintendo DS, Windows PC, Mac und PlayStation Portable. In diesem schlüpft der Spieler in die Rolle von Buzz, Woody oder Jessie oder bei dem PlayStation-3-Spiel erstmals auch in die Rolle des Zurg.\n\n"}
{"id": "5484267", "url": "https://de.wikipedia.org/wiki?curid=5484267", "title": "Background Intelligent Transfer Service", "text": "Background Intelligent Transfer Service\n\nDer Background Intelligent Transfer Service (engl. für \"Intelligenter Hintergrundübertragungsdienst\", kurz BITS) ist eine Softwarekomponente in neueren Versionen von Microsoft Windows zur Übertragung von Daten über HTTP im Hintergrund. Für den Transfer von Daten zieht BITS ungenutzte Netzwerkressourcen heran, so dass der Durchsatz anderer Netzwerkaktivitäten nicht nachteilig beeinflusst wird. Der Dienst wird hauptsächlich von Windows Update, Microsoft Update, Windows Server Update Services und Systems Management Server zum Verteilen von Software-Updates genutzt. Weiterhin findet er beispielsweise im Antivirenprogramm Microsoft Security Essentials zum Laden von Signaturdateien Verwendung. BITS kann über eine COM-Schnittstelle angesprochen werden, was den Zugriff über viele Programmiersprachen ermöglicht.\n\n"}
{"id": "5495082", "url": "https://de.wikipedia.org/wiki?curid=5495082", "title": "Lexikalische Dichte", "text": "Lexikalische Dichte\n\nDie lexikalische Dichte ist ein Maß in der Linguistik, besonders in der Computerlinguistik, das den Anteil der Inhaltswörter an der Gesamtzahl aller Wörter in Prozent angibt. Der Begriff leitet sich vom englischen Ausdruck für Inhaltswörter, , her. Inhaltswörter sind diejenigen Wörter, die eine eigene lexikalische Bedeutung haben. Ihnen gegenüber stehen die Funktionswörter, die überwiegend grammatikalische Bedeutung tragen.\n\nDie lexikalische Dichte kann nach folgender Formel berechnet werden:\nformula_1\n\nDie Skalierung auf Werte zwischen 0 und 100 ist nicht notwendig und wird nicht immer vorgenommen, insbesondere wenn man die lexikalischen Wörter nicht ins Verhältnis zur Gesamtzahl der Wörter setzt, sondern zur Anzahl an grammatikalischen Einheiten, wie beispielsweise Teilsätzen. Außerdem ist eine Gewichtung der lexikalischen Wörter je nach Häufigkeit in der Sprache möglich.\n\nDas Maß wurde von Jean Ure zur Beschreibung von Registervariation eingeführt. Auch Michael Halliday stellte fest, dass die lexikalische Dichte im Gesprochenen geringer ist als bei geschriebener Sprache. Die lexikalische Dichte kann zur Textanalyse in der forensischen Linguistik (unter anderem Plagiarismuserkennung) angewendet werden.\n\n"}
{"id": "5501593", "url": "https://de.wikipedia.org/wiki?curid=5501593", "title": "ProjektPro", "text": "ProjektPro\n\nPROJEKT PRO ist die kommerzielle Planungssoftware der Firma PROJEKT PRO GmbH für Architekten und Bauingenieure, die seit 1992 entwickelt wird. Die Software wird zur Planung von Bauprojekten und für die Abwicklung administrativer Aufgaben in Planungsbüros verwendet.\n\nDie Software besteht aus den Produkten PRO controlling, PRO enterprise mit PRO simulation, PRO management, PRO building, PRO forms, PRO tasks, PRO mobile, PRO ava (Ausschreibung, Vergabe und Abrechnung) und PRO ava X.\n\nPROJEKT PRO kam im Jahr 1992 auf den deutschen Markt und kann mit über 10.000 Installationen auf eine große Verbreitung in Architekturbüros im deutschsprachigen Raum verweisen. Seit 2009 liegen eine englische, seit 2015 eine französische Version vor. Derzeit (Stand Januar 2019) wird die Software nach Aussage des Herstellers in 5 Ländern in über 1.700 Architektur- und Ingenieurbüros mit von 14.000 Usern genutzt. Bei der Weiterentwicklung der Software werden die Bedarfe der Nutzer in kooperativen Pilotprojekten berücksichtigt.\n\nPROJEKT PRO baut auf einem Datenbankmanagementsystem von FileMaker auf. Die Integration in Fremdsystemen erfolgt über eine GAEB-Schnittstelle. PROJEKT PRO läuft unter den Betriebssystemen Windows, mac OS und iOS. Mischnetzwerke sind möglich.\n\nDie erste Version kam 1992 auf den Markt und war eine solitäre Lösung zur Abwicklung der AVA. 1995 folgte das Modul ProjektControlling. Im Jahr 2000 wurden die Module Büro & CRM sowie Projektmanagement ergänzt. Mit dem letzten Modul Workflow & QM kam 2010 die erste Workflow-Lösung speziell für Planungsbüros auf den Markt. 2013 positionierte sich das Unternehmen mit einem neuen Marktauftritt und mit dem Selbstverständnis \"einfach arbeiten\".\n\nBisher erschienene Versionen:\n\n\n\n\n"}
{"id": "5510269", "url": "https://de.wikipedia.org/wiki?curid=5510269", "title": "EliteCAD", "text": "EliteCAD\n\nEliteCAD ist ein CAD-Programm der Firma \"Xeometric\", das als Branchenlösung für Architektur sowie Maschinenbau und Anlagenbau verfügbar ist.\n\nEliteCAD AR ist eine modellorientierte 3D-CAD-Software für die Planung von Gebäuden. Ergebnisse sind dreidimensionale BIM-Projekte, von denen Pläne in diversen Darstellungen bis zum fotorealistischen Rendering und Massenauszüge automatisch generiert werden. Das 3D-Gebäude ist aus parametrisierten Objekten (Wände, Türen, Fenster, Dächer etc.) aufgebaut und kann in beliebigen Ansichten definiert und modifiziert werden. Für Ergänzungen in Plänen oder für die Ausarbeitung von Details ist weitreichende 2D-Funktionalität verfügbar. Neben der CAD-Grundfunktionalität existieren Zusatzmodule für Kanalisation und Geländemodellierung. EliteCAD AR ist IFC2x3 Stufe 2 zertifiziert.\n\nIn EliteCAD ME umfasst der eigentliche Konstruktionsprozess die vollhybride Modellierung von zweidimensionalen und dreidimensionalen Konstruktionsobjekten sowie die Ableitung von dazugehörigen zweidimensionalen Zeichnungen. Darüber hinaus gibt es zusätzliche Module, die Funktionalitäten wie Rohrleitungsbau, Gelände, Maschinenelemente und Normteile bieten. Im Gegensatz zu EliteCAD AR verwendet EliteCAD ME den 3D-ACIS-Modeler und existiert auch als reine 2D Version.\n\nDie aktuell etablierte EliteCAD Version 14 besitzt eine Windows-basierte Oberfläche und liegt in einer 64-Bit-Version vor. Das Standarddateiformat lautet D, für temporäre Arbeitskopien WFL.\n\nIntegrierte Schnittstellen: DXF, DWG, TGF, WRL, TIFF, JPEG, BMP, PNG, IFC, 3DS, VDA, SAT, IGES, MI, STEP, CATIA-V4, CATIA-V5, Autodesk Inventor, Pro/ENGINEER, Parasolid, NX, SolidWorks, Gamma-Ray, PDF, Postscript, SketchUp\n\nEliteCAD AR wird vor allem in der Architektur, Innenarchitektur, Geländeplanung und im Baunebengewerbe als Standard-CAD-System eingesetzt. EliteCAD AR findet Anwendung als Planungswerkzeug für die dreidimensionale Planung von Gebäuden, Siedlungen, Überbauungen mit mehreren Baukörpern und beliebiger Anzahl von Geschossen. Das Einsatzgebiet erstreckt sich von Kleinprojekten wie Einfamilienhäusern, Bürogebäuden, öffentlichen Gebäuden und Hotels, bis hin zu Großprojekten wie Einkaufszentren, Krankenhäuser, Hochhäuser, Wohnanlagen, Flughäfen etc.\n\nDie Hauptanwendungen von EliteCAD ME liegen im Bereich des Maschinenbaues, Anlagenbau und Infrastrukturplanung. In der Kombination von\nAnlagenbau und Geländebau gehört EliteCAD zu den Branchenführern und wird unter anderem für die Planung von Seilbahnen, Liftanlagen und Förderanlagen in der Rohstoffgewinnung eingesetzt. Eine besondere Anwendung ist die Planung der RopeCon-Förderanlagen des österreichischen Seilbahnspezialisten Doppelmayr.\n\nBeim Engineering-Dienstleister HAN-Dataport wurde in den frühen 1980er Jahren damit begonnen, mit Hilfe der Computertechnologie interaktiv Zeichnungen zu erstellen. Die Vorgängersoftware CAD400 wurde international von vielen Unternehmen eingesetzt. Von CAD400 gab es mehrere Versionen, die auf den jeweiligen Anwendungsfall angepasst wurden. So wurden Versionen für Architektur, Haustechnik, Elektrotechnik, Maschinenbau und CAM entwickelt. In dieser Zeit entstand auch die Verbindung zur \"Roland Messerli AG\" (heute \"Messerli Informatik AG\"), die den Vertrieb der Software für die Schweiz durchführte.\n\nMit dem Aufkommen der 3D Modeller in den frühen 1990er Jahren begann auch bei HAN-Dataport die Entwicklung eines 3D Aufsatzes für CAD400. Parallel dazu startete die Neuentwicklung eines CAD-Kernes unter dem Namen \"Elite\". Version 1.0 kam 1995 auf den Markt. \"Elite\" wurde ursprünglich unter UNIX entwickelt. Mit der Portierung auf Windows Ende der 1990er Jahre unterschied man zwischen \"EliteNT\" und \"EliteUX\".\n\n2001 wurden die CAD Aktivitäten von HAN-Dataport herausgelöst und an die \"Messerli Informatik GmbH\" verkauft. Mit dem Wechsel wurde die UNIX-Version eingestellt und \"EliteNT\" auf \"EliteCAD\" umbenannt. Messerli Informatik fokussierte sich mit der Anwendung auf die Kernbereiche Architektur und Mechanik. Die anderen Bereiche wurden teilweise an Partner abgegeben oder eingestellt. Aus dieser Neuausrichtung entstanden die beiden Produktlinien EliteCAD AR und EliteCAD ME, deren Daten kompatibel sind.\n\n2017 wurde die Firma Messerli Informatik GmbH auf Xeometric GmbH umbenannt.\n\nMit EliteCAD können Zeichnungen aller Vorgängerversionen, sowie Zeichnungen bis zur Version CAD400 1.6 geöffnet werden. CAD400 in der aktuellen Version 5.8 wird nach wie vor von Xeometric gewartet.\n\n\n"}
{"id": "5511084", "url": "https://de.wikipedia.org/wiki?curid=5511084", "title": "9 (Film)", "text": "9 (Film)\n\n\nNach einem apokalyptischen Krieg zwischen Menschen und \"Der Maschine\" liegt die Welt in Schutt und Asche, die Menschheit ist ausgelöscht. In einem halb zerstörten Haus erwacht die Stoffpuppe #9. Neben einem toten Wissenschaftler findet sie ein Objekt (Talisman) und nimmt es an sich.\nNach Verlassen des Hauses trifft #9 auf seiner Wanderung eine andere Puppe, #2. Diese repariert die Stimme von #9 und entdeckt den Talisman, doch noch bevor es zu einem weiteren Austausch zwischen den beiden kommen kann, werden sie von einer katzenähnlichen Maschine, \"Biest\" genannt, angegriffen. #2 rettet #9 und wird daraufhin zusammen mit dem Talisman verschleppt. #9 irrt weiter umher und wird dabei von einer weiteren Puppe entdeckt. Diese nimmt #9 mit zu einem Versteck in einer verfallenen Kathedrale, wo sie auf weitere Puppen treffen, die von #1 angeführt werden. Nach einem Streit kann #9 #5 davon überzeugen, #2 zu suchen und zu retten. Sie finden ihn in einer großen Fabrik zusammen mit der Maschine \"Brain\", die unabsichtlich von #9 mithilfe des Talismans zum Leben erweckt wird. Infolgedessen wird #2 getötet – die Maschine saugt ihm die Lebensenergie aus. Den anderen gelingt mit Hilfe der totgeglaubten #7 die Flucht.\n\nUm mehr über die Zusammenhänge und den Talisman zu erfahren, schleichen sie sich zurück zum Versteck der anderen Puppen. Dort werden sie von einer neuen, flugfähigen Maschine angegriffen und können sie nur durch konsequente Zusammenarbeit zerstören. Ihre Zuflucht brennt dabei nieder – die Puppen sind jetzt heimatlos und werden von Brain verfolgt.\n\nAuf der Flucht werden sie von einer neuen Art Maschine überlistet, #8 und #7 werden in die Fabrik verschleppt. Die Puppen verfolgen die neue Maschine zurück zur Fabrik, #9 dringt in die Fabrik ein und bittet die anderen, die Fabrik zu zerstören, falls er nicht zurückkommt. #9 kommt zu spät, um #8 zu retten, dieser wird von Brain ausgesaugt.\nTrotzdem gelingt die Rettung von #7, und die Fabrik wird zerstört. Brain überlebt jedoch und beginnt nun selbst die Verfolgung der überlebenden Puppen – und tötet dabei #5.\n\nWährend der dramatischen Flucht gibt #6 #9 den Rat, zurück zur Quelle – zum ersten Raum – zu gehen, und wird dann ebenfalls von Brain getötet.\n\nWährend die anderen Puppen den näher kommenden Brain mit einer Kanone beschießen, geht #9 zurück in den ersten Raum, in dem er gemacht wurde. Dort kommt er schließlich hinter das Geheimnis Brains und des Talismans. Beim Duell Brain gegen #9 opfert sich #1 und verschafft #9 die benötigte Sekunde, um Brain den Talisman wieder zu entreißen. #9 aktiviert den Talisman und kann Brain zerstören. Der Talisman hat jetzt die Seelen bzw. die Lebensenergie der getöteten Puppen gespeichert, und #9 lässt sie in den Himmel frei. Daraufhin setzt Regen ein, und die Regentropfen begründen neues Leben.\n\nMittels eines nicht genauer beschriebenen Verfahrens konnte der Wissenschaftler Teile von seiner Seele trennen und in den Puppen manifestieren. Die Nummerierung der Puppen erfolgte anhand der Reihenfolge der Erschaffung. \nSie unterscheiden sich nicht nur durch ihr reines Äußeres, sondern auch in ihren Materialien und ihrer daraus abgeleiteten Funktion. Jede Puppe hat besondere Charaktereigenschaften, die in ihrem Handeln dominieren und Auswirkungen auf die Handlung haben.\n\n\n\nDie Synchronisation wurde durchgeführt bei FFS Film- & Fernseh-Synchron in München.\nDer Regisseur Shane Acker ist auch Autor und Regisseur des gleichnamigen Kurzfilms. Animationen zum Film wurden bei \"Attitude Studio\" in Luxemburg begonnen und später bei \"Starz Animation\" in Toronto fortgesetzt.\n\nDer Film kostete ca. 30 Mio. US-Dollar und spielte weltweit über 48 Mio. US-Dollar ein.\n\n"}
{"id": "5511471", "url": "https://de.wikipedia.org/wiki?curid=5511471", "title": "Macintosh File System", "text": "Macintosh File System\n\nDas (engl. Macintosh-Dateisystem) ist ein Dateisystem, das von Apple für 400K-Disketten entwickelt wurde. MFS wurde mit den originalen Apple-Macintosh-Computern im Januar 1984 vorgestellt.\n\nDa das , kurz MFS, für Disketten konzipiert war, wurde bereits mit der Einführung des Macintosh XL 1985 und des Macintosh SE sowie des Macintosh II 1987, die mit einer Festplatte ausgeliefert wurden, ein neues Dateisystem benötigt. MFS wurde daher bereits 1985 vom Hierarchical File System, kurz HFS, abgelöst. System 1 hatte eine Beschränkung in der Verwaltung seiner Verzeichnisstruktur, die bei 128 Dokumenten und 128 Verzeichnissen lag.\n\nNoch bis System 7.6 war MFS voll durch Mac OS unterstützt. Ab System 7.6.1 kann es wegen diversen Stabilitätsproblemen beim schreibenden Zugriff nur noch lesend eingebunden werden. Mit Mac OS 8.1, erschienen 1998, wurde die Unterstützung für MFS vollständig entfernt. Durch den von Apple als Beispiel für einen VFS-Treiber veröffentlichten Quelltext, MFSLives, kann ab Mac OS X 10.4 wieder lesend auf MFS-Dateisysteme zugegriffen werden.\n\n\n"}
{"id": "5515704", "url": "https://de.wikipedia.org/wiki?curid=5515704", "title": "Osborne Executive", "text": "Osborne Executive\n\nDer Osborne Executive war das zweite tragbare Computermodell der von Adam Osborne gegründeten Firma Osborne Computer Corporation aus dem Jahr 1983 und Nachfolger des legendären Osborne 1. Im Vergleich zu seinem Vorgänger verfügte der Executive insbesondere über einen größeren Bildschirm sowie einen auf 128 Kilobyte vergrößerten RAM-Speicher. Er stand insbesondere in Konkurrenz zu tragbaren Computern wie dem Kaypro II, der mit einem 9-Zoll-Bildschirm ausgestattet war und preisgünstig angeboten wurde.\n\nIm September 1983 musste Osborne Konkurs anmelden. Daher kam der Executive nur in begrenzter Anzahl auf den Markt. \nAls möglicher Grund für den Konkurs galt der so genannte „Osborne-Effekt“: Nachfolgemodelle wurden öffentlich angepriesen, lange bevor sie erhältlich waren. Während die Kundschaft bereits auf den besseren „Executive“ wartete, blieb der „Osborne 1“ in den Lagern liegen und die Preise fielen. Mitarbeiter von Osborne verweisen dagegen auf den hohen Konkurrenzdruck durch besser ausgestattete und günstigere Modelle der Hersteller Apple und Kaypro.\n\n\nDer Osborne Executive wurde mit einem Softwarepaket ausgeliefert, das neben dem Betriebssystem CP/M 3.0 (CP/M Plus) das Textverarbeitungsprogramm Wordstar, das Tabellenkalkulationsprogramm SuperCalc, die Programmiersprachen CBASIC und MBASIC sowie einige andere Programme umfasste.\n\nDer Osborne Executive unterstützte folgende Diskettenformate: Osborne 1, einfache und doppelte Dichte, IBM PC (CP/M-86), DEC VT 180, Xerox 820-1, Cromemco mini-disk und UCSD p-System Universal Format.\n\n"}
{"id": "5526869", "url": "https://de.wikipedia.org/wiki?curid=5526869", "title": "Peeker", "text": "Peeker\n\nPeeker war eine deutsche Computerzeitschrift für den Apple-II-Computer. Hauptthema des Magazins waren Programme für den Apple II. Der Zeitschriftentitel stützt sich auf den Befehl \"PEEK\". Die meisten Artikel von Peeker enthielten die Beschreibungen eines Programms, das entweder eine Anwendung, ein Utility für den Rechner oder eher selten ein Spiel war. In der Regel wurde die genaue Funktionsweise der jeweiligen Programme beschrieben. Die Hefte enthielten u. a. auch Programmierkurse und Hardwaretipps. Die Programme wurden zumeist auf Sammeldisketten veröffentlicht, die käuflich zu erwerben waren. In den späten Ausgaben wurde Programmcode auch direkt im Heft veröffentlicht.\n\nDie Zeitschrift wurde erstmals im September 1984 von Ulrich Stiehl beim Hüthig-Verlag herausgebracht. Die Zeitschrift wurde monatlich veröffentlicht, die letzte Ausgabe erschien im März 1987. Insgesamt wurden 28 Ausgaben produziert.\n\n"}
{"id": "5528436", "url": "https://de.wikipedia.org/wiki?curid=5528436", "title": "DIALux", "text": "DIALux\n\nDIALux ist eine von der DIAL GmbH in Lüdenscheid entwickelte und vertriebene 3D-Grafiksoftware für Lichtplanung im Innen- und Außenbereich. Zahlreiche Hersteller von Lampen und Leuchten bieten für ihre Produkte Plug-ins an, die die Abstrahlcharakteristik in Dialux verfügbar machen. Über den Ray-Tracer POV-Ray lassen sich mit Dialux erstellte 3D-Modelle rendern.\n\nDialux unterstützt unter anderem die Lichtplanung von Sportstätten oder die Planung von Notbeleuchtung nach DIN EN 1838. Mit den neueren Versionen lassen sich zudem Energiebewertungen nach DIN V 18599 und EN 15193 durchführen, wie sie für Energieausweise benötigt werden. Wie beispielsweise Porumb et al. zeigen, lässt sich Dialux darüber hinaus für Planungsaufgaben wie die Beleuchtung der optimalen Ausleuchtung von Kunstwerken in einer Galerie einsetzen.\n\nDie Software ist über die Webseite des Herstellers kostenfrei erhältlich. Sie kam etwa bei der Lichtplanung der Alten Pinakothek in München zum Einsatz.\n\n\n"}
{"id": "5529192", "url": "https://de.wikipedia.org/wiki?curid=5529192", "title": "IOS 4", "text": "IOS 4\n\niOS 4 ist die vierte Hauptversion von dem mobilen Betriebssystem iOS für iPhone und iPad des US-Amerikanischen Unternehmens Apple Inc. und der Nachfolger von iPhone OS 3. Es wurde an der Worldwide Developers Conference \"WWDC\" von Apple am 7. Juni 2010 vorgestellt und bereits 14 Tage später am 21. Juni 2010 veröffentlicht. Diese Version ist die erste, die unter dem iOS-Branding veröffentlicht wurde und die Namenskonvention \"iPhone OS\" früherer Versionen fallen ließ. Am 12. Oktober 2011 wurde es durch iOS 5 auf allen Geräten außer dem iPhone 3G ersetzt.\n\nDie Multitasking-Funktion wurde eingeführt, die Apps mit Internet-Aufrufen, Standortverwendungen oder Audiowiedergaben im Hintergrund arbeiten lässt. Zudem wurden Ordner auf dem Startbildschirm eingeführt, sodass deutlich mehr Apps auf einer Seite Platz haben. Für iOS 4 haben die Entwickler außerdem iBooks auf dem iPhone aktiviert, den Mail-Posteingang vereinheitlicht, eine systemweite Rechtschreibprüfung hinzugefügt, das Game Center für Social Gaming und FaceTime für Videoanrufe.\n\niPhone 3G-Nutzer beschwerten sich über Leistungs- und Akkuprobleme nach dem iOS 4-Update. Apple versprach den Nutzern, den Fehler in den bevorstehenden Updates zu beheben.\n"}
{"id": "5534216", "url": "https://de.wikipedia.org/wiki?curid=5534216", "title": "Watson (Künstliche Intelligenz)", "text": "Watson (Künstliche Intelligenz)\n\nWatson ist ein Computerprogramm aus dem Bereich der Künstlichen Intelligenz. Es wurde von IBM entwickelt, um Antworten auf Fragen zu geben, die in digitaler Form in natürlicher Sprache eingegeben werden. Das nach Thomas J. Watson, einem der ersten Präsidenten von IBM, benannte Programm wurde als Teil des DeepQA-Forschungsprojektes entwickelt.\n\nZur Demonstration seiner Leistungsfähigkeit konkurrierte das Programm in drei vom 14. bis 16. Februar 2011 ausgestrahlten Folgen der Quizsendung \"Jeopardy!\" mit zwei menschlichen Gegnern, die in der Show zuvor Rekordsummen gewonnen hatten. Die Partie, für die ein Preisgeld von einer Million Dollar ausgelobt war, wurde in den Medien daher mit dem Duell des Schachweltmeisters Garri Kasparow gegen den Computer Deep Blue verglichen. Das System gewann das Spiel mit einem Endstand von $77.147 gegenüber den $24.000 bzw. $21.600 seiner menschlichen Konkurrenten. Im Januar 2017 ersetzte eine japanische Versicherung mehr als 30 Mitarbeiter durch die Watson-Plattform. Die KI soll Namen und Daten der Versicherten sowie deren medizinische Vorgeschichte prüfen und Verletzungen bewerten.\n\nZiel des Projekts ist es letztlich, eine hochwertige Semantische Suchmaschine zu schaffen. Diese soll den Sinn einer in natürlicher Sprache gestellten Frage erfassen und in einer großen Datenbank, die ebenfalls Texte in natürlicher Sprache umfasst, innerhalb kurzer Zeit die relevanten Passagen und Fakten auffinden. Eine derartige Software könnte in vielen Bereichen, etwa der medizinischen Diagnostik, komplexe Entscheidungen unterstützen, insbesondere wenn diese unter Zeitdruck getroffen werden müssen.\n\nWatson implementiert Algorithmen der Natürlichen Sprachverarbeitung und des Information Retrieval, aufbauend auf Methoden des Maschinellen Lernens, der Wissensrepräsentation und der automatischen Inferenz. Das System enthält Softwaremodule zur Erstellung von Hypothesen, ihrer Analyse und Bewertung. Es greift dabei auf eine Aussagensammlung und umfangreiche Textbestände zurück, ist jedoch nicht mit dem Internet verbunden. Anfragen an Watson werden bislang in Textform gestellt. Anders als aktuelle Systeme wie z. B. Wolfram Alpha benötigt es jedoch keine formale Abfragesprache. Seit Februar 2011 arbeitet IBM mit der Firma Nuance zusammen, einem führenden Hersteller von Software zur Spracherkennung. Die geplante Fähigkeit, auch gesprochene Fragen zu bearbeiten, soll den Einsatz einer spezialisierten Version Watsons im Gesundheitswesen erleichtern.\n\nIBM plant, auf Watson basierende Systeme im Laufe der nächsten Jahre kommerziell zu vermarkten. Der Leiter des zuständigen Forschungslabors geht davon aus, dass die Kosten des Gesamtsystems zunächst mehrere Millionen US-Dollar betragen könnten, da bereits die notwendige Hardware mindestens eine Million Dollar kostet. Im Rahmen von Pilotstudien wurde das System bislang unter anderem dazu verwendet, Vorhersagen zu treffen, welche Arzneistoffe gegen bestimmte Krankheiten wirksam sein könnten; durch Integration zahlreicher Sensordaten und Informationen zu Umwelteinflüssen vorherzusagen, welche Bauteile komplexer Industriemaschinen Gefahr laufen vorzeitig auszufallen und daher gewartet werden sollten; aber auch dazu, innovative Kombinationen von Zutaten für schmackhafte Kochrezepte vorzuschlagen. Zudem ist geplant zukünftig neuromorphe Chips, wie z. B. TrueNorth, zu integrieren um Eingaben in Form von natürlicher Sprache, Bildern und Videos, sowie beliebigen Sensoren zu ermöglichen. Darüber hinaus soll Watson in Zukunft Rechtsanwälte bei der rechtlichen Recherche in juristischen Datenbanken entlasten.\n\nDie Quizshow \"Jeopardy!\" stellt Systeme zur automatischen Beantwortung natürlichsprachiger Fragen vor eine interessante Herausforderung, da die als Antworten gestellten Aufgaben meist bewusst mehrdeutig formuliert sind, häufig die Verknüpfung mehrerer Fakten erforderlich machen und die passende Frage innerhalb eines Zeitlimits von fünf Sekunden gefunden werden muss. Die Entwickler des System Watson setzten sich daher das Ziel, in diesem Spiel menschliche Kandidaten zu schlagen.\n\nBei ersten Testläufen im Jahr 2006 fand Watson nur für etwa 15 % von 500 Umschreibungen vorangegangener \"Jeopardy!\"-Sendungen die korrekte Frage. Die besten Kandidaten von \"Jeopardy!\" erreichen im Vergleich dazu etwa 95 % Genauigkeit. Im Laufe der nächsten Jahre wurde Watson mit einer Datenbank von ungefähr 100 Gigabyte an Texten ausgestattet, darunter Wörterbücher, Enzyklopädien, wie z. B. die gesamte Wikipedia, und anderes Referenzmaterial. Watson hat jedoch keine Verbindung zum Internet, ist also, wie seine menschlichen Gegenspieler, auf \"sich allein\" gestellt. Die Informationen werden unter anderem statistisch ausgewertet, um Sinnbezüge herzuleiten. Anstatt sich auf einen einzelnen Algorithmus zu stützen, nutzt Watson hunderte davon gleichzeitig, um über einen Pfad eine potentiell richtige Antwort zu finden. Je mehr Algorithmen unabhängig voneinander die gleiche Antwort erreichen, als desto wahrscheinlicher wird es angesehen, dass Watson die korrekte Lösung gefunden hat. Wenn das System für eine Aufgabe eine kleine Anzahl potentieller Lösungen erarbeitet hat, werden diese anhand einer Datenbank überprüft, um zu bewerten, welche davon als potentiell sinnvoll gelten können. Dazu werden z. B. Zeitangaben überprüft.\n\nIn einer Sequenz von 20 Übungsspielen nutzten die menschlichen Kandidaten die 6 bis 8 Sekunden Dauer während des Lesens des Ratebegriffes dazu, den Buzzer zu betätigen und die korrekte Antwort zu geben. Das auf diese Zeitspanne optimierte System Watson evaluiert eine Antwort und entscheidet, ob es genügend Sicherheit bezüglich des Ergebnisses gibt, um den Buzzer auszulösen.\n\nSeit Februar 2010 ist Watson in der Lage, im Rahmen regelgerechter Partien menschliche \"Jeopardy!\"-Kandidaten zu schlagen. IBM stellte zunächst eine Übungssituation in einem Konferenzraum im Thomas J. Watson Research Center in Yorktown Heights, New York, nach, die die Situation bei \"Jeopardy\" nachahmt, und ließ Einzelpersonen, einschließlich früherer \"Jeopardy\"-Kandidaten, in Probespielen gegen Watson teilnehmen, mit Todd Alan Crain von \"The Onion\" als Quizmaster. Dem Computersystem, auf dem Watson ausgeführt wurde, wurden die Ratebegriffe (als Antwort auf eine Frage) elektronisch übermittelt und es war in der Lage, den Buzzer zu betätigen und mit einer elektronischen Stimme die Antworten im \"Jeopardy\"-eigenen Frageformat zu geben.\n\nSchließlich trat Watson bei \"Jeopardy\" in drei Sendungen, die zwischen dem 14. und 16. Februar 2011 ausgestrahlt wurden, gegen die früheren Champions Ken Jennings und Brad Rutter an, welche in der Show zuvor Rekordsummen gewonnen hatten. Nachdem das System Watson und der Kandidat Rutter nach der ersten Runde noch gleichauf lagen, ging Watson aus den beiden anderen als klarer Sieger hervor. Das Preisgeld von einer Million US-Dollar stellte IBM gemeinnützigen Zwecken zur Verfügung. Jennings und Rutter kündigten an, jeweils die Hälfte ihrer Preise von $300.000 bzw. $200.000 zu spenden.\n\nDie Softwareengine von Watson ist DeepQA. Diese läuft bei Watson auf dem Betriebssystem SUSE Linux Enterprise Server.\n\nDer Rechnerverbund besteht aus 90 Power 750 Servern mit 16 TB RAM. Jeder Server besitzt einen mit 3,5 GHz getakteten Power7 8-Kern Prozessor, wobei jeder Kern bis zu 4 Threads gleichzeitig ausführt.\n\nGeschrieben wurde DeepQA in verschiedenen Programmiersprachen; darunter Java, C++ und Prolog. DeepQA ist hierbei in Form von Annotatoren einer UIMA-Pipeline implementiert.\n\nDurch den Einsatz von \"UIMA Asynchronous Scaleout\" und Hadoop wird eine massive Parallelisierung ermöglicht. Spezielle UIMA Annotatoren ermöglichen dabei eine Abbildung auf Hadoop MapReduce-Schema um eine große Anzahl von Textdokumenten parallel durchsuchen zu können.\n\nWatson übernimmt eine Jeopardy!-Antwort (die Frage) des Moderators in elektronischer Form über eine Tastatur. Eine solche Jeopardy!-Antwort kann dabei sehr komplex sein und aus mehreren Sätzen, Rätseln und Wortwitzen bestehen.\n\nDie Jeopardy!-Antwort wird von der DeepQA-Engine mit Hilfe eines Linguistischen-Präprozessors analysiert. Dabei wird die logische Struktur mit Hilfe eines Parsers des Satzes als Baum in Prolog abgebildet.\n\nEin Tokenizer, bestehend aus UIMA-Annotatoren für Pattern Matching, kümmert sich um die Abbildung auf \"Lexikalische Antworttypen\" (LAT). Dabei wird die Beziehung der Satzteile zueinander (die Grammatik) analysiert. Das betrifft insbesondere das Pronomen (auf das Watson sich mit der von ihm zu generierenden Frage beziehen muss), sowie Wörter, die angeben, welche Klasse von Antwort (z. B. Poet, Land, Epoche, etc.) gesucht wird.\n\nDas Pronomen wird – sofern dieses nicht als solches erkennbar ist – dadurch gefunden, dass durch dessen Entfernung aus der Frage eine Aussage wird. Auf diesen Teil des Satzes legt DeepQA den \"Fokus\" bei der Kandidatenbewertung.\n\nDie Kandidatengenerierung nimmt den Prolog-Code des Linguistischen Präprozessors entgegen und leitet diese an verschiedene Suchmaschinen weiter. Hierbei wird etwa INDRI und Lucene für die Durchsuchung von unstrukturierten Dokumenten eingesetzt, welche in einem HDFS gespeichert sind. Zudem gibt es spezielle Engines die den LAT-Prolog-Code entgegennehmen und SPARQL-Abfragen auf semantischen Datenbanken () bzw. SQL-Abfragen auf relationalen Datenbanken durchführen, welche auf DB2 basieren. Die Dokumente decken hierbei ein breiteres Wissensgebiet ab und sind schneller durchsuchbar, während die strukturierten und insbesondere semantischen Datenquellen eine höhere Genauigkeit bieten.\n\nDie Daten stammen aus verschiedenen Quellen, wie etwa DBpedia, Wordnet, Yago, Cyc, Freebase, Wikipedia, IMDB, World Book Encyclopedia, der Bibel sowie verschiedenen Taxonomien und Ontologien, Literarischen Werken und Artikeln von PR Newswire und New York Times. Zudem werden Webseiten analysiert und in Form von Textschnipseln in den Datenbanken von Watson gespeichert.\n\nDeepQA generiert dabei zwischen 100 und 250 Suchergebnisse. Diese Ergebnisse (\"Kandidaten\") stellen Hypothesen für die mögliche Antwort dar.\n\nIn Jeopardy! hat Watson keinen Zugriff auf das Internet, sondern nur auf die Daten in den internen Datenbanken. Prinzipiell hat DeepQA für zukünftige Anwendungen jedoch auch die Möglichkeit, weitere Informationen aus dem Internet zu beziehen und mit Hilfe von Webservices auch Echtzeitdaten zu berücksichtigen.\n\nDie wahrscheinlichsten Ergebnisse der Suche werden genauer analysiert. Hierzu besitzt DeepQA mehrere tausend Softwareagenten die jeweils eine ganz spezielle Analyse parallel durchführen. Hierzu gehören vor allem Agenten für die Analyse von zeitlichen (temporalen) und räumlichen (spatiellen) Zusammenhängen, Taxonomien, einfachen Berechnungen für Rechenrätsel, Bewertung der Akustik für Wörter die ähnlich klingen, Scrabble-Bewertung für Wörter deren Buchstaben vertauscht wurden, Agenten, die Suchergebnisse einer genaueren semantischen Analyse durchführen, sowie viele andere mehr.\n\nDiese Analyse umfasst oft ein sehr breites Wissensspektrum, wobei verschiedene Kandidaten und Wissensdomänen von den jeweiligen Agenten voneinander unabhängig und massiv parallel analysiert werden. Da jedes Suchergebnis von bis zu tausend Agenten analysiert wird, multipliziert sich die Anzahl der gleichzeitig analysierten Evidenzfragmente. Aus den 100 bis 250 Hypothesen werden somit bis zu 100.000 Evidenzfragmente die in unabhängigen Threads analysiert werden. Ein Softwarefilter eliminiert alle Ergebnisse von Agenten, die keinen Beweis für die Richtigkeit eines Suchergebnisses erbracht haben.\n\nEnde August 2016 veröffentlichte 20th Century Fox einen Trailer zum Film \"Das Morgan Projekt\", der von Watson gefertigt wurde. Es handelt sich dabei um den ersten Trailer der Filmgeschichte, der durch einen Algorithmus entstanden ist. Der IBM-Manager John R. Smith erklärte in einem Blogeintrag, Watson habe insgesamt 100 Trailer von Horrorfilmen analysiert, um den rund 60 Sekunden langen Trailer zu fertigen. Watson unterteilte diese in Segmente, und nach einer visuellen Analyse, einer Audio-Analyse und einer Analyse der Szenen-Zusammensetzung, analysierte die künstliche Intelligenz den Film \"Morgan\" und filterte die passenden Stellen heraus. Letztlich entschied sich das System für zehn Sequenzen, aus denen dann ein Filmteam den Trailer zusammensetzte.\n\nAuf der CeBIT 2017 präsentierte IBM einen autonomen Bus namens Olli, der durch Watson gesteuert wird. Watson und Olli sind vernetzt, die Rechenleistung kommt aus IBMs Datenzentrum in Frankfurt.\n\nIn Form von unterschiedlichen Anwendungen steht Watson mittlerweile auch Endnutzern zur Verfügung. Ein Beispiel hierfür ist Watson Analytics, eine Software für intelligente Datenanalyse und Visualisierung.\n\nIm Bereich der Onkologie berät \"Watson for Oncology\" Krebsärzte in 230 Krankenhäusern weltweit bei der Suche nach der jeweils besten Therapie (Stand Mitte 2018). Allerdings kritisierte 2017 der Leiter der Krebsabteilung von Kopenhagens Reichskrankenhaus das System scharf und stoppte an seiner Klinik das Experiment.\n\n\n\n"}
{"id": "5535477", "url": "https://de.wikipedia.org/wiki?curid=5535477", "title": "Ich – Einfach unverbesserlich", "text": "Ich – Einfach unverbesserlich\n\nIch – Einfach unverbesserlich (Originaltitel \"Despicable Me\"; engl. für „Ich Verabscheuungswürdiger“) ist ein US-amerikanischer CGI-Animationsfilm der Universal Studios, produziert von Chris Meledandri. Für die Computeranimation verpflichtete die Produktionsfirma Illumination Entertainment das französische Studio Mac Guff. Der Film erschien am 9. Juli 2010 in den Vereinigten Staaten und wurde sowohl von Kritikern als auch vom Publikum positiv aufgenommen. In Deutschland kam der Film am 30. September 2010 in die Kinos.\n\nDer Nachfolger \"Ich – Einfach unverbesserlich 2\" lief am 4. Juli 2013 in den deutschen Kinos an. 2017 folgte \"Ich – Einfach unverbesserlich 3\".\n\nDer Superschurke Gru lebt inmitten einer wunderschönen Vorstadtidylle. Seine Lieblingsbeschäftigung ist es, der Menschheit den Tag zu vermiesen. Sein schwarzes Haus und der verödete Rasen davor sind leicht zwischen den anderen gepflegten Häusern zu erkennen. Sein wahres Reich verbirgt sich jedoch tief unter seinem Haus in einer weit verzweigten Geheimfestung. Umgeben von einer Armee von Minions, seinen gelben kleinen Untergebenen, schmiedet der Hausherr hier seine weltweiten Schurkenstreiche, deren Krönung der Diebstahl des Mondes werden soll. Mit diesem Streich will er auch sein Lebensziel erreichen: Dass seine Mutter stolz auf ihn ist.\n\nDie Probleme beginnen, als ein junger aufstrebender Schurke namens Vector ihn durch den spektakulären Raub der Cheops-Pyramide von Platz 1 der Superschurken verdrängt. Um seinen Platz zurückzuerobern, beantragt er bei der „Bank des Bösen“ einen Kredit für die Finanzierung der Mondentführung. Der Bankdirektor Mister Perkins verlangt jedoch als Sicherheit, dass Gru zunächst den dafür erforderlichen Schrumpfstrahler in seinen Besitz bringt.\n\nGru kann den Schrumpfstrahler durch einen Diebstahl zwar zunächst an sich nehmen, doch entwendet Vector diesen im Anschluss daran und kann flüchten. Daraufhin versucht Gru, in Vectors Festung einzubrechen. Nach vielen vergeblichen Versuchen bemerkt er, dass Vector drei kleine Waisen namens Margo, Edith und Agnes hineinlässt, um ihnen Kekse abzukaufen. Gru beschließt, die drei für seinen Plan zu benutzen. Zu diesem Zweck adoptiert er sie, indem er sich im Heim als Zahnarzt ausgibt. Während die kleine Agnes ihn gleich ins Herz schließt, zweifelt Edith noch und Margo ist sich sicher, dass Gru niemals ein guter Vater sein wird.\n\nAnfangs kommt Gru überhaupt nicht mit den Kindern zurecht und betrachtet sie nur als Mittel zum Zweck. Er lässt die Kinder Vector als Kekse getarnte Spionageroboter verkaufen, mit deren Hilfe er den Schrumpfstrahler an sich bringt. Jedoch verweigert Mister Perkins Gru weiterhin den Kredit, weil er ihn für veraltet hält und lieber jüngere Schurken unterstützen möchte. Der Zuschauer erfährt, dass Perkins möchte, dass Vector, sein Sohn, den Mond stiehlt. Perkins informiert Vector, dass Gru den Schrumpfstrahler gestohlen hat. Vector verspricht seinem Vater, dass er den Mond trotzdem als erster stehlen wird.\n\nNach Ablehnung seines Kreditwunsches sieht sich Gru nun gezwungen, seine Pläne aufgrund von Finanzierungsproblemen aufzugeben. Jedoch legen die Kinder und die Minions ihre Ersparnisse zusammen, sodass eine Rakete aus Schrottteilen gebaut werden kann. Während dieser Zeit wachsen Gru die Mädchen ans Herz. Grus Helfer Dr. Nefario befürchtet, dass Gru durch seine Beziehung zu den Kindern von seinem Ziel abgelenkt werden könnte. Der Diebstahl des Mondes ist für den 26. Mai geplant, am selben Tag findet auch ein Ballettauftritt der Mädchen statt. Dadurch sieht Dr. Nefario das gemeinsame Projekt gefährdet. Dr. Nefario kontaktiert daraufhin hinter Grus Rücken das Heim und bittet im Namen von Gru um die Auflösung der Adoption. Als die Kinder abgeholt werden, bricht es die Herzen der Kinder und das von Gru. Gru lässt sich aber überzeugen, dass es das Beste für ihn sei, und er konzentriert sich wieder auf das Stehlen des Mondes. Sein Plan gelingt: Gru fliegt zum Mond, den er mit Hilfe des Schrumpfstrahlers auf Tomatengröße schrumpft.\n\nNoch während er den Mond in den Händen hält und seinen Triumph genießt, entdeckt er die Eintrittskarte zur kurz bevorstehenden Ballettaufführung der Kinder. Spontan eilt er zurück zur Erde, wo die Aufführung aber bereits vorüber ist und Vector die Kinder entführt hat. Im Austausch für die Kinder fordert Vector den Mond. Jedoch hält sich Vector nach Übergabe des Mondes nicht an sein Versprechen und flieht mit dem Mond und den Mädchen in seinem Raumschiff.\n\nDr. Nefario hat mittlerweile herausgefunden, dass der Schrumpfstrahl nur begrenzte Zeit wirkt. Alle sind damit in großer Gefahr, wenn der Mond zu seiner ursprünglichen Größe zurückkehrt. Dr. Nefario und Gru können die Mädchen in letzter Sekunde retten, bevor der geschrumpfte Mond wieder seine normale Größe erreicht und einen Hypersprung bei Vectors Raumschiff auslöst, was den Mond auf seine alte Umlaufbahn befördert. Vector überlebt, ist aber auf dem Mond gestrandet. Die Welt jubelt über den unbekannten Helden und erwartet seine nächsten Taten.\n\nGru sieht nun ein, wie wichtig die Mädchen für ihn sind, und nimmt die Rolle des ersehnten Vaters an. Auch Margo und Edith vertrauen ihm nun. Bei einer Extraballettvorstellung der Kinder für Gru, seine Mutter und die Minions gesteht Grus Mutter, wie stolz sie auf ihren Sohn ist. Damit hat Gru auch sein Lebensziel erreicht. Gru schreibt ein Kinderbuch, das auf seinen Erkenntnissen basiert.\n\nDie deutsche Synchronisation des Films übernahm die Berliner Synchron nach einem Dialogbuch und unter der Dialogregie von Frank Schaff.\n\nDer Soundtrack des Films wurde von Heitor Pereira und Pharrell Williams komponiert.\nWeitere Songs des Films stammen von Lupe Fiasco („Minion Mambo“), Robin Thicke („My Life“), den Bee Gees („You Should Be Dancing“), Lynyrd Skynyrd („Sweet Home Alabama“) und den Sylvers („Boogie Fever“).\n\nDer Film wurde überwiegend positiv aufgenommen. Rotten Tomatoes verzeichnet eine positive Wertung von 81 %, basierend auf 183 Kritiken. Metacritic gibt eine Bewertung von 72/100 basierend auf 35 Kritiken an. In der Internet Movie Database erhält \"Ich – Einfach unverbesserlich\" eine Durchschnittsbewertung von 7,7/10 (Stand: 16. Mai 2017).\n\n\"Ich – Einfach unverbesserlich\" wurde mehrfach als bester Animationsfilm nominiert, so etwa 2011 für den Golden Globe Award als \"Bester Animationsfilm\". Bei den Nickelodeon Kids’ Choice Awards 2011 gewann der Film in der Kategorie \"Lieblings-Animationsfilm\".\n\nDie Deutsche Film- und Medienbewertung (FBW) vergab das \"Prädikat besonders wertvoll\".\n\nDer Film erschien am 3. Februar 2011 in Deutschland auf DVD, Blu-ray und 3D-Blu-ray. Die Blu-ray-Versionen beinhalten eine Digital Copy.\n\nDie Fortsetzung zu \"Ich – Einfach unverbesserlich\" unter dem Titel \"Ich – Einfach unverbesserlich 2\" kam am 4. Juli 2013 in die deutschen Kinos. Am 2. Juli 2015 erschien der Film Minions in den deutschen Kinos, der die Vorgeschichte der Minions thematisiert. Am 6. Juli 2017 war der Deutschlandstart von \"Ich – Einfach unverbesserlich 3\".\n\n"}
{"id": "5535583", "url": "https://de.wikipedia.org/wiki?curid=5535583", "title": "Kontron PSI 80", "text": "Kontron PSI 80\n\nDer Kontron PSI Ψ 80 war ein kompaktes Microcomputer-Modell, hergestellt Anfang der 1980er Jahre von der damaligen Firma KONTRON Mikrocomputer GmbH, Eching bei München, einer Vorläufer-Firma der heutigen Kontron AG.\n\nDas Gerät wurde in zwei Gehäusevarianten angeboten, als PSI Ψ 80, ein Tischcomputer mit eingebautem 9-Zoll-CRT-Bildschirm, und unter der Bezeichnung PSI Ψ 82 als Industriecomputer zum Einbau in ein 19-Zoll-Rack mit separatem 12-Zoll-Monitor. Beide Gehäuse zeichneten sich durch den eingebauten Einschubrahmen aus, der Baugruppen und Schnittstellen im Europaformat aufnehmen konnte. Der Computer war mit dem ECB-Bus konstruktiv zur Aufnahme von Subprozessorbaugruppen, Echtzeituhr, digitalen und Analogen Ein-/Ausgabeschnittstellen, IEC/IEEE488-Bus-Controller und weiteren Zusätzen ausgelegt. Als Einsatzgebiete waren u. a. industrielle Steuerung, Laborautomatisierung, Ausbildung, technisch-wissenschaftlicher Einsatz, Messdatenerfassung, Prozesskontrolle, Softwareentwicklung und Büroeinsatz vorgesehen.\n\nDer Computer wurde weitgehend baugleich auch als Kienzle CC-9010 von der damaligen Kienzle Apparate GmbH angeboten.\n\nDas Gehäuse des PSI Ψ 80 hatte die Abmessungen 455 × 355 × 270 mm (B/T/H) und wog ca. 15 kg. Die Zentraleinheit war als damals hochintegrierte Computerbaugruppe mit Ausbaumöglichkeiten ausgeführt. Als Prozessor wurde ein Zilog Z80A mit einer Taktfrequenz von 4 MHz eingesetzt. Weitere Merkmale waren:\n\nDer eingebaute Monochrom-Bildschirm war in grün oder optional in bernstein ausgeführt und stellte im Text-Modus 2.000 Zeichen in 25 Textzeilen mit 80 Zeichen dar. Im Grafikmodus waren es über 130.000 Bildpunkte in 256 Bildzeilen zu je 512 Punkten.\n\nMaximal waren zwei Diskettenlaufwerke integriert und bis zu vier Laufwerke anschließbar. Standardmäßig verfügten sie über eine Speicherkapazität von 308 KB (77 Spuren) bzw. 616 KB (2 × 77 Spuren) bei der Modellreihe PSI Ψ 80/Q. Das Modell PSI 80 D/W5 beinhaltete anstelle eines zweiten Diskettenlaufwerk eine Festplatte mit einer Kapazität von 5 MB (formatiert). Zudem wurden externe Festplatten im 8-Zoll-Format mit einer Kapazität von 10 oder 20 MB angeboten, anzuschließen über die Parallelschnittstelle.\n\nKontron stattete die PSI Ψ 80 Computer mit dem firmenspezifischen Betriebssystem KOS aus, das durch ein Software-Modul Kompatibilität zu den Systemaufrufen von CP/M 2.2 bot, aber in seiner Funktionalität weit darüber hinausging. Dazu zählten unter anderem ein fortschrittliches Dateiverwaltungssystem sowie Multitasking mit Vordergrund-/Hintergrundbetrieb, beispielsweise Spooling für Druckerausgabe, Datenkommunikation oder anwendungsspezifische Teilaufgaben. KOS verwaltete bis zu 10 Tasks, die mit Priorisierung in Zyklen von 20 ms abgearbeitet wurden.\nWichtige Eigenschaften von KOS waren:\n\nIm Preis des PSI Ψ 80 war ein Paket von Standardsoftware beinhaltet – ein Programm zur Erstellung von Texten und Software-Quellcode (PSI/EDITOR), als Treiber bzw. relokative Objektmodule realisierte Software zur Grafikdarstellung (PSI/GRAPH), dazu PSI/ASM und PSI/LINK, Makro-Assembler und Linker zur Umwandlung von Assembler-Programmen und zum Zusammenbinden von Programmteilen, sowie PSI/BASIC, ein Interpreter der Programmiersprache BASIC mit spezifischen Erweiterungen und Funktionen.\n\nDarüber hinaus wurden von KONTRON separat lizenziert angeboten:\n\nAufgrund der weitgehenden CP/M-Kompatibilität von KOS konnte, gegebenenfalls nach Adaption, die am Markt verfügbare Software für CP/M eingesetzt werden, sofern diese keine Speicherbedarf von mehr als 50 KB hatte.\n\nAuf Basis der PSI-80-Systeme und des Betriebssystems KOS realisierte Kontron das Mehrbenutzersystem KOBUS, quasi eine Fileserver-Lösung. Eine PSI-Masterstation steuerte die Kommunikation zwischen Master und bis zu 16 PSI-Terminalstationen. Der Master war ein erweiterter PSI-Computer mit Festplatte, meist 20 MB, und einem selbständig arbeitenden KOBUS-Preprozessor als Subsystem zur Steuerung der Übertragung und zur Unterstützung der Festplattenverwaltung. Als Endgeräte waren PSI-Systeme mit eigenem Massenspeicher einsetzbar, aber auch Systeme ohne Massenspeicher (PSI Ψ 80/TC), die vom zentralen Server booteten. Die Anbindung ins Netz erfolgte über den KOBUS-Anschluss (RS-422), der über Koaxialkabel eine Übertragungsrate von 800 kBit/s zur Verfügung stellte. Der Transfer zwischen KOBUS und RAM war DMA-gesteuert.\n\n\n\n"}
{"id": "5536578", "url": "https://de.wikipedia.org/wiki?curid=5536578", "title": "UNetbootin", "text": "UNetbootin\n\nUNetbootin steht für \"Universal Netboot Installer\" und ist ein freies Programm, mit dessen Hilfe eine Linux- oder BSD-Distribution auf Rechnern ohne CD- oder DVD-Laufwerk, beispielsweise über einen USB-Wechseldatenträger, installiert werden kann.\n\nEs unterstützt eine Vielzahl von Betriebssystemen nativ, wie zum Beispiel Ubuntu, Fedora und Gentoo, die das Programm selbstständig im Hintergrund herunterladen und einrichten kann. Außerdem ist es möglich, auf ein auf einer Festplatte bereits vorliegendes ISO-Speicherabbild eines Installationsmediums einer beliebigen Linux-Distribution zuzugreifen.\n\nNeben der Installation für unixähnliche Betriebssysteme ist das Programm auch für die Erstellung portabler Direktstartsysteme geeignet. Das Installationsmedium kann dabei beispielsweise ein USB-Stick oder auch eine Partition auf demselben Rechner sein.\n\nBei der Installation auf eine Festplattenpartition, neben ein bestehendes (eventuell auch gerade laufendes) System, kann UNetbootin einen bestehenden GRUB oder das Windows-Startprogramm (\"ntldr\" oder \"bootmgr\") nutzen, um das neu eingerichtete System startbar zu machen. Mit UNetbootin installierte Systeme können selber wiederum als Installationssystem eines Betriebssystems verwendet werden.\n\nUNetbootin wird als freie Software auch im Quelltext unter den Bedingungen von Version 2 oder höher der GNU General Public License (GPL) verbreitet. Es liegt in einer portablen Windows- und einer Linux-Version vor. Es ist bei vielen populären Linux-Distributionen direkt aus den Standard-Paketquellen installierbar.\n\nMit FUSBi existierte eine Abspaltung, die auf Betriebssysteme spezialisiert war, die als frei von proprietären Restbestandteilen von der Free Software Foundation abgesegnet waren.\n\nDie Software wird von Geza Kovacs in der Programmiersprache \"C++\" programmiert und nutzt Qt4 für die graphische Benutzerschnittstelle.\n\n"}
{"id": "5546207", "url": "https://de.wikipedia.org/wiki?curid=5546207", "title": "Geschlossene Plattform", "text": "Geschlossene Plattform\n\nEine geschlossene Plattform (auch Walled Garden oder geschlossenes System genannt) ist eine Plattform, die vom Hersteller mit Restriktionen versehen ist. Im Gegensatz dazu stehen offene Plattformen, die dem Benutzer viele Freiheiten gewähren. Beispiel für eine Einschränkung sind die iOS-Geräte von Apple, auf denen der Benutzer nur vom Hersteller zugelassene Anwendungen nutzen kann.\n\nBesonders bei Smartphones und Spielkonsolen verfolgen Hersteller ein Geschäftsmodell, bei dem der Hersteller über ein exklusives Vertriebsmodell die Kontrolle über ausgeführte Software, nutzbare Medien und weitere Inhalte behalten möchte. Das Betriebssystem ist mittels DRM derart gestaltet, dass nur vom Hersteller erlaubte bzw. signierte Inhalte mit dem Gerät nutzbar sind. Dieses Geschäftsmodell bietet einige Vorteile, etwa durch die vorherige Kontrolle einen gewissen Schutz vor Schadsoftware, aber es schränkt zugleich Entwickler und Nutzer in der Selbstbestimmung über die von ihnen erworbene Geräte ein. Bei einigen Geräten lassen sich die Beschränkungen des Herstellers über einen sog. Jailbreak aufheben (z. B. bei Apple iOS oder Nintendo Wii). Meist werden dazu Sicherheitslücken des Gerätes ausgenutzt, um die Schutzmechanismen des Betriebssystems auszuhebeln.\n\nDifferenzieren lassen sich geschlossene Plattformen auch über Eigenschaften wie z. B. das Entwicklungsmodell, Kostenmodell oder den Grad der Offenheit bzw. Freiheit, die bei der Verwendung auf verschiedenen Ebenen gewährt wird. Eine geschlossene Plattform kann z. B. in der Verwendung durch den Endnutzer, als Plattform für Softwareentwicklung oder in der Unterstützung von Hardware durch technische Maßnahmen, das Fehlen von offenen Spezifikationen oder die Notwendigkeit von Lizenzen restriktiert sein. Eine wissenschaftliche Veröffentlichung von 2008 fand beispielsweise die in der Tabelle wiedergegebene Einordnung und den Vergleich verschiedener Betriebssysteme:\n\n"}
{"id": "5552686", "url": "https://de.wikipedia.org/wiki?curid=5552686", "title": "Apple Magic Trackpad", "text": "Apple Magic Trackpad\n\nDas Magic Trackpad ist ein Multi-Touch-Trackpad der Firma Apple. Es wurde am 27. Juli 2010 vorgestellt. Verglichen mit den Trackpads der MacBook- und MacBook-Pro-Serie ist das Magic Trackpad etwa 20 % größer. Am 13. Oktober 2015 wurde die zweite Generation, das Magic Trackpad 2, mit Lightning-Schnittstelle, Lithium-Ionen-Akku und Taptic Engine veröffentlicht.\n\nDas Magic Trackpad besitzt wie die Apple Magic Mouse eine Multi-Touch-Oberfläche, welche in ihrer Funktionsweise dem Trackpad der aktuellen Apple-Notebooks beziehungsweise den Bildschirmen von iPhone, iPad oder iPod touch ähnlich ist. Es gibt verschiedene Gesten, um den Computer zu bedienen. Durch einfache Auf- oder Abwärtsbewegungen mit zwei Fingern kann der Benutzer beispielsweise scrollen. Es unterstützt Gesten wie das Streichen durch Webseiten wie in einem Buch oder auch dynamisches Scrollen. Die ganze Oberfläche ist außerdem eine Taste zum Klicken. Das Magic Trackpad besteht aus geformtem Aluminium sowie berührungsempfindlichem und verschleißfestem Glas.\n\nDas Trackpad wird mit zwei AA-Batterien betrieben, die Verbindung zu einem Mac findet via Bluetooth statt.\n\n\n"}
{"id": "5561001", "url": "https://de.wikipedia.org/wiki?curid=5561001", "title": "ParaView", "text": "ParaView\n\nParaView ist ein Open-Source-Programm, das für wissenschaftliche Visualisierung eingesetzt wird. ParaView beruht auf der ebenfalls von Kitware entwickelten VTK-Visualisierungsbibliothek.\n\nEin vergleichbares Open-Source-Projekt ist das ebenfalls auf VTK basierende Visit.\n\nDas ParaView-Projekt entstand als eine Gemeinschaftsentwicklung von Kitware und dem Los Alamos National Laboratory. Seine Entwicklung wurde durch das ASCI-Programm des US-Energieministeriums gefördert. Die erste öffentliche Version erschien im Oktober 2002.\n\nIm September 2005 startete Kitware mit den Sandia National Laboratories und weiteren Partnern die Entwicklung von ParaView 3.0, das im Jahr 2007 veröffentlicht wurde. Im Juni 2013 erschien ParaView 4.0 und im Januar 2016 Version 5.0.\n"}
{"id": "5563001", "url": "https://de.wikipedia.org/wiki?curid=5563001", "title": "Address manager", "text": "Address manager\n\nDer address manager ist eine erfolgreiche Kundenmanagement-Software zum Verwalten von Kontakten. Der Hersteller ist combit.\n\nDas für kleine und mittlere Unternehmen konzipierte Programm basiert auf einer proprietären Datenbank und verwaltet neben den Kontakten auch Termine und Schriftverkehr. Verschiedene Designer- und Scriptingmöglichkeiten machen Anpassungen an Sonderwünsche möglich. Peripheriegeräte und auch E-Mail-Clients können zur Ausgabe verwendet werden, außerdem ist die Synchronisation mit externen Datenträgern wie PDAs möglich.\n"}
{"id": "5568438", "url": "https://de.wikipedia.org/wiki?curid=5568438", "title": "Sumatra PDF", "text": "Sumatra PDF\n\nSumatra PDF ist ein freier, kleiner und schneller Dokumentenbetrachter für Windows, der ursprünglich nur für das Anzeigen von PDF-Dateien entwickelt wurde. Inzwischen unterstützt das Programm ebenso die Formate PS, XPS und OXPS, die E-Book-Formate DjVu, mobi, Comic Book (codice_1, codice_2, codice_3 und codice_4), EPUB, FictionBook (codice_5) und PalmDOC, das Format des Windows-Hilfesystems CHM sowie die Bilddateiformate TIFF (mehrseitig), TGA und JPEG XR. Sumatra PDF wird von Krzysztof Kowalczyk aus San Francisco entwickelt.\n\nBei der Entwicklung von Sumatra PDF hatte Einfachheit höchste Priorität. So entstand ein auf das Wesentliche – das Betrachten von PDF-Dateien – reduziertes, sehr kleines Programm mit wenigen Funktionen. Da das Programm aus nur einer einzigen Datei besteht und keine weiteren externen Abhängigkeiten besitzt, ist es ideal für den portablen Einsatz. Dank der schlanken Oberfläche lädt und arbeitet das Programm sehr schnell.\n\nMan kann eine oder mehrere Seiten gleichzeitig anzeigen lassen und in die Textdatei hinein- oder herauszoomen. Außerdem kann man zwischen Seiten hin und her springen, Ansichten drehen und Text im Dokument suchen. Alle Dokumente können direkt aus Sumatra heraus als E-Mail verschickt, als reine Textdatei gespeichert oder gedruckt werden. Text lässt sich entweder direkt mit der Maus markieren, oder durch das Aufziehen eines Rechtecks mit Maus und gleichzeitig gedrückter Strg-Taste um den Text herum. Der in der Auswahl befindliche Text kann anschließend durch einen Menüpunkt bzw. mit einer Tastenkombination in die Zwischenablage kopiert werden.\n\nSumatra PDF wurde inzwischen in mehr als 60 Sprachen übersetzt, darunter auch Deutsch, und ist mit Wine auch auf Linux lauffähig.\n\nDurch den Aufruf mit bestimmten Optionen kann das schnelle Beenden mit der Escape-Taste oder ein eingeschränkter Modus (Deaktivieren des Dateimenüs) eingeschaltet werden, wodurch sich das Programm ideal als Betrachter z. B. für Hilfedateien und Druckvorschau aus Anwendungen eignet. Das Aussehen und Verhalten von Sumatra PDF kann der Anwender durch Bearbeiten einer Konfigurationsdatei ändern.\n\nSeit Version 0.8.1 (Mai 2008) enthält Sumatra PDF eine LaTeX-Unterstützung von William Blum. Es kann in Verbindung mit einem LaTeX-Editor so konfiguriert werden, dass LaTeX- und PDF-Datei mittels der LaTeX-Funktionen \"pdfsync\" oder \"SyncTeX\" synchronisiert werden. Die Kommunikation zwischen LaTeX-Editor und Sumatra geschieht über das DDE-Protokoll, das von vielen Editoren, wie TeXnicCenter und WinEdt, unterstützt wird. Durch Doppelklick auf eine Textstelle in Sumatra gelangt man zur entsprechenden Quelltextzeile in der LaTeX-Datei, umgekehrt gelangt man auch von der LaTeX-Quelldatei an die entsprechende Stelle in der PDF-Datei, wobei die entsprechende Stelle in Sumatra hervorgehoben wird.\n\nZur Erzeugung von PDF-Dokumenten mit pdfTeX oder XeTeX ist Sumatra PDF eine gute Lösung, es lässt sich problemlos mit den Editoren TeXnicCenter, WinEdt, Emacs, Vim und Texmaker kombinieren.\n\nErstmals erschien das vor allem in C++ geschriebene Programm am 1. Juni 2006. Diese Version 0.1 nutzte noch Xpdf als PDF-Render-Programmbibliothek.\n\nMit Version 0.2 (August 2006) erfolgte der Umstieg auf Poppler als Renderer. Wegen der besseren Unterstützung der Windows-Plattformen wurde zusätzlich der Renderer des Dokumentenbetrachters MuPDF eingebaut. Poppler wurde mit Version 0.9 (August 2008) endgültig entfernt, damit basiert Sumatra PDF ausschließlich auf MuPDF.\n\nDie erste inoffizielle Übersetzung ins Deutsche wurde im Juni 2007 durch Lars Wohlfahrt vorgenommen, diese legte den Grundstein für die in Version 0.7 (Juli 2007) eingeführte Mehrsprachigkeit.\n\nDie Lizenz von Sumatra PDF wurde im Juli 2009 von GPLv2 auf GPLv3 geändert, da auch MuPDF seine Lizenz geändert hatte.\n\nVersion 1.0 von Sumatra PDF wurde am 17. November 2009 veröffentlicht.\n\nEine Übersetzung der PDF-Dateien in Rastergrafik vor dem Drucken findet von Version 1.2 an nicht mehr statt, was den Druckvorgang beschleunigen und Ressourcen einsparen soll. Das Markieren von Text mit der Maus wurde in Version 1.3 dem Verhalten des Adobe Reader angepasst.\n\nVon Version 1.4 an kann ein Plug-in für die Webbrowser Mozilla Firefox, Opera und Google Chrome installiert werden. Auch lassen sich nun AES-256-verschlüsselte PDF-Dokumente darstellen. Die Unterstützung für XPS und Comic Book wurde in Version 1.5 integriert. Im Browser-Plug-in kann ein Dokument mittels des Kontextmenüs gedruckt oder gespeichert werden.\n\nMit der 2011 veröffentlichten Version 1.6 wurde das Anzeigen von DjVu- und (vorausgesetzt Ghostscript ist installiert) auch von PostScript-Dokumenten ergänzt, sowie eine noch experimentelle Vorschaufunktion für PDF-Dokumente im Explorer für Windows Vista und 7 eingebaut, was bisher lediglich in den 32-Bit-Versionen problemlos funktioniert. Zudem können nun auch Bildformate angezeigt und das Programm somit als alternativer Bildbetrachter verwendet werden.\n\nVon Version 2.0 (April 2012) an ist der Sumatra-PDF-Reader in der Lage, E-Book-Formate zu lesen. Dafür wurde das Layout behutsam an das Aussehen eines klassischen E-Book-Lesegerätes angenähert.\n\nMit Version 2.3 (Mai 2013) wurde vorübergehend die Unterstützung für Prozessoren ohne SSE2-Befehlssatz eingestellt. Das hatte zur Folge, dass das Programm auf Prozessoren älter als Intel Pentium 4 oder AMD Athlon 64 nicht mehr lauffähig war. Nach massiven Nutzerprotesten wurde diese Änderung nur einen Tag später mit Version 2.3.1 wieder rückgängig gemacht.\n\nIm Februar 2014 entzog die Free Software Foundation Europe die vorher bestehende Empfehlung von Sumatra PDF als freie Software. Der Grund war die Verwendung der UnRAR-Bibliothek, deren Lizenz von der FSF als nicht frei eingeordnet wird. In Version 3.0 (Oktober 2014) wurde der problematische Code ersetzt, so dass Sumatra PDF von der FSF wieder als vollständig freie Software angesehen wird. Bei Verarbeitungsproblemen komprimierter Comic Books besteht dennoch die Möglichkeit, UnRAR einzusetzen, indem die fragliche Bibliothek manuell hinzugefügt wird. Weiterhin wurde in Version 3.0 die Comic-Book-Unterstützung um LZMA- und PPMd-Komprimierung erweitert, auch wird das PalmDOC-Format unterstützt. Comic Books können nun als PDF-Dokumente gespeichert werden.\n\nVon Version 3.1 (Oktober 2015) an gibt es Sumatra PDF auch in einer 64-Bit-Version.\n\nNach Aussage des Autors soll der Name \"Sumatra\" keine Hommage an die Insel Sumatra oder an Kaffee sein, vielmehr gebe es keine besonderen Gründe für die Wahl dieses Namens.\n\n"}
{"id": "5568500", "url": "https://de.wikipedia.org/wiki?curid=5568500", "title": "Personal Ancestral File", "text": "Personal Ancestral File\n\nPersonal Ancestral File (\"deutsch: Persönliche Ahnendatei\") oder PAF ist eine kostenlose Genealogie-Software, die durch die Kirche Jesu Christi der Heiligen der Letzten Tage („Mormonen“) angeboten wurde.\n\n\"Personal Ancestral File\" erlaubt es den Anwendern, Namen, Geburts-, Sterbe- und andere Daten, Zitate sowie Quelleninformationen in eine private Datenbank einzugeben, sie zu sortieren und darin nach genealogischen Daten zu suchen. Mit Hilfe dieser Software können Formulare und Stammbäume ausgedruckt und die Daten mit anderen Familienforschern im GEDCOM-Dateiformat ausgetauscht werden. PAF kann jeden individuellen Datensatz mit Bildern und anderen Mediadaten verbinden und ist Unicode-kompatibel. Das Programm verfügt unter anderem über einen Verwandtschafts-, einen Datums- und einen Soundexrechner.\n\nNachdem die Software mehrere Jahre lang nicht aktualisiert worden war, wurde im Juni 2013 die Einstellung des Projektes bekannt gegeben.\n\nMehrere Versionen von \"Personal Ancestral File (PAF)\" für Windows sind von \"FamilySearch\" freigegeben worden. Die Version 5.2.18.0 begann mit einer Adaption von \"Ancestral Quest\" des Softwareherstellers \"Incline Software\", geschrieben von Gaylon Findlay. Findlay ist an Aktualisierungen der gegenwärtigen Version beteiligt worden. \"Ancestral Quest\" ist getrennt von PAF entwickelt worden, obwohl es Grundlegendes, wie das Erscheinungsbild und die Datenstruktur, davon beinhaltet. Findlay ist auch weiter in der Entwicklung der PAF-Datenstruktur eingebunden und hat mit der Version 12.1 von \"Ancestral Quest\" eine Reihe von Anpassungen freigegeben, die es dem Anwender erlauben, Informationen in die PAF-Datei einzuschließen, die von der Online-Datenbank des neuen \"FamilySearch\" bereitgestellt werden.\n\nEine \"Ancestral File Number (AFN)\" (deutsch: Ahnendateinummer) sollte ursprünglich für jede Person eine eindeutige und unverwechselbare Kennzeichnung eines Datensatzes im Ahnendateiformat sein, aber die Nummer ist nicht immer eindeutig, weil vielen Personen mehrfach AFNs über die Jahre zugeteilt worden sind. AFNs werden durch die LDS-Kirche (Latter-Day Saints\", deutsch: Heilige der Letzten Tage\") als Index-Werkzeug beim Erschließen ihrer Datenbestände verwendet. AFNs bestehen aus vier Großbuchstaben oder Ziffern, einem Strich und dann zwei oder drei weiteren Großbuchstaben oder Ziffern. Eine AFN enthält keine Vokale (A, E, I, O, U oder Y). Ein Beispiel ist 1BS3-9X1. AFNs können online auf der Ahnenforschungs-Website von \"FamilySearch\" gesucht werden.\n\nFamilySearch setzt seine Unterstützung für AFNs in seiner neuen Datenbank, genannt \"New FamilySearch\", fort. Obwohl die AFN durch den sogenannten „Person Identifier“ (deutsch: Personenkennzeichnung) ersetzt wird, kann weiterhin eine Suche nach einer Person mit Hilfe einer AFN erfolgen. Neuen Personen wird keine AFN mehr zugeteilt, obwohl jeder Person ein „Person Identifier“ zugeteilt wird. Die AFN wird nicht angezeigt, wenn man eine Person in der neuen Datenbank betrachtet, und \"New FamilySearch\" wird die bisherige Ahnendatenbank nicht getrennt von derjenigen von \"New FamilySearch\" pflegen. Wenn der Wechsel von \"FamilySearch\" zu \"New FamilySearch\" vollständig vollzogen ist, wird die Ahnendatenbank mit Informationen von mehreren anderen Datenbanken vereint worden sein, wobei sich viele der Informationen ändern.\n\nHersteller von Third-Party-Software entwickeln Programme, die es dem Anwender erlauben, ihre Datenbanken mit der \"New FamilySearch\" auf der Basis des „Person Identifier“ zu synchronisieren. Es ist jedoch unklar, welche Rolle (falls vorhanden) AFNs bei der Synchronisation spielen. Die Liste von Programmen, von denen bestätigt wird, dass sie mit \"New FamilySearch\" zusammenarbeiten, findet man bereits bei \"FamilySearch\".\n\nDie Geschichte der Entwicklung von \"Personal Ancestral File (PAF)\" verlief parallel mit der Entwicklung von GEDCOM (engl. GEnealogical Data COMmunication), dem De-facto-Standard für den Austausch von Genealogie-Daten zwischen verschiedenen Computerprogrammen zur Ahnen- und Familienforschung.\n\nHier eine Auswahl aus der historischen Entwicklung:\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "5574977", "url": "https://de.wikipedia.org/wiki?curid=5574977", "title": "Transformers: Beast Wars", "text": "Transformers: Beast Wars\n\nBeast Wars (engl. \"Transformers: Beast Wars\") war eine US-amerikanische CGI-Serie, welche auf der Spielzeugreihe der Transformers basierte. Die Serie wurde von Mainframe Entertainment in Kanada produziert und die Drehbücher wurden von Bob Forward und Larry DiTillio geschrieben.\nDie Serie ist eine Fortsetzung der Original-Transformers-Serie aus den 1980er Jahren und wurde später als selbst fortgesetzt.\n\nDie sich bekriegenden Fraktionen dieser Serie sind die Maximals, Nachfahren der Autobots, und die Predacons, Nachfahren der Decepticons, welche auf einem mysteriösen Planet fern von Cybertron bruchlanden. Die Fraktionen werden von Optimus Primal, Anführer der Maximals, und Megatron, Anführer der Predacons, geleitet. Ohne eine Möglichkeit den Kontakt nach Cybertron aufzubauen setzten die beiden gestrandeten Teams ihren Krieg auf dem primitiven Planeten fort.\n\nDie Transformers sind gezwungen sich \"Alternativformen\" anzueignen, um den schädigenden Einfluss des rohen Energons auf dem Planeten zu entgehen und wählen hierfür das Aussehen von Tieren, Dinosauriern und Insekten.\n\nDie erste Staffel etabliert die Figuren der beiden Fraktionen und dreht sich um den ständigen Versuch den Kontakt zum Heimatplaneten der Transformers aufzubauen. Erste Auftritte vergangener Transformer wie z. B. Starscream in seiner Geistform, oder auch Aufgreifen vergangener Ereignisse, z. B. der Kampf gegen Unicron, finden sich ebenfalls in dieser Staffel.\n\nIn der zweiten Staffel wird klar, dass die beiden Teams auf dem prähistorischen Planeten Erde gelandet sind und dass Megatron absichtlich bruchlanden wollte um die Zukunft aller Transformers zu ändern. Er möchte den noch in Stasis befindlichen Autobot-Anführer Optimus Prime auslöschen, damit die Decepticons im Jahre 1984 den Krieg gegen die Autobots gewinnen und die Predacons der Gegenwart die Herrscher über Cybertron werden.\n\nIn Staffel 3 bauen die Maximals ihre Basis vor der Arche, dem Raumschiff der Autobots, auf um diese vor den Angriffen der Predacons zu schützen. Nach etlichen Fehlschlägen reist Megatron mit zwei seiner Predacons auf den Grund des großen Ozeans um die Nemesis, das Raumschiff der Decepticons, zu reaktivieren und mit den Waffen den gesamten Planeten in die Luft zu sprengen.\n\nMegatron scheitert und seine Predacon-Krieger werden im Verlauf des finalen Kampfes zerstört. Die Maximals, zusammen mit einem beschädigten Megatron, borgen sich eines der Rettungsschiffe der Arche um durch ein neues Transwarp-Portal zurück in die Zukunft zu reisen...\n\nUrsprünglich sollte die Serie in der Gegenwart stattfinden und viele Figuren der Original-Transformers-Serie wieder verwenden. Da allerdings Bob Forward und Larry DiTillio kaum etwas über das Original wussten, entschieden sie sich die Serie in einer komplett neuen Kontinuität spielen zu lassen und recycelten lediglich ein paar Namen und platzierten einige Referenzen zur Originalserie. Auch war der Planet zu Beginn der Planung nicht die Erde, sondern sollte ein komplett anderer sein, weswegen auch in der ersten Staffel der Planet von zwei Monden umkreist wurde. Erst im späteren Verlauf wurde entschieden, den Planeten zur prähistorischen Erde zu machen, wobei sich einer der Monde als getarnte Alien-Waffe entpuppte.\n\nDie Serie sollte ursprünglich auch einen weitaus größeren Cast an Figuren bieten, durch die damals noch sehr junge CGI-Technik musste man die Mitglieder der beiden Fraktionen auf je fünf stutzen.\n\"Beast Wars\" war auch die erste Transformers-Serie welche Todesfälle in einigen Episoden behandelte, unter den Verstorbenen fanden sich Dinobot, Dinobot 2, Skorpinok, Terrorsaurus, Tarantulus, Depth Charge, Rampage, Tigerhawk, Inferno und Quickstrike. Von den 10 Kriegern, welche in Episode 1 ihren Auftritt feierten, überlebten lediglich 6 bis zum Ende der Serie, und von diesen 6 lediglich 3 das Finale der Nachfolge Serie \"Beast Machines\". Hervorzuheben ist die Figur Waspinator, welcher zwar in jeder Folge in die Luft gesprengt wurde, allerdings nie offiziell starb. Selbst die Nachfolgeserie überlebte er, allerdings in einem neuen Körper und neuen Persönlichkeit; als Thrust.\n\nWaspinator war einer der Charaktere die am Anfang der zweiten Staffel sterben sollte, er wurde aber Aufgrund des Einspruches der beiden Drehbuchschreiber Forward und DiTillio verschont, da er unter den Fans als Comic Relief der Serie geschätzt wurde.\n\nDie dritte Staffel sollte ursprünglich eine Episode mit dem Titel „Dark Glass“, von Christy Marx geschrieben, beinhalten. Die Folge sollte ein Treffen zwischen Rattrap und dem geklonten Dinobot 2 beinhalten, in der Rattrap Erinnerungen an vergangene Ereignisse des Original-Dinobots im Speicher der Axalon, dem Schiff der Maximals findet und diese in den Klon einpflanzen will um seinen Verbündeten wiederzubeleben. Das Script wurde verworfen, da es für zu dunkel für die jungen Zuschauer der Szene befunden wurde, woraufhin die Folge auch nie produziert wurde. Stattdessen wurde die Folge „Go with the Flow“ produziert und verursachte eine Lücke im Handlungsstrang der dritten Staffel, da im Finale dieser der geklonte Dinobot, durch einen starken Elektroschock, plötzlich Erinnerungen an seine Abenteuer mit den Maximals wiederentdeckt und Megatron hintergeht.\n\nIn den 1990ern wurden ausgewählte Episoden auf VHS veröffentlicht, welche im Gegensatz zur deutschen Ausstrahlung bei RTL 2 ungeschnitten waren. Die VHS Kassetten sind mittlerweile nicht mehr erhältlich. Am 24. April 2012 erschien beim Vertrieb Pandastorm Pictures die komplette erste Staffel der Serie auf DVD.\n\nDie Synchronisation der ersten Staffel der Serie fand in Hamburg bei Planet Wave statt.\n"}
{"id": "5576541", "url": "https://de.wikipedia.org/wiki?curid=5576541", "title": "Dell Adamo", "text": "Dell Adamo\n\nDas Dell Adamo ist ein Subnotebook des texanischen Herstellers Dell, das in Konkurrenz mit Geräten wie Apples MacBook Air, Lenovos ThinkPad X301 und Hewlett-Packards „Voodoo Envy 133“ steht. Im November 2009 veröffentlichte Dell das \"Adamo XPS\", welches nur noch 9,7 bis 10,3 mm dick ist. \n\nDas Adamo wurde 2009 auf der Consumer Electronics Show vorgestellt. Das Notebook kam in der ersten Jahreshälfte 2009 auch auf den Markt.\nIm November veröffentlichte Dell das Adamo XPS. Es ist mit einer Dicke von 9,7 bis 10,3 mm das dünnste Notebook der Welt und wird in Deutschland über die Media-Markt-Elektronikkaufhäuser vertrieben.\n\nDas Adamo ist in je zwei Ausstattungsvarianten verfügbar. Das Gerät besitzt ein Aluminium-Gehäuse. Das Adamo hat ein 13,4 Zoll großes Display. Es ist mit einem Intel Core 2 Duo auf Penryn-Basis mit 1,4 oder 2,1 GHz (nur bei Version „Onyx“) zu haben. Eine SSD mit 128 oder 256 GB (nur bei Version \"Onyx\") ist im Adamo verbaut. Es fehlt im Adamo ein eingebautes DVD-Laufwerk. Der Akku soll bis zu 5 Stunden durchhalten. Das Notebook kommuniziert drahtlos per WLAN in Netzen, die auf IEEE-802.11a/b/g/n basieren, sowie per Bluetooth 2.1. Ein Modem für UMTS und HSDPA ist ebenfalls vorhanden, allerdings nur in der teureren Variante des Geräts. Als Betriebssystem wird Microsoft Windows 7 Home Premium eingesetzt. Das Adamo hat einen Display Port, 3 USB-Ports (einmal eSATA-Kombination), Klinke-Audioausgang und einen integrierten RJ-45-Anschluss. Die Abmessungen des Notebooks betragen 331 mm × 242 mm × 9,99 mm (B×T×H) bei einem Gewicht von 1,81 kg.\n"}
{"id": "5576568", "url": "https://de.wikipedia.org/wiki?curid=5576568", "title": "Transformers: Beast Machines", "text": "Transformers: Beast Machines\n\nBeast Machines (engl. \"Transformers: Beast Machines\") ist eine US-amerikanische CGI-Serie, welche auf der Spielzeugreihe der Transformers basiert. Die Serie wurde von Mainframe Entertainment in Kanada produziert und die Drehbücher wurden von Bob Skir und Marty Isenberg geschrieben.<br>\nDie Serie ist eine Fortsetzung der Serie und sollte selbst noch als \"Transformers: Transtech\", welche es aber nie über die Planungsphase hinaus schaffte, fortgesetzt werden.\n\nDie Maximals finden sich ohne Erinnerungen auf ihrem Heimatplaneten Cybertron wieder und werden von den Verteidigungsrobotern des Planeten angegriffen. Unmöglich sich von ihrem Tiermodus zu befreien, suchen sie Zuflucht in den Ruinen unter der Oberfläche von Cybertron, wo sie das transformieren erst wieder erlernen müssen. Währenddessen übernimmt Megatron die Herrschaft über Cybertron und erschafft eine neue Fraktion von Transformern: Die Vehicons.\n\nIn der ersten Staffel versuchen die Maximals herauszufinden, was mit allen Transformern des Planeten geschah, warum alle plötzlich verschwunden sind und gegen die Vehicons ausgetauscht wurden. Die Staffel gipfelt in der Konfrontation zwischen Optimus Prime, Megatron und Tankor, einem der Vehicon Generäle, alles technische Leben auf Cybertron auszulöschen.\n\nDie Maximals finden heraus, dass Cybertron einst ein organischer Planet war, bevor er durch das Orakel in einen technischen umgewandelt wurde und machen es sich zur Aufgabe, den Planeten wieder in seinen ursprünglichen Zustand zu transformieren. Währenddessen rekrutiert Megatron zwei neue Vehicon Generäle, Obsidian und Strika, welche ihm dabei helfen sollen, die Maximals zu vernichten. Im Finale der Staffel opfert sich Optimus Prime um Megatron zu zerstören und den Planeten in einen „techno-organischen“ umzuwandeln und die Sparks der verschwundenen Transformers aus ihrer Gefangenschaft zu befreien.\n\nDie Produktion an der Serie begann gleich nach der Fertigstellung der letzten Staffel von . Die beiden ursprünglichen Drehbuchautoren Bob Forward und Larry DiTillio wurden durch Bob Skir und Marty Isenberg ersetzt. Durch diesen Tausch entstanden einige Lücken im Handlungsstrang der ersten Staffel, welche allerdings im Zuge der zweiten Staffel wieder bereinigt wurden.\nDurch die veränderte Erzählweise der Serie, anstelle von alleinstehenden Episoden eine auf sich aufbauende Geschichten, war es für Zuschauer, welche nicht ab der ersten Episode der Serie folgten, sehr schwer bis unmöglich, irgendeinen Sinn in den Beweggründen einiger Figuren zu finden.\nAnders als bei bisherigen Transformers-Serien wurde das Titellied nicht extra für die Serie erstellt, sondern man griff auf ein bereits existierendes Lied, „Phat Planet“ von Leftfield, zurück.\n\nSony Home Entertainment hat beide Staffeln 2007 in zwei DVD Boxen veröffentlicht.\n\nDie Synchronisation der Serie fand in Berlin bei Arena Synchron statt, Dialogbuch und Synchronregie führte Björn Schalla\n"}
{"id": "5585089", "url": "https://de.wikipedia.org/wiki?curid=5585089", "title": "Screenguide", "text": "Screenguide\n\nScreenguide (in eigener Schreibweise \"SCREENGUIDE\"), ehem. Webstandards Magazin, war eine Fachzeitschrift zu Themen aus Social Media, Webentwicklung, Interfacedesign, Usability, Accessibility, Webanwendungen und E-Commerce sowie aktuellen Entwicklungen in den genannten Bereichen. Das Magazin erschien quartalsweise in einer Druckauflage von ca. 10.000 Exemplaren (Stand: November 2012) und wurde hauptsächlich über den Bahnhofsbuchhandel und per Abonnement vertrieben. Neben der Print-Ausgabe gab es auch eine App für iOS- und Android-Smartphones und -Tablets. Herausgeberin war bis zur Ausgabe 19 die Screenguide Publishing GmbH, seit Oktober 2013 wurde das Magazin von der WEKA MEDIA PUBLISHING GmbH verlegt.\nIm September 2018 wurden die Abonnenten informiert, dass die Zeitschrift ab sofort \"aus wirtschaftlichen Gründen\" eingestellt wird. Ihnen wurde ersatzweise ein Abonnement des monatlich erscheinenden PC Magazin angeboten.\n\nDie Publikation wurde Anfang 2009 gestartet und behandelte relevante Themen aus dem Webworking-Bereich unter professionellen Gesichtspunkten. Das Spektrum umfasste Techniken und Trends zu HTML, CSS, JavaScript sowie PHP und MySQL. Ein weiterer inhaltlicher Schwerpunkt lag auf Designthemen und -trends sowie diversen Tools, wie beispielsweise Adobe Flash, Flex und Air. Ferner wurden Themen wie Rapid Prototyping und Frameworks sowie Applikationsentwicklung und Content-Management-Systeme behandelt.\n\nEine Besonderheit des Magazins war die enge Vernetzung mit Twitter für den Newsbereich sowie als „Seismograph“ für Trends und Entwicklungen. Jede Ausgabe des Magazins umfasste mindestens 100 Seiten. Online finden sich ältere Magazine als PDF-Dokumente zum Download. Auch hier spielt Twitter wieder eine Rolle, die Herausgeber nutzten eine Payment-Lösung namens \"Pay with a Tweet\" ( „Bezahle mit einem Tweet“). Inzwischen ist die Online-Plattform mit einem täglich aktualisierten News-Angebot versehen und setzt verstärkt auf Social Media zur Verbreitung von aktuellen Inhalten.\n\n \n"}
{"id": "5592811", "url": "https://de.wikipedia.org/wiki?curid=5592811", "title": "Ceph", "text": "Ceph\n\nCeph (Aussprache oder ) ist eine verteilte Storage-Lösung. Kernkomponente ist mit \"RADOS\" () ein über beliebig viele Server redundant verteilbarer Objektspeicher (englisch '). Ceph bietet dem Nutzer drei Arten von Storage an: Einen mit der Swift und S3-API kompatiblen Objektspeicher ('), virtuelle Blockgeräte (\"\") und \"CephFS\", ein verteiltes Dateisystem.\n\nCeph kann als RADOS Block Device (RBD) über das Ceph iSCSI Gateway auch als hochverfügbares iSCSI-Target bereitgestellt werden. Dadurch kann es auf Client-Seite durch viele Betriebssysteme (auch Windows) genutzt werden.\n\nWie üblich bei verteilten Dateisystemen werden die Objekte \"repliziert\" (oder auch \"redundant\") gespeichert. Ceph kann so den Ausfall von jeder Komponente auffangen und sich selbst heilen, das heißt, zerstörte Daten aus Replikaten auf anderen Speichermedien wiederherstellen.\n\nMit Veröffentlichung der Version 10.2 im April 2016 wurde CephFS für stabil erklärt.\n\n\n\n"}
{"id": "5592818", "url": "https://de.wikipedia.org/wiki?curid=5592818", "title": "NILFS", "text": "NILFS\n\nNILFS bzw. NILFS2 (\"New Implementation of a Log-structured File System\") ist ein Logging-Dateisystem, das für Linux implementiert wurde. Es wurde in Japan von den Nippon Telegraph and Telephone (NTT) Cyber Space Laboratories entwickelt und steht unter der GNU General Public License (GPL).\n\nNILFS unterscheidet sich von den meisten anderen heute gebräuchlichen Dateisystemen dadurch, dass es wie ein Tagebuch bzw. eine Protokolldatei (englisch \"log\") aufgebaut ist. D.h. das Dateisystem beginnt chronologisch am Anfangspunkt der Partition zu schreiben und arbeitet sich kontinuierlich bis zum Endpunkt durch.\n\nDarüber hinaus ist NILFS ein Copy on Write Dateisystem. D.h., dass bei Änderungen einer Datei die neue Version separat gespeichert wird. Die alte Version der Datei bleibt auf der Festplatte bestehen und wird lediglich in den Metadaten als obsolet markiert. Einmal geschriebene Dateien werden also nicht verändert, sondern durch erneuerte Versionen ersetzt, die wiederum am Ende des belegten Bereichs geschrieben werden. Allerdings werden zur Effizienzsteigerung nicht die gesamten Dateien neu geschrieben, sondern nur jene Blöcke, die verändert wurden.\n\nEs wird somit vorerst überhaupt nichts gelöscht. Dies kann so lange beibehalten werden, bis der Schreibprozess am Ende der Partition angekommen und diese voll ist. Ist dies der Fall, so muss der Garbage Collector zum Einsatz kommen, der veraltete Versionen gespeicherter Dateien löscht. NILFS beginnt dann erneut am Anfang der Partition zu schreiben, um sich von dort wie gehabt kontinuierlich bis zum Ende der Partition durchzuarbeiten. Konzeptuell versteht NILFS also eine Partition als endlosen Kreis (Digitaler Ringspeicher).\n\nDer Vorteil dieser Funktionsweise liegt darin, dass einmal geschriebene Daten nicht verloren gehen, solange das Medium (Festplatte, SSD) nicht beschädigt ist. Versehentlich gelöschte Dateien können einfach wieder hergestellt werden, solange sie nicht vom Garbage Collector endgültig gelöscht und zum Überschreiben freigegeben wurden.\n\nAuch die Wiederherstellung nach einem Systemabsturz ist wesentlich einfacher als bei anderen Dateisystemen, da wie bei einem Tagebuch, das vorübergehend zugeklappt wurde, einfach von dort weitergeschrieben werden kann, wo zuletzt geschrieben wurde.\n\nIm Falle einer SSD hat dieses Prinzip auch den großen Vorteil, dass alle Bereiche einer Partition gleichmäßig belastet werden. Es entstehen so keine Hotspots von Speicherbereichen, die wesentlich öfter beschrieben wurden als andere und daher erheblich früher ausfallen als der Rest der SSD.\n\nNILFS unterstützt kontinuierliche Schnappschüsse. Zusätzlich zur Versionierungsfähigkeit des gesamten Dateisystems können Benutzer sogar Dateien, die vor wenigen Sekunden fälschlicherweise überschrieben oder zerstört wurden, wiederherstellen. Da das NILFS die Konsistenz des Dateisystems wie ein herkömmliches LFS aufrechterhalten kann, kann es nach Systemabstürzen schnell wiederhergestellt werden.\n\nNILFS erstellt alle paar Sekunden oder pro Synchron-Schreib-Basis eine Anzahl von Checkpoints (es sei denn, es gibt keine Änderung). Benutzer können signifikante Versionen von kontinuierlich erstellten Checkpoints auswählen und diese in Schnappschüsse ändern, die beibehalten werden, bis sie wieder zu Checkpoints geändert werden.\n\nBis das Volume voll ist, gibt es keine Beschränkung für die Anzahl der Schnappschüsse. Jeder Schnappschuss kann als schreibgeschütztes Dateisystem bereitgestellt werden.\n\nDie aktuelle Hauptversion von NILFS ist Version 2, die als NILFS2 bezeichnet wird. In NILFS2 wurde die Online-Garbage-Sammlung implementiert, die Festplattenplatz frei macht, wobei eine gewisse Anzahl an Schnappschüssen erhalten bleibt.\n\nWeitere NILFS-Funktionen sind:\n\n\nDem ursprünglichen Entwicklerteam gehörten Yoshiji Amagai, Hisashi Hifumi, Ryusuke Konishi, Koji Sato, Seiji Kihara und Satoshi Moriai an.\n\n\n"}
{"id": "5600913", "url": "https://de.wikipedia.org/wiki?curid=5600913", "title": "Linn LM-1", "text": "Linn LM-1\n\nDer LM-1 Drum Computer, hergestellt von Linn Electronics, war der erste programmierbare Drumcomputer, der digitale Samples von einem akustischen Schlagzeug verwendete. Erdacht und entwickelt wurde er von Roger Linn.\n\nRoger Linn war ein semiprofessioneller Gitarrist in Kalifornien. Im Jahr 1978 begann er den LM-1 als ein Begleitinstrument für sein Heimstudio zu entwickeln. Er wollte \"„Eine drum machine, die mehr konnte als nur voreingestellte Samba-Rhythmen abspielen und dabei wie eine Grille klingen.“\" Linn hatte gelernt in BASIC und Assembler zu programmieren und begann an einem Computerprogramm zu arbeiten, das benutzerprogrammierte Rhythmusmuster abspielen und sie zu einem ganzen Song verbinden konnte. Linn war der Erste, der die Idee hatte, digitale Samples zu verwenden. Er erinnert sich nicht, wer die für die Samples benutzten Sounds eingespielt hatte. Es wird angenommen, dass es mehrere Studio-Schlagzeuger aus Los Angeles waren, möglicherweise James Gadson, Art Wood, Ron Tutt oder Jeff Porcaro.\n\nLinn verwendete einen 8-Bit-Kompander-Digital-Analog-Umsetzer-Chip, um die eingebauten, digitalisierten Sounds in ein analoges Audiosignal umzuwandeln. Sein erster in der Zeit um 1979 gebauter Prototyp war in einer Pappschachtel untergebracht und Linn vertrieb diesen auf Partys an seine Co-Musiker, unter ihnen Peter Gabriel, Gruppenmitglieder von Fleetwood Mac und Stevie Wonder. Insgesamt wurden etwa 525 Stück gebaut und bis 1983 verkauft, dann kam der LinnDrum auf den Markt. Die ersten 35 Geräte wurden in Linns Haus zusammengebaut, bevor „360 Systems“ die Produktion und Vermarktung übernahm.\n\nAnfang 1980 wurde er für 4.995 US-Dollar verkauft, verteuerte sich dann auf 5.500 US-Dollar, als zusätzliche Funktionen ergänzt wurden. Danach sank der Preis wieder auf 4.995 US-Dollar und konnte aufgrund von Kostenreduktionen auf 3.995 US-Dollar reduziert werden, bevor die Produktion nach dem Erscheinen des Nachfolgers LinnDrum eingestellt wurde. Er wurde in den 1980er Jahren von Künstlern benutzt wie Prince, Michael Jackson, Madonna, The Human League, Peter Gabriel, Wally Badarou, Kraftwerk, Ultravox, Falco, Kate Bush und anderen.\n"}
{"id": "5605680", "url": "https://de.wikipedia.org/wiki?curid=5605680", "title": "Terminal (Apple)", "text": "Terminal (Apple)\n\nTerminal (auch bekannt als Terminal.app) ist der Terminalemulator von Apple für macOS. Er hat seinen Ursprung im Vorgänger von Mac OS X, NeXTStep; beide Systeme bauen auf einem BSD-Unix-Kern auf. Benutzer können mit diesem Programm mit einem Kommandozeileninterpreter arbeiten, standardmäßig ist das eine Shell namens Bash.\n\nAlle Mac-OS-Systeme (1984–2001) vor Mac OS X (entwickelt ab 1998, erstmals veröffentlicht 2000) waren nicht unixoid und besaßen keine Kommandozeile. Das Betriebssystem NeXTStep von NeXT sowie dessen Nachfolger Mac OS X Server und Mac OS X, die auf einem BSD-Kern (von Apple ab 1999 auch separat als Darwin veröffentlicht) basieren, besitzen sowohl eine Kommandozeile wie auch eine Terminalemulation.\n\nMit Mac OS X 10.0 („Cheetah,“ 2001) wurde erstmals auf einem Mac-System ein Terminalemulator eingeführt. Unter Mac OS X 10.1 („Puma,“ 2001) konnten im Terminal neue Zeichenkodierungen genutzt werden, mit Mac OS X 10.2 („Jaguar,“ 2002) kamen dann auch Unterstützung für Unicode, transparente Hintergründe und geteilte Fenster hinzu.\n\nZusammen mit Mac OS X Leopard (10.5, 2007) wurde Version 2.0 des Terminal ausgeliefert. Als neue Features kamen Tabs und Fenstergruppen dazu, zudem konnte das Aussehen von Fenstern gespeichert werden. Allerdings verschwanden im gleichen Zug die geteilten Fenster. Diese kamen erst mit Mac OS X Snow Leopard (10.6, 2009) zurück, das gleichzeitig eine 64-bit-Version von Terminal mitbrachte.\n\nIn Mac OS X Lion (10.7, 2011) bekam das Terminal wieder einige neue Features, so etwa der Vollbildschirm-Modus und verschwommene transparente Hintergründe und Unterstützung für 256 Farben (xterm-256color). Zudem können aktive und inaktive Fenster ein unterschiedliches Aussehen bekommen.\n\nEs können folgende Terminals emuliert werden (Mac OS X Snow Leopard, 10.6, 2009): codice_1, codice_2, codice_3, codice_4, codice_5, codice_6, codice_7, codice_8. Ab Mac OS X Lion (10.7, 2011) kommt noch codice_9 dazu.\n\nAls Shell kann jede beliebige Shell verwendet werden; Standard ist bash. Andere vorinstallierte Shells sind csh, ksh, sh, tcsh und zsh.\n\nEine Besonderheit des Programms ist es, dass eine Suche im Hilfe-Menü nicht nur passende Menüelemente hervorhebt (wie bei Mac OS X üblich), sondern es werden auch passende manpages angezeigt. Beim Klicken auf eine manpage wird ein separates Terminal-Fenster mit der manpage geöffnet.\nSo gibt eine Suche nach „get“ nicht nur \"Geteiltes Fenster\" zurück, sondern auch z. B. \"getconf (1)\".\n"}
{"id": "5608732", "url": "https://de.wikipedia.org/wiki?curid=5608732", "title": "Retina-Display", "text": "Retina-Display\n\nAls Retina-Display (wörtlich übersetzt „Netzhaut-Bildschirm“) bezeichnet das US-amerikanische Unternehmen Apple die in seinen Produkten eingesetzten Bildschirme, die eine so hohe Punktdichte haben, dass das menschliche Auge nicht in der Lage sein soll, aus einem typischen Betrachtungsabstand einzelne Bildpunkte zu erkennen. Der Werbebegriff wird für Bildschirme verschiedener Geräte benutzt (iPod, iPhone, iPad, iMac, MacBook). Apple hat den Namen RETINA in den Vereinigten Staaten und Kanada als Markennamen registriert.\n\nApple stellt seine Displays nicht selbst her, sondern lässt sie von verschiedenen koreanischen und japanischen Zulieferern produzieren, u. a. von LG Display, Samsung und Japan Display. Bildschirme anderer Hersteller erreichen teilweise höhere Punktdichten.\n\nDie meisten der bisher von Apple verwendeten \"Retina-Displays\" sind Flüssigkristallanzeigen (LCDs) mit \"In-Plane Switching (IPS).\" Eine Ausnahme bildet die OLED-Displays der Apple Watch und des iPhone X. Die folgende Tabelle gibt eine Übersicht über ihre Punktdichten (in Pixel pro Zoll) und Bildschirmauflösungen:\n"}
{"id": "5609806", "url": "https://de.wikipedia.org/wiki?curid=5609806", "title": "Virtuelle Inbetriebnahme", "text": "Virtuelle Inbetriebnahme\n\nUnter virtueller Inbetriebnahme (kurz: \"VIBN\") versteht man das Einspielen, Erproben und Ändern von Planungsdaten auf einer virtuellen Maschine, bevor die erfolgreich getesteten Programme auf die reale Maschine übertragen werden. Dabei können unvorhergesehene Fehler aufgedeckt und bereits in den frühen Entwicklungsphasen beseitigt werden, noch bevor diese in der Realität zu Mehraufwendungen und Kosten führen.\n\nDie Basis für die virtuelle Inbetriebnahme bildet die 3D-Simulation, die das Verhalten der Maschine nachbildet. Die Simulation kann auf die gesamte Fabrik im Rahmen der digitalen Fabrik übertragen werden. So wird ermöglicht, dass nicht nur einzelne Roboter und Maschineninseln betrachtet, sondern auch die komplexen Zusammenhänge hinsichtlich Materialfluss und Robotersteuerung abgebildet werden können, um so eine Optimierung der Produktionsplanung vorzunehmen.\nDie virtuelle Inbetriebnahme gewinnt heute immer mehr an Bedeutung. Eine umfassende Studie hat ergeben, dass durch eine frühzeitige VIBN eine Verkürzung der Inbetriebnahmezeiten, geringere Entwicklungs- und Realisierungsaufwände, die Sicherung der Prozess- und Produktqualität und somit die Reduzierung der Produktionskosten ermöglichen.\n\nBei der virtuellen Inbetriebnahme wird die vorher erzeugte Ablaufsimulation mit der realen Steuerung verbunden. Hierfür stehen im Allgemeinen drei Ebenen zur Verfügung:\nDas Simulationsmodell deckt dabei immer diejenige Ebene ab, die nicht Teil des Testaufbaus ist. Soll die Logik der Speicherprogrammierbaren Steuerung (SPS) überprüft werden, deckt das Modell nur die Sensor- Aktorebene ab. Soll der MFR getestet werden, beinhaltet das Model außerdem die SPS- Logik. Auch Mischformen sind möglich, wobei die SPS einzelner Anlagenbereiche vorhanden sind, andere Bereiche aber vom Model übernommen werden. So ist ein ganzheitlicher Anlagentest auf MFR-Ebene möglich, obwohl einzelne Bereiche auf SPS Ebene noch nicht fertiggestellt sind.\n\nHier wird das Modell mit der realen SPS verbunden und durch diese gesteuert. So kann die Logik der SPS vor tatsächlichem Betrieb der Anlage getestet werden.\nFür den Test der SPS Software verhält sich das Computermodell genauso wie die reale Anlage.\nDie von der SPS kommenden Aktorsignale und Steuerworte werden interpretiert und steuern das Modell. Beispiele für Aktorsignale sind:\n\nDas VIB-Modell sendet die Sensor- und Feedbacksignale an die SPS zurück. Klassische Inputsignale sind:\n\nBei der Virtuellen Inbetriebnahme auf Materialflussrechner (MFR) Ebene erfolgt die Kommunikation zwischen MFR und Simulationsmodell auf Telegrammebene. Die Logik der SPS- Ebene befindet sich im Simulationsmodell.\nDer MFR schickt Transportaufträge an das System und fragt Statusmeldungen ab.\nDer MFR (Materialflussrechner) führt z. B. für das Lagerverwaltungssystem einzelne Transportaufträge durch, überwacht Fördertechnikstrecken und gibt die Daten an die SPS (das Modell) weiter.\nHier kann die Simulation die Steuerung jedes einzelnen automatisierten Bedien-, Förder- und auch Sortierelementes darstellen, überprüfen und ggf. vor Inbetriebnahme verbessern.\n\nZu beachten ist, dass die VIBN die reale Inbetriebnahme nicht vollständig ersetzen kann bzw. durch sie nicht alle Fehlerquellen ausgeschlossen werden können, da der Faktor Mensch nicht hinreichend simuliert werden kann (falsche Verkabelung, geänderte Sensorpositionen). Diese Punkte werden erst bei der realen Inbetriebnahme sichtbar.\n\nDem Detaillierungsgrad der 3D-Simulation und des 3D-Modells steht anfänglich ein höherer Aufwand gegenüber, der sich schnell amortisiert, wenn die vermiedenen Kosten zur Fehlerbeseitigung und das frühere Erreichen der Gewinnzone betrachtet werden.\n\nDaneben hat die VIBN noch weitere Vorteile:\n\n"}
{"id": "5613314", "url": "https://de.wikipedia.org/wiki?curid=5613314", "title": "Can4linux", "text": "Can4linux\n\ncan4linux ist ein Open-Source-CAN-Gerätetreiber für den Linux-Kernel.\nDie Entwicklung begann Mitte der 1990er Jahre für den CAN Controller Baustein Philips 82C200 auf einem ISA Board AT-CAN-MINI. Die erste Version entstand um 1995 im Rahmen des Linux Lab project an der FU Berlin, um unter Linux den CAN-Bus in der Laborautomatisierung zu nutzen.\n\nDurch die zunehmende Verbreitung von CAN in der Automatisierungstechnik insbesondere auch im embedded Bereich, in dem seit der Jahrtausendwende auch verstärkt Linux eingesetzt wird, kommt Gerätetreibern als Basis für höhere CAN basierende Protokolle wie CANopen, J1939 und DeviceNet. eine gestiegene Bedeutung zu.\n\nNeben dem NXP SJA1000 als Nachfolger des CAN Controllers Philips 82C200 und dem Intel 82527 wurden ab 2005 verstärkt Anpassungen für sogenannte integrierte CAN Controller in leistungsstarken Mikrocontrollern, für die Linux Portierungen existieren, erstellt. Als Beispiele sollen hier die Freescale ColdFire Prozessoren oder ARM Derivate von ATMEL und Freescale\naber auch der Stand-Alone CAN Controller MCP2515, angeschlossen über den SPI Bus, dienen.\n\nEine Liste befindet sich auf der can4linux Projekt Seite.\n\nDie neueste Version unterstützt eine \"virtuelle\" CAN Betriebsart in welcher sich Anwendungen ohne spezielle CAN Hardware nur über den Treiber CAN Nachrichten austauschen können.\nIn dieser Betriebsart ist auch schon das Frame Format für CAN FD implementiert, welches Datenlängen bis zu 64 Byte erlaubt.\n\nDie Anwendungssoftware öffnet einen CAN Device Descriptor und erhält einen File Descriptor. Über diesen werden die CAN Frames über die Standard Betriebssystem Funktionen codice_1 und codice_2 mit anderen Teilnehmern am CAN Bus ausgetauscht.\n\nDer folgende Code ist ein Beispiel, welches einen Frame sendet und anschließend auf einen Frame von einem anderen Bus-Teilnehmer wartet. Weitere Beispiele befinden sich auf der Projektseite.\n/* simple CAN application example\n\n\nint main(int argc,char **argv)\n\ncan4linux kann so übersetzt werden, dass verschiedene Prozesse auf den gleichen CAN Controller lesend und schreibend zugreifen können. Auf diese Weise kann z. B. neben der eigentlichen Anwendung ein unabhängiger Diagnoseprozess den Bus beobachten.\n\n"}
{"id": "5624349", "url": "https://de.wikipedia.org/wiki?curid=5624349", "title": "SRWare Iron", "text": "SRWare Iron\n\nSRware Iron, auch kurz Iron, ist ein Webbrowser auf der Codebasis von Chromium. Auf der Website des Herstellers wird behauptet, Iron sei Open Source, allerdings wurde seit spätestens Version 6 bis Mitte 2015 kein Weg geboten, den Quelltext zu erhalten. Seit Mitte 2015 werden wieder Downloads mit Quellcode angeboten, jedoch ohne Angaben zur zugehörigen Version.\n\nIm September 2008 brachte die deutsche Softwarefirma SRware die erste Windows-Version des Browsers heraus. Dabei handelte es sich um eine veränderte Version des Browsers Chrome, bei der wegen datenschutzrechtlicher Bedenken einige Funktionen entfernt wurden.\nEinige dieser Funktionen, wie Chromes eindeutige Identifikationsnummer, wurden inzwischen auch bei Chrome ganz entfernt oder sind im zugrundeliegenden Chromium nicht vorhanden oder zumindest leicht abschaltbar.\n\nFür Linux gab es am 26. Mai 2009 eine erste Vorschau-Version, die erste Alpha am 17. Juni und die erste Beta am 7. November 2009. Am 7. Januar 2010 erschien erstmals eine (Beta-)Version für Mac OS X. Die Version für Android ist seit dem 11. April 2016 im Google Play Store verfügbar.\n\nDer Support für Windows XP endete mit Version 50. Alle älteren Versionen sind weiterhin verfügbar.\nMit der Version 55.0.2900 wird die Steuerung von WebRTC von einem Addon übernommen. Daher entfallen die „WebRTC disabled“-builds.\n\nIron enthält zusätzliche Funktionen gegenüber Chrome und verzichtet auf andere. Beispielsweise ist ein Werbeblocker eingebaut.\n\nIm Gegensatz zu Chrome gibt Iron keine automatischen Suchvorschläge und zeigt keine Google-Fehlerseiten an. Er hat keine Option zum Senden von automatischen Fehlerberichten und Google wird bei erfolgreicher Installation nicht informiert.\n\nWeitere nicht enthaltene Funktionen sind RLZ-Tracking (eine verschlüsselte Zeichenkette), der Google Updater (da Iron keinen Ersatz verwendet, hat es somit keine Auto-Update-Funktion) und DNS-Prefetching.\n\n"}
{"id": "5627609", "url": "https://de.wikipedia.org/wiki?curid=5627609", "title": "Genius Project", "text": "Genius Project\n\nGenius Project ist eine Projektmanagementsoftware für mittelständische und Großunternehmen zur Optimierung von Unternehmensprozessen wie zum Beispiel Geschäftsprozessoptimierung. Die von der in Luzern ansässigen Cerri.com AG hergestellte Software ist in vier Sprachen erhältlich: Deutsch, Englisch, Französisch und Spanisch.\n\nGenius Project ist in drei Produktvarianten erhältlich:\n\nDie wichtigsten Funktionen von Genius Project sind:\n\nGenius Project ist das erste Projektmanagement-Softwareprodukt der Firma Genius Inside und wurde 1997 in Lausanne, Schweiz geschrieben. Gründer des Unternehmens Genius Inside war Patrice Cerri. 1998 erfolgte eine Zertifizierung durch Ernst & Young als führende Enterprise-Projektmanagement-Software. Im selben Jahr war die Gründung eines Partner-/Verkaufsnetzwerks in der Schweiz und in Frankreich. 1998 wurde das Unternehmen „Lotus Premium Partner“ Lotus Notes. 2001 begann die Einführung der Software auf den deutschen Markt und 2002 auf den nordamerikanischen Markt. Sinn und Zweck der Software ist erleichtertes Projektmanagement für mittelständische und Großunternehmen. Seit 2015 gehört die PM-Software zum Produktportfolio der Cerri.com AG.\n\n\n"}
{"id": "5633894", "url": "https://de.wikipedia.org/wiki?curid=5633894", "title": "Domain-Wall-Fermion", "text": "Domain-Wall-Fermion\n\nDomain-Wall-Fermionen bezeichnen eine spezielle Formulierung chiraler Fermionen in der Gittereichtheorie.\n\nDie Idee der Domain-Wall-Fermionen geht auf einen Vorschlag von Kaplan zurück, der von Shamir zur numerischen Simulationen weiterentwickelt wurde. Bei dieser Formulierung von Fermionen auf dem Gitter wird dieses um eine zusätzliche Dimension erweitert. Die Wirkung in den physikalischen Dimensionen entspricht im Wesentlichen der von Wilson-Fermionen. Durch die Kopplung an die zusätzliche Dimension wird erreicht, dass die fermionischen Zustände unterschiedlicher Chiralität an den Wänden der zusätzlichen Dimension separiert werden – sie fallen in der zusätzlichen Dimension exponentiell ab – und damit getrennt behandelt werden können. \n\nDomain-Wall-Fermionen stellen eine Möglichkeit dar, das im Nielsen-Ninomiya-Theorem beschriebene Problem bei der Erzeugung chiraler Teilchen in einer diskretisierten Version einer Feldtheorie zu umgehen.\n\n"}
{"id": "5634906", "url": "https://de.wikipedia.org/wiki?curid=5634906", "title": "Worterkennungssystem", "text": "Worterkennungssystem\n\nEin Worterkennungssystem dient zur Identifikation von Wörtern durch Erkennung der Wortgrenzen mittels Zugriff auf das mentale Lexikon (Wortschatz) und die Semantik (Bedeutung).\n\nEs wird heute in Form Software vorrangig auf Mobiltelefonen zur Beschleunigung der Eingabe per Tastatur oder Touchscreen eingesetzt, am bekanntesten sind T9 und Swype. In gängigen Schreibprogrammen und Browsern ist es die Grundlage zur Erkennung von Rechtschreibe- und Grammatikfehlern.\n\nDie Worterkennung ist abzugrenzen von der Spracherkennung, welche die gesprochene Sprache der automatischen Datenerfassung zugänglich macht, wobei es auch innerhalb der Spracherkennung Worterkennungs-Algorithmen geben kann – dies ist in modernen Systemen nur noch selten der Fall.\n"}
{"id": "5637316", "url": "https://de.wikipedia.org/wiki?curid=5637316", "title": "Goldschmidt-Division", "text": "Goldschmidt-Division\n\nDie Goldschmidt-Division ist ein Verfahren, um eine Division in einer digitalen Schaltung schnell und mit geringem Hardwareaufwand zu realisieren. Dabei wird die Division auf eine Multiplikation zurückgeführt, womit bereits evtl. vorhandene Multiplizierer mitverwendet werden können.\n\nDer Ansatz der Goldschmidt-Division ist die Betrachtung der Division als Bruch formula_1, welcher so lange mit dem Faktor formula_2 erweitert wird, bis der Nenner nahe genug an den Wert 1 konvergiert ist. Der Wert des Zählers entspricht somit dann dem Ergebnis der Division.\n\nDie auszuführenden Schritte sind:\n\nSind formula_4 und formula_5 so skaliert, dass formula_6, dann können die Erweiterungsfaktoren formula_2 einfach berechnet werden:\n\nDamit ergibt sich:\n\nNach einer genügend großen Zahl von Iterationen formula_10 ist der gesuchte Quotient formula_11.\n\nBei der Umsetzung als Schaltung können die Multiplikationen von Nenner und Zähler parallel durchgeführt werden, was eine schnelle Abarbeitung des Algorithmus ermöglicht. Die Goldschmidt-Division wird in den AMD-Athlon-CPUs und späteren Modellen verwendet.\n\nDie Faktoren der Goldschmidt-Division können so gewählt werden, dass eine Vereinfachung mit der binomischen Formel möglich ist. \n\nAngenommen formula_1 wurde mit einer Zweierpotenz so skaliert, dass formula_13.\n\nWir setzen formula_14 und formula_15.\n\nDann gilt:\n\nDa formula_17 können wir nach formula_18 Schritten formula_19 zu 1 runden. Der maximale relative Fehler ist dabei formula_20, und wir erhalten eine Genauigkeit von formula_21 Digitalstellen. Dieser Algorithmus wird in als die IBM-Methode bezeichnet.\n\n"}
{"id": "5651406", "url": "https://de.wikipedia.org/wiki?curid=5651406", "title": "Arthur und die Minimoys 2 – Die Rückkehr des bösen M", "text": "Arthur und die Minimoys 2 – Die Rückkehr des bösen M\n\nArthur und die Minimoys 2 – Die Rückkehr des bösen M (Originaltitel: \"Arthur et la Vengeance de Maltazard\") ist ein französischer Spielfilm von Luc Besson aus dem Jahr 2009. Die Fortsetzung des Films \"Arthur und die Minimoys\" ist eine Mischung aus Realfilm und Computeranimation.\n\nArthur sieht, nachdem die zehn Monde vergangen sind, voller Vorfreude seinem nächsten Besuch bei den Minimoys entgegen. Den Aufnahmeritus in den Stamm der Bogomatasalei hat Arthur mit Bravour bestanden, Arthur ist nun ein Beschützer der Natur. Im Gegensatz zu seinen Eltern, die aus Angst um Arthur aufgrund seiner Insektengiftallergie mit Insektenmittel Jagd auf eine Biene machen, rettet Artur die Biene.\n\nWährenddessen bereiten sich die Minimoys auf ein Festbankett ihm zu Ehren vor, denn besonders Prinzessin Selenia sehnt sich nach einem Wiedersehen. Es kommt aber so, dass Arthur trotz eines Hilferufs auf einem Reiskorn mit seinen Eltern abreisen muss. Nach einer erfolgreichen Flucht kann Arthur mit Hilfe von verzauberten Lianen und den Bogomatasalei zu den Minimoys zurückkehren. Arthur wird nach einer kurzen Odyssee vom König und den Minimoys freudig empfangen.\n\nNach einer erfolglosen Suche nach der Prinzessin Selenia taucht der böse Maltazard mit Prinzessin Selenia als Geisel vor den Stadttoren auf. Maltazard zwingt Arthur, ihn mit den Minimoys durch das magische Tor zu schicken. Arthur kann zwar Prinzessin Selenia retten, allerdings entkommt Maltazard in die Welt der Menschen und wird groß.\n\nDie deutsche Synchronbearbeitung entstand durch die FFS Film- & Fernseh-Synchron, München/Berlin. Für Dialogbuch und -regie war Marius Clarén zuständig.\n\nDas \"Lexikon des internationalen Films\" meinte: „Die Fortsetzung von Luc Bessons Fantasy-Saga gewinnt im inszenatorisch hingeschluderten Mix aus Realfilm und Computeranimation keine Eigenständigkeit und weist lediglich abendfüllend auf eine weitere Fortsetzung hin. Die klischeehaften Figuren wecken freilich kaum Neugier auf ihr weiteres Schicksal.“\n\nDas Onlineportal \"cinefacts.de\" bewertet den Film positiv mit 4,5 von 5 Punkten: „Die reiche Fantasiewelt rund um den Jungen Arthur und die winzigen animierten Gartenbewohner umgarnt erneut mit ihrem eigenwilligen Charme.“\n\n\"Kino.de\" schreibt: „Die außergewöhnliche Animation bietet ein Füllhorn verrückter Gestalten und Aktionen, alle Figuren gehen auf ein einziges jeweils variierendes Modell zurück und sind völlig unterschiedlich. Die Referenzschauspieler für die Bewegungsabläufe durften richtig aufdrehen. Technisch beeindruckt diese ausgefeilte Fantasy-Welt, nur Herz und Charme des ersten Teils sind verloren gegangen beim atemlosen Trip durch die Möglichkeiten der CGI-Animation, der – für einen Film ungewöhnlich – mit einem Cliffhanger endet und wie eine Übergangsstation zum demnächst folgenden Finale wirkt.“\n\nDer zweite und dritte Teil wurden aus Kostengründen gleichzeitig gedreht. Der dritte Teil (Originaltitel: \"Arthur et la Guerre des deux mondes\") hatte am 13. Oktober 2010 in Frankreich Premiere und erschien in Deutschland unter dem Titel \"Arthur und die Minimoys 3 – Die große Entscheidung\" direkt auf DVD.\n\n"}
{"id": "5652062", "url": "https://de.wikipedia.org/wiki?curid=5652062", "title": "Proxmox VE", "text": "Proxmox VE\n\nProxmox VE (\"Proxmox Virtual Environment\"; kurz PVE) ist eine auf Debian basierende Open-Source-Virtualisierungsplattform zum Betrieb von virtuellen Maschinen mit einer Web-Oberfläche zur Einrichtung und Steuerung von x86-Virtualisierungen. Die Umgebung basiert auf QEMU mit der Kernel-based Virtual Machine (KVM). PVE bietet neben dem Betrieb von klassischen virtuellen Maschinen (Gastsystemen), die auch den Einsatz von Virtual Appliances erlauben, auch LinuX Containers (LXC) an.\n\nDurch die Verwendung einer Web-Oberfläche wird ein Großteil der einfachen Arbeiten wie das Einrichten, Starten und Stoppen, Erstellen von Backups und Verwaltung der Netzwerkinfrastruktur und der laufende Betrieb von virtuellen Maschinen und den dazugehörigen Speichersystemen am Hostsystem erleichtert. Weiters können Cluster von mehreren PVE-Hostsystemen basierend auf der Corosync Cluster Engine gebildet werden welche gemeinsam verwaltet werden und zwischen welchen virtuelle Maschinen und deren virtuelle Festplattenspeicher ausgetauscht werden können. Dies ermöglicht den Aufbau von Hochverfügbarkeitsclustern.\n\nEine Besonderheit von PVE ist, dass beliebige Pakete des Debian-Projekts mittels dem Debian Package Manager (dpkg) und darauf aufbauend Advanced Packaging Tool (apt) am Hostsystem nachinstalliert werden können. Auch die Verwaltung und Aktualisierung von Proxmox-Paketen erfolgt über eigene Repositories mittels dpkg. Der Veröffentlichungszyklus von PVE liegt dabei meist bei zwei bis vier Monaten, bei größeren Änderungen auch länger. Proxmox VE wird von der Wiener Proxmox Server Solutions GmbH entwickelt und betreut.\n\nBis Version 3.4 wurde als Container-Technologie OpenVZ verwendet, mit Version 4.0 wurde dieser durch LXC ersetzt. Die Proxmox-VE-Version 5.1 arbeitet auf Basis von Linux 4.13 und unterstützt im Parallelbetrieb sowohl KVM-basierte Gastsysteme, als auch LXC-basierte Linux-Container\n\nIm einfachsten Fall wird PVE auf einer kompatiblen x86-64-Plattform wie beispielsweise einem Bladeserver von dem zur Verfügung gestellten ISO-Image aus installiert. Das Installationsprogramm erledigt den gesamten Installationsvorgang in einer Debian-Grundinstallation praktisch automatisch und nutzt dabei die gesamte erste Festplatte des PCs. Weitere Installationsarten sind möglich und werden im PVE-Wiki erklärt. Die Unterschiede zu einer gewöhnlichen Debianinstallation bestehen primär in der Vorauswahl der zu unterstützenden Hardware: So werden beispielsweise eine größere Auswahl der im Serverbereich anzutreffenden PHY-Ethernet-Netzwerkchips von der Firma Intel direkt unterstützt, die Nachinstallation von Treibern entfällt damit. Das Proxmox-Wiki bietet dazu diverse FAQs, Howtos sowie zahlreiche Video-Tutorials.\n\nProxmox VE unterstützt am Hostsystem jede Hardware, die auch von Debian in der jeweiligen Version unterstützt wird, somit auch uneingeschränkt SMP-Systeme mit mehreren Prozessoren und Prozessorkernen.\n\nDie Administration von PVE erfolgt für einfache Schritte über ein Webinterface. Ergänzend steht ein SSH-Zugang zur Kommandozeile auf root-Ebene zur Verfügung auf welchem sich mit entsprechenden Scripts und Systemprogrammen auch umfangreichere Arbeiten und spezielle Konfigurationen am Hostsystem erledigen lassen.\n\nProxmox VE beinhaltet auf der einen Seite einen Linux-Kernel, der auf KVM-Basis als Hypervisor (auch \"Virtual Machine Monitor\" genannt) direkt auf der Hardware läuft. Der Linux-Kernel stellt ab der Version 2.6.21 als Rahmenbedingung für Virtualisierungs-Anwendungen die \"paravirt ops\"-Schnittstelle bereit.\n\nDer Vorteil von KVM liegt darin, nahezu beliebige x86-Betriebssysteme ohne zusätzliche Anpassungen unter einer zentralen Verwaltung ausführen zu können. Diese Betriebsart wird als \"volle Virtualisierung\" oder \"Hardware Virtual Machine\" (HVM) bezeichnet. Für die HVM-Virtualisierungstechniken wird am Hostsystem standardmäßig vorhandene hardwareunterstützung für Virtualisierung mit AMD-V oder Intel VT benötigt.\n\nAb Version 4.0 lösen Linux Containers (LXC) die bisher verwendeten OpenVZ-Container (bis Proxmox VE 3.4) ab. Bei einem Upgrade eines Proxmox-Clusters können die OpenVZ-Container zu LXC konvertiert werden. Im Gegensatz zu virtuellen Maschinen weisen Container einen geringeren Speicherbedarf auf, dafür ist das Gastsystem auf das Betriebssystem Linux limitiert da bei Containern der Kernel des Hostsystem im Gastsystem verwendet wird.\n\nMit dem Wechsel auf LXC kann Proxmox die aktuellen Linux-Kernels nutzen. Die komplette Integration von LXC in das Proxmox VE-Framework erlaubt ab Proxmox VE 4.x die Verwendung von LXC mit Storage-Plugins wie Ceph, ZFS (Dateisystem) (lokal oder via iSCSI), NFS (Network File System), GlusterFS, iSCSI, Sheepdog oder lokalem Speicher (Verzeichnisse oder LVM). DRBD9 wird seit Proxmox 4.4 aufgrund von Lizenzproblemen nicht mehr direkt unterstützt und kann nur durch externe Plugins eingebunden werden.\n\nProxmox VE integrierte bis Version 3.4 auch OpenVZ, eine auf Linux aufbauende Servervirtualisierung auf Betriebssystemebene. Hier wird anders als bei KVM ein gemeinsamer Kernel für alle virtuellen Maschinen (Instanzen) verwendet, die in sogenannten \"Containern\" voneinander isoliert sind. Der Vorteil ist hier die Schlankheit dieser Technik, d. h. der Speicherverbrauch und die Prozessornutzung ist günstiger als bei KVM.\n\nJedoch ist es mit OpenVZ nur möglich, Linux-VMs mit auch auf Hostseite angepasstem Kernel zu betreiben; die Gäste können weiterhin auch keine eigenen Änderungen am Kernel vornehmen oder eigene Kernelmodule laden, da der Kernel mit dem Hostsystem geteilt wird. Um diese Technik benutzerfreundlich zu halten, verfügt Proxmox VE/OpenVZ über Templates, die alle notwendigen Änderungen des Gastsystems automatisiert durchführen. Wiederum profitieren von einem Update des zentralen Kernel sofort alle Instanzen; der Verwaltungsaufwand ist also gegebenenfalls geringer.\n\nPVE unterstützt die Aufnahme und Einrichtung der für den Betrieb notwendigen virtuellen Laufwerke der Gastsysteme, Snapshots und Backups. Dabei können sowohl lokale im Hostsystem eingebaute Speichermedien wie Festplatten (HDD) oder Solid-State-Drives (SSD) als auch netzwerkbasierende Speichersysteme, wie Storage Area Networks (SAN) oder Network Attached Storages (NAS), zur Anwendung kommen. Die Anbindung kann dabei dateisystembasierend erfolgen, beispielsweise mittels Network File System (NFS), als auch als Blockgerät über Schnittstellen wie iSCSI.\n\nZur Verwaltung der lokalen Speichermedien wird generell ein Volume-Management (LVM) eingesetzt, darauf aufbauend erfolgt für die virtuellen Laufwerksabbildungen die Speicherung entweder in eigenen Partitionen in oder in einem Dateisystemen, beispielsweise in dem standardmäßig von QEMU verwendeten Dateiformat \"qcow2\". Damit ist auch der Austausch der Laufwerksabbildungen zwischen verschiedenen Virtualisierungsumgebungen auf Dateiebene möglich. Als Dateisysteme am Hostsystem wird neben ext4 auch das im Serverbereich anzutreffende und speicherintensive ZFS zur Auswahl angeboten.\n\nPVE bietet sowohl für das Hostsystem als auch darauf aufbauend individuell für jedes Gastsystem einzeln die Möglichkeit einer auf iptables basierenden Firewall an. Die Konfiguration für die Netzwerkregeln kann über das Web-Interface erfolgen.\n\nDie Schnittstelle zur Konsole der Gastsysteme, beispielsweise die Ausgabe einer grafischen Oberfläche und die Eingabe der Tastatur- und Maussteuerungen im Rahmen eines virtuellen KVM-Switchs, erfolgt wahlweise über das Protokoll SPICE oder über eine auf HTML5 basierende Variante von Virtual Network Computing (noVNC). Damit nicht jedes Gastsystem einen eigenen Port für die Konsolenschnittstelle am Hostsystem belegt, erfolgt der verschlüsselte Zugang mit Authentifizierung über einen Proxy.\n\nAb Version 5.3 besteht über die Weboberfläche die Möglichkeit einzelne Hardwarekomponenten vom Hostsystem, wie beispielsweise Einsteckkarten mit Peripheral Component Interconnect (PCI) oder Grafikkarten (GPU), direkt in bestimmte Gastsysteme für den exklusiven Zugriff durchzureichen.\n\n\n"}
{"id": "5652106", "url": "https://de.wikipedia.org/wiki?curid=5652106", "title": "Windows Fotogalerie", "text": "Windows Fotogalerie\n\nWindows Fotogalerie ist ein Programm zur Bildbearbeitung. Es gehörte zu Windows Essentials und wurde von Microsoft entwickelt. Die Weiterentwicklung und der Download wurden eingestellt.\n\nFotos können beispielsweise nach dem Aufnahmedatum sortiert werden. Die Software ist nur für Windows verfügbar.\n\nDie in Windows XP eingeführte Windows Bild- und Faxanzeige wurde in Windows Vista überarbeitet und in Windows Fotogalerie umbenannt. Dann gab Microsoft das Windows Live Dashboard heraus. Es beinhaltete die Windows Live Fotogalerie. Diese enthielt mehr Funktionen. Dann veröffentlichte Microsoft Windows 7. Damit auch die Windows Fotoanzeige, diese konnte Bilder nicht bearbeiten. Deshalb wurde Windows Live Essentials 2009 inklusive einer neuen Version der Live Fotogalerie veröffentlicht. Dann gab Microsoft Windows Live Essentials 2012 heraus. Diese Version enthält weitere Funktionen.\nZu den Neuerungen der Version 2011 zählt die Einführung der Ribbon-Oberfläche, wie sie auch in den anderen Office-2010-Produkten verwendet wird. Mit dem Programm können Fotos einfach bearbeitet und auf verschiedene Internetplattformen veröffentlicht werden. Es gibt eine Auswahl an Plug-Ins. Das Programm arbeitet nicht-destruktiv – die Originalfotos bleiben erhalten und werden, wie die hinter dem Programm liegende Datenbank, standardmäßig im jeweiligen Benutzerprofil gespeichert. Eine Speicherung auf anderen Shares ist möglich. Als eines der wenigen nicht-professionellen Bildbetrachtungsprogrammen verfügt das Programm über eine Datenbank, in der auch „Markierungen“ („Keywords“) in den IPTC-Daten gespeichert werden. Bereits für Fotos vergebene Markierungen können verwaltet oder geändert werden. Allerdings gibt es keine Möglichkeit, die Markierungen und andere Metadaten, wie Bewertungen oder Geo-Tags, in ein Foto zurückzuschreiben, weshalb sie für andere Bildbearbeitungsprogramme nicht zur Verfügung stehen. Für die Zuteilung von Geo-Daten gibt es ein Plug-In.\n"}
{"id": "5655673", "url": "https://de.wikipedia.org/wiki?curid=5655673", "title": "OpenChrom", "text": "OpenChrom\n\nOpenChrom ist eine freie Software zum Analysieren massenspektrometrischer Daten der Chromatographie. Der Fokus liegt auf der Bearbeitung von Messdaten chromatographischer Systeme (z. B. GC/MS, LC/MS, Py-GC/MS, HPLC-MS). Dabei werden Datenformate unterschiedlicher Hersteller wie Agilent, Bruker, Shimadzu, Thermo Fisher Scientific, PerkinElmer und weiterer Anbieter unterstützt.\n\nOpenChrom unterstützt nur die Analyse bereits aufgezeichneter Messdaten. Eine Gerätesteuerung wird nicht unterstützt. Die Software verfügt über eine anpassbare grafische Oberfläche. Zum Bearbeiten der chromatographischen Daten stehen Methoden zum Finden von Basislinien als auch zum Detektieren und Integrieren von Spitzen bereit. Filter erlauben eine zusätzliche Optimierung der Daten, zum Beispiel, um Massenfragmente (m/z) wie Wasser (18) und Stickstoff (28) zu entfernen. OpenChrom ist freie Software und basiert auf einem modularen Ansatz, um zusätzliche Methoden und Algorithmen in die Plattform zu integrieren. OpenChrom baut auf der Eclipse Rich Client Platform (RCP) auf und ist für die Betriebssysteme Microsoft Windows, Linux und Mac OS X verfügbar. OpenChrom steht unter der Eclipse Public License 1.0 (EPL). Drittkomponenten werden über separate Plugins bereitgestellt und liegen unter verschiedenen OSI-kompatiblen Lizenzen vor.\n\nOpenChrom entstand im Rahmen der Dissertation von Philip Wenig an der Universität Hamburg. In seiner Arbeit beschäftigte er sich mit der Mustererkennung auf Daten der analytischen Pyrolyse gekoppelt mit der Gaschromatographie und Massenspektrometrie (Py-GC/MS). Mittels des Moduls ChromIdent können eigene Pyrogramm-Datenbanken zur Identifizierung aufgebaut werden. Die Software wurde entsprechend generisch implementiert, und schnell wurde klar, dass sich die Anwendung auch auf andere Fragestellungen mit schwer auswertbaren Chromatogrammen wie etwa der Analytik von Geruchsstoffen in komplexer Matrix anwenden lässt.\n\nIm August 2010 hat OpenChrom den ersten Platz beim Thomas Krenn Open-Source-Förderwettbewerb belegt sowie im März 2011 den Eclipse Community Award als beste RCP-Anwendung gewonnen. Die Entwickler sind zudem Gründungsmitglieder der Eclipse Science Working Group. Auch nach der erfolgreichen Kommerzialisierung der freien Software und damit in Verbindung stehender Dienste wurde das Engagement der Firma Lablicate im Bereich Open Source durch die Veröffentlichung der Schwestersoftware \"ChemClipse\", deren Namensrechte die Eclipse Foundation trägt, erneut bestätigt.\n\nDas Team der Firma Lablicate ist in die Forschung und Lehre des Fachbereichs Chemie der Universität Hamburg integriert. An Chemometrik und Bioinformatik interessierte Studenten werden durch Mentoring gezielt gefördert und unterstützt. Durch Kooperation mit der Abteilung für Massenspektrometrie bleiben die OpenChrom-Entwickler in direktem Kontakt mit den Praktikern und ihren alltäglichen Benutzbarkeitsproblemen im Umgang mit komplexer wissenschaftlicher Auswertesoftware. Zudem ist das Team von Lablicate auch auf wissenschaftlichen Veranstaltungen präsent und bietet Workshops für Nachwuchswissenschaftler an.\n\nJeder Hersteller legt die aufgenommen Messdaten üblicherweise in einem eigenen Datenformat ab. Diese Datenformate sind in den meisten Fällen proprietär und damit für Softwarelösungen anderer Hersteller unzugänglich. Es kommt zur Wettbewerbsverzerrung durch einen technisch herbeigeführten Vendor-Lock-in. Das erschwert den Vergleich von Messdaten und behindert den wissenschaftlichen Austausch. Zudem müssen Software-Entwickler ein aufwändiges Reverse Engineering der Formate durchführen, um die Daten lesbar zu machen.\n\nDas Ziel von OpenChrom ist es, eine möglichst große Bandbreite an unterschiedlichen Formaten zu unterstützen. Hierfür werden in das Programm integrierte Konverter kostenfrei zur Verfügung gestellt. Die Rohdaten werden importiert und bleiben selbst unverändert. Darüber hinaus ermöglicht es OpenChrom die analysierten Messdaten in offenen Formaten abzuspeichern. Dazu stellt OpenChrom ein eigenes Open-Source-Format (*.ocb) zur Verfügung. Dieses Format speichert nicht nur die Messdaten, sondern auch die Identifizierungsergebnisse.\n\n\n\n\nOpenChrom stellt eine Vielzahl an Funktionen zum Bearbeiten chromatographischer Daten zur Verfügung, die modular durch Erweiterungen (Plug-ins) zur Verfügung gestellt werden und unabhängig vom Hauptprogramm eingespielt und aktualisiert werden können:\n\n\nSeit 2010 gibt es offizielle Versionen von OpenChrom. Jede Version ist nach einem berühmten Wissenschaftler aus dem Bereich der Chromatographie und/oder Massenspektrometrie benannt.\n\n\n"}
{"id": "5677676", "url": "https://de.wikipedia.org/wiki?curid=5677676", "title": "Lustre (Dateisystem)", "text": "Lustre (Dateisystem)\n\nLustre ist ein paralleles, verteiltes Dateisystem, welches üblicherweise in großen Cluster-Computing-Umgebungen Einsatz findet. Der Name Lustre leitet sich aus Linux und Cluster ab. Lustre ist unter der GNU GPL (nur v2) verfügbar und bietet ein hochperformantes Dateisystem für sowohl kleine wie auch große, über mehrere Standorte verteilte Cluster.\nDa Lustre besonders auf hohe Leistungsfähigkeit ausgerichtet ist und unter einer freien Lizenz steht, wird es oft im Umfeld von Supercomputern genutzt. Aktuell setzen 15 der TOP30-Supercomputer auf das Lustre-Dateisystem, inklusive des ehemals weltschnellsten TOP500-Supercomputers, des Titan.\n\nLustre-Dateisysteme sind skalierbar und unterstützen mehrere tausend Client-Systeme, mehrere Petabyte (PB) Speicherplatz und hunderte Gigabyte pro Sekunde (GB/s) gebündelter Schreib-/Lese-Last. Dies macht Lustre zu einer beliebten Wahl für z. B. große Rechenzentren wie bei Internet-Service-Providern, Finanzdienstleistern oder für die Öl- und Gas-Industrie.\n\nMit Linux-Kernel 4.17 wurde Lustre aus dem Staging-Bereich des Kernels entfernt, nachdem es nicht gelungen war deutliche Qualitätsverbesserungen in den Kernel einzupflegen. Die Weiterentwicklung erfolgt nun – wie schon teilweise zuvor – außerhalb des Kernels.\n\n\n"}
{"id": "5680642", "url": "https://de.wikipedia.org/wiki?curid=5680642", "title": "Plenoptische Kamera", "text": "Plenoptische Kamera\n\nEine plenoptische Kamera, auch Lichtfeldkamera genannt, erfasst neben den üblichen 2 Bilddimensionen eine weitere, nämlich die Richtung einfallender Lichtstrahlen. Durch die zusätzliche Dimension enthalten plenoptische Aufnahmen Informationen über die Bildtiefe.\n\nDer besondere Vorteil plenoptischer Kameras liegt in der theoretisch unendlichen Schärfentiefe und der Möglichkeit der Refokussierung, also der nachträglichen Verschiebung der Schärfeebene im Objektraum (Fokusvariation). Durch die zusätzliche Tiefeninformation kann eine plenoptische Kamera auch als 3D-Kamera verwendet werden.\n\nEntscheidend für die Funktion plenoptischer Kameras ist, dass dieselbe Szene aus mehreren Blickwinkeln erfasst wird. Dabei ist es irrelevant, ob ein Array aus konventionellen Kameras die Szene erfasst, oder die verschiedenen Blickwinkel innerhalb der Kamera erzeugt werden – z. B. durch einen Array aus Mikrolinsen vor dem Bildsensor.\n\nDie Entwicklung plenoptischer Systeme basiert auf theoretischen Überlegungen des Physikers Gabriel Lippmann, der das Konzept 1908 vorstellte.\n\nDie Verteilung der Strahldichte entlang von Lichtstrahlen in einem Bereich des dreidimensionalen Raums, die durch statische, zeitlich nicht veränderbare Lichtquellen hervorgerufen wird, bezeichnet man als plenoptische Funktion. Die plenoptische Funktion ist eine idealisierte Funktion, die in der Bildverarbeitung und der Computergrafik genutzt wird, um ein Bild zu einem bestimmten Zeitpunkt aus jeder beliebigen Position aus jedem Blickwinkel zu beschreiben, also unabhängig von der Position des Betrachters und Kameraparametern wie Blende und Entfernungseinstellung.\n\nPraktisch wird die plenoptische Funktion nicht genutzt, jedoch ist sie sinnvoll, um verschiedene andere Konzepte der Bildverarbeitung und der Computergrafik zu verstehen. Eine Gerade (Strahl) wird durch einen Punkt auf dem Strahl (drei Koordinatenwerte) und die Richtung des Strahls (zwei Winkel) beschrieben. Da der Punkt längs des Strahls verschoben werden kann, geben seine drei Koordinaten effektiv nur zwei Freiheitsgrade wieder. Daher ist die plenoptische Funktion vierdimensional. Wellenlänge, Polarisationswinkel und die Zeit können gegebenenfalls als weitere Variable betrachtet werden, wodurch weitere Dimensionen hinzukommen.\n\nDurch das Linsengitter wird jeder Bildpunkt nochmals gebrochen und zu einem Kegel erweitert, der kreisförmig auf die Sensorfläche trifft. Dies verrät, aus welcher Richtung der Lichtstrahl ursprünglich kam: Ein senkrecht auftreffender Lichtstrahl landet im Mittelpunkt des Kreises, ein schräg eintreffender weiter am Rand. So kann mit einer Software die Schärfe nachträglich neu berechnet und wie bei einem herkömmlichen Objektiv der Brennpunkt geändert werden. Die Informationen aus einer Szene müssen auf mehreren Bildpunkten des Kamerachips abgebildet werden, damit die Informationen über die Richtung des einfallenden Lichtstrahls genutzt werden kann. Daher geht mit dieser Methode eine Verringerung der effektiven Auflösung des Kamerasensors einher.\n\nEin Team an der Stanford University verwendet eine 16-Megapixel-Kamera mit einem 90.000-Mikrolinsen-Array, das heißt jede Mikrolinse belichtet etwa 175 Pixel.\n\nEin Entwurf der amerikanischen Firma Adobe verwendet 19 Linsen in Kreisanordnung und belichtet damit einen 100-Megapixel-Sensor, so dass jedes Bild etwa 5-Megapixel-Auflösung erreicht.\n\nEine plenoptische Kamera für den Einsatz in Industrie und Forschung, die von der deutschen Firma Raytrix seit 2010 kommerziell vertrieben wird, verwendet ein Linsenraster aus drei unterschiedlichen Linsen, die sich in ihrer Brennweite unterscheiden. Jede Mikrolinse deckt dabei drei bis sechs Bildpunkte auf dem Kamerasensor ab. Dadurch ist die effektive Auflösung der Kamera nur um den Faktor drei bis sechs geringer als die Auflösung des Sensorchips.\n\nVon der amerikanischen Firma Lytro wurde ab dem April 2012 eine Lichtfeldkamera für den Konsumentenbereich vertrieben. Dieses Modell hat einen siebenfachen optischen Zoombereich, eine fest eingestellte, durchgehende Blendenzahl von 2,0, einen berührungsempfindlichen Bildschirm und einen internen Speicher von 8 oder 16 Gigabyte für farbige Einzelbildaufnahmen. Die effektive Bildauflösung beträgt bei einer Dateigröße von zirka 20 Megabyte 540 mal 540 Bildpunkte (dies entspricht 0,29 Megapixel), was für Demonstrationszwecke, jedoch nicht für hochwertige Reproduktionen geeignet ist. Bei rund 11 Millionen registrierten Bildpunkten ergibt sich ein Verhältnis von sechs mal sechs (36) Lichtstrahlen pro Bildpunkt.\n\nIm April 2014 wurde das Nachfolgemodell Illum vorgestellt, das einer klassischen Kamera ähnelt. Sie soll eine höhere Bildauflösung von maximal 4 MP bei 2D-Bilddateien haben.\n\nIm April 2016 hatte die Firma Lytro angekündigt, sich aus dem Endkundengeschäft für Lichtfeldkameras wegen mangelnden Absatzmöglichkeiten zurückziehen zu wollen und sich von nun an auf den professionellen TV- und Video Markt zu konzentrieren. Die neue Lichtfeldkamera Lytro Cinema ermöglicht eine Auflösung von 755 Megapixeln, einen Dynamik-Umfang von 16 Blendenstufen, 40k-Videos und 300 FPS.\nDie Firma gab am 28. März 2018 bekannt, die Geschäftstätigkeit einzustellen.\n\nEine Nahaufnahme einer Tastatur mit einer plenoptischen Kamera mit Reproduktionen bei vier verschiedenen Entfernungseinstellungen:\n\nEine Aufnahme einer Klaviatur mit einer plenoptischen Kamera mit Reproduktionen bei fünf verschiedenen Entfernungseinstellungen:\n\nDas Unternehmen Pelican Imaging hat im Mai 2013 angekündigt, zusammen mit dem Anbieter von Mobiltelefonen Nokia eine flache, in ein Smartphone integrierte Lichtfeldkamera mit einer Matrix von vier mal vier Objektiven auf den Markt zu bringen.\n\nDas HTC One M8 benutzt zur Simulation des Funktionsprinzipes neben dem eingebauten 4-MP-Bildchip einen zweiten Kamera-Chip zum Erfassen der Tiefeninformationen. Mit dieser U-Fokus genannten Funktion ist ebenfalls das nachträgliche Ändern von Tiefenschärfe und Fokusbereichen möglich.\n\nGoogles seit April 2014 für Android-Geräte verfügbare Kamera-App Google Kamera ermöglicht im Fotomodus „Lens Blur“ („Fokuseffekt“) das nachträgliche Setzen und Bearbeiten von Tiefenschärfe bei Foto. Dafür werden keine zusätzlichen Sensoren oder Optiken benötigt. Stattdessen wird aus den dafür notwendigen automatischen Mehrfachaufnahmen eine 3D-Positionierung der Elemente im Bild berechnet, die dann die nachträgliche Bearbeitung erlaubt.\n\n"}
{"id": "5680734", "url": "https://de.wikipedia.org/wiki?curid=5680734", "title": "Unstrukturierte Daten", "text": "Unstrukturierte Daten\n\nIn der Wirtschaftsinformatik und Computerlinguistik sind unstrukturierte Daten digitalisierte Informationen, die in einer nicht formalisierten Struktur vorliegen und auf die dadurch von Computerprogrammen nicht über eine einzelne Schnittstelle aggregiert zugegriffen werden kann. Beispiele sind digitale Texte in natürlicher Sprache und digitale Tonaufnahmen menschlicher Sprache.\n\nUnterschieden werden unstrukturierte Daten von strukturierten und semistrukturierten Daten.\nBetrachtet man eine E-Mail, so liegt diese in einer gewissen Struktur vor: Sie enthält einen Empfänger, einen Absender und eventuell einen Titel. Damit gehört sie zu den semistrukturierten Daten. Der Inhalt der E-Mail selbst ist jedoch strukturlos.\n\nDie automatische Nutzbarkeit unstrukturierter Daten ist dadurch eingeschränkt, dass für sie kein Datenmodell und meist auch keine Metadaten vorliegen. Auch in Textdokumenten sind Metadaten und Daten vermischt. Um Strukturen daraus zu gewinnen, ist Modellierung erforderlich. Des Weiteren wird von unstrukturierten Daten im Zusammenhang mit der Ablage von Dokumenten ohne vorhandenem Data-Warehousing gesprochen. Dadurch sind diese nicht indizierbar und können dementsprechend nicht gemeinsam durchsucht werden.\n\nViele Daten sind bei ihrem Ursprung unstrukturiert. Sie gewinnen Struktur, indem sie durch menschliche Intervention in ein Schema gebracht werden. Der Vorgang der Strukturierung kann Nachteile hervorrufen, da er oft mit einem Informationsverlust verbunden ist. Im Unternehmensumfeld liegen oftmals wichtige Informationen in unstrukturierten Daten vor, deren Nichterfassung auch rechtliche Probleme verursachen kann. Daher befassen sich die Felder Wissensmanagement und Datenmanagement mit deren Integration und Verwaltung.\n\nUm die unstrukturierten Daten mit Strukturen zu versehen, existiert im Bereich Open Source das Framework UIMA (Unstructured Information Management Architecture). Dies ist ein Framework zum Erstellen von Anwendungen zur Verarbeitung von unstrukturierten Informationen.\n\nSpeziell für die Strukturierung der Daten können folgende Verfahren in Betracht gezogen werden:\n\n"}
{"id": "5684837", "url": "https://de.wikipedia.org/wiki?curid=5684837", "title": "CyanogenMod", "text": "CyanogenMod\n\nCyanogenMod [] (CM) ist eine eingestellte Aftermarket-Firmware bzw. Betriebssystem für eine Reihe von Smartphone- und Tabletmodellen. Es handelt sich um einen Abkömmling des von Google entwickelten freien Betriebssystems \"Android\", der von der Android-Community erstellt und gepflegt wurde, unter anderem vom namensgebenden Entwickler \"Cyanogen\" (Steve Kondik). CyanogenMod versprach für die unterstützten Geräte gegenüber den mitgelieferten Firmwares zusätzliche Funktionen und Verbesserungen der Leistung, Sicherheit und Stabilität. Sie war mit mehr als 50 Millionen Nutzern (Stand: August 2015) das beliebteste angepasste bzw. Community-basierte Android-Derivat.\n\nDie Weiterentwicklung wurde Dezember 2016 eingestellt. Direkter Nachfolger ist LineageOS.\n\nCyanogenMod weist eine Reihe von Unterschieden gegenüber Android auf:\nCyanogenMod unterstützte eine große Zahl an Smartphones und Tablets. Einige davon wurden selbst dann noch unterstützt und mit neuen Versionen versorgt, wenn es vom Hersteller des Gerätes keine Aktualisierungen mehr gab.\n\nEs wurde Software-Kompatibilität zu Android angestrebt. Alle Community-Entwickler, die CyanogenMod auf ein neues Gerät portieren wollten, wurden dazu angehalten, die Kompatibilität ihrer Portierungen mittels der \"Android Compatibility Test Suite\" zu überprüfen. Portierungen, die die Tests der \"Compatibility Test Suite\" bestehen, gelten als kompatibel zu sämtlichen Android-Apps.\n\nDurch Lizenzierungsschwierigkeiten wurde CyanogenMod ohne die proprietären \"Google Apps\" wie Google Play oder Google Maps ausgeliefert. Die Funktionen konnten teilweise durch freie Alternativen wie F-Droid als App-Store ersetzt werden. Auch bestand die Möglichkeit, die Google Apps nachträglich in CyanogenMod zu installieren. Einige Anwendungen von Drittanbietern waren ohne die Google Apps nicht lauffähig, z. B. wenn diese auf spezielle Funktionen dieser Apps zurückgreifen wie Bezahlfunktionen für den Google Playstore.\n\nKurz nach der Einführung des Mobiltelefonmodells \"HTC Dream\" im September 2008 wurde eine Methode gefunden, um allumfassenden administrativen Zugriff (root-Zugriff) auf das Linux-Subsystem von Android zu erlangen. Diese Entwicklung erlaubte zusammen mit der quelloffenen Natur des Betriebssystems \"Android\" das beliebige Ändern und Neueinrichten (oder \"Neuinstallieren\") der Firmware des Gerätes. Ein Entwickler mit dem Pseudonym \"JesusFreke\" machte sich dies zunutze und entwickelte eine modifizierte Firmware für das HTC Dream. Die erste Version von CyanogenMod, veröffentlicht am 25. Mai 2009 auf dem Forum der \"XDA-Developers\"-Gemeinschaft, basierte auf dieser von \"JesusFreke\" modifizierten Firmware. Später stellte \"JesusFreke\" seine Arbeiten ein und empfahl stattdessen CyanogenMod.\n\nCyanogenMod enthält eine bedeutende Menge eigener Codezeilen des CyanogenMod-Teams. Die Anpassungen des CyanogenMod gegenüber Android wurden hauptsächlich von Steve Kondik geschrieben, enthalten jedoch auch Beiträge der \"XDA-Developers\"-Gemeinschaft (wie ein verbessertes Anwendungsstarterfeld, Wählvorrichtung und Browser) und anderer Quellen (wie BusyBox in der Shell).\n\nCyanogenMod war das erste Betriebssystem für Mobilgeräte, das mit Version 4.1.6 vorübergehend für die Prozessverwaltung den Brain Fuck Scheduler (BFS) einsetzte – eine Änderung, die auch in experimentelle Zweige des offiziellen Android-Codebaums übernommen wurde.\n\nKondik veröffentlichte von CyanogenMod eine Reihe von Versionen der Nummern 6.x mit dem Codenamen „Makin’ Bacon“ für das Nexus One. Zu den Merkmalen der Nexus-One-Version gehörten unter anderem ein neuer Kernel, High-Memory-Unterstützung für erweiterten Speicher, Tethering (auch über USB), die Ausführung von Anwendungen von SD-Karte, OpenVPN-Integration, ein sauberes System zum Starten und Herunterfahren, BusyBox, FLAC-Unterstützung, Erweiterungen der Telefon- und Kontaktenanwendung, Optimierungen an Oberfläche und Grafik, neue Live-Hintergrundbilder, 360° \"auto-orientation\" und \"full color trackball notifications\".\n\nSteve Kondik veröffentlichte CyanogenMod 6 für die HTC-Geräte \"Nexus One\", \"Dream (T-Mobile G1)\", \"Magic\", \"Desire\", \"Evo 4G\", \"Espresso\" und \"Hero\" sowie für das Motorola \"Droid\", welches auf Android 2.2 (Codename „Froyo“) basierte. Eine Release-Candidate-Version von CyanogenMod 6 wurde am 11. Juli 2010 verfügbar; die stabile Version folgte am 28. August 2010.\n\nAnfang 2011 wurde die Entwicklung von CyanogenMod in der Version 7 fortgesetzt, die auf Android 2.3.2 (Codename \"Gingerbread\") basierte. Die ersten Release-Candidate-Versionen waren seit dem 16. Februar 2011 verfügbar. Am 11. April 2011 folgte die stabile Version von CyanogenMod 7.0 mit Android 2.3.3. Im selben Jahr, am 10. Oktober 2011, brachten die Entwickler das auf Android 2.3.4 basierende CyanogenMod 7.1 heraus. Die letzte stabile Version dieses Entwicklungszweigs war die Version 7.2, veröffentlicht am 16. Juni 2012. Die neue Version enthielt unter anderem Neuerungen im Bereich der Bildschirmsperre, Ice-Cream-Sandwich-Animationen, Android 2.3.7, diverse Fehlerkorrekturen und unterstützte neuere Android-Geräte.\n\nIm Dezember 2011 wurde CyanogenMod 9 vorgestellt, das für verschiedene Geräte eine Portierungen von Android 4.0.1 (\"Ice Cream Sandwich\", kurz: ICS) verfügbar machte. Die CyanogenMod-Versionen befanden sich zu der Zeit im Alpha-Stadium. Ein halbes Jahr später, am 26. Juni 2012, wurde kurz vor der Entwicklerkonferenz Google I/O 2012 der Release Candidate 1 (RC1) veröffentlicht. Am 19. Juli 2012 folgte der RC2. Er unterstützte weitere Samsung-Galaxy-Geräte. Die stabile Version des CyanogenMod 9 erschien am 9. August 2012. Laut Ankündigung der Entwickler sollte dies die erste und einzige endgültige Version im 9er-Zweig bleiben. Der Fokus der Entwickler lag auf der anschließenden Version CyanogenMod 10, welche alle Geräte der Version 9 unterstützen sollte. Wenige Wochen danach wurde am 29. August 2012 das Update 9.1.0 veröffentlicht. Es behob jedoch lediglich Programmfehler.\n\nIm Juli 2012 kündigten die Entwickler CyanogenMod 10 auf der Basis von Android 4.1 (Jelly Bean) an. Da CM10 keine größeren Änderungen gegenüber dem Vorgänger enthielt, planten die Entwickler Updates für fast alle Geräte, für die auch CM9 erschienen war. Dadurch wurde die weitere Entwicklung von CM9 stark eingeschränkt und später ganz eingestellt. Die ältere Versionen CM7 sollte weiterhin parallel zu CM10 gepflegt werden. Im August 2012 waren erste Nightly-Versionen verfügbar. Ab dem 11. September 2012 wurden erstmals sogenannte „M-Versionen“ regelmäßig am Monatsanfang zur Verfügung gestellt, beginnend mit \"CM10 M1\". Die erste stabile Version von CyanogenMod 10 erschien am 14. November 2012.\n\nMitte Dezember 2012 begann das Ausliefern von Nightly-Versionen von CyanogenMod 10.1 auf Basis von Android 4.2 (Jelly Bean). Am 24. Juni 2013 wurde die fertige Ausgabe der Reihe 10.1 veröffentlicht. Neu waren unter anderem die \"Pie Controls\". Damit ließen sich die Steuerungstasten im Vollbildmodus ausblenden und bei Bedarf einblenden, wenn der Benutzer über den Rand des Bildschirms streift. Bereits wenige Tage nach dem Erscheinen der ersten stabilen Version wurden mit den Versionen 10.1.1 und 10.1.2 einige Sicherheitslücken geschlossen. Die Entwicklung des Versionszweigs 10.1 wurde durch eine letzte Version 10.1.3 abgeschlossen, die unter anderem um den \"Privacy Guard\" ergänzt wurde.\n\nIm Zuge der Vorstellung von Android 4.3 wurde bekanntgegeben, dass das CyanogenMod-Team an einer Version 10.2 arbeitet. Erste Nightly-Versionen wurden ab Mitte August 2013 veröffentlicht, zudem stand seit dem 1. November 2013 die erste \"M\"-Version für über 70 Modelle zur Verfügung. Am 2. Dezember 2013 wurde die stabile Version von CM 10.2 veröffentlicht. Neu war ein \"Blacklist\"-Feature zum Blockieren bestimmter Rufnummern. Am 1. Februar 2014 folgte die fehlerbereinigte Version 10.2.1 mit neuen Sprachunterstützungen, einigen Rückportierungen aus dem CM-11-Zweig und dem Nachrichtenverschlüsselungsdienst \"WhisperPush\".\n\nDie Entwicklung von CyanogenMod 11.0 begann Anfang November 2013. Es basiert auf Android 4.4 (KitKat). Eine erste Version für verschiedene Nexus-Geräte wurde am 5. Dezember 2013 veröffentlicht. Später kamen weitere Geräte hinzu; bereits das zweite \"M-Release\" erschien für über 65 Modelle.\n\nNeu hinzugekommen war die Möglichkeit, SMS-Nachrichten mittels \"WhisperPush\" mit dem Axolotl-Protokoll verschlüsselt an andere CM- oder TextSecure-Nutzer zu versenden. Im Laufe der Zeit wurden unter anderem ein verbesserter Theme-Manager, der aus CM9 und CM10 bekannte Anwendungsstarter \"Trebuchet\" in stark überarbeiteter Form, neue Optionen für den \"Privacy Guard\" und die FFmpeg-Bibliothek in die elfte Version von CyanogenMod integriert.\n\nAm 25. Juni 2015 wurde offiziell der finale \"Snapshot\" des Zweiges „CyanogenMod 11.0“ veröffentlicht. 23 Modelle erhielten dieses letzte CM-11.0-Update. Die CM-Entwickler wandten sich der CM 12.1-Entwicklung zu. Nachdem eine schwere Sicherheitslücke in der Softwarebibliothek „Stagefright“ bekannt geworden war, wurde am 1. September 2015 eine weitere, nicht geplante Version von CM 11.0 veröffentlicht. Auch danach wurden noch Sicherheitsaktualisierungen in den Quellcode von CM 11.0 eingepflegt. Diese wurden jedoch als nicht mehr offiziell unterstütze \"Nightly\"-Versionen für bestimmte Geräte veröffentlicht.\n\nMitte November 2014 wurde die auf Android 5.0 (Lollipop) basierende Version CyanogenMod 12 für Ende des Jahres 2014 angekündigt. Erste Nightly-Versionen wurden jedoch erst Anfang Januar 2015 veröffentlicht. Diese hatten Android 5.0.2 als Basis und unterstützten zunächst nur etwa 30 Gerätetypen. Laut den Entwicklern war diese erste Version zu 85 Prozent fertig, aber nicht für den täglichen Gebrauch gedacht. Mit CM12 wurde das Aussehen der Oberfläche an das neue Material Design von Android 5 angepasst.\n\nFür CM12 wurden keine \"M\"-Versionen mehr veröffentlicht, stattdessen erschienen in unregelmäßigen Abständen sogenannte \"Snapshots\". Der erste \"Snapshot\" mit Bezeichnungen „YNG4NAO09M“, „YNG4NAO09N“ oder „YNG4NAO0A0“ (je nach Gerät) des CM12-Zweiges wurde am 25. Juni 2015 für 22 Modelle veröffentlicht.\n\nIm März 2015 wurde bekannt, dass mit der Entwicklung von Cyanogenmod 12.1 basierend auf Android 5.1 begonnen wurde. Der erste \"Snapshot\" von CM12.1 erschien am 1. September 2015.\n\nDie Version 13 wurde Anfang Oktober 2015 passend zur Veröffentlichung von Android 6.0 (Marshmallow) angekündigt.\nAm 24. November 2015 wurden die ersten Nightly Builds für sieben Modelle veröffentlicht.\nDas erste stabile CM 13.0-Release \"ZNH0E\" wurde am 16. März 2016 für circa 28 Modelle veröffentlicht. Der Code basierte auf Android 6.0.1 (r17).\n\nDie Version 14.1 wurde Anfang November 2016 für die ersten Geräte zur Verfügung gestellt. Sie basierte auf Android 7.1. Am 8. November 2016 wurden die ersten Nightly Builds für neun Modelle veröffentlicht.\n\nIm Dezember 2016 gab der kommerzielle Ableger Cyanogen Inc. bekannt, dass die Dienste und Infrastruktur des kommerziellen CyanogenOS abgeschaltet werden. Davon betroffen waren auch Teile der Infrastruktur von CyanogenMod. Die Entwickler von CyanogenMod beschlossen daraufhin, das Projekt unter neuem Namen (LineageOS) fortzuführen. Die Umbenennung sollte ferner der Vermeidung von Markenrechtsstreitigkeiten dienen. Die Namensrechte liegen bei Cyanogen Inc.\n\nFür das Installieren von CyanogenMod auf dem Smartphone oder Tablet musste in der Regel zunächst ein gesondertes „Recovery-Image“ auf dem Gerät aufgespielt werden. Der Recovery-Mode ist ein besonderer Bootmodus, der dem Sichern oder Wiederherstellen des Festspeicherinhaltes des Gerätes, der Reparatur oder eben dem Austausch der Firmware dient. Die CM-Community selbst arbeitete an dem weit verbreiteten \"ClockworkMod Recovery\" mit. Daneben gibt es für manche Geräte einen sogenannten \"CyanogenMod Installer\". Hierbei handelte es sich um eine App für Android, die den Installationsprozess stark vereinfachte.\n\nEine Anwendung namens \"CyanogenMod Updater\" (kurz \"CM Updater\") benachrichtigte CyanogenMod-Nutzer über die Verfügbarkeit neuer Aktualisierungen und ermöglichte deren Herunterladen und Einrichten auf dem eigenen Gerät. Sie wurde erstellt und betreut von den xda-developers-Mitgliedern \"Garok89\" (Ross McAusland) und \"Firefart\" (Christian Mehlmauer) und basierte auf dem \"JF-Aktualisierer\" von Sergi Velez. Das Programm wird mittlerweile nicht mehr gepflegt. Mit CM 10.0 am 13. März 2012 wurde der \"CM Updater\" in die CM-Firmware integriert.\n\nProgrammfehler in einer stabilen Version (sogenannten Snapshots) und Regressionsfehler in einer Nightly-Version konnten mit dem Bugtracker JIRA an die Entwickler gemeldet werden.\n\nEnde September 2009 schickte Googles Rechtsabteilung CyanogenMods Hauptentwickler Steve Kondik eine Abmahnung. Dieses Verhalten wurde als eine Kampfansage an die freie Software-Community angesehen, der Google eigentlich nahestand. Unzufrieden mit diesem Vorgang waren unter anderem Googles Android-Entwickler.\n\nDas rechtliche Problem bestand im Einbau proprietärer Anwendungen von Google in die CyanogenMod-Gesamtpakete. Bis Version 4.1.11.1 enthielt der CyanogenMod einige unfreie Anwendungen von Google wie Gmail, Maps, Market, Talk und YouTube sowie einige proprietäre Hardware-Treiber. Diese Pakete waren in den Verkaufsversionen von Android enthalten, jedoch nicht für die freie Weiterverteilung lizenziert. Nach dem Eingang der Abmahnung gegen die Verbreitung der genannten Anwendungen kam die Entwicklung kurzzeitig zum Erliegen. Die Abmahnung führte zur Auseinandersetzung mit der Frage, wie stark der Betrieb oder die Funktionalität von Android von proprietären Bestandteilen abhängt.\n\nGoogles Vorgehen schlug sich in einer umfassenden Berichterstattung in einschlägigen Medien nieder, unter anderem in \"PC World\", The Register, The Inquirer, Ars Technica, The H, ZDNet, Gigaom und eWeek.\n\nNach einer erläuternden Äußerung von Google zu seiner Position und einer folgenden Verhandlung zwischen Google und Cyanogen wurde eine Lösung für den Fortbestand des CyanogenMod-Projektes erreicht. Die proprietären Bestandteile waren anschließend in CyanogenMod nicht mehr enthalten. Es wurde herausgearbeitet, dass Nutzer ihre bei einem Gerät mitgekauften, lizenzierten Kopien proprietärer Google-Anwendungen ohne Copyright-Verletzung aus der mitgelieferten Firmware eines Gerätes sichern und nachher in eine CyanogenMod-Installation einbinden dürfen. Für diesen Zweck sollte ein Programm in CyanogenMod entwickelt werden, das den Vorgang automatisieren sollte. Anlässlich der Kontroverse beschlossen einige Android-Entwickler, quelloffenen Ersatz für die Google-Anwendungen zu schaffen. Eine weitere Gruppe Entwickler fand sich mit demselben Ziel zur \"Open Android Alliance\" zusammen.\n\nKondik wies darauf hin, dass neben den behobenen Problemen weiterhin potenzielle Lizenzprobleme mit proprietären, unfreien Gerätetreibern bestünden. Später stellte er klar, dass er diese Lizenzprobleme für lösbar hielte, indem die entsprechenden Treiber nicht mehr zusammen mit dem Quellcode veröffentlicht würden. Beim Lösen der Lizenzprobleme erhielt er auch Hilfe von Google-Angestellten.\n\nUrsprünglich gab es vier Veröffentlichungsvarianten von CyanogenMod, die sich hinsichtlich Stabilität und Veröffentlichungintervall unterschieden: \"Nightly\", \"M-releases\", \"Release Candidate\" und \"Stable\". Die \"M-releases\" erschienen einmal monatlich und wurden direkt aus einem wenige Tage zurückliegenden „Code-Freeze“ des \"Nightly\"-Zweigs erstellt.\n\nMit dem Erscheinen von CM11 wurden die Varianten \"Release Candidate\" und \"Stable\" eingestellt. An deren Stelle traten die \"M-releases\", welche anschließend nicht mehr direkt aus dem \"Nightly\"-Zweig erstellt wurden. Stattdessen wurden sie in einem separaten Entwicklungszweig geführt, sodass nicht alle Bestandteile des \"Nightly\"-Zweigs, vor allem nicht die experimentellen Bestandteile, in den \"M-releases\" enthalten waren. Durch Zusammenfassung der Veröffentlichungsvarianten und die regelmäßige monatliche Veröffentlichung der \"M-releases\" wurde angestrebt, neue Funktionen und Fehlerbereinigungen schneller an die Nutzer weitergeben zu können, als dies bisher mit den unregelmäßig erschienenen \"Stable\"-Versionen möglich war.\n\nEnde 2014 wurde die regelmäßige, monatliche Veröffentlichung neuer \"M-releases\" eingestellt. Stattdessen erschienen in unregelmäßigen Abständen sogenannte \"Snapshots\". Die Versionsbezeichnung wurde dabei in ROT13 kodierten Zeichenketten angegeben. Die ersten beiden Buchstaben bezogen sich auf die Versionsnummer. Ein Beispiel: „XN“ entsprach dekodiert „KA“. „KA“ stand für Android KitKat in der ersten Nebenversion („\"minor version number\"“). Der Buchstabe A im Alphabet entsprach einer „0“. Der Systematik entsprechend standen die Buchstaben „YN“ dekodiert für „LA“ (Android Lollipop in der ersten Nebenversion). „YO“ bezeichnete Android Lollipop in der zweiten Nebenversion („B“ entsprach einer „1“). Die Bedeutung der restlichen Zeichen war nicht näher angegeben.\n\nDer Artikel Liste von Android-Versionen enthält eine detaillierte Auflistung vieler Änderungen am Android-Betriebssystem.\n\n\n"}
{"id": "5687238", "url": "https://de.wikipedia.org/wiki?curid=5687238", "title": "Brain Fuck Scheduler", "text": "Brain Fuck Scheduler\n\nDer Brain Fuck Scheduler (BFS) ist ein Desktop-orientierter Prozess-Scheduler für den Linux-Kernel. Er wurde im August 2009 als Alternative zum Completely Fair Scheduler (kurz CFS) und dem O(1)-Scheduler entwickelt. Das Ziel des \"BFS\" ist eine überragende Desktop-Interaktivität (\"desktop interactivity\") und System-Reaktionsfähigkeit (\"responsiveness\").\n\n\"BFS\" wurde von dem langjährigen Kernel-Entwickler Con Kolivas entwickelt und verbessert das Reaktionsverhalten bei Linux-basierten Mobilgeräten mit light-NUMA-Architektur (Non-Uniform Memory Architecture) und Desktop-Rechnern mit weniger als 16 Kernen.\n\nKurz nach seiner Einführung sorgte der neue Scheduler in der Linux-Gemeinde für Schlagzeilen unter anderem mit Berichten auf der Frontseite von Slashdot, im Linux Magazine und Linux Pro Magazine.\n\nDer \"BFS\" hat keine direkte Beziehung zur Programmiersprache \"Brainfuck\".\n\nAm 3. Oktober 2016 gab Con Kolivas bekannt, dass der Scheduler in Multiple Queue Skiplist Scheduler (MuQSS) umbenannt wurde. Als Gründe für die Umbenennung gab Kolivas die großen und einschneidenden Code-Änderungen und den einigen Leuten zu anstößigen Namen „Brain Fuck Scheduler“ an. MuQSS unterstützt eine \"run-queue\" per logischer CPU und eine Skiplist für \"task lookups\". Mit den beiden neuen Eigenschaften möchte Kolivas zwei große BFS-Beschränkungen (nur eine \"run-queue\" und teure \" lookups\" mit der Zeitkomplexität formula_1) umgehen.\n\nDer Brain Fuck Scheduler orientiert sich beim Verteilen von Rechenzeiten am CFS. Allerdings beeinflussen beim CFS auch die am Prozess gemessenen Ruhepausen der Vergangenheit die Entscheidung, wie lange eine Zeitscheibe für den Prozess in der Zukunft dauern wird.\nGerade bei leistungsschwacher Hardware, wie beispielsweise Mobiltelefonen, kann dies für die Benutzereingaben hinderlich sein. Wenn zu viele Ruhezeiten des Eingabeprozesses in der Vergangenheit aufgetreten sind, wird auch in Zukunft weniger Zeit dafür vorgesehen, bis sich die Statistik wieder ändert – eben dann, wenn wieder eine Benutzerinteraktion stattfindet. Der \"BFS\" entfernt diese komplexe Berechnung der Zeitscheiben anhand von Sleep-Aufrufen und versucht eine komplett faire Verteilung anzustreben.\n\nDieser „verkehrten“ Herangehensweise verdankt der Algorithmus auch seinen Namen.\n\nEin erster Test der Version 0.208 durch Ingo Molnar ergab keine Performancevorteile. Der Kernel-Entwickler stimmte aber dem grundsätzlichen Ziel von Con Kolivas nach mehr Unterstützung von Desktop-Systemen zu. Obwohl es verschiedene Berichte über verbesserte Leistung und Reaktionsverhalten gab, ist es unwahrscheinlich, dass \"BFS\" in den Hauptzweig des Linuxkernels übernommen wird.\n\nDer \"BFS\" wurde mit Version 4.1.6 in den CyanogenMod, eine Distribution des Mobil-Betriebssystems \"Android\", integriert und hat zu berichteten Geschwindigkeitsverbesserungen geführt. Steve Kondik kündigte Ende Oktober 2009 an, den \"BFS\" wieder aus dem Hauptentwicklungszweig zu entfernen. Der \"BFS\" wurde am 23. September 2009 auch in einen experimentellen Zweig des Android-Entwicklungsrepositoriums aufgenommen. Er wurde jedoch nicht in die Froyo-Veröffentlichung (Android 2.2.x) aufgenommen, nachdem Blindtests mit dem Droid und dem NexusOne keine Verbesserung im Benutzererlebnis zeigten.\n\nDer \"BFS\" ist der vorgegebene Scheduler der GNU/Linux-Distributionen \"Zenwalk Linux 6.4\" und PCLinuxOS 2010.\n\nIm Dezember 2012 wurde bekannt, dass der Linux-Entwickler Matthias Kohler an einem neuen Scheduler auf \"BFS\"-Basis und Linux 3.6.2 arbeitet. Die Besonderheit ist die Unterstützung von verschiedenen run-queues-Konfigurationen. \"BFS\" benutzt nur eine \"run-queue\" für alle CPUs. Zusätzlich zu dieser Funktion kann über den noch unbenannten Scheduler zum Beispiel eine \"run-queue\" pro CPU oder eine \"runqueue\" alle zwei CPUs konfiguriert werden.\n\n\n"}
{"id": "5687349", "url": "https://de.wikipedia.org/wiki?curid=5687349", "title": "Shrek – Oh du Shrekliche", "text": "Shrek – Oh du Shrekliche\n\nShrek – Oh du Shrekliche ist ein Weihnachts-Special zur Shrek-Filmreihe, das zu Weihnachten 2008 als Direct-to-DVD-Kurzfilm auf DVD herauskam. Die Sprecher der Hauptrollen sind dieselben wie in den Kinofilmen. In den USA lief der knapp halbstündige Film im November 2007 im ABC Television Network. In Deutschland war er im Dezember 2007 und 2008 auf ProSieben zu sehen.\n\nGerade als Shrek denkt, er könne sich endlich einmal zurücklehnen, ausspannen und mit seiner neu gegründeten Familie ein paar glückliche Stunden genießen, steht Weihnachten vor der Tür. Shrek hat keine Ahnung, worum es dabei geht. Fiona teilt ihm jedoch mit, sie erwarte von ihm, dass ihr erstes gemeinsames Weihnachtsfest etwas ganz Besonderes werde. Shrek besorgt sich ein Buch über Weihnachten, um alles bis ins Detail zu planen. Es ist der Tag vor Heiligabend und alle sind voller freudiger Erwartungen – alle außer Shrek. Leider hat jeder Einzelne in seinem Umfeld seine eigenen Vorstellungen davon, wie Weihnachten gestaltet werden sollte. Doch Fiona und den Kindern zuliebe versucht Shrek, ein perfektes Weihnachtsfest vorzubereiten. Das Weihnachtsessen schmort bereits im Ofen und den Weihnachtsbaum hat Shrek liebevoll mit aufgeblasenen Kröten geschmückt, so wie es in seinem Ratgeber „Weihnachten für Dorftrottel“ beschrieben stand. Es fehlt nur noch die Weihnachtsgeschichte, die er gerade seinen drei Kindern vorlesen möchte, als plötzlich seine Freunde hereinspazieren. Der Esel, der Lebkuchenmann und der Gestiefelte Kater geben ihm reichlich gute aber auch verwirrende Ratschläge und zerstören die schöne Stimmung. So erzählt der Esel eine lustige aber auch verstörende Geschichte seiner ersten Weihnachtsparade, Kater erzählt vom „mexikanischen Weihnachtsmann“ und der Pfefferkuchenmann erzählt davon, dass der Weihnachtsmann seine Freundin aufgegessen hätte. Also wirft Shrek sie kurzerhand hinaus. Fiona versucht die Situation zu retten, indem sie sich bei den anderen für das unmögliche Verhalten ihres Gatten entschuldigt. Am Ende feiern alle im Märchenland einen einzigartigen Heiligabend.\n\n"}
{"id": "5690409", "url": "https://de.wikipedia.org/wiki?curid=5690409", "title": "LibreOffice", "text": "LibreOffice\n\nLibreOffice [] (Abkürzungen: LibO oder LO) ist eine freie Zusammenstellung typischer Standardsoftware für Bürotätigkeiten (Office-Paket). Zu LibreOffice gehören Programme für Textverarbeitung, Tabellenkalkulation, Präsentation und zum Erstellen von Zeichnungen. Ein Datenbankmanagementsystem und ein Formeleditor sind ebenfalls enthalten.\n\nLibreOffice spaltete sich Ende 2010 vom Office-Paket OpenOffice.org ab, wird seither unabhängig weiterentwickelt und ist inzwischen die modernere Alternative.\n\nNeben der Desktop-Variante für Linux und Windows gibt es eine für Android-Smartphones und -Tablets. Außerdem existiert unter der Bezeichnung \"LibreOffice Online\" eine Webapp als Online-Office.\n\nDie Geschichte von LibreOffice und der Document Foundation begann mit der Veröffentlichung der ersten Beta-Version des Office-Pakets am 28. September 2010. Die Ursachen für die Abspaltung vom OpenOffice.org-Projekt und damit die Vorgeschichte reichen jedoch bis in das Jahr 1999 zurück. LibreOffice sieht sich als eine legitime Fortführung von OpenOffice.org. Da OpenOffice.org seinerseits eine offizielle Abspaltung von StarOffice (zwischenzeitlich Oracle Open Office) darstellt, wird auch deren Geschichte als Teil des LibreOffice-Projekts verstanden.\n\nNachdem 1999 das ursprüngliche Unternehmen hinter dem Projekt, Star Division, von Sun Microsystems übernommen worden war, wurden im darauf folgenden Jahr die Quellen des proprietären StarOffice freigegeben: OpenOffice.org entstand. Im Zuge dieser Freigabe regte Sun Microsystems bereits im Jahr 2000 die Gründung einer Stiftung an. Das Ziel hinter diesem Vorhaben hat sich mit der Gründung der Document Foundation nicht verändert: Die Entwicklung des Office-Pakets soll unabhängig von Firmeninteressen weitergeführt und die Freiheiten sowohl von Entwicklern als auch von Anwendern gestärkt werden.\n\nNachdem Sun Microsystems im Januar 2010 von Oracle übernommen worden und daraus folgend auch die Entwicklung von OpenOffice.org in deren Verantwortung übergegangen war, entstand innerhalb der OpenOffice.org-Gemeinschaft Unzufriedenheit. Kritisiert wurde insbesondere, dass Oracle die Zukunft von OpenOffice.org offenließ und die Unterstützung des Projektes immer spärlicher ausfiel. Im September 2010 entschieden sich schließlich führende Mitglieder der OpenOffice.org-Gemeinde, die \"Document Foundation\" zu gründen.\n\nKurz nach der Entstehung von LibreOffice hat sich Oracle aus dem OpenOffice.org-Projekt vollständig zurückgezogen und es an die Apache Software Foundation übergeben, die es in Apache OpenOffice umbenannte.\n\nDie Abspaltung und unabhängige Weiterführung des Office-Pakets wurde möglich, da OpenOffice.org als freie Software entwickelt wurde. Anders als bei der Software selbst besaß Oracle am Namen „OpenOffice.org“ das ausschließliche Verwendungsrecht. Die Weiterführung des Projekts unter dem Namen OpenOffice.org erforderte die Zustimmung von Oracle. Oracle entschied, die Namensrechte nicht an die neu gegründete Document Foundation zu übergeben und strebte die Auflösung bestehender Verflechtungen beider Projekte an. Dies erzwang die Fortentwicklung unter dem neuen Namen \"LibreOffice.\" Dieser ist ein Hybridwort aus \"libre,\" dem spanischen und französischen Wort für \"frei\" und dem englischen Wort für Büro, \"office.\"\n\nAm 16. Februar 2011 veröffentlichte die Document Foundation einen Spendenaufruf, um eine Stiftung nach deutschem Recht zu gründen. Das Ziel war es, der Document Foundation den Status einer juristischen Person zu geben. Die hierzu benötigten 50.000 Euro waren acht Tage nach Bekanntgabe des Aufrufs erreicht.\n\nDa sich LibreOffice als legitimer OpenOffice.org-Nachfolger sieht, vergibt das Projekt die Versionsnummern wie unter OpenOffice.org. Die Versionsnummer der ersten stabilen Veröffentlichung vom 25. Januar 2011 lautete daher 3.3.0. Diese Version gilt als Nachfolger von OpenOffice.org 3.2.1. Im Januar 2015 wurde mit der Version 4.4 das neunte Major-Release des Projekts veröffentlicht. Die Förderung und Koordination des Projekts wird von der gemeinnützigen Stiftung \"The Document Foundation\" getragen, die ihrerseits von ehemals führenden Mitgliedern der OpenOffice.org-Gemeinschaft gegründet wurde.\n\nIm April 2011 erklärte Oracle, dass das OpenOffice.org-Projekt der Open-Source-Community bzw. der Apache Software Foundation übergeben werden solle. Da die Community bereits nahezu vollständig zu LibreOffice abgewandert war, kam dies einer Einstellung von OpenOffice.org gleich. Die Document Foundation betonte, dass sie einer Wiedervereinigung der Projekte positiv gegenüberstehe und jederzeit neue Mitglieder aufnehmen würde. Die Lizenzierung des OpenOffice.org-Projekts unter der Apache-Lizenz würde neue Möglichkeiten des Codeaustauschs zwischen beiden Projekten eröffnen. Trotzdem empfahl die Free Software Foundation nur wenig später, auf LibreOffice und nicht auf OpenOffice.org zu setzen.\n\nDie Abbildung zeigt die weltweite Anzahl der LibreOffice-Nutzer von 2011 bis 2018 in Millionen. Einzelnachweise sind im Text vorhanden.\n\n2011: LibreOffice wurde nach Angaben der Document Foundation in der ersten Woche nach Start des Projekts 350.000 Mal heruntergeladen. Sechs Monate nach Start des Projekts stieg die Zahl der Downloads auf 1,3 Millionen, Downloads über andere Webseiten und die Paketverwaltung von Linux-Distributionen nicht mitgezählt. Zum ersten „Geburtstag“ von LibreOffice im September 2011 konnte das Projekt bereits über 6 Millionen Downloads verzeichnen. Allein im September 2011 wurde das Office-Paket 900.000 Mal heruntergeladen, wofür 81 Spiegelserver zur Verfügung standen. Hinzu kommen geschätzte 1,5 Millionen Downloads über andere Webseiten. Die Document Foundation schätzte 2011, dass weltweit 10 Millionen Menschen LibreOffice aktiv verwenden und über Downloads oder CDs bezogen haben. Hinzu kommen geschätzte 15 Millionen Nutzer, die LibreOffice über die Paketverwaltung ihrer Linux-Distribution beziehen. Die Stiftung plant, bis zum Ende des Jahrzehnts diese Zahl von 25 Millionen Nutzern auf über 200 Millionen Nutzer zu steigern.\n\n2013: Im September 2013, nach zwei Jahren, belief sich die geschätzte Anzahl der LibreOffice-Nutzer auf 75 Millionen.\n\n2015: Im Jahr 2015 wurde LibreOffice von 100 Millionen Nutzern und 18 Regierungen verwendet.\n\n2016: Im August 2016 wurde die Anzahl der LibreOffice-Nutzer auf 120 Millionen geschätzt.\n\n2018: Die Document Foundation schätzte 2018, dass es weltweit 200 Millionen aktive LibreOffice-Nutzer gibt. Etwa 25 % davon seien Studenten und 10 % Linux-Nutzer (welche LibreOffice automatisch durch ihre Distribution erhalten). Im Vergleich dazu wurde Microsoft Office 2018 von 1,2 Milliarden Nutzern verwendet.\n\nOpenOffice, der Vorläufer von LibreOffice, und Derivate davon hatten im Jahr 2010 laut einer Studie von Webmasterpro.de einen Marktanteil unter deutschsprachigen Internetnutzern von über 20 Prozent. In der EU betrug dieser Wert zwischen 9 Prozent (Großbritannien) und 22 Prozent (Polen); für die USA wurde in dieser Studie ein Marktanteil von 9 Prozent ermittelt.\n\nAuch die ersten größeren Unternehmen erklärten ihre Absicht, künftig auf LibreOffice zu setzen. So wechselten beispielsweise die Kopenhagener Krankenhäuser und das dänische Verkehrsministerium zu LibreOffice. Die Verwaltung der französischen Region Île-de-France gab im Oktober 2011 bekannt, 800.000 USB-Sticks, welche LibreOffice und andere freie Software beinhalten sollen, an Studenten verschenken zu wollen.\n\nDie maßgebliche Entwicklung und Pflege von LibreOffice leistet die am 28. September 2010 gegründete gemeinnützige Organisation \"The Document Foundation\" (Abkürzung: TDF). Sie fördert und koordiniert die Weiterentwicklung des Office-Pakets und beteiligt sich an der Weiterentwicklung des offenen Dateiformatstandards \"OpenDocument\" bei der OASIS. Die Document Foundation bekennt sich dabei zu freier Software und bewirbt so auch keine proprietären Zusatzmodule oder ähnliches. Sie ist meritokratisch organisiert und verpflichtet sich zur vollkommenen Transparenz. Sie möchte auf die zehnjährige Geschichte des OpenOffice.org-Projekts in der Überzeugung aufbauen, dass nur eine unabhängige Stiftung sowohl den Entwicklern die bestmöglichen Voraussetzungen als auch den Benutzern ein exzellentes Produkt bieten könne. Bis 2012 handelte es sich bei \"The Document Foundation\" nicht um eine rechtsgültig gegründete Stiftung. Vielmehr wurde die „Foundation“ bis zur Gründung einer Stiftung nach deutschem Recht von Mitgliedern des Vereins \"Freies Office Deutschland e. V.\" getragen.\n\nDass Oracle im April 2011 erklärte, jegliche kommerziellen Interessen am OpenOffice.org-Projekt aufzugeben, und das Projekt Anfang Juni 2011 an die Apache Software Foundation übergab, ändere nach Verlautbarungen der Stiftung nichts an ihrem Vorhaben. Sie zeigte sich im Gegenteil eher enttäuscht darüber, dass Oracle die Chance nicht genutzt habe, beide Projekte wieder zu vereinen. Sie betonte nochmals, dass die Stiftung jederzeit für neue Mitglieder offen stehe und einer Wiedervereinigung positiv gegenüberstehen würde, dennoch würden formale Differenzen zwischen der Document Foundation und der Apache Software Foundation das erschweren. Bereits kurze Zeit später, Mitte Juni 2011, besetzte die Document Foundation ihr \"Advisory Board\" (Beirat). Besonderes Augenmerk wurde dabei auf Herstellerunabhängigkeit gelegt, sind in ihm doch alle Sponsoren unabhängig von ihrem Beitrag jeweils mit einem Sitz vertreten. Zu den Mitgliedern zählen Google, SUSE, Red Hat, Novell, Intel, die Vereine Freies Office Deutschland e. V. und Software in the Public Interest (SPI) sowie die Free Software Foundation.\n\nAm 1. Februar 2012 teilte \"The Document Foundation\" mit, dass sie eine rechtsfähige Stiftung bürgerlichen Rechts in Berlin gründen wolle. Die hierdurch entstehende Rechtssicherheit stelle die langfristige Weiterentwicklung der Community und der Software sicher. Als Vorstandsvorsitzender der neuen Stiftung fungierte Florian Effenberger, als Stifter trat der Verein Freies Office Deutschland e. V. (früher OpenOffice.org Deutschland e. V.) auf. Am 17. Februar 2012 wurde die Stiftung in Berlin von der Stiftungsaufsicht anerkannt. Im Februar 2014 übernahm Thorsten Behrens den Vorsitz.\n\nDie Stiftung arbeitet eng mit anderen Organisationen der ehemaligen OpenOffice.org-Gemeinde wie dem deutschen \"Freies Office Deutschland e. V.\" und dem brasilianischen BrOffice.org zusammen und erhält Unterstützung von Projekten wie NeoOffice, von Organisationen wie der Free Software Foundation, der Gnome Foundation und der Open Source Initiative und von Firmen wie Google. Die Linux-Distributoren Canonical (Ubuntu), SUSE (openSUSE, SUSE Linux Enterprise Desktop, zur Zeit der Verlautbarung noch unter dem Dach von Novell) und Red Hat (Fedora, Red Hat Enterprise Linux) haben neben ihrer Unterstützung auch die Aufnahme von LibreOffice in die nächsten Versionen ihrer Betriebssysteme zugesagt. Auch die Regierungen verschiedener Länder, darunter Brasilien, Indien, China und Russland, haben sich wegen ihres intensiven Einsatzes von OpenDocument für eine von Firmeninteressen unabhängige Entwicklung ausgesprochen und die Gründung der Document Foundation begrüßt. Schnell nach Gründung des Projekts haben sich große Teile der OpenOffice.org-Community neu organisiert und LibreOffice zugewandt. Die Document Foundation betonte seit ihrer Gründung wiederholt, dass sie die Beteiligung neuer Mitglieder und Partner ausdrücklich begrüße. Ende September 2011, ein Jahr nach Gründung des Projekts, zählte die Document Foundation 136 registrierte Mitglieder.\n\nDie Document Foundation ist Mitglied im Open Invention Network und SPI und präsentierte sich bereits im ersten Jahr auf Messen wie der Cebit und FOSDEM. Sie nimmt beim Google Summer of Code teil.\n\nDas deutsche Bundesamt für Sicherheit in der Informationstechnik sieht in LibreOffice (und Linux) eine Alternative zu proprietären Cloud-Produkten für Organisationen mit Interesse an Informationssicherheit und sponserte einige kryptographische Funktionen von LibreOffice. Weitere kryptographische Funktionen wurden vom niederländischen Verteidigungsministerium gesponsert.\n\nIn Anlehnung an die jährlich stattfindenden OpenOffice.org-Konferenzen veranstaltet die Document-Foundation seit 2011 jährlich eine „LibreOffice Conference“, im Web jeweils unter codice_1 auffindbar.\n\n\nIn ihrem „Manifest fürs nächste Jahrzehnt“ definiert die Document Foundation die ihrer Arbeit zugrunde liegenden Werte und Ziele. So verpflichtet sie sich dazu, ihren Beitrag zur Überwindung der digitalen Kluft beizutragen, indem sie jedermann den Zugang zu einem kostenlosen Office-Paket ermöglicht. Das bestehende „Monopol der Anbieter von Büro-Software“, gemeint ist das Quasi-Monopol von Microsoft Office, wird abgelehnt, da dieses „de facto eine Steuer auf elektronische freie Meinungsäußerung“ bedeute. Die Vielfalt der Muttersprachen soll gefördert werden, indem sowohl LibreOffice als auch die zugehörigen Dokumentationen in möglichst vielen Sprachen angeboten werden sollen und die Übersetzung in neue Sprachen aktiv gefördert wird. „Die schleichende Dominanz der Computersysteme in einer einzigen Sprache“ soll überwunden werden und niemand gezwungen sein, vor Verwendung eines Computers eine andere Sprache zu erlernen. Die Document Foundation teilt die Ziele des OpenDocument-Projekts und lehnt „die Kontrolle über Dateiformate durch proprietäre Software-Unternehmen“ ab. LibreOffice soll in „einem offenen, transparenten und durch gegenseitige Begutachtung geprägten Softwareentwicklungsprozess, in dem hohe technische Qualität geachtet wird“, entwickelt werden. Das alles soll unter dem Dach einer demokratischen, jedermann offen stehenden Stiftung geschehen, die auch der Beteiligung von Firmen und Organisationen positiv gegenübersteht.\n\nOpenOffice.org wurde, insbesondere in den meisten Linux-Distributionen, sukzessiv durch LibreOffice ersetzt. So setzen Ubuntu ab Version 11.04, Fedora ab Version 15, openSUSE ab Version 11.4 und Linux Mint ab Version 11 auf LibreOffice. Das Debian-Projekt geht noch einen Schritt weiter und ersetzt auch bereits bestehende OpenOffice.org-Installationen in Debian 7.0 automatisch, in Debian 6.0 mit Hilfe eines für den Benutzer verfügbaren Backports, durch LibreOffice. Mit Version 6.3 von Oracle Linux liefert auch Oracle LibreOffice als festen Bestandteil der eigenen Linux-Distribution aus.\n\nDie Document Foundation arbeitet an einer stetigen Verbesserung der Unterstützung von LibreOffice. So wurde im Februar 2012 die Plattform \"Ask LibreOffice\" eröffnet, an die sich Anwender bei Problemen wenden können, um von anderen Benutzern Hilfe zu erhalten. Das zunächst nur in englischer Sprache verfügbare Angebot ist inzwischen auch auf Deutsch verfügbar.\n\nDa LibreOffice eine Abspaltung von OpenOffice.org darstellt, waren die Funktionen und Eigenschaften der Office-Pakete zunächst im Wesentlichen identisch. Zu Beginn des Projekts erschien unwahrscheinlich, dass Neuerungen in OpenOffice.org aufgenommen werden, die im Rahmen des LibreOffice-Projekts entwickelt wurden. Der Grund waren lizenzrechtliche Erwägungen im Zusammenhang mit der zu dieser Zeit von Oracle vertriebenen, kommerziellen Variante von OpenOffice.org, StarOffice. Im Gegenzug standen einer Aufnahme von Neuerungen in LibreOffice, die im Rahmen des OpenOffice.org-Projekts entwickelt wurden, nichts entgegen \"(→ siehe auch: Abschnitt „Rechtliches“).\" Durch die Übergabe des OpenOffice.org-Projekts an die Apache Software Foundation und die Umbenennung des Office-Pakets in Apache OpenOffice wurden diese lizenzrechtlichen Probleme nur teilweise aus dem Weg geräumt. Während eine Codeübernahme von Apache OpenOffice zu LibreOffice weiterhin kein lizenzrechtliches Problem darstellt, ist eine entgegengesetzte Übernahme nur schwer möglich. LibreOffice wurde unter der GNU GPL, einer Lizenz mit Copyleft, veröffentlicht, deren Konzept in der Apache-Lizenz keine Entsprechung findet. Da die GNU GPL aber ein Bestehenbleiben des Copyleft voraussetzt, ist eine Codeübernahme ausgeschlossen. Da LibreOffice unter der Mozilla Public License (MPL) mehrfachlizenziert ist, wäre eine Codeübernahme zumindest in Binärform theoretisch denkbar.\n\nNach Untersuchungen des von SUSE bezahlten LibreOffice-Entwicklers \"Michael Meeks\" sei ein gegenseitiger Codeaustausch aber immer schwieriger und werde durch die fortschreitende Entwicklung immer unwahrscheinlicher. Durch die inzwischen erheblichen Unterschiede im Quelltext beider Projekte sei eine quasi automatische Übernahme von Neuerungen nicht möglich, stattdessen sei es notwendig, jede einzelne Neuerung, die zwischen den Projekten ausgetauscht werden soll, anzupassen. Demnach sei davon auszugehen, dass mit fortschreitender Entwicklung LibreOffice andere Funktionen enthalten wird als OpenOffice.org und lediglich Änderungen, die den Aufwand rechtfertigen, zwischen den Projekten ausgetauscht werden. In geringem Umfang bestanden bereits bei Veröffentlichung der ersten stabilen Version 3.3 Unterschiede zwischen beiden Projekten \"(→ Abschnitt „LibreOffice 3.3“).\" Die OpenOffice.org-Abspaltung Go-oo ist in LibreOffice aufgegangen.\n\nLibreOffice ist, wie auch OpenOffice.org, modular aufgebaut und besteht anwenderseitig aus sechs Einzelprogrammen.\n\nDiese Komponenten können unabhängig voneinander installiert und verwendet werden, dem Konzept des Gesamtpakets folgend. Um unnötigen Mehraufwand zu vermeiden, werden verschiedene Funktionen, wie beispielsweise die Rechtschreibprüfung und der Thesaurus, in mehreren Komponenten verwendet.\n\nDurch diesen modularen Aufbau ist es außerdem möglich, Plug-ins und Vorlagen Dritter zu installieren und zu verwenden. Die Möglichkeiten sind dabei kaum begrenzt und reichen von simplen Dokumentvorlagen über zusätzliche Cliparts bis hin zu komplexen Erweiterungen des Funktionsumfangs. Da die Installation von Zusätzen aus nicht vertrauenswürdigen Quellen ein Sicherheits- und Stabilitätsrisiko darstellt, eröffnete die Document Foundation im September 2011 zwei zunächst als Beta-Version gekennzeichnete Plattformen, die dieses Risiko minimieren und den Benutzer bei der Suche unterstützen sollen. Entwickler können dort Zusätze als freie Software hochladen, welche nach einer Prüfung durch ein Team aus Freiwilligen in die Datenbank aufgenommen und veröffentlicht werden. Die Datenbank soll auch Erweiterungen mit einschließen, die mit OpenOffice.org kompatibel sind. Ende Oktober 2011 wurde die Plattform als final gekennzeichnet und überschritt einen Monat später die Marke von 100 aufgelisteten Erweiterungen. Erweiterungen in LibreOffice und OpenOffice teilen sich die Dateinamenserweiterung \".oxt.\"\n\nLibreOffice wird zurzeit in 115 Sprachen angeboten, darunter auch Deutsch. Das Standard-Dateiformat ist OpenDocument.\n\nLibreOffice unterstützt von sich aus, also ohne Installation eines externen PDF-Druckertreibers, auch im aktuellen Versionszweig 6.x nur PDF Version 1.4 mit einer Verschlüsselung im RC4-Verfahren, das mit Stromchiffre und Schlüssellängen bis 128 Bit als unsicher gilt (vgl. RC4#Sicherheit).\n\nLibreOffice steht für die Betriebssysteme \"Windows\" (ab \"XP\"), \"Linux\" (ab Kernel 2.6.18) und \"macOS\" (ab Version 10.4) zur Verfügung. Microsoft Windows 2000 wird ab der Version 4.0, XP und Vista ab der Version 6.0 von LibreOffice nicht mehr unterstützt. Zum Betrieb von LibreOffice 3.x unter Microsoft Windows 2000 wird der Windows Installer in Version 3.1 oder höher benötigt. Die Linux-Version benötigt mehrere Pakete und Bibliotheken Dritter, die bei der Mehrzahl der Distributionen ab Erscheinungsdatum Anfang 2007 enthalten sind. Anfang 2015 wurde ein LibreOffice-Viewer für Android veröffentlicht, um Open-Document-Textdokumente, Präsentationen und bedingt Tabellenkalkulationen ansehen zu können. Um diese auch verändern zu können muss dies in den Einstellungen aktiviert werden, da sich die Funktion noch in der Experimentalphase befindet.\n\nDie Systemvoraussetzungen für Windows und Linux sind ein Intel-Pentium-kompatibler Prozessor (ab Intel Pentium III), 256 MB RAM und 1,5 GB Festplattenspeicher. Die Versionen für Mac benötigen mindestens einen PowerPC- oder Intel-Pentium-Prozessor, 512 MB RAM und 800 MB Festplattenspeicher. Die Bildschirmauflösung sollte mindestens 1024×768 Bildpunkte betragen.\n\nDa der Quelltext des Pakets verfügbar ist, ist eine Installation auch auf anderen Plattformen wie Solaris, FreeBSD und anderen Unix-Varianten möglich. Hierbei sind die Systemvoraussetzungen der Linux-Variante zu erfüllen. Auch Portierungen auf weitere, nicht genannte Plattformen sind möglich.\n\nLibreOffice Online ist die Ausführung von LibreOffice als Online-Office. Es handelt sich dabei um eine Webapp, welche auf einem Server installiert wird und die Benutzer mit einem Webbrowser nutzen können. Sie bietet eine grundlegende gemeinsame Bearbeitung von Dokumenten unter Verwendung des „Kerns“ von LibreOffice. Der Quellcode von LibreOffice Online wurde im Februar 2017 mit der Version 5.3 von LibreOffice veröffentlicht. 2016 entstand aus LibreOffice Online Collabora Online, welches für die Cloud-Integration optimiert ist.\n\nUnter Windows legt die Installation von LibreOffice wie auch bei anderen Programmen üblich auf der Partition C: programm- und nutzerspezifische Daten ab, was den Einsatz auf mehreren Rechnern mit Wechseldatenträgern (beispielsweise USB-Sticks oder Speicherkarten) oder auf mehreren Windows-Installationen im selben Rechner erschwert. Mit Hilfe einer portablen Ausgabe, die erstmals 2011 verfügbar wurde, ist es möglich, das Office-Paket auch ohne Installation zu verwenden. Nach dem Entpacken in die Ziel-Partition kann das portable LibreOffice mit vollem Funktionsumfang und mit den vom Nutzer gewählten Einstellungen verwendet werden; nahezu keine Daten werden dann in die Partition C: geschrieben. Die offizielle portable Ausgabe wurde inzwischen auch in das Projekt PortableApps aufgenommen.\n\nIm Herbst 2010 wurde erstmals die \"LibreOffice-Box\" veröffentlicht. Das von der Document Foundation offiziell unterstützte Projekt stammte vom Verein \"Freies Office Deutschland e. V.\" (vormals \"OpenOffice.org Deutschland e. V.\"), der zuvor die vergleichbare \"OpenOffice.org PrOOo-Box\" anbot. Die LibreOffice-Box ist eine DVD, die – neben der Java-Laufzeitumgebung und jeweils aktuellen Version von LibreOffice für Windows, macOS und Linux – verschiedene weitere Features rund um das Projekt beinhaltet, beispielsweise Dokumentvorlagen, Cliparts und verschiedene Plug-ins wie Anaphraseus und ein Wörterbuch. Zusätzlich sind verschiedene Programme beigelegt, die im Büroalltag häufig benötigt werden, wie beispielsweise 7-Zip, Inkscape, Mozilla Firefox und Ghostscript. Für LibreOffice-Entwickler enthält die DVD neben dem Quelltext des Programms auch das Software Development Kit und verschiedene weitere Programme für Entwickler. Ende 2013 wurde das Projekt „mangels […] Mitarbeiter und fehlender Perspektive“ vorerst eingestellt.\n\nMit der Version 4.0 wurde die LibreOffice Impress Remote eingeführt, mit der Präsentationen per Bluetooth oder WLAN ferngesteuert werden können. Diese Fernsteuerung muss nur in LibreOffice selbst aktiviert werden. Die LibreOffice Impress Fernsteuerung existiert als App für Android, Apple iOS und Pebbles.\n\nBereits zum Start der Document Foundation am 28. September 2010 erschien die erste Beta-Version 3.2.99.1. Während zu diesem Zeitpunkt lediglich 20 Personen an der Entwicklung des Office-Pakets arbeiteten, ist diese Zahl bei der Veröffentlichung der stabilen Version 3.3 bereits auf über 100 gestiegen. Zwei Monate später stieg die Zahl der Entwickler auf 150. Ein Jahr nach Gründung, im September 2011, zählte das Projekt 270 Entwickler und nochmal so viele Übersetzer. Im Jahr 2011 wuchs die Entwickleranzahl nahezu linear und stieg zum Januar 2012 auf 390 Entwickler. Die Mehrzahl dieser ist ehrenamtlich für das Projekt tätig, einige der im Projekt engagierten Unternehmen richten aber auch Mitarbeiterteams ein, die die LibreOffice-Entwicklung vorantreiben sollen.\n\nZum ersten Geburtstag des Projekts im September 2011 wurde die Codebasis von LibreOffice analysiert. So waren zu diesem Zeitpunkt nur noch 20 Prozent des Codes direkt auf OpenOffice.org zurückzuführen, 25 Prozent entfielen auf ehrenamtliche Entwickler und die verbleibenden 55 Prozent wurden von verschiedenen Unternehmen beigesteuert. Dabei wurden 25 Prozent der Codebasis von SUSE-Mitarbeitern und weitere 20 Prozent von Red Hat entwickelt.\n\nIn den 18 Monaten seit der Abspaltung von OpenOffice.org haben ungefähr 80 Entwickler pro Monat an über 30.000 Codebeiträgen gearbeitet.\nEin Vergleich von LibreOffice und OpenOffice im März 2014 ergab, dass LibreOffice sowohl bei der Häufigkeit der Updates als auch bei Zahl der Entwickler und eingereichten Changesets weit vor OpenOffice liegt.\n\nDas Projekt hält den im Umfeld der freien Software üblichen sechsmonatigen Veröffentlichungszyklus im März und September seit Beginn ein. Da insbesondere von Linux-Distributoren Vorlaufzeiten erwünscht sind, sieht die Planung Veröffentlichungen jeweils einen Monat früher, im Februar und August eines jeden Jahres vor. Stabilitätsaktualisierungen, welche in der Regel ausschließlich Fehlerkorrekturen enthalten, sollen, sofern notwendig, in ungefähr monatlichen Abständen erscheinen. Da ein Entwicklungszweig ein Jahr lang mit derartigen Aktualisierungen versorgt werden soll, werden folglich vom Projekt der jeweils aktuelle und der vorausgehende Entwicklungszweig unterstützt.\n\nDas Qualitätsmanagement der Document Foundation hat erheblich Einfluss darauf, wem welche Veröffentlichung empfohlen wird.\nDie Versionen werden in die Kategorien „Developer“, „Bleeding Edge“, „Stable“, „Very Stable“ und „Rock Solid“ eingeteilt. Selbstkompilierte Versionen, Nightly Builds, Vorschauversionen und Freigabekandidaten fallen grundsätzlich in die Kategorie „Developer“ und sollten ausschließlich von dieser Benutzergruppe (Softwareentwickler) verwendet werden.\n\nDie jeweils erste Version eines neuen Entwicklungszweigs, beispielsweise 3.4.0, wird als „Bleeding Edge“ nur Early Adoptern empfohlen. Für die Verwendung im weniger professionellen Umfeld, beispielsweise für Privatanwender, ist ein Entwicklungszweig ab dem ersten Stabilitätsupdate, beispielsweise 3.4.1, geeignet; dieser wird in die Kategorie „Stable“ eingeteilt. Die Kategorie „Very Stable“, welche mit dem zweiten Stabilitätsupdate vergeben wird, richtet sich an konservative Anwender, beispielsweise kleine und mittlere Unternehmen. Als „Rock Solid“ werden Versionen betrachtet, die für Anwender geeignet sind, die eine hohe Stabilität benötigen – etwa Großunternehmen. Diesen Status erreicht das dritte Stabilitätsupdate. Nach den Planungen der Document Foundation wird danach ein neuer Entwicklungszweig veröffentlicht, in dem der Zyklus von neuem beginnt. In Ausnahmefällen erscheinen auch Versionen x.x.4 und höher.\n\nAnwendern, für die im neuen Entwicklungszweig noch keine Versionen erschien, wird die jeweils letzte Version des vorherigen Entwicklungszweigs, die als „Rock Solid“ gilt, empfohlen. Für Unternehmen, die professionelle Hilfe bei einer Migration erwägen, möchte die Document Foundation künftig eine Liste zertifizierter Organisationen veröffentlichen.\n\nLibreOffice knüpft bei der Vergabe seiner Versionsnummern direkt an OpenOffice.org an. Die erste stabile Veröffentlichung lautete daher 3.3.0 und wird vom Projekt als Nachfolger von OpenOffice.org 3.2.1 betrachtet.\n\nNeben den Entwicklerversionen gibt es seit März 2014 und Version 4.2.2 zu jedem Zeitpunkt zwei wichtige veröffentlichte Versionen von LibreOffice: „Fresh“, die neueste Version, und „Still“, die stabile Version. Die Namen dieser zwei Versionen weisen darauf hin, dass sie jeweils für unterschiedliche Einsatzszenarien geeignet sind. Die zwei Versionen von LibreOffice werden wie folgt charakterisiert:\n\n\nLibreOffice 3.3 basiert auf OpenOffice.org 3.3, dessen Codebasis gesichtet und überarbeitet wurde. Die Import-, Öffnen- und Speicherfunktionen wurden verbessert, so ist in allen Programmen des Office-Pakets das Öffnen und Speichern von Dokumenten als einzelnes XML-Dokument möglich. Der Druckdialog wurde überarbeitet und soll dem Benutzer einen übersichtlicheren und schnelleren Zugriff auf die wesentlichen Funktionen bieten. Auf Linux-Systemen ist das Java Media Framework zum Abspielen von Musik und Filmen nicht mehr erforderlich.\n\nDer Import von PDF-Dokumenten ist nun möglich. Diese werden in Draw geöffnet und können dort bearbeitet und wieder gespeichert werden. Eine Integration in Dokumente ist als OLE-Objekt in jedem Programm des Office-Pakets möglich. Zur Standardinstallation wurden verschiedene Plug-ins hinzugefügt, die den Funktionsumfang von LibreOffice erweitern. Die grafische Benutzeroberfläche hat Detailverbesserungen erhalten und ist in 19 zusätzlichen Sprachen verfügbar.\n\nMit Veröffentlichung der Version 3.3.1 erhielt das Office-Paket außerdem neue Dokumenten-Icons.\n\nWriter hat eine überarbeitete Funktion zur Autokorrektur erhalten, und Titelseiten lassen sich mit Hilfe eines neuen Dialogs leichter verwalten. Der \"Navigator,\" mit dessen Hilfe die Struktur größerer Dokumente schneller und leichter nachvollzogen werden kann, wurde überarbeitet. Die Such- und die Statistikfunktionen wurden im Detail verbessert. In Microsoft-Word-Dokumenten lassen sich Formulare einfügen und in Lotus Word Pro und Microsoft Works erstellte Dokumente können importiert werden. Der Import von in WordPerfect erstellten Dokumenten wurde wie auch der Export ins Rich Text Format deutlich verbessert.\n\nIn Calc wurde die Möglichkeit überarbeitet, Tastenkürzel zu verwenden. So ist beispielsweise die Navigation in Formeln mittels Tastenkombinationen möglich. Das Öffnen von Tabellendokumenten wurde generell beschleunigt. Das Anlegen neuer Tabellenblätter wurde vereinfacht, die zugehörigen Registerkarten lassen sich einfärben. Die Zahl der in einem Tabellenblatt nutzbaren Zeilen wurde von 65.536 auf 1.048.576 erhöht. In Diagrammen können mehrere, hierarchisch strukturierte Achsenbezeichnungen dargestellt werden. Draw kann Grafiken im SVG-Format bearbeiten; der Import in die übrigen Programme des Office-Pakets ist ebenfalls möglich. Das Öffnen von Microsoft-PowerPoint-Dokumenten in Impress wurde beschleunigt und die Handhabung von Folien-Layouts verbessert.\n\nZusätzlich sind alle Neuerungen von OpenOffice.org 3.3 auch in LibreOffice 3.3 enthalten. Das gilt auch für die im Rahmen von Go-oo entwickelten Verbesserungen.\n\nDie folgenden Versionen von LibreOffice zielten nicht auf große Änderungen, sondern kleine inkrementelle Verbesserungen hinsichtlich Schnelligkeit, geringeren Verbrauchs von Systemressourcen, Stabilität, Fehlerfreiheit, Kompatibilität und neuer Funktionalität. Ein weiteres wichtiges Ziel war die Aufarbeitung des Quelltextes, um diesen für neue Programmierer einfacher verständlich und bearbeitbar zu machen. Im Zuge dieser Aufarbeitung wurde viel unbenutzter Quelltext entfernt und die Implementierung automatisierter Tests vorangetrieben. Darüber hinaus wurden Abhängigkeiten von anderen Programmen, insbesondere Java, reduziert.\n\nBei der Entwicklung von LibreOffice 3.4 wurde das Hauptaugenmerk auf Stabilität gelegt. So finden sich zwar auch zahlreiche Neuerungen in dieser neuen Hauptversion („major release“), die Großzahl der Änderungen entfällt aber auf Verbesserungen der Stabilität und Geschwindigkeit. So arbeitet LibreOffice unter Linux schneller und verbessert die Textdarstellung, wurde entschlackt und nimmt auf allen Plattformen weniger Arbeitsspeicher in Anspruch. Die Graphite-Engine wurde neu geschrieben, wodurch sie neben einer höheren Stabilität auch zehnmal schneller arbeiten soll. Die Unterstützung spezieller internationaler Schriftarten, unter anderem Rechts-nach-Links-Schriftarten wurde verbessert. Neben der altbekannten Suchfunktion wurde eine Suchleiste, wie auch aus modernen Webbrowsern bekannt, hinzugefügt. Die Kompatibilität zu OpenDocument und zu den OOXML-Formaten wurde verbessert.\nLibreOffice 3.5 konzentriert sich, wie bereits LibreOffice 3.4, primär auf Fehlerkorrekturen und die weitere Überarbeitung des Quellcodes. In LibreOffice 3.5 neu hinzugekommen ist unter anderem eine Online-Update-Funktion, die unter Windows und Mac Aktualisierungen der Software automatisch einspielt und die Windows-Installationsdatei liegt als MSI-Paket vor. Für die Verschlüsselung wird AES statt Blowfish verwendet. Die Bedienoberfläche wurde insbesondere bei der Behandlung von Kopf- und Fußzeilen und Seitenumbrüchen sowie der Bearbeitung von Grafiken überarbeitet und vereinfacht. Die Unterstützung für die OpenFormula-Spezifikation wurde verbessert, ein nativer Treiber für PostgreSQL-Datenbanken hinzugefügt, der Import von Microsoft-Visio-Grafiken in Draw wurde erstmals ermöglicht und der Import von RTF-Textdokumenten wurde verbessert.\n\nWie bereits bei den Vorgängerversionen konzentrierte sich das LibreOffice-Projekt auch bei der vierten Hauptversion 3.6 eher auf zahlreiche Detailverbesserungen und Fehlerkorrekturen anstelle von einzelnen, umfangreichen Neuerungen. Neben zusätzlichen Optionen für Formatierungen in Writer und Calc können Dokumenten beim PDF-Export Wasserzeichen hinzugefügt werden. Die Oberfläche der Office-Suite wurde bereinigt und erhielt einige Detailverbesserungen, so werden Statistiken wie die Wortzahl des geöffneten Writer-Dokuments in der Statuszeile angezeigt, und das Design von Startbildschirm, „Start Center“ und Info-Bildschirm wurde vereinheitlicht. Verschiedene Dialoge wurden überarbeitet und bestehende Beschränkungen entfernt, insbesondere wurde das Kontextmenü an einigen Stellen erweitert, wodurch Funktionen schneller erreicht werden können. Der Import von „Smart Arts“ aus Microsoft-Office-Dokumenten und von Grafiken aus CorelDraw wurde erweitert, die Unterstützung von OpenFormula wurde weiter verbessert und unter Linux wurde die Unterstützung für GTK-Themes und Trinity verbessert.\n\nLibreOffice 4.0 bringt wie die vorigen Versionen eine Reihe kleiner Neuerungen und einige Verbesserungen in der Kompatibilität mit verschiedenen Formaten, insbesondere dem DOCX-Format. Einige dieser Verbesserungen wurden aus der Lotus-Suite importiert, deren Quelltext IBM an Apache OpenOffice gespendet hat. Die bedeutendsten Änderungen, die zur Begründung des Versionssprungs angeführt werden, sind allerdings nicht für Nutzer offensichtlich. So wurde die Relizenzierung des Quelltextes abgeschlossen, der nun vollständig unter der GPL 3 und folgenden Versionen, der LGPL 3 und folgenden Versionen sowie der MPL lizenziert ist. Außerdem wurde die offizielle Unterstützung für einige sehr alte Formate eingestellt und die veraltete Funktionalität der Uno-Programmierschnittstelle entfernt. Damit besteht erstmals ein Unterschied zwischen den Programmierschnittstellen von LibreOffice und Apache OpenOffice, so dass Erweiterungen für eines der Programme in Zukunft nicht mehr automatisch mit dem jeweils anderen Programm kompatibel sind. Die Abhängigkeit von Java wurde weiter reduziert, aber nicht vollständig beseitigt.\n\nAb Version 4.4 bringt LibreOffice die freien Schriftarten \"Carlito\" und \"Caladea\" mit, die metrikkompatibel zu den proprietären Schriftarten Calibri und Cambria sind und diese ersetzen können, wenn sie nicht installiert sind. Microsoft Office verwendet seit 2007 die Schriftart Calibri als Standardschriftart, die freien Schriftarten verbessern daher die wahrgenommene Kompatibilität mit Microsoft-Office-Dokumenten erheblich.\n\nDie Hauptversion 4.5 wurde im April 2015 in „Version 5.0“ umbenannt., weil LibreOffice 5 unter Android Texte nicht nur anschauen (wie seit Mai 2015 möglich), sondern auch bearbeiten kann. Die Version 5.0.0 erschien am 5. August 2015. Die Version 5.0.4 erschien am 17. Dezember 2015 und leitete ab 2016 den massenhaften Umstieg von LibreOffice 4 auf LibreOffice 5 ein.\n\nDie für die erste Hälfte des Jahres 2018 geplante Hauptversion 5.5 wurde im Juni 2017 in „Version 6.0“ umbenannt. Gründe dafür waren wohl Veränderungen in der Markenpolitik und der Benutzeroberfläche (schließlich erschienen mehrere neue Versionen des Menübandes „LibreOffice Ribbon UI“). Die erste Version 6.0.0 wurde am 31. Januar 2018 veröffentlicht. Die Distribution Ubuntu machte in ihrer im April 2018 erschienenen Version mit langfristiger Unterstützung (18.04 LTS) den Sprung zu LibreOffice 6, was den Umstieg auf LibreOffice 6 ab April 2018 beschleunigte. Windows XP und Vista werden ab der LibreOffice-Version 6.0.0 nicht mehr unterstützt.m\n\nLibreOffice ist, wie auch OpenOffice.org, freie Software. Vor der Übertragung des OpenOffice.org-Projekts an die Apache Software Foundation wurde OpenOffice.org unter der GNU Lesser General Public License (LGPL) in Version 3 veröffentlicht. Die dem Benutzer häufig eingeräumte Möglichkeit, eine neuere Version der Lizenz zu nutzen, bestand nicht. Das galt folglich zunächst auch für LibreOffice. Durch die Übertragung von OpenOffice.org an die Apache Software Foundation ist der Programmcode auch unter der hauseigenen Lizenz, der Apache-Lizenz, erhältlich. Diese erlaubt sowohl eine nahezu bedingungslose Weiternutzung als auch eine Wiederveröffentlichung unter vollkommen anderen Bedingungen. Da die Document Foundation freie Softwarelizenzen mit Copyleft bevorzugt und die Apache-Lizenz ein derartiges Lizenzmodell ermöglicht, ist LibreOffice unter der LGPL in Version 3 oder neuer und der Mozilla Public License (MPL) in Version 1.1 oder neuer mehrfachlizenziert.\n\nSowohl bei LibreOffice als auch bei OpenOffice.org werden dem Anwender die aus dieser Lizenzierung entstehenden Freiheiten uneingeschränkt zugestanden. Vor der Übertragung des OpenOffice.org-Projekts an die Apache Software Foundation wurden beteiligte Entwickler, anders als bei LibreOffice, mit Bestimmungen konfrontiert, die ihre Rechte einschränken. Oracle verfolgte, wie auch schon Sun Microsystems seit Bestehen des Projekts, bei der Entwicklung von OpenOffice.org das Ziel, die urheberrechtlichen Verwertungsrechte zu erhalten. Um das zu realisieren, musste jeder Entwickler, der eine Verbesserung einbringen wollte, das \"Sun Microsystems Inc. Contributor Agreement\" unterschreiben. Die Wirkung dieser Vereinbarung war unter anderem, dass Oracle das Recht zugesprochen wurde, die Lizenz, unter der die eingebrachten Verbesserungen veröffentlicht werden, zu wählen. Erst dadurch war es Oracle möglich, in OpenOffice.org eingebrachte Änderung zurück in ihr kostenpflichtiges, proprietäres Office-Paket StarOffice fließen zu lassen.\n\nDie Vereinbarung ging jedoch noch weiter und sprach alle urheberrechtlichen Rechte des Entwicklers auch Oracle zu – es entstand eine „gemeinsame Urheberschaft“. Die Vereinbarung wurde insbesondere auch deshalb kritisiert, da diese gemeinsame Urheberschaft erlosch, sobald eine Änderung an der eingebrachten Verbesserung vorgenommen wurde. Konkret bedeutete dies, dass eine gemeinsame Urheberschaft nur so lange bestand, wie die eingebrachte Verbesserung unverändert blieb – wurde sie verändert, verlor der ursprüngliche Entwickler seine Rechte. Die Vereinbarung war in diesem Fall mit einer Übertragung jeglicher Urheberrechte gleichbedeutend. Oracle wurde mit dieser Vereinbarung auch das Recht zugesprochen, gewerbliche Schutzrechte (Patente, Gebrauchsmuster, Geschmacksmuster, Marken usw.) anzumelden und in Anspruch zu nehmen sowie das dafür notwendige Eigentum geltend zu machen.\n\nAnders als bei OpenOffice.org brauchten Entwickler, die ihre Verbesserungen LibreOffice zur Verfügung stellen möchten, nie derartige Vereinbarungen zu unterzeichnen. Sie blieben dadurch alleinige Inhaber des Urheberrechts. Seit der Übertragung des OpenOffice.org-Projekts an die Apache Software Foundation gilt das entsprechend auch bei OpenOffice.org. Dennoch seien laut der Document Foundation gerade diese rechtlichen Aspekte ausschlaggebend dafür gewesen, dass sich schnell nach Gründung des Projekts weit mehr Entwickler LibreOffice zuwandten, als es jemals zuvor bei OpenOffice.org der Fall gewesen sei.\n\n\n"}
{"id": "5700889", "url": "https://de.wikipedia.org/wiki?curid=5700889", "title": "Die Legende der Wächter", "text": "Die Legende der Wächter\n\nDie Legende der Wächter ist ein 3D-Animationsfilm von Regisseur Zack Snyder aus dem Jahr 2010. In den deutschen Kinos startete der Film am 14. Oktober 2010. Die Handlung basiert auf den ersten sechs Bänden des 16-teiligen Zyklus Die Legende der Wächter (Guardians of Ga’Hoole) von Kathryn Lasky.\n\nIm Eulen-Königreich Tyto (lat.: \"Gattung der Schleiereulen\") lebt eine Familie von Schleiereulen. Vater Noctus erzählt den ältesten Brüdern Kludd und Soren gerne alte Geschichten vom Kampf der „Wächtereulen von Ga’Hoole“, geführt von Lyze von Kjell, gegen die Mächte des Bösen. Soren glaubt an die Wächter, während Kludd die Geschichten als Legenden abtut. Eines Nachts beim Ästeln fällt Soren aus dem Nest der Eltern. Hilflos auf dem Boden sitzend, wird er von anderen Eulen gepackt und entführt, und in das Sankt-Ägolius-Internat gebracht.\n\nDort lernt Soren die Elfenkäuzin Gylfie kennen, mit welcher er im Sankt Ägolius „herumschnüffelt“ und Infos sammelt. Soren und Gylfie finden heraus, dass man sie mondwirr machen will, ein Zustand in dem man alles vergisst, gefügig und willenlos wird. Zusammen mit Grimbel, einem abtrünnigen Aufseher im Sankt Ägolius, lernen sie fliegen und den beiden gelingt die Flucht, während Grimbel von Nyra getötet wird.\n\nSoren, Gylfie, der Bartkauz Morgengrau und der Höhlenkauz Digger, die sie auf dem Weg ihrer Flucht kennengelernt hatten, glauben alle an die Wächter des Ga’Hoole Baumes und machen sich gemeinsam auf den Weg zur Insel im Hoolemeer.\n\nIn einem Sturm über dem Meer werden die Eulen von den Wächtern von Ga’Hoole gefunden und zum Großen Baum gebracht, wo sie von dem Königspaar, den Schneeeulen Boron und Barran, über das Sankt-Ägolius-Internat befragt werden.\n\nAuf der Insel von Ga’Hoole weiht Ezylryb die Jungeulen in seine Flugkünste ein, die darin bestehen, sich auf das Bauchgefühl (den Muskelmagen) zu verlassen. Soren entdeckt, dass der alte Flecken-Kreischeulerich in Wirklichkeit der berühmte Lyze von Kjell ist. Er hat eine Chronik über den Krieg der Eiskrallen gegen König Eisenschnabel verfasst, die den Krieg nicht verherrlicht. Soren ist desillusioniert. Allomere, ein weiterer Wächter, kehrt von einer Erkundungsmission mit einer dezimierten Brigade und zwei geretteten Jungeulen aus den Schnabelbergen zurück, eine davon ist die mondwirre Eglantine, Sorens und Kludds kleine Schwester.\n\nDer König schickt eine Armee aus, um die Reinen zu bekämpfen. Soren und die anderen Jungeulen bleiben zurück. Soren kümmert sich um Eglantine. Als diese von der Mondwirrheit geheilt ist, berichtet sie, dass Kludd sie freiwillig an Lord Allomere übergeben habe – und dass sowohl Kludd als auch Allomere Verräter seien. Die Jungeulen brechen auf, um die Hauptarmee zu warnen.\n\nSie kommen zu spät, die Reinen und die mit ihnen verbündeten Fledermäuse haben die Wächter bereits in einen Hinterhalt gelockt: Die metallenen Flecken, genannt Tupfen, die von den Sklaven gesammelt wurden, bilden ein elektromagnetisches Netz, das schädlich für den Eulen-Metabolismus ist. Nur die Fledermäuse können sich dort frei bewegen.\n\nAls Soren und die Jungeulen ankommen, wird Lord Allomere von Eisenschnabel und Nyra bestraft, weil er nicht alle Wächter ausgeliefert habe. Sein Abkommen mit Eisenschnabel, zum König von Ga’Hoole gemacht zu werden, widerruft Eisenschnabel – es könne nur ein Eulenkönigreich in der Welt geben, das der Reinen.\n\nSoren macht das elektrische Feld mit Feuer unschädlich, und dies führt zum unverhofften Sieg der Wächter von Ga’Hoole. Ezylryb bekämpft Eisenschnabel, Soren versucht eine Verständigung mit Kludd, der ihn jedoch fanatisch in den Tod zu reißen versucht. Schließlich tötet Soren Eisenschnabel, als dieser ihm den Gnadenstoß erteilen will. Nyra und einigen der Reinsten gelingt die Flucht, doch die Schlacht endet siegreich für die Wächter, und Ezylryb kündigt an, seiner Chronik ein neues Kapitel hinzuzufügen. Die Schlussszene zeigt den zum Wächter ernannten Soren mit seiner auf Ga’Hoole wiedervereinigten Familie – mit Ausnahme von Bruder Kludd, der „verschollen“ ist. Man sieht noch Kludd, wie er auf die Maske von Eisenschnabel mit roten Augen schaut.\n\nMarco Rauch schreibt in seiner Kritik vom 12. Oktober 2010: \"„Die Geschichte bietet keinerlei Überraschungen und dürfte selbst bei Kindern, die bereits den einen oder anderen Film gesehen haben, kaum für Erstaunen sorgen.“\" und \"„Alles wovon sie leben ist, dass sie süß animiert sind. Dabei haben zahlreiche andere Animationsfilme bewiesen, dass man auch dem jüngeren Publikum durchaus dreidimensionale und originelle Figuren zumuten kann.“\"\n\nFilmszene.de urteilt: \"„Die Legende der Wächter“ bewegt sich stimmungsmäßig in derart dunklen Gefilden, dass der Gute-Laune-Song zum Film beinahe wie ein atmosphärischer Fremdkörper wirkt, als er zur Mitte des Films eine Montagesequenz untermalt. […] So erweist sich „Die Legende der Wächter“ als ein sehr zwiespältiger Film, der zwar einerseits eines der bombastischsten visuellen Erlebnisse dieses Kinojahres anbietet, andererseits jedoch eine mehr als dürftig ausgeführte Erzählung präsentiert, die für ihr junges Publikum zu hart und für ein älteres Publikum wiederum viel zu plump und gehetzt ist. So kann man diesen Film letztlich leider nur als gescheitert betrachten – wenn auch in spektakulären 3D-Bildern gescheitert.\"\n\nDie Los Angeles Times schreibt über den Film: \"„Die Legende der Wächter ist im Grunde genommen eine Kinderversion von Braveheart mit Eulen – eine düstere und dichte Fabel voller edler Krieger, gewaltiger Kämpfe und fliegender Federn. […] Die Animation ist unglaublich schön, genauso wie die alte Eulenwelt, die sie kreiert. Die Kämpfe sind aufwändig und, in wahrer Snyder-Tradition – äußerst Action-betont. Die Flugsequenzen sind atemberaubend, allerdings dauern sie, wie so oft bei Flügen, zu lange.“\"\nDer Film erhielt folgende Award oder wurden Nominiert:\nDer Titelsong zu diesem Film wurde von Adam Young, besser bekannt als „Owl City“, beigesteuert und heißt „To the Sky“.\nEbenso wurde ein Song – „Kings and Queens“ von „30 Seconds to Mars“ – für den ersten Trailer verwendet.\n\nFür die deutsche Vertonung war die FFS Film- & Fernseh-Synchron in München verantwortlich. Alexander Löwe schrieb das Dialogbuch, Dietmar Wunder führte die Dialogregie.\nDer Film umfasst die ersten sechs Bücher. Da nicht alle Abschnitte eines Buches in den Film schaffen, gibt es auch einige Änderungen, um die Handlung dem Zuschauer verständlich zu machen. Jedoch gibt es Abweichungen zu den Büchern bei diesem Film, die über diese Art der Änderungen hinausgehen.\n\nZu Anfang des Films sind Soren und sein Bruder Kludd in etwa im selben „Alter“ und ästeln (Flugübungen, bei denen die Jungeulen von Ast zu Ast springen) gemeinsam. Im Buch jedoch hat Soren noch sein Flaumfederkleid und kann daher nicht ästeln. Das führt unweigerlich zur zweiten Abweichung, denn dadurch, dass Soren nicht ästelt, fällt er auch nicht wie im Film durch einen Unfall mit seinem Bruder vom Baum, sondern wird durch seinen Bruder vom Baum gestoßen. Außerdem werden Soren und Kludd im Buch nicht gemeinsam nach Sankt Ägolius entführt. Auch das Tier, das die beiden Jungeulen im Film angreift, gibt es in den Büchern nicht.\n\nDie zum Anfang des Films von Vater Noctus erzählte Geschichte über eine Schlacht, die von den Wächtern geschlagen wurde, ist auch eine Abweichung. Zwar wird die Schlacht in den Büchern erwähnt und Ezylryb war als Lyze von Kjell der Anführer seiner Armee, aber die Wächter waren nie in den „Krieg der Eiskrallen“ involviert. Soren erfährt erst später von der Schlacht, als er ein von Lyze von Kjell (Ezylryb) verfasstes Buch liest.\n\nIm Film sind die Reinsten und Sankt Ägolius anscheinend dasselbe. Im Buch 6 wird Sankt Ägolius von den Reinsten überfallen und Eingenommen und sind dann eine Organisation. Des Weiteren ist im Buch nicht Nyra die Ablah-Generalin von Sankt Ägolius, sondern Skench, die im Film überhaupt nicht auftaucht. Auch der im Buch genannte Schlafmarsch bei Vollmond ist im Film falsch dargestellt. Damit die Eulen vom Mondlicht hypnotisiert werden, müssen sie laut den Büchern nicht schlafen, sondern dem Mondlicht ausgesetzt sein. Jedoch stimmt es, dass Kludd ein begeisterter Anhänger der Reinsten wurde bzw. war. Dass die Reinsten und die Wächter Eisenmasken tragen, ist ebenfalls eine Abweichung. In den Büchern ist Eisenschnabel (Kludd) der einzige, der so eine Maske trägt.\n\nMehrere Charaktere werden darüber hinaus auch mehr oder weniger anders dargestellt:\n\nDer Bartkauz Morgengrau wird im Film als ältere Eule mit Laute und einer Liebe zur Musik dargestellt. Im Buch jedoch ist er ein junges Waisenkind ohne Laute, aber mit einer Neigung zu Kriegsgesängen. Außerdem kennt er, anders als im Film, den Höhlenkauz Digger noch nicht, als er Soren kennenlernt.\n\nSoren hat im Film eine offensichtliche Schwäche für die Fleckenkäuzin Ottulissa, obwohl er sie im Buch eher nervig findet.\nDort ist es in einem Kapitel sogar so, dass Ottulissa ihm schöne Augen macht, nicht umgekehrt.\n\nDer Höhlenkauz Digger wird im Film als komische, leicht vertrottelte Eule dargestellt, die gerne einen Witz erzählt. Im Buch ist er jedoch eine sehr nachdenkliche Eule.\n\nMrs. Plithiver wird im Film anscheinend als Schlange dargestellt, die sehen kann. Im Buch wird jedoch erklärt, dass nur blinde Schlangen als Haushälterin genommen werden.\n\nDie Vettern Jutt und Jatt werden im Film als gut befreundete Kumpels dargestellt, obwohl sie im Buch des Öfteren zanken und in Rivalität zueinander stehen.\n\nEisenschnabel ist im Bezug auf Film und Buch etwas schwierig. Der eigentliche Eisenschnabel war bereits von Kludd ermordet worden, als Soren gegen ihn (Eisenschnabel) gekämpft hatte; jedoch wird im Buch nicht genau erwähnt, wann Kludd dies getan hatte, um selbst zu Eisenschnabel zu werden.\n\nDie FSK verweigerte für den Film eine Ab-6-Freigabe. Der Film wäre in seiner normalen Form ab 12 Jahren freigegeben worden. Warner Bros. schnitt daraufhin drei der insgesamt 96 Minuten Laufzeit heraus. Daraufhin erteilte die FSK eine Ab-6-Freigabe. Für die Heimkinoauswertung veröffentlichte man auf DVD nur die geschnittene Kinofassung, während die Blu-ray die ungeschnittene FSK-12-Version beinhaltet.\n\n"}
{"id": "5702470", "url": "https://de.wikipedia.org/wiki?curid=5702470", "title": "Barbie und Die Drei Musketiere", "text": "Barbie und Die Drei Musketiere\n\nBarbie und die drei Musketiere (Original: \"Barbie and the Three Musketeers\") ist ein computeranimierter Film von William Lau, der im Jahr 2009 erschien. Die Direct-to-Video-Produktion der sechzehnte von bisher vierunddreißig Barbiefilmen.\n\nIhr ganzes Leben träumt Corinne (Barbie), die Tochter des berühmten Musketiers D’Artagnan, davon, ebenfalls zu den berühmten Musketieren zu gehören. An ihrem siebzehnten Geburtstag macht sie sich schließlich auf den Weg nach Paris. Dort angekommen, trifft sie drei Mädchen, die ihren Wunsch, ein Musketier zu werden, teilen. Als die vier herausfinden, dass ein Anschlag auf den Prinzen geplant ist, erhalten sie ihre Chance sich zu beweisen. Hilfe bekommen sie von der alten Haushälterin des Schlosses, welche ihnen die Techniken des Kampfes beibringt und sie somit auf den Kampf vorbereitet. Schon bald tanzen sie in wundervollen Kleidern auf einem Maskenball, schleichen durch Geheimgänge und schaffen es sogar den Feind zu stellen. Dabei geht auch ihr Traum in Erfüllung – sie gehören ab sofort zu den Musketieren.\n\nDie DVD wurde bis April 2010 etwa 1,1 Millionen Mal verkauft und erreichte dabei einen Umsatz von 16 Millionen US-Dollar. \n"}
{"id": "5704862", "url": "https://de.wikipedia.org/wiki?curid=5704862", "title": "RadioSure", "text": "RadioSure\n\nRadioSure ist ein Audioprogramm zum Abspielen von Radio Streams für das Betriebssystem Windows. Es enthält bereits eine sehr umfangreiche Datenbank an weltweiten webbasierten Radiostationen (über 34.000 Stück, Stand Dezember 2016); Benutzer können aber auch eigene Stationsadressen speichern. Als zusätzliche Funktion bietet das Programm eine Möglichkeit, das Abgespielte mit der integrierten Aufnahmefunktion aufzuzeichnen. Das Erscheinungsbild von RadioSure lässt sich mittels Skins verändern.\nEine aktive Gemeinschaft behandelt Fragen und Probleme rund um das Programm innerhalb eines Online-Forums.\n\nDas Standard-Installationsprogramm bietet die Möglichkeit, RadioSure als portable Version zu installieren. Diese eignet sich z. B. zur Mitnahme auf einem USB-Stick.\n\nDer Betreiber der Seite und der Entwickler der Software wird nicht genannt. Im Programm ist unter \"About\" der Unternehmensname \"The Best Ware Studio\" hinterlegt. Laut Angaben des Entwicklers wurde das Programm 2008 entwickelt, da es keine Software mit ähnlichem Umfang und ähnlich einfacher Bedienbarkeit gab.\n\n"}
{"id": "5707787", "url": "https://de.wikipedia.org/wiki?curid=5707787", "title": "Die Olsenbande in feiner Gesellschaft", "text": "Die Olsenbande in feiner Gesellschaft\n\nDie Olsenbande in feiner Gesellschaft, Originaltitel: Olsen-banden på de bonede gulve (wörtlich \"Die Olsenbande auf poliertem Fußboden\") ist ein computeranimierter 3D-Film aus Dänemark rund um die Olsenbande.\n\nDie Olsenbande erhält vom dänischen Staatsministerium den Auftrag, gegen einen hohen Geldbetrag die Schreibfeder Hans Christian Andersens zu stehlen, die einen unschätzbaren ideellen Wert in der dänischen Geschichte darstellt. Die Feder soll dem chinesischen Ministerpräsidenten zum erfolgreichen Abschluss eines erfolgreichen Handelsabkommens zwischen Dänemark und der Volksrepublik China als Gastgeschenk überreicht werden. Die Bande bricht dazu in das Kopenhagener H.C. Andersen-Museum ein, wo sie dank Egons Plan die Alarmanlage außer Gefecht setzen kann. Als Egon jedoch den Franz-Jäger-Tresor im Museum öffnet, finden sie darin statt Andersens Schreibfeder nur einen modernen Kugelschreiber vor. Durch ein Missgeschick wird außerdem der Alarm ausgelöst. Während Benny und Kjeld noch gerade so rechtzeitig entkommen können, wird Egon Olsen vor dem Museum noch gestellt und ins Gefängnis verbracht. Die Olsenbande ist offenbar von ihrem Auftraggeber Hallandsen hereingelegt worden. Dieser hatte schon zuvor Andersens Feder ausgetauscht und brauchte nur noch einen einschlägig vorbestraften Sündenbock wie Olsen, um eine Erklärung für ihr Verschwinden zu haben. Hallandsen präsentiert nach Olsens Festnahme die richtige Feder dem dänischen Ministerpräsidenten Anders Fogh Rasmussen.\n\nDurch eine Amnestie kommt Olsen jedoch nach kurzer Zeit wieder frei und hat natürlich sofort einen Plan, wie sie an die Feder und damit an die Millionen kommen, sowie sich dabei an Hallandsen rächen können. Die Schreibfeder von Andersen soll sich mittlerweile zur Aufbewahrung im Tresor des Arbeitszimmers von Hallandsen im Folketing auf Schloss Christiansborg befinden. Um sie dort herauszuholen, benötigt die Olsenbande einen Akkuschrauber, Honigpflaumensaft und ein paar tote Ratten, was von Benny und Kjeld für den Plan organisiert wird.\n\nDen dreizehn ursprünglichen Filmen der Reihe um das Kopenhagener Gaunertrio, die von 1968 bis 1981 erschienen waren, folgte zunächst 1998 ein letzter (vierzehnter) Film in der ursprünglichen Besetzung, \"Der (wirklich) allerletzte Streich der Olsenbande\". Von der Kindheit der Olsenbande erzählten anschließend die Fernsehserie \"Olsen-bandens første kup\" (1999) und der Kinofilm \"Olsenbande Junior\" (2001).\n\nIm September 2007 gab es schließlich die erste Ankündigung, dass ein Animationsfilm mit der Bande produziert werde. Als Regisseur wurde ursprünglich Stefan Fjeldmark, unter anderem Regisseur von \"Terkel in Trouble\", genannt. Der Film entstand als Gemeinschaftsproduktion von Nordisk Film, dem traditionellen Produzenten der Olsenbande, und dem dänischen Trickfilmstudio A. Film; subventioniert wurde er durch das Dänische Filminstitut. Zuvor hatte A. Film unter anderem \"Hugo, das Dschungeltier\" oder \"Hilfe! Ich bin ein Fisch\" animiert. Teile des Films entstanden bei \"Happy Flyfish\" in Viborg; die Gemeinde Viborg sowie der Westdänische Filmpool gehörten ebenfalls zu den Finanzierern des Films. Der internationale Boom des 3D-Films führte schließlich zu der Ankündigung, als ersten dänischen Film auch \"Olsen-banden på de bonede gulve\" in 3D zu veröffentlichen.\n\nEs wurde darauf verzichtet, die zum Zeitpunkt des Einsprechens noch lebenden Hauptdarsteller der Originalfilme (Morten Grunwald, Ole Ernst) als dänische Synchronsprecher einzusetzen, stattdessen wurden junge Schauspieler und Komiker ausgewählt.\n\nDie Welturaufführung des Films fand am 3. Oktober 2010 in Viborg statt; die offizielle Galapremiere am 9. Oktober im Kopenhagener Kino \"Imperial\". An den dänischen Kinokassen startete er am 14. Oktober 2010. Im April 2011 wurde er auf Dänisch sowie auch in russischer Sprache synchronisiert als DVD und Blu-Ray veröffentlicht. Eine deutschsprachige Version ist am 21. September 2012 bei \"Capelight Pictures\" auf Blu-Ray/DVD erschienen. Am 21. Februar 2016 erlebte der Film seine deutsche Fernsehpremiere im MDR Fernsehen.\n\nIm Juni 2011 wurde angekündigt, als Fortsetzung einen weiteren 3D-Animationsfilm zu produzieren unter dem Titel: \"Olsen-banden på dybt vand\" (\"Die Olsenbande geht baden\" oder wortwörtlich \"Die Olsenbande in tiefem Wasser\") und am 29. September 2014 seine deutschsprachige Premiere unter dem Namen \"Die Olsenbande auf hoher See\" haben soll. Dieser Film wurde in Dänemark durch die 60/40-Regelung des Dänischen Filminstitut gefördert und hatte 2013 seine Premiere.\n\n"}
{"id": "5718123", "url": "https://de.wikipedia.org/wiki?curid=5718123", "title": "Jailbreak (iOS)", "text": "Jailbreak (iOS)\n\nJailbreak ( für „Gefängnisausbruch“) bezeichnet das nicht-autorisierte Entfernen von Nutzungsbeschränkungen bei Computern, deren Hersteller bestimmte Funktionen serienmäßig gesperrt hat. Der Begriff entstand ursprünglich mit Bezug auf die Virtualisierungsumgebung von FreeBSD. Populär wurde er durch den Jailbreak der Apple-Mobilgeräte, die das Betriebssystem iOS verwenden (iPhone, iPod touch, iPad und Apple TV). Apple verfolgt ein striktes \"Closed-World\"-Geschäftsmodell, was bedeutet, dass im Serienzustand auf den Geräten nur Software aus dem firmeneigenen App Store installiert werden kann. Bei Geräten mit Linux oder dem damit verwandten Betriebssystem Android ist der Begriff \"Rooten\" gebräuchlich. Im nachfolgenden Artikel wird ausschließlich auf iOS-Geräte eingegangen.\n\nMittels entsprechender Software wird bei einem Jailbreak das Betriebssystem \"Apple iOS\" modifiziert, um erweiterte, sogenannte \"Root-Zugriffsrechte\" auf interne Funktionen sowie das Dateisystem zu erhalten. Im Serienzustand der Geräte ist dies nicht möglich. Anschließend wird von den meisten Jailbreaking-Programmen eine Softwareverwaltung (meistens Cydia) aufgespielt, mit welcher beliebige, auch vom Hersteller Apple nicht freigegebene Software installiert werden kann. Da iOS auf dem Unix-artigen Betriebssystem Darwin basiert, erhält der Benutzer mit dem Jailbreak gleichzeitig Administrator-Zugriff auf ein vollwertiges Unix-Betriebssystem. Dieses kann etwa über Kommandozeilen-Tools genutzt werden.\nDie erste Jailbreak-Methode wurde am 10. Juli 2007 von der Hacker-Gruppe \"iPhone Dev Team\" bekanntgemacht, die bisher die meisten Jailbreaks entwickelt hat. Diese Lücke des iPhone-Betriebssystems wurde mit dem ersten Jailbreaking-Programm \"iBrickr\" erstmals in einem einfach bedienbaren GUI nutzbar gemacht. Die Funktion von iBrickr beschränkte sich jedoch anfangs auf das Installieren und Löschen von Klingeltönen auf dem iPhone. Mit Updates wurde diese Funktion später auch standardmäßig in iOS integriert. Nach dem Erscheinen der iPhone-Software-Version 1.1.x wurde auch für diese ein öffentlicher Jailbreak sowie ein Baseband-Unlock entwickelt, was dazu führte, dass Apple die dafür genutzte Sicherheitslücke schloss. In der Folge begann ein Wechselspiel aus gefundenen Jailbreak-Methoden und dem Sperren dieser Angriffspunkte durch den Hersteller Apple, der dies jeweils in neuen Betriebssystem-Versionen integrierte.\n\nWährend zu Anfangszeiten der iOS-Jailbreaks die meisten aufwändigeren Jailbreaking-Programme teilweise kommandozeilenbasiert und noch recht kompliziert waren, wurde der Vorgang mit der Zeit immer einfacher. Dies mündete in auch für unversierte Benutzer einfacher zu bedienenden Programmen zum Durchführen des Jailbreaks, wie zum Beispiel QuickPWN im Frühjahr 2009 und dem Ende 2009 vom Hacker George Hotz („GeoHot“) für iPhone OS 3.1 entwickelten ersten One-Click-Jailbreak \"blackra1n\", mit dem man jedes iOS-Gerät mithilfe nur eines Klicks mit einem Jailbreak versehen konnte. Am 11. August 2010 veröffentlichte Apple erstmals iOS-Versionen (4.0.2 für das iPhone und iPod Touch und iOS 3.2.2 für das iPad), die ausschließlich Sicherheitslücken schlossen, um einen Jailbreak zu verhindern.\nBereits einen Monat später (8. September 2010) fand ein Mitglied des Chronic Dev Team eine neue Sicherheitslücke (\"SHAtter Exploit\"). Es war der erste „Boot-ROM exploit“, den Apple nur durch die Änderung der Hardware verhindern könnte. Dieser kam jedoch nie zum Einsatz, da George Hotz den Limera1n-Exploit zuvor veröffentlichte. Ende 2011 schloss Apple mit iOS 5 Lücken im Signatursystem von iOS um den Downgrade auf ältere Firmwares endgültig zu verhindern. Von 2012 bis Ende 2013 erschienen verschiedene Jailbreaking-Programme die nach dem Prinzip von George Hotz’ \"blackra1n\" funktionierten und einen Userland-Exploit verwendeten. Am 18. Mai 2014 zeigte der deutsche Entwickler Stefan Esser in einem Post auf Twitter erstmals einen Jailbreak für iOS 7.1.1. Dieser Jailbreak verwendet einen Bug im Kernel von iOS und wurde mit der Software \"Pangu\" Ende Juni 2014 für die Öffentlichkeit nutzbar gemacht. Im Juni 2015 veröffentlichte das chinesische Entwicklerteam des TaiG-Jailbreaks mehrere Jailbreak-Anwendungen für verschiedene Versionen von iOS 8. Am 14. Oktober 2015 folgte der erste öffentliche Jailbreak für iOS 9, entwickelt vom chinesischen Pangu-Team.\nIm Februar 2017 wurde ein Jailbreak für iOS 10.2 von Luca Todesco veröffentlicht. Der aktuellste Jailbreak ist für iOS 11.0 bis 11.4 (beta 3) verfügbar und wurde von Coolstar unter dem Namen Electra entwickelt. Unterstützt werden bei diesem Jailbreak alle 64-Bit Geräte, einschließlich des iPhone X.\nDie Verbreitung des Jailbreaks ist eher gering. So wurden laut Apple von Oktober bis Dezember 2011 rund 37 Millionen iPhones abgesetzt. Drei Tage nach dem Erscheinen des Jailbreaks für iOS 5.0.1 wurden rund 491.000 iPhone 4S gezählt, auf denen Cydia installiert war, was einem Anteil von 1,3 Prozent aller bis dahin produzierten iPhone-4S-Geräte entspricht. Laut Cydia-Entwickler Jay Freeman wurden vom 4. bis 8. Februar 2013 rund 5,15 Millionen iOS 6.0 und 6.1 iPhones mit dem \"Evasi0n\"-Jailbreak versehen, was einem Anteil von 3,6 Prozent aller jemals hergestellten iPhones entspricht, auf denen iOS 6 aufgespielt werden kann. Apple setzte von 2007 bis 2013 insgesamt über 700 Millionen iOS-Geräte ab, davon war im März 2013 auf etwa 23 Millionen ein Jailbreak installiert. Das entspricht einem Gesamtanteil von 3,3 Prozent aller jemals produzierten iOS-Geräte. Mit etwa 8 Millionen Geräten war 2013 das iPhone 4 das am häufigsten mit einem Jailbreak versehene Gerät.\n\nEs gibt mehrere Möglichkeiten, das Endgerät zu \"jailbreaken\". Meistens wird dazu ein PC oder Mac benötigt, auf dem das Jailbreaking-Programm läuft. Das Jailbreaking-Programm nutzt entweder Schwachstellen im iOS-Betriebssystem oder Designfehler der Hardware aus. Während die ersten Jailbreaks meist ausschließlich einen Hardwarefehler nutzten und im niedrigsten Betriebszustand des iOS-Geräts, genannt \"DFU Mode\", installiert wurden, der eigentlich für die Installation von iOS vorgesehen ist, gibt es heute sowohl Jailbreaks, die im DFU Mode, als auch solche, die bei hochgefahrenem Betriebssystem installiert werden. Dazu wird bei Jailbreaks im \"DFU Mode\" eine RAM-Disk in den Speicher geladen, die ein kleines Betriebssystem enthält, das dann das eigentliche iOS-System modifiziert. Jailbreaks im hochgefahrenen Betriebssystem nutzen einen Fehler direkt in iOS, genannt \"Userland-Exploit\", sodass vom Jailbreaking-Programm vom PC aus Modifikationen vorgenommen werden können. Eine RAM-Disk kann hier nicht geladen werden, da das iOS-Betriebssystem bereits gestartet ist und somit den Arbeitsspeicher belegt. Es gibt jedoch auch einige wenige Jailbreaks, die ohne das Verwenden eines PC oder Mac direkt auf dem Gerät ablaufen, z. B. über den Safari-Browser. Diese \"Userland-Exploits\" können von Apple im Gegensatz zu Schwachstellen in der Hardware mit einem Softwareupdate behoben werden.\n\nNach einem Jailbreak sind Nutzer nicht mehr an den App Store gebunden. Sie können dann Anwendungen von anderen Anbietern, etwa über den Cydia-Paket-Manager, auf ihrem Gerät installieren. Cydia hat sich gegen Konkurrenten wie \"Installer\", \"Icy\" oder \"Rock\" durchgesetzt. Die Möglichkeit, ein bestimmtes Gerät mit einem Jailbreak zu versehen, hängt von der Firmware-Version und dem verwendeten Gerät ab.\n\nWird mit einem Jailbreak der Paketmanager Cydia installiert, muss dieser zu Anfang meist aktualisiert werden. Viele Jailbreak-Programme laden beim Jailbreakvorgang nicht die neueste Version des Paketmanagers, sondern installieren eine zum Veröffentlichungsdatum der Jailbreak-Software aktuelle Version von Cydia. Es ist üblich, dass besonders in den ersten Wochen nach dem Erscheinen einer neuen Jailbreak-Variante viele Systemaktualisierungen erscheinen, wodurch die vom Jailbreak-Programm gelieferte Version von Cydia schnell obsolet ist. Neben der eventuell nötigen Aktualisierung ist ebenfalls eine Vorbereitung des Dateisystems vonnöten. Dabei werden die Standardapplikationen von iOS in ein neues Verzeichnis verschoben. Anwendungen aus Cydia werden ebenfalls in dieses Verzeichnis installiert und sind standardmäßig nicht im Anwendungsverzeichnis des Benutzerordners zu finden.\n\nFür den Jailbreak wird eine kompatible iOS-Version vorausgesetzt, da die genutzten Sicherheitslücken in nachfolgenden Versionen oft geschlossen werden. In dieser Übersicht werden nur die neuesten Builds von iOS und deren Jailbreakstatus aufgeführt.\nBeim Jailbreak wird zwischen verschiedenen Variationen unterschieden:\n\n\n\n\nIm weiteren Sinne ist ein Jailbreak auch die Voraussetzung, um die Bindung der SIM-Karte an einen bestimmten Telefonanbieter, beispielsweise die Deutsche Telekom in Deutschland, ohne Entgelt und vor dem bei einigen Anbietern vertraglich geregelten Laufzeitende des SIM-Locks aufzuheben, ein sogenannter Unlock. Ein \"Unlock\" beziehungsweise das \"Unlocken\" oder \"Entsperren\" des iPhones ist nicht mit Jailbreaking gleichzusetzen; iOS kann mit einem Jailbreak versehen werden \"ohne\" dass der SIM-Lock aufgehoben wird. Die Freischaltung des SIM-Locks ist nicht bei allen Geräten möglich; es gibt verschiedene Methoden ein iPhone oder iPad zu entsperren:\n\nDas iPhone verwendet eine Konstruktion mit einem Applikationsprozessor und einem Baseband-Prozessor. Der Applikationsprozessor führt das Hauptbetriebssystem iOS und dessen Anwendungen aus, während der Baseband-Prozessor im Modem für die Kommunikation mit dem Handynetz zuständig ist. Das Modem hat ein eigenes Betriebssystem welches parallel zu iOS ausgeführt wird. In iOS wird es \"Modem-Firmware\" genannt. Ein Baseband-Unlock nutzt einen Programmierfehler in der Modem-Firmware oder einen Hardwarefehler im Baseband-Prozessor aus. Apple hat mit dem Einsatz neuer Modems alle in der Vergangenheit aufgetretenen Schwachstellen sowohl in Hard- als auch in Software geschlossen, sodass seit September 2010 kein neuer Baseband-Unlock entwickelt wurde. Das Interesse an Unlocks hat ebenfalls nachgelassen, da Apple mittlerweile die meisten Geräte ohne SIM-Lock ausliefert.\n\nÜber den Network-Control-Key-Code kann das Gerät dauerhaft entsperrt werden. Beim iPhone besteht dieser Code aus der IMEI-Nummer und vielen diversen Hardware-Seriennummern sowie einer willkürlichen, fünfstelligen Zahl. Im Normalfall wird der NCK-Code über Apple auf das Handy installiert, um die offizielle Entsperrung zu ermöglichen. Das „iPhone Dev-Team“ hatte entdeckt, dass sich nahezu der gesamte Code leichter auslesen ließ, als damals erwartet. Dies wurde mit dem SAM-Unlock (Subscriber Artificial Module) des Entwicklers Sam Bingner zu einem dauerhaften Unlock weiterentwickelt. Einmal mit SAM entsperrte iPhones bleiben theoretisch für immer ohne SIM-Lock. Inzwischen hat Apple die Schwachstelle wieder geschlossen und einige Quellen berichten, dass der SAM-Unlock auf bereits entsperrten Geräten nur noch bis 2015 funktionieren könne, und danach wieder ein SIM-Lock auf dem Gerät installiert werde.\n\nApple kann jedes iPhone nach Belieben für alle Netze freischalten. Wird die Entsperrung eines iPhone beim Netzbetreiber eingereicht, muss dieser die IMEI-Nummer des zu entsperrenden Geräts bei Apple anzeigen. Ist das Gerät bei Apple durch den Netzbetreiber erfolgreich zum Entsperren eingetragen, wird es beim nächsten Synchronisieren mit iTunes für alle Netze freigeschaltet.\n\n\"Downgrade\" bedeutet in diesem Zusammenhang, dass man die vorhandene Firmware oder Betriebssoftware eines Geräts auf eine ältere Version zurückstuft, beispielsweise bei Apple-Geräten von der iOS-Version 4.0 auf 3.1. Dies ist sinnvoll, wenn es für die ältere iOS-Version bereits einen Jailbreak gibt, für die neuere aber (noch) nicht. Dafür werden vorher gesicherte Signaturdateien zur iOS-Installation, sogenannte \"SHSH-Blobs\" benötigt. Namhafte Jailbreak-Entwickler empfehlen diese vor dem Erscheinen einer neueren iOS-Version zu sichern, da ein nachträgliches Sichern nicht möglich ist. Einsetzen lassen sich SHSH-Blobs nur bei Geräten welche über den Samsung S5L8930 oder ein älteres SoC verfügen. Eine originale iOS-Firmware lässt sich mit SHSH-Blobs nicht installieren, das Erstellen und Einspielen einer sogenannten \"CFW\" (Custom Firmware), die mit den gesicherten SHSH-Blobs signiert wird, ist vonnöten. Mittlerweile ist ein Downgrade jedoch als obsolet zu betrachten, da sich bei Geräten, die neuere SoCs verwenden keine CFW installieren lässt, und aufgrund der eingeführten Beschränkungen der Downgrade bei allen mit iOS 8 kompatiblen Geräten nicht möglich ist. Deswegen hat das Sichern der SHSH-Blobs heute die Relevanz verloren.\n\nDer \"DFU Mode\", Abkürzung für \"Device-Firmware-Upgrade Mode\" ist der niedrigste oder auch Basis-Betriebszustand jedes iOS-Geräts. Der DFU Mode ist in der Hardware integriert und bietet die Möglichkeit, Betriebssysteme zu installieren. Im \"DFU Mode\" ist der Bildschirm des Geräts ausgeschaltet. Der Modus kann nicht durch Software ausgelöst werden, mit Ausnahme von speziell modifizierten Firmwares, die nach der Installation direkt im DFU Mode booten. Bis zum iPhone 3GS wurden alle iOS-Geräte im DFU Mode ausgeliefert, iOS musste anschließend durch den Benutzer selbst installiert werden.\n\nDer Recovery Mode ist der Wiederherstellungsmodus für iTunes. iTunes versetzt Geräte vor einem normalen Update von iOS in den Recovery Mode. Er wird deshalb oft mit dem DFU Mode verwechselt. Standardmäßig zeigt der Recovery Mode das Logo der aktuellen iTunes-Version an. Er kann durch das Ändern der Variable \"auto-boot\" auf \"true\" oder \"false\" aktiviert beziehungsweise deaktiviert werden. Er ist im Gegensatz zum DFU Mode softwarebasiert.\n\nDer Safe Mode ist der Abgesicherte Modus des Geräts. Er wird mit dem Cydia-Programm \"Substrate Safe Mode\" installiert. Der Safe Mode schützt das System vor Abstürzen durch fehlerhafte Software. Funktioniert ein Programm aus Cydia nicht richtig, so wird das Gerät meistens in den Safe Mode versetzt und das fehlerhafte Programm kann deinstalliert werden. Der Safe Mode kann manuell durch Drittprogramme oder den Konsolenbefehl \"killall -SEGV SpringBoard\" ausgelöst werden. Wird beim Bootvorgang des Geräts der Volume-Up Knopf gehalten, so bootet das iOS-Gerät direkt in den Safe Mode. Dabei ist jedoch Substrate Safe Mode komplett deaktiviert, sodass im Status Bar nicht wie sonst üblich \"Exit Safe Mode\" steht. Durch das Wechseln der Sprache oder das Antippen der Statusbar kann der Safe Mode verlassen werden.\nDer Normal Mode ist der normale Betriebszustand von iOS nach dem Entriegeln mit dem \"Slide to Unlock\" Slider.\n\nBeim Respring wird die Benutzeroberfläche von iOS, das \"Springboard\" neu geladen. Dieser Vorgang wird zum Wechseln der Sprache von iOS ohne Jailbreak unterstützt. Führt man einen Respring aus, so wird im Display \"Sprache Wechseln\" angezeigt. Ein Respring kann je nach iOS-Version und Anzahl installierter Programme zwischen wenigen Sekunden und etwa zwei Minuten in Anspruch nehmen. Während des Resprings kann das Gerät nicht bedient werden, es zeigt lediglich \"Sprache wechseln\" im Display an. Nach einem Respring sind alle Erweiterungen aus Cydia neu geladen.\n\nDa die Standardquellen (genannt \"Repositories\" oder \"Repos\") von Cydia ebenso wie der AppStore einer Zensur durch die Quellenbetreiber unterliegen, ist der Verbreitung von Schadsoftware eine Hürde gesetzt. Apps werden geprüft und bei Bedenken abgelehnt. Seit dem Start von Cydia im Jahr 2008 sind nur wenige Berichte von Schadsoftware aus den Standardquellen bekannt.\n\nBei anderen durch den Nutzer manuell hinzugefügten Repos, insbesondere Repos mit illegalem Inhalt wie Raubkopien, besteht eine erhöhte Gefahr Schadsoftware zum Opfer zu fallen, da die Kontrolle entfällt und sämtliche Inhalte von Kriminellen angeboten werden. Das Verschwinden von anderen Cydia-Repositories, Protokollierung der Benutzereingaben mit Keyloggern, dauerhafte Werbung durch Adware oder Ausspionieren der Apple-ID sind keine Seltenheit.\n\nEine beliebte und vergleichsweise simple Variante, Schadsoftware auf ein mit einem Jailbreak versehenes iPhone zu installieren, ist die Infektion über den von vielen Nutzern installierten SSH-Dienst OpenSSH. Aus Bequemlichkeit oder Unwissenheit ändern viele Nutzer das bei iOS-Geräten standardmäßig gesetzte Root-Passwort alpine nicht, wodurch ein Wurm mit Root-Berechtigung über SSH auf das iPhone zugreifen und sich selbst aufspielen kann. Der Cydia-Entwickler \"saurik\" empfiehlt deshalb, das root-Passwort schnellstmöglich zu ändern. Bedingung für eine Infektion über SSH ist jedoch, dass sich ein bereits infiziertes Gerät im selben WLAN befindet.\n\nGrößere Bekanntheit erlangte der Anfang November 2009 vom 21-jährigen australischen Studenten Ashley Towns programmierte iPhone-Wurm namens \"ikee\". Bereits direkt im Quelltext war vermerkt:\nTowns wollte damit auf das Sicherheitsrisiko des SSH-Dienstes hinweisen.\n\nAm 22. November 2009 berichtete F-Secure von einem neuen Computerwurm namens \"Ikee.B\", welcher auf dem Prinzip von \"ikee\" aufbaute, aber die Sicherheitslücke ausnutzte, um Banktransaktionen von mit Jailbreak versehenen iPhones auszuführen.\n\nDie genaue Anzahl an SSH-Würmern lässt sich nicht genau bestimmen, da ein solcher schnell und einfach programmiert werden kann und es kaum gesicherte Informationen über die Verbreitung gibt. Öffentliche WLANs stellen in jedem Fall eine stärkere Infektionsgefahr dar, da hier potentiell viele Geräte angemeldet sind und so die Wahrscheinlichkeit, auf ein infiziertes Gerät zu treffen, steigt.\n\nMit einem speziellen RAM-Disk-Jailbreak lassen sich von Geräten Daten stehlen. Dazu wird im DFU Mode ein Jailbreak in den Speicher des Geräts geladen, der anschließend Zugriff auf das Dateisystem über eine USB-SSH Verbindung ermöglicht. Diese Methode funktioniert bei allen iOS-Geräten, die über einen A4-Chip oder eine ältere CPU verfügen, unabhängig von der installierten iOS-Version. Gegen diese Methode gibt es keinen wirksamen Schutz. Die Codesperre des Geräts kann so auch umgangen werden, da sie gar nicht abgefragt wird. Alternativ lässt sich so auch ein Brute-Force-Angriff auf die Codesperre starten, mit dem diese vollständig entschlüsselt werden kann.\n\nDurch einen Jailbreak kann die Stabilität des iOS-Systems beeinträchtigt werden. Viele Programme aus Cydia belegen Speicher, der im Design von iOS eigentlich als frei zur Verfügung stehender Speicher festgelegt ist. Wird zu viel dieses Speichers von Cydia-Tweaks belegt, so können Systemabstürze verursacht werden oder Apps aus dem App-Store nicht mehr einwandfrei laufen. Ebenso ist eine Verlangsamung des Systems deutlich festzustellen. Dem kann jedoch entgegengewirkt werden, indem Programme aus dem Cydia-Store nur in Maßen installiert werden. Ist dies der Fall, so treten keine Performance-Einbußen auf.\n\nKurz nach der Veröffentlichung eines neuen Jailbreaks sind die meisten Programme aus dem Cydia-Store noch nicht angepasst, wodurch sie oftmals fehlerhaft oder gar nicht funktionieren.\n\nMit der steigenden Popularität des Jailbreaks bieten zunehmend dubiose Entwickler Software an, die einen Jailbreak lediglich vortäuscht und daher keinen Nutzen für den Endnutzer hat. Viele dieser, teilweise auch gegen Entgelt angebotenen Programme ahmen populäre Jailbreaking-Programme nach oder installieren ohne Kenntnis des Benutzers Schadprogramme auf dessen Computer. Ebenfalls häufig werden die von den Jailbreak-Entwicklern durchweg gratis zur Verfügung gestellten Programme von Dritten verkauft. Zudem wird die Verbreitung von Fake-Jailbreaking-Programmen dadurch begünstigt, dass Jailbreak-Software in der Regel nicht von offensichtlich zuverlässigen Quellen bezogen werden kann.\n\nOft werden bei Erscheinen neuer iOS-Firmwareversionen neue Jailbreak-Programme entwickelt, anstatt ältere Jailbreaking-Software weiterzuentwickeln. So ist eines der populärsten Jailbreaking-Programme, \"Redsn0w\" seit März 2013 obsolet, da es ohne das Cachen eines älteren Firmware-Images nicht den Umgang mit neueren iOS-Versionen als 6.0.1 beherrscht. Viele Fake-Jailbreaking-Programme werden in der Folge als untethered Jailbreak oder Unlock für Geräte und iOS-Versionen ausgegeben, für die es bisher keinen öffentlich zugänglichen Jailbreak gibt.\n\nApple vertritt den Standpunkt, dass durch das Entsperren die Herstellergarantie erlischt. Dies passiert aber nur dann, wenn das Problem mit dem man das Gerät einschicken möchte, durch den Jailbreak verursacht worden ist.\nÜber iTunes kann allerdings der ursprüngliche Zustand des Geräts wiederhergestellt und der Jailbreak so entfernt werden.\nBisher sind in Deutschland keine Fälle bekannt, in denen Apple die Garantie im Falle eines Jailbreaks verweigert hat.\n\nDer Jailbreak von iOS wird immer wieder in den Medien, gerade IT-Fachzeitschriften thematisiert. Dabei fällt das Fazit nicht immer nur positiv aus. Apple selbst warnt vor möglichen Komplikationen, die ein Jailbreak mit sich bringen kann, auch andere Quellen berichten von Nachteilen, überwiegend in puncto Sicherheit und Systemstabilität. Die Funktionen, die durch Software aus dem Cydia-Store geboten werden, sind nach Ansicht einiger Quellen mittlerweile in iOS integriert, wodurch es immer weniger Gründe gäbe, einen Jailbreak zu installieren. Ebenfalls wird das Erlöschen der Herstellergarantie durch einen Jailbreak oft als negativ gesehen.\n\nGegen Ende des Jahres 2013 geriet der Jailbreak massiv in die Kritik, da zu dem \"Evasi0n7\"-Jailbreak auf Geräten, die als Systemsprache Chinesisch eingestellt hatten, ein alternativer chinesischer App Store installiert wurde (\"TAiG\"), der teilweise raubkopierte Apps anbot. Die Anbieter dieses App Stores boten viel Geld an, damit die Software zusammen mit dem Jailbreak installiert wird. Auf Twitter gab es daraufhin einen Shitstorm gegen die Ersteller des Jailbreaks, die evad3rs, die sich nachfolgend entschuldigten und \"TAiG\" aus dem Evasi0n-Jailbreak entfernt haben.\nViele Quellen sehen im Jailbreak einen Vorteil. Die Möglichkeiten, beliebige Apps zu installieren und freien Zugriff auf das Dateisystem zu haben werden gelobt, die Zeit betitelte in ihrer Onlineausgabe einen Artikel zum Thema Jailbreak mit \"„Mehr Freiheit für iPad und iPhone“\". Die negative Kritik am Jailbreak wird von derartigen Quellen oft mit der Begründung neutralisiert, dass bei einer maßvollen Anwendung des Jailbreaks kaum Probleme auftreten würden, oder sich diese leicht beheben ließen. Die Gefahr sich durch einen Jailbreak mit Malware zu infizieren sei geringer als dies beim Rooten von Android-Telefonen der Fall ist, teilweise soll auch durch einen Jailbreak die Sicherheit vor Schadprogrammen erhöht werden. Beim Erscheinen von iOS 6 wurde in der Jailbreak-Gemeinde angemahnt, dass ein Jailbreak mehr Funktionen als ein Update auf iOS 6 bieten würde.\n\nDas Bundesamt für Sicherheit in der Informationstechnik (BSI) schneidet den Jailbreak in einem Überblickspapier zu iOS an und warnt vor potenziellen Gefahren, die auftreten können. Laut BSI entstehen durch einen Jailbreak zahlreiche Angriffspunkte, weil viele Sicherheitsmechanismen von Apple ausgeschaltet werden und Anwendungen und Anwender mittels root-Konto vollen Zugriff auf das Betriebssystem erhalten. root-Benutzerkonten sind jedoch bei Betriebssystemen durchaus üblich und stellen im Allgemeinen kein besonderes Gefährdungspotenzial dar – sie gestatten dem Nutzer lediglich vollkommene Kontrolle über das Betriebssystem. Ebenfalls warnt das BSI vor der Gefahr des Datendiebstahls, der dank eines Jailbreaks relativ einfach durchzuführen ist. Das Erstellen eines Speicherabbildes ist jedoch bei einem älteren iOS-Gerät auch ohne fest installierten Jailbreak problemlos möglich. Laut BSI ist es besonders bedenklich, dass Anwendungen aus unsicheren Quellen installiert werden können. Dies ist jedoch bei den meisten Betriebssystemen standardmäßig möglich. Ebenso wie viele Jailbreak-Entwickler weist auch das BSI darauf hin, das root-Kennwort von iOS zu ändern. Des Weiteren wird darauf hingewiesen, dass die Signaturprüfung von iOS durch einen Jailbreak unterbunden wird, was ein Sicherheitsrisiko darstellt. Aus diesen Gründen empfiehlt das BSI, den Jailbreak auf dienstlich genutzten iOS-Geräten zu untersagen.\n\nLaut BSI sollen Programme, die einen Jailbreak durchführen, das Betriebssystem verändern und sich vor Erkennung schützen. Diese Ansicht impliziert die Auffassung, dass es sich bei Programmen wie z. B. Evasi0n um Malware handelt. Dies ist jedoch nicht der Fall. Um sich vor Jailbreaks auf firmeneigenen Geräten zu schützen, empfiehlt das BSI den Einsatz von Apps, die Veränderungen an iOS registrieren. Damit solche Apps korrekt ausgeführt werden können, sind jedoch Root-Rechte erforderlich, die selbst wiederum einen Jailbreak voraussetzen.\n\n\n"}
{"id": "5718659", "url": "https://de.wikipedia.org/wiki?curid=5718659", "title": "Systemd", "text": "Systemd\n\nsystemd ist ein Hintergrundprogramm (Daemon) für Linux-Systeme, das als init-Prozess als erster Prozess (Prozess-ID 1) zum Starten, Überwachen und Beenden weiterer Prozesse dient. Es wurde von Lennart Poettering, Kay Sievers (Red Hat Inc.) und anderen in C programmiert und wird als freie Software unter der GNU Lesser General Public License (LGPL) veröffentlicht.\n\nDer Name entspricht mit dem abschließenden „d“ dem für Daemons üblichen Namensschema: systemd ist der Daemon, der das System startet und betreut.\n\nDie Ideen und Konzepte zu systemd entstanden aus der Betrachtung von bereits bestehenden modernisierten init-Systemen wie launchd von macOS und SMF (Service Management Facility) von Solaris. Es wurde am 10. April 2010 veröffentlicht. Distributionen, die systemd als vorgegebenen init-Dienst verwenden, sind Fedora ab Version 15, openSUSE ab Version 12.1, Mandriva 2011, Mageia ab Version 2, Arch Linux seit Oktober 2012, Red Hat Enterprise Linux ab Version 7, Tizen sowie siduction ab Version 2013.2, SUSE Linux Enterprise Server ab Version 12, Ubuntu ab Version 15.04 und Debian ab Version 8.\n\nAb Version 221 enthält systemd \"sd-bus\", eine unabhängige D-Bus-Programmierschnittstelle, die bei der Komplexität zwischen libdbus und GDBus angesiedelt ist. sd-bus unterstützt sowohl das klassische dbus1 im Userspace als auch kdbus als Backend und soll so den reibungslosen Übergang zur Interprozesskommunikation im Kernel ermöglichen.\n\nSystemd ist abwärtskompatibel zu SysVinit-Skripten. Allerdings werden bewusst Features benutzt, die nur unter Linux zur Verfügung stehen, nicht aber auf anderen unixoiden Betriebssystemen. Es kann daher nur auf Systemen mit Linux-Kernel laufen.\n\nEs soll den gegenseitigen Abhängigkeiten von Prozessen besser gerecht werden, durch mehr Parallelisierung zu einer besseren Auslastung beim Systemstart führen und somit weniger Verzögerungen verursachen als das ältere, klassische SysVinit oder das inzwischen auch von Ubuntu aufgegebene Upstart.\n\nGrundlegendes Konzept dafür ist es, weitgehend alle Prozesse gleichzeitig zu starten. Um nicht, wie bei anderen zwar grundsätzlich auf Parallelisierung setzenden Systemen, anhand der in einem Modell erfassten wechselseitigen Abhängigkeiten der Prozesse teilweise noch mit Serialisierung zu arbeiten, werden die D-Bus-Verbindungen und Sockets zur Interprozesskommunikation schon vor dem Start des zugehörigen Dienstes bereitgestellt und vom Kernel eventuell auflaufende Nachrichten bis zur Bereitschaft des Dienstes gepuffert. Ähnliches wird für Anfragen an Dateisysteme mittels autofs bewerkstelligt.\n\nDaneben kann es nur gelegentlich benötigte Dienste ereignisbasiert erst bei Bedarf starten und so beim Systemstart weniger Dienste starten. Damit nimmt es Aufgaben wahr, die bei klassischen Unix-Systemen von inetd übernommen werden.\n\nWeiterhin sollen alle Shell-Boot-Skripte durch deklarative Konfigurationsdateien ersetzt werden, in denen definiert wird, wie die jeweiligen Dienste gestartet werden. Diese Dateien sind in der Regel deutlich einfacher zu schreiben als init-Skripte und vermeiden den erheblichen Overhead von Shell-Skripten.\n\nSystemd polarisiert die Community äußerst stark. Dadurch kommt es zu Flame-Wars und Shitstorms seitens der Befürworter und Gegner, die zum Teil jedoch auch gegen die Person der Entwickler selbst, insbesondere Poettering und Sievers, gerichtet ist. Die Diskussion, ob man in Debian weiter SysVinit verwenden oder auf systemd oder aber ein anderes Init-System umsteigen sollte, führte zu monatelangen Streitereien und schließlich zu einer Abstimmung („General Resolution“), zahlreichen Rücktritten und einem Fork unter dem Namen Devuan.\n\nDer Hauptkritikpunkt an systemd liegt in seinem Anspruch, deutlich mehr verschiedene Aufgaben als das alte SysVinit erledigen zu wollen, was es recht kompliziert und fehleranfällig mache und überdies die Unix-Philosophie verletze (Ein Programm soll nur ein Problem lösen, dieses aber möglichst gut). Viele Entwickler äußerten die Sorge, systemd schränke durch zu starke Festlegungen der Systemumgebung Freiheit und Flexibilität ein. Vielfach wurde bemängelt, dass systemd Log-Dateien im Binärformat und nicht als einfache Textdateien speichert. Ein weiterer Kritikpunkt besteht in der Entscheidung, systemd explizit nur für Linux zu entwickeln. Wiederholt wurde kritisiert, die Entwickler würden dazu neigen, Programmierfehler zu ignorieren oder zu bestreiten. Die Devuan-Entwickler äußerten die Befürchtung, Debian und die anderen Großdistributionen seien nun von Red Hat in einem „Vendor-Lock-in“ gefangen.\n\nTheodore Ts’o kritisierte die zu starke Ausrichtung auf die Gnome-Desktop-Umgebung; es bestehe die Gefahr, dass viele Systemkomponenten mit anderen Desktops nicht mehr funktionieren würden. Dies könne langfristig zur völligen Unbenutzbarkeit anderer Desktops führen, wenn es keine Alternative zu systemd mehr gebe. Die Devuan-Entwickler spekulierten darüber, dass es langfristig zu einer Übernahme von Debian durch das Gnome-Projekt kommen könne. Linus Torvalds gab an, er habe keine feste Meinung zu systemd; einige Eigenschaften wie binäre Logs seien irrsinnig, aber das seien Detailfragen und keine grundsätzlichen Probleme. Die systemd-Entwickler hätten generell eine zu großzügige Haltung gegenüber Programmfehlern und Kompatibilitätsproblemen. InfoWorld berichtete, systemd-Entwickler hätten Programmierfehler ignoriert und Bugreports geschlossen, ohne die Fehler zu beheben, was dazu geführt habe, dass Torvalds mit Kay Sievers einen der führenden systemd-Entwickler von der Kernel-Entwicklung ausgeschlossen habe. In der Gesamtschau sei durch systemd eine Spaltung der Linux-Community eingetreten, die Linux langfristig schaden werde.\nMark Shuttleworth bezeichnete systemd im Oktober 2013 als „höchst invasiv und kaum gerechtfertigt“. Ende Oktober 2015 berichtete Slashdot, BusyBox-Entwickler Denys Vlasenko habe die systemd-Unterstützung aus BusyBox entfernt. Vlasenko erklärte, die für systemd Verantwortlichen seien unfreundlich zum Rest der Welt, somit gebe es für den Rest der Welt keinen Anlass, mit ihnen zu kooperieren. Linus Torvalds äußerte im Juli 2017 auf der Linux-Kernel-Mailingliste „LKML.org“, er könne nicht mehr darauf vertrauen, dass „init“ das Richtige tue.\n\nIm September 2014 wurde bekannt, dass eine Komponente des systemd in bestimmten Fällen DNS-Anfragen an die Google-Nameserver weiterleitet, ohne dass der Administrator dies eingestellt hat, was zu Diskussionen um die Vertraulichkeit, Sicherheit und Integrität von Nutzerdaten führte. Der zuständige Debian-Maintainer wies die Kritik zurück. Dieser Sachverhalt wurde im Juli 2015 erneut festgestellt. Poettering verteidigte diese Einstellung mit der Begründung, er wolle ein funktionsfähiges System sicherstellen.\n\nEbenfalls im Juli 2015 wurde auf GitHub moniert, dass Google-Zeitserver als default bzw. fallback fest in den Code des systemd eingebunden sind. Auch diese Entscheidung wurde von Poettering verteidigt, obwohl er einräumte, dass die Google-Server ungenaue Daten lieferten. Ein Google-Entwickler kritisierte diese Einstellung.\n\nIm September 2016 wurde ein Bug bekannt, der jedem unprivilegierten Benutzer eine DoS-Attacke auf systemd und die damit verbundenen Prozesse ermöglicht. Der Musl-Entwickler Rich Felker sagte dazu, systemd sei ein großer monolithischer Prozess, der bei einem Fehler nicht teilweise ausfalle, sondern das ganze System zum Absturz bringe. Der entdeckte Bug sei weniger ein ernstes Sicherheitsproblem, sondern zeige vielmehr einen grundlegenden Designfehler auf.\n\nAnfang 2017 entwickelte sich eine Diskussion darüber, dass systemd Daemons mit Root-Rechten ausführt, wenn in der Konfiguration des Daemons ein mit einer Ziffer beginnender Benutzername angegeben ist. Die Sicherheitslücke wurde unterschiedlich bewertet. Seitens der Entwickler wurde erklärt, es handele sich um keinen Programmierfehler, denn derartige Benutzernamen seien auf Linux-Systemen unzulässig und es läge in der Verantwortung des Administrators, sie nicht zuzulassen. Darüber hinaus müsse ein Angreifer auf dem betroffenen System bereits Root-Rechte besitzen, um derartige Benutzernamen anlegen zu können. Der Bugreport wurde zunächst geschlossen. Später wurde ein Patch eingebaut, der bewirkt, dass fehlerhafte Parameter bei sicherheitskritischen Optionen nicht mehr ignoriert werden, sondern dazu führen, dass der Prozess nicht geladen wird.\n\nIm Juni 2017 wurde eine seit 2015 bestehende Verwundbarkeit in systemd-resolved entdeckt. Diese erlaubt es, systemd durch einen kompromittierten DNS-Server zur Ausführung von Schadprogrammen zu veranlassen, wodurch der Dienst zum Absturz gebracht oder durch externe Angreifer übernommen werden könne. Über die Sicherheitslücke wurde zuerst von Canonical-Mitarbeiter Chris Coulson berichtet. Demnach sind seit 2015 die Versionsnummern 223 bis 233 betroffen. Red Hat teilte mit, das von ihnen vertriebene Red Hat Enterprise Linux 7 sei nicht verwundbar. Debian erklärte, das kürzlich erschienene Debian 9 (Codename „Stretch“) sei ebenfalls nicht betroffen, da systemd-resolved standardmäßig nicht aktiviert sei. Inzwischen existiert ein Patch, der die Sicherheitslücke schließt.\n\nIm Oktober 2018 wurde bekannt, dass ein Programmierfehler im IPv6-DHCP-Client von systemd dazu missbraucht werden kann, verwundbare Linux-Systeme mit manipulierten DHCP-Paketen zu übernehmen.\n\nDas US-amerikanische IT-Sicherheitsunternehmen Qualys berichtete im Januar 2019 über einen Fehler in der systemd-Komponente \"journald\", der es Benutzern erlaube, auf einem System root-Rechte zu erlangen. Dies gelang auf einem x86-System innerhalb von zehn, auf einem amd64-System innerhalb von 70 Minuten.\n\n\n\nKritik:\n"}
{"id": "5719996", "url": "https://de.wikipedia.org/wiki?curid=5719996", "title": "Tastaturaufkleber", "text": "Tastaturaufkleber\n\nTastaturaufkleber sind ein Computerzubehör, das die Darstellung zusätzlicher Schriftzeichen auf einer PC- oder Laptop-Tastatur ermöglicht.\n\nIn den meisten Fällen werden Tastaturaufkleber dazu benutzt, Schriftzeichen einer anderen Sprache oder Sonderzeichen darzustellen. Tastaturaufkleber bestehen aus transparenter Folie und werden meist auf einem Papierbogen geliefert, von dem sie auf die gewünschten Tasten geklebt werden können. Sie haben eine mit Klebstoff beschichtete Unterseite und eine glatte Oberseite. Das Schriftzeichen wird im Siebdruckverfahren spiegelverkehrt auf die Unterseite gedruckt. Durch die Tastaturbetätigung kann deshalb kein Abrieb entstehen, der das Zeichen unleserlich macht. Die Schriftzeichen sind auf der Folie so angebracht, dass sie die Originalbeschriftung der Tastatur nicht überdecken.\n\nPopulär wurden die Aufkleber bei der Einführung des Euro, um das seinerzeit auf Tastaturen nicht angegebene nachzutragen, heute befindet es sich standardmäßig auf (-).\n"}
{"id": "5733590", "url": "https://de.wikipedia.org/wiki?curid=5733590", "title": "Mixxx", "text": "Mixxx\n\nMixxx ist eine freie, plattformübergreifend verfügbare DJing-Software mit Digital-Vinyl-Funktionen.\nEs wird seit 2002 als freie Software unter den Bedingungen der GNU General Public License (GPL) für alle verbreiteten (Desktop-)Betriebssysteme/Plattformen (Windows, macOS, Linux) veröffentlicht.\n\nMixxx bietet vier virtuelle Plattenspieler mit Tonhöhenregelung (Pitch-Shifting) und automatischem Beatmatching.\nZum Vorhören ohne Störung des Hauptausgabekanals kann entweder ein zweiter Kanal der vorhandenen oder auch eine zweite Soundkarte verwendet werden.\nDie Software kann den BPM-Wert von Musikstücken automatisch ermitteln und ein Beatmatching zu einem anderen Stück vornehmen, das dazu auch unter Vermeidung von Veränderungen in der Tonhöhe (durch Streckung) in erhöhter oder verringerter Geschwindigkeit wiedergegeben werden kann. Schlägt die automatische BPM-Erkennung fehl, so kann durch Mitklopfen (Mitklicken) des Takts manuell nachgeholfen werden.\nDie Unterstützung für Audioformate umfasst zunächst MP3, Ogg Vorbis, WAV, AIFF und FLAC und kann durch Decodermodule um weitere Formate ergänzt werden.\n\nMixxx importiert ein beliebiges Verzeichnis, welches die Musikdateien enthält, in seine Musikbibliothek.\nZusätzlich kann auch auf fremde Musikbibliotheken zugegriffen werden, unter Linux auf die Rhythmbox-Bibliothek, unter Windows und Mac auf die ITunes-Bibliothek.\nMusikstücke können sowohl mittels Wiedergabelisten als auch sogenannten \"Crates\" (englisch für „Kiste“) organisiert werden.\n\nIst eine Abwesenheit des DJs erforderlich, kann eine Auto-DJ-Funktionalität eingeschaltet werden, die vollautomatisch eine bestimmte Musikauswahl abspielt und auch das Überblenden selbstständig vornimmt.\n\nMixxx kann über die grafische Benutzeroberfläche oder externe Steuergeräte gesteuert werden. Dazu kennt es die Kommunikationsmuster für einige MIDI-Controller und bietet für weitere eine Lernfunktion. Mixxx kann auch über herkömmliche Plattenspieler in Verbindung mit verschiedenen Timecode-Platten gesteuert werden. Die graphische Benutzeroberfläche kann mit Skins angepasst werden.\n\nMixxx bietet einen Equalizer und Filter zur Nachbehandlung und kann Mix-Sitzungen mitschneiden.\n\nDie Software ist in C++ geschrieben und verwendet Qt für die graphische Benutzeroberfläche.\nUm eine Vielzahl an Timecode-Signalformaten zu unterstützen, wird die Software \"xwax\" als Programmbibliothek eingebunden. Zur Streckung des Audiosignals wird Code aus der Programmbibliothek \"SoundTouch\" verwendet.\nFür besonders niedrige Latenz und Reaktionszeiten kann unter Linux JACK bei der Tonausgabe eingesetzt werden, was allerdings die Ausgabe auf ein Gerät (Soundkarte) beschränkt. Weiterhin werden unter Windows ASIO, die Windows Audio Session API (WASAPI) und DirectSound, unter Linux OSS und ALSA sowie Core Audio unter Mac OS X unterstützt.\n\nDas Projekt begann Anfang 2001 im Rahmen einer Doktorarbeit.\nIn den Jahren 2007, 2008, 2010 und 2012 wurden dem Projekt im Rahmen des Google Summer of Code jeweils mehrere Programmierstipendien zuteil.\nNachdem sich Final Scratch von Linux verabschiedete gehört Mixxx – neben UltraMixer – zu den wenigen unter Linux lauffähigen DJ-Programmen; es gibt hier fertige Installationspakete für Debian-basierte Systeme, bei Debian und Ubuntu findet sie sich in den Software-Repositorien.\n\n"}
{"id": "5733718", "url": "https://de.wikipedia.org/wiki?curid=5733718", "title": "Windows Imaging Format Archive", "text": "Windows Imaging Format Archive\n\nDas Windows Imaging Format (WIM) ist ein dateibasiertes Disk-Image- bzw. Archiv-Format, entwickelt von Microsoft für Windows Vista, Windows 7 und Windows Server 2008 (für deren Installation es auch verwendet wird).\n\nIm Gegensatz zu gewöhnlichen Disk-Image-Formaten für CD/DVD (wie codice_1 oder codice_2/codice_3) bildet eine WIM-Datei keine physikalischen Sektoren ab, sondern enthält wie ein Archiv eine Anzahl von Dateien + Metadaten, die ein Dateisystem konstituieren (dateibasiertes Disk Image).\n\n\nImageX ist ein Kommandozeilen-Programm zum Erstellen, Mounten und Bearbeiten von WIM-Images. Es ist Teil des Windows Automated Installation Kit (WAIK) von Microsoft.\n\nImageX Kommandozeilen-Optionen (Auswahl):\n"}
{"id": "5737381", "url": "https://de.wikipedia.org/wiki?curid=5737381", "title": "Microsoft Gadget", "text": "Microsoft Gadget\n\nEin Microsoft Gadget ist ein Miniprogramm (Widget), das auf dem Desktop unter Windows Vista und Windows 7 angezeigt werden kann. Gadgets können frei auf dem Desktop oder in einer Sidebar, die in Windows 7 wegfiel, platziert werden. Die geöffneten, aktiven Minianwendungen erscheinen nicht wie sonst üblich in der Taskleiste von Windows.\n\nMit Windows 8 wurden die Funktion von Microsoft eingestellt, da das Unternehmen systembedingt eine erhebliche Gefährdung sah. Als Ersatz wurden Windows-Apps eingeführt.\n\n\nDas Programm Kurznotizen, welches in Windows 7 enthalten ist, zählt nicht zu den Minianwendungen, weil es nicht auf dem Desktop verankert werden kann und als geöffnetes Programm in der Taskleiste erscheint.\nWeitere Minianwendungen (z. B. Nachrichtenticker, kleine Spiele, Überwachungstools für Computer usw.) können bei Microsoft und anderen Anbietern im Internet meist kostenlos heruntergeladen werden.\n\nAls Programmiersprachen kommen JavaScript und HTML zum Einsatz.\n\nDie Minianwendungsgalerie-Website wurde aufgrund des Windows 8 App-Angebots geschlossen.\n\nMicrosoft gab auch bekannt, dass die Sidebar und die Gadgets aufgrund einer Sicherheitslücke eingestellt wird.\nAuf anderen Websites gibt es weiterhin Gadgets.\n\n"}
{"id": "5738313", "url": "https://de.wikipedia.org/wiki?curid=5738313", "title": "Zentyal", "text": "Zentyal\n"}
{"id": "5740239", "url": "https://de.wikipedia.org/wiki?curid=5740239", "title": "HTC HD7", "text": "HTC HD7\n\nDas HTC HD7 (auch bekannt als HTC Schubert, HTC HD3) ist ein Smartphone des taiwanesischen Herstellers HTC Corporation. Es nutzt das Betriebssystem Windows Phone 7.\n\nDas HTC HD7 gehört zu den ersten verfügbaren Smartphones, welche Microsofts neustes mobiles Betriebssystem Windows Phone 7 einsetzen. Um (ähnlich dem Apple iPhone) eine gesicherte Qualität zu erlangen, setzte Microsoft strenge (Mindest-)Anforderungen an die Geräte-Hersteller fest, was in einigen Bereichen zu starken Einschränkungen und einer Erschwerung bei der Schaffung eines Alleinstellungsmerkmales führt. So glänzte das erste HD-Modell des Herstellers HTC (wobei HD als Abkürzung für \"High Definition\", also hochauflösend steht), das HTC Touch HD, mit einer bis anhin noch nicht dagewesenen hohen Display-Auflösung. Bei Windows Phone 7-Geräten ist WVGA (480×800 Pixel) eine feste Vorgabe, was den eigentlichen Sinn hinter dem Gerätenamen ad absurdum führt. Auch HTCs sehr beliebte Weiterentwicklung der Benutzeroberfläche, HTC Sense, kann künftig nicht mehr in dem Rahmen eingesetzt werden wie noch unter Windows Mobile und Android.\n\nDas HTC HD7 ist seit dem 21. Oktober 2010 offiziell in Europa erhältlich .\nNeben dem freien Handel wird das Smartphone auch in Kooperation mit verschiedenen Mobilfunkkonzernen angeboten.\n\nIn Deutschland ist das HTC HD7 exklusiv beim Anbieter O2 erhältlich .\n\nDie Version, welche von O2 angeboten wird, verfügt im Gegensatz zum europäischen Standard über 16 GB statt nur 8 GB Speicher .\n\nO2 gab bekannt, dass das HD7 schon nach der ersten Woche komplett ausverkauft war.\n\nAls Partner für den Vertrieb des HD7 konnte HTC in Österreich das Mobilfunkunternehmen A1 sowie deren Konkurrenten 3 gewinnen .\n\nIn der Schweiz erhielt jedes der drei großen Mobilfunkunternehmen jeweils eines der drei HTC WP7-Smartphones, welche für den europäischen Raum freigegeben wurden, zugesprochen.\nHierbei erhielt Sunrise Communications den Zuschlag für das HTC HD7; Orange vertreibt künftig das HTC 7 Mozart und die Swisscom das HTC 7 Trophy .\n\nAls Hardware-Basis kommt ein Snapdragon-Chipset des Typs QSD8250 zum Zuge, welches bereits im Vorgänger HTC HD2 verbaut war. Der mit 1 GHz taktende Prozessorkern namens Scorpion ist vergleichbar mit dem \"ARM-Cortex-A8\"-Kern und wird von 576 MB Arbeitsspeicher unterstützt. Grafische Berechnungen übernimmt der fest auf der Platine verbaute Adreno 200-Chip von Qualcomm, welcher unter anderem den OpenGL-ES-2.0- sowie Direct3D-Standard beherrscht.\nDas QSD8250-Chipset stellt die erste Generation der Snapdragon-Produktelinie dar und unterstützt mehrere Mobilfunkstandards, darunter GPRS, EDGE, UMTS und HSPA.\nZudem beinhalten alle Snapdragon-Chipsets Recheneinheiten zum Dekodieren von HDTV mit einer Auflösung von 720p sowie einen GPS-Empfänger.\n\nDas HD7 verfügt über einen 4,3 Zoll (10,9 cm) großen kapazitiven Multi-Touch-Screen, welcher mit 480×800 Pixel (WVGA) auflöst und eine Farbtiefe von 24 Bit (nach dem HTC Update nur noch 16 Bit) anzuzeigen vermag, was rund 16,78 Millionen Farben entspricht (True Color).\n\nEntgegen anderen Modellen, wie etwa dem Samsung Omnia 7, kommt im HTC HD7 kein festgelöteter NAND-Speicher zum Zuge, sondern ein interner, nicht frei zugänglicher SD-Kartenslot. Je nach Ausführung befindet sich in dem Kartenslot eine 8 oder 16 GB SDHC-Speicherkarte der Geschwindigkeitsklasse Class 4 des Herstellers SanDisk. Der interne ROM-Speicher mit einer Kapazität von 512 MB wird hierbei, gemeinsam mit der SD-Karte, in einem JBOD-Verbund zu einem Speicher zusammengefügt; innerhalb des Betriebssystems kann also nicht mehr zwischen ROM oder SD-Karte unterschieden werden.\n\nDie integrierte Kamera kann Fotos mit einer Auflösung bis zu 5 Megapixel (2.560 × 1.920 Pixel) schießen. Zur Lichtmessung kommt ein aktiver Pixelsensor (auch bekannt als \"CMOS-Sensor\") zum Zuge. Unterstützung erhält die Kamera dabei von einem Dual-LED-Blitzlicht. Die Kamera kann zudem Filme mit einer Auflösung bis zu 720p (1280 × 720 Pixel) aufnehmen. Im Weiteren stehen dem Nutzer verschiedene Aufnahmeprogramme zur Verfügung, darunter \"Kerzenschein\", \"Landschaft\" und \"Portrait\".\n\nDrahtlos kommuniziert das HD7 per WLAN-Standard 802.11 b/g/n, GPRS, EDGE, UMTS, HSPA und Bluetooth 2.1. Zudem ist eine A-GPS-Antenne eingebaut.Es werden die Bluetooth-Profile A2DP, AVRCP, HFP, HSP und PBAP unterstützt.\n\nAls Sensoren dienen ein G-Sensor, ein digitaler Kompass, ein Näherungssensor sowie ein Umgebungslichtsensor.\n\nDie Maße des Smartphones betragen 122×68×11,2 mm (H×B×T), wobei das Gerät auf ein Gewicht von 162 Gramm (mit Akku) kommt.\n\nDer Lithium-Ionen-Akku hat eine Nennkapazität von 1230 mAh.\n\nHTC gibt eine Laufzeit des Akkumulators im GSM-Netz von rund 380 Minuten Gespräch oder 310 Stunden (entspricht knapp 13 Tagen) im Standby an.\n\nAls Besonderheit hat das HD7 einen sogenannten \"Kickstand\" (Ständer) erhalten, wodurch sich das Gerät für den medialen Genuss aufrecht auf einer Tischplatte positionieren lässt.\n\nNeben dem HTC HD7 erhielt nur das in Europa (aktuell) nicht erhältliche HTC 7 Surround einen solchen Ständer.\n\nDie Modelle HTC 7 Trophy sowie HTC 7 Mozart, welche ebenfalls am 11. Oktober 2010 offiziell vorgestellt wurden, gehören zur selben Veröffentlichungs-Generation von HTC für Microsoft Windows Phone 7 wie das HTC HD7. Noch unklar ist, ob das Modell HTC 7 Surround in D-A-CH oder generell in Europa erscheinen wird. Das einzige Gerät der ersten Generation von \"Windows Phones\" mit Hardware-Tastatur, das HTC 7 Pro, wurde vom Provider O2 für den Januar 2011 für den deutschen Markt angekündigt.\n\nDa die Launch-Geräte von HTC für Windows Phone 7 alle die gleiche Hardware-Basis haben, sind die Unterschiede teilweise erst im Detail zu finden.\n\nErweiterung des internen Speichers\n\nNur wenige Tage nach dem offiziellen Release des HTC HD7 wurden bereits erste Berichte veröffentlicht, in denen geschildert wird, wie der interne Speicher durch Ersetzung der SDHC-Karte erweitert werden kann. Hierfür müssen an mehreren Stellen unterhalb des Akku-Faches Torx-Schrauben gelöst werden, um an den Kartenslot zu gelangen. Wird allerdings die Karte, welche über eine maximale Kapazität von 32 GB verfügen darf, getauscht, so wird das Betriebssystem aufgrund der Trennung des JBOD-Verbundes von ROM und SD-Karte unbrauchbar und muss mittels Hardreset komplett rückgesetzt werden; es werden also sämtliche persönlichen Daten gelöscht.\n\nGemäß mehreren Berichten innerhalb der Online-Community XDA Developers funktionieren zudem nicht alle SDHC-Karten. Während Karten des Herstellers SanDisk, welche auch standardmäßig von HTC eingebaut werden, scheinbar problemlos funktionieren, so erwiesen sich die getesteten 32 GB-Versionen von Kingston als unbrauchbar.\n\nEin weiteres Problem stellt die Tatsache dar, dass die nun entfernte SD-Karte aufgrund einer unbekannten Formatierung nicht ohne weiteres abseits eines Windows-Phone-7-Smartphones, beispielsweise am Computer oder in einer Digitalkamera, benutzt werden kann. Hier hilft aktuell lediglich ein Workaround unter Beizug eines Symbian-Smartphones.\n\nAuf der Video-Plattform YouTube wurde ein Video veröffentlicht, welches den Wechsel der SD-Karte im Detail zeigt, ohne dass ein Verlust der Garantie erfolgt.\n\nWeiter sind auch Modifikation im Bereich Software möglich die sogenannten Custom ROM die ihren Ursprung bei den XDA-Developer hatten, aber mittlerweile auch in Deutschen Windows Phone Foren erhältlich sind.\n\nVor der offiziellen Ankündigung seitens HTC kursierten viele Spekulationen hinsichtlich der möglichen Leistungsdaten des HD7, welche die Messlatte der Erwartungen bei den Interessenten sehr hoch anlegte. Dies insbesondere deswegen, da die \"HD\"-Modell von HTC bis dahin stets als die Flaggschiffe des eigenen Portfolios galten. Die Gerüchte prophezeiten dem HD7 (damals noch \"HD3\" genannt) unter anderem ein 4,5 Zoll Display mit einer Auflösung von 800×1280 Pixeln sowie einem 1,5 GHz starken Snapdragon-Chipset. Neben der Möglichkeit Full-HD-Filme (1080p) wiederzugeben, sollte das HD7 auch bereits den neusten 4G-Standard LTE implementiert haben. HTC kommentierte oder bestätigte solcherlei Gerüchte nie.\n\nEntsprechend hoch war dann die Zahl derer die enttäuscht waren, als die ersten effektiven Randdaten des Gerätes veröffentlicht wurden. Vor allem die Tatsache, dass sich das Gerät kaum von seinem Vorgänger, dem einjährigen HTC HD2, unterschied, sorgte für großen Frust.\n\nAuf großes Unverständnis stieß die Wahl des verbauten Snapdragon-Chipsets – Mit dem QSD8250 wurde die erste und somit älteste Generation gewählt, wohingegen HTC in der Android-Sparte bei Geräten wie dem HTC Desire HD bereits die zweite Generation (MSM8255) einbaute. Durch den Shrink von 65 nm auf 45 nm konnte bei den neueren Chipsets nicht nur die Leistungsfähigkeit erhöht, sondern auch der Energieverbrauch gesenkt werden. Zudem sanken die Produktionskosten, da mehr Dies per Wafer gefertigt werden können.\n\nEin weiterer Nachteil bei der Verwendung des älteren Snapdragon-Chipsets liegt in der verbauten GPU. War die erste Generation noch mit einer Adreno 200-GPU bestückt, so verrichtet in der zweiten Generation die deutlich leistungsfähigere Adreno 205 ihre Dienste . In einem Durchlauf des \"3DMarkMobile ES 2.0\" Benchmarks der Firma Rightware (vormals der Firma Futuremark), wurde der Adreno 205-GPU rund viermal höhere Leistungswerte zugesprochen als noch dem Vorgänger Adreno 200.\n\nAls absolutes No-Go stellte für viele jedoch erst die Tatsache dar, dass HTC einem Gerät, welches auf die mediale Nutzung ausgelegt ist, nur 8 GB Speicher ausrüstete. Dies empfinden viele gerade deswegen als frappant, da das Gerät über keinen frei zugänglichen Speicherkarten-Slot verfügt, der Speicher also nicht ohne Modifikation erweitert werden kann \"(Siehe auch: Erweiterung des internen Speichers)\". Einige Mobilfunkanbieter, wie etwa der deutsche Anbieter O2, wirken dem mit einer Sonderversion mit 16 GB verbautem Speicher entgegen.\n\n"}
{"id": "5741128", "url": "https://de.wikipedia.org/wiki?curid=5741128", "title": "HTC 7 Mozart", "text": "HTC 7 Mozart\n\nDas HTC 7 Mozart ist ein Windows Phone 7 Smartphone des Herstellers HTC Corporation.\n\nWindows Phone 7 wurde im Oktober 2010 freigegeben und an die ersten Hersteller ausgeliefert. Das HTC 7 Mozart war ab dem 3. November 2010 über Telekom Deutschland erhältlich.\n\nDas HTC 7 Mozart verfügt über einen 3,7 Zoll großen kapazitiven Touchscreen und einen Qualcomm QSD8250 Snapdragon System-on-a-Chip mit einem 1-GHz ARM Cortex A8 Single-Core-Prozessor. Als Betriebssystem kommt Microsoft Windows Phone 7 zum Einsatz. Im Smartphone ist eine 8-Megapixel-Kamera mit Xenon-Blitzlicht verbaut, die Videos mit 720p (HD) aufnehmen kann. Der NAND-Flash-Speicher des Mozart beträgt 8 oder 16 GByte; der Arbeitsspeicher (RAM) beträgt 576 MByte. Drahtlos kommuniziert das 7 Mozart per GPRS, EDGE, UMTS, Wi-Fi (802.11 b/g/n), Bluetooth 2.1 und GPS. Es verfügt über einen Beschleunigungssensor, einen Umgebungslichtsensor, einen Annäherungssensor und einen digitalen Kompass. Ein voll aufgeladener Akku reicht laut Hersteller bei der Gesprächszeit für bis zu 320 Minuten, bei der Standby-Zeit bis zu 320 Stunden. Die Maße des 7 Mozart betragen 119 mm × 60,2 mm × 11,9 mm und es wiegt 130 g.\n"}
{"id": "5751643", "url": "https://de.wikipedia.org/wiki?curid=5751643", "title": "Proteus (Software)", "text": "Proteus (Software)\n\nProteus ist ein Softwarepaket für den computerunterstützten Entwurf, die Simulation und das Design elektronischer Schaltungen. Es besteht aus zwei Hauptteilen, dem \"ISIS\", die Schaltungsentwurfsumgebung, welche auch den Simulator \"VSM\" beinhaltet, und dem \"ARES\", dem Leiterplatten-Designer. Entwickler und Hersteller des Softwarepaketes ist die Firma Labcenter Electronics.\n\nMit Proteus PCB Design können elektronische Schaltungen und Leiterplatten (engl. printed circuit boards) computerunterstützt entworfen werden.\n\nDas ISIS, Intelligent Schematic Input System (\"Intelligentes Schaltungs-Eingabe-System\") ist die Umgebung für den Entwurf und die Simulation elektronischer Schaltungen.\n\nDie Bauteilbibliothek umfasst nach eigenen Angaben \n\nISIS enthält eine Basis-VSM-Engine mit Unterstützung folgender Funktionalitäten:\n\nDas VSM, Virtual System Modeling (\"Virtuelle System-Modellierung\"), ermöglicht eine grafische SPICE Schaltungssimulation und -animation direkt in der ISIS-Umgebung. Der SPICE-Simulator basiert auf dem Berkeley-SPICE3F5-Modell.\n\nEs können mikroprozessororientierte Systeme simuliert werden. Mit der VSM-Engine kann während der Simulation direkt mit der Schaltung interagiert werden. Änderungen von Tastern, Schaltern oder Potentiometern werden in Echtzeit abgefragt sowie LED-Indikatoren, LC-Displays und \"Hot/Cold\"-Wires angezeigt.\n\n\nDie Mikrocontroller werden (bis auf wenige Ausnahmen, die in der Anleitung explizit angeführt werden) in der Peripherie und im Code voll unterstützt (Interrupt, ADC, I2C, USB, Komparatoren u. a.). Es enthält eine Debugumgebung für den Programmcode des Mikrocontrollers. Für die Simulation sind die .HEX- und die .COF-Datei der kompilierten Software notwendig. Der Takt wird in Echtzeit simuliert.\n\n\n\nDie ARES, Advanced Routing and Editing Software (\"Höheres Routing- und Editier-System\"), ist eine Software zum Leiterplatten-Design. Sie ist per Drag & Drop zu bedienen, hardwarebeschleunigt und erlaubt \"shape based\" Autorouting und Autoplacement.\nIn manchen Versionen ist ein Export der 3D-Schaltung in .DXF-Dateien möglich.\n\n"}
{"id": "5757720", "url": "https://de.wikipedia.org/wiki?curid=5757720", "title": "Tianhe-1A", "text": "Tianhe-1A\n\nDer Tianhe-1A (, Milchstraße-1A) ist ein chinesischer Supercomputer. \n\nMit einer Rechenleistung von 2,56 Petaflops (gemessen nach Linpack-Benchmark) löste der Tianhe-1A im November 2010 den US-amerikanischen Cray Jaguar (1,76 PFLOPS) als bis dahin weltweit leistungsstärksten Supercomputer ab. Im Juni 2011 wurde dieser Rekord vom viermal schnelleren japanischen Fujitsu K computer (10,51 PFLOPS) übertroffen.\n\nMit einer Anschlussleistung von etwa 4 Megawatt ist er deutlich energieeffizienter als sein Vorgänger an der Spitze, der Jaguar des Oak Ridge National Laboratory (etwa 7 Megawatt).\n\nIm Juni 2012 galt der Tianhe-1A als das fünftschnellste Rechnersystem der Welt, hinter dem SuperMUC in München (2,9 PFLOPS). Die theoretische Maximalleistung liegt bei 4,67 Petaflops. Der Tianhe-1A besteht aus 7.168 Nvidia Tesla M2050 GPGPUs mit je 448 Prozessorkernen und 14.336 Intel Xeon X5670 CPUs mit je sechs Prozessorkernen. Er wurde von der National University of Defense Technology entwickelt und steht im National Supercomputing Center in Tianjin. Als Betriebssystem dient eine speziell angepasste Linux-Distribution.\n\nDas Nachfolgesystem Tianhe-2 war mit rund 13-facher Rechenleistung (33,86 PFLOPS) vom Juni 2013 bis zum Juni 2016 der weltweit leistungsstärkste Supercomputer.\n\nDer Computer musste am 13. August 2015 heruntergefahren werden, nachdem das Gebäude des National Supercomputing Center bei einer Explosion in Tianjin beschädigt wurde. Der Computer selbst wurde nicht beschädigt.\n\n"}
{"id": "5759506", "url": "https://de.wikipedia.org/wiki?curid=5759506", "title": "Msconfig", "text": "Msconfig\n\nDie Datei msconfig.exe, betitelt mit \"Systemkonfiguration\", ist ein natives Konfigurationsprogramm für Microsoft Windows, welches mithilfe des Kommandozeilenbefehls \"msconfig\" gestartet werden kann. Das Programm erlaubt teilweise die Konfiguration des Systemstarts und das Verwalten von automatischen Starts diverser Programme und Systemdienste.\n\nDer automatische Start verschiedener Programme und Dienste ließ sich in früheren Windows-Versionen mit Hilfe der AUTOEXEC.BAT und CONFIG.SYS verwalten. \"msconfig\" löst diese Dateien ab und stellt eine grafische Oberfläche für den Benutzer zur Verfügung. Die Datei wird mit Ausnahme von Windows 2000 nativ bereitgestellt, mit dem Service Pack 2 für Windows XP wurde sie funktionell erweitert. Die Funktionsvielfalt des Programms unterschied sich innerhalb der Windows-Betriebssystemversionen leicht.\n\nDas Programm bietet dem Benutzer die Möglichkeit, den Startmodus des Betriebssystems einzustellen. Hierbei ist ein \"Diagnosesystemstart\" wählbar, bei dem nur die nötigsten Geräte und Dienste geladen werden; diese Option wird meist zum Beheben von Startproblemen verwendet. Des Weiteren können die Systemstarts anderer Betriebssysteme verwaltet werden, ebenso kann auch ein Start ohne grafische Benutzeroberfläche (GUI) veranlasst werden. Ein Menüpunkt befasst sich mit der Verwaltung für automatisch zu startende Programme und Dienste. Des Weiteren stellt Msconfig Programmverknüpfungen für verschiedene Windowseinstellungen bereit, etwa die Benutzerkontensteuerung oder das Windows-Sicherheitscenter.\n\n\n"}
{"id": "5760045", "url": "https://de.wikipedia.org/wiki?curid=5760045", "title": "Chessmate", "text": "Chessmate\n\nDer Commodore Chessmate ist ein Schachcomputer des Anbieters Commodore International, der im Juni 1978 auf den Markt kam.\n\nDer Schachcomputer basierte auf dem Einplatinencomputer KIM-1, der auch von Commodore vertrieben wurde. Als Schachprogramm war auf dem ROM des Gerätes das Programm „Microchess 1.5“ von Peter R. Jennings integriert worden. Um die einzelnen Schachzüge auf dem Gerät darzustellen, benutzte man eine vierstellige 7-Segment-Anzeige. Die Zugeingabe erfolgte über eine Folientastatur.\n\nEr beinhaltet neben einem minimalen Computersystem eine Schachbibliothek mit 32 Eröffnungen je 16 Züge. \n\nDer Schachcomputer wird über ein Netzteil betrieben und über einen Schalter ein- bzw. ausgeschaltet. Die Zugeingabe erfolgt über die Tasten bis und bis bzw. und mit der Bestätigung von und die Zugausgabe und Zeitanzeige über 4 LEDs sowie über die leuchten \"Black\", \"White\", \"Check\" und \"CHESSmate loses\". Weiterhin gibt es noch die zusätzlichen Tasten (für neues Spiel) und (Eingabekorrektur). Außerdem sind die Eingabetasten noch mit den Zusatzfunktionen für die Spieloptionen \"Board Verify\" (Schachcomputertest), \"Chess Clock\" (Schachuhr ein), \"Display Time\" (Schachuhr anzeigen), \"Stop Time\" (Schachuhr anhalten), \"Skill Level\" (Schwierigkeitsstufe), \"Game Moves\" (Spielzüge) sowie \"Black\" (Schwarz) und \"White\" (Weiß) belegt.\n\n\n"}
{"id": "5766163", "url": "https://de.wikipedia.org/wiki?curid=5766163", "title": "Wartungscenter", "text": "Wartungscenter\n\nDas Wartungscenter (in Windows Vista Windows-Sicherheitscenter, in Windows XP Sicherheitscenter) wurde von Microsoft mit dem Service Pack 2 für Windows XP eingeführt. Es dient zur Überprüfung der Sicherheitseinstellungen des PCs. \n\nAnwender sollen sich bei der Sicherheit ihres Windows-PCs aber nicht nur auf die Angaben des Windows-Sicherheitscenter verlassen, da es auch Computerviren oder Spyware u. a. gibt, die den Status des Windows-Sicherheitscenter manipulieren können, was teilweise Anlass zur Kritik am Sicherheitscenter war.\n\nSicherheitselemente:\nAb Windows 7 gibt es weitere Funktionen:\n\n"}
{"id": "5767358", "url": "https://de.wikipedia.org/wiki?curid=5767358", "title": "KDE Plasma Workspaces", "text": "KDE Plasma Workspaces\n\nDie KDE Plasma Workspaces sind ein Satz von Desktop-Umgebungen von KDE. Sie sind die Nachfolger des \"K Desktop Environments\" und stellen ein eigenständiges Produkt innerhalb der Programmsammlung KDE Software Compilation 4 dar. Der Nachfolger dieser retrospektiv auch kurz „KDE Plasma 4“ genannten Desktop-Umgebungen ist seit Juli 2014 KDE Plasma 5, bei dem nicht mehr verschiedene \"Workspaces\" (PC, Netbook, Tablet etc.) individuell bestehen, sondern eine einheitliche grafische Oberfläche existiert, die sich automatisch auf unterschiedliche Geräte einstellt.\n\nIn \"K Desktop Environment 1\" wurde der Desktop-Hintergrund, ähnlich wie unter Windows, vom Dateimanager dargestellt. Ab Version 2 wurden die Funktionen auf separate Programme ausgelagert: Während Dateiverwaltungsfunktionen seitdem von Konqueror bereitgestellt werden, wurden Desktop und Taskleiste von \"KDesktop\" und \"Kicker\" verwaltet.\n\nInsbesondere ab 2005 erlangten Widget-Engines zunehmende Verbreitung, die Miniprogramme auf der Desktop-Oberfläche darstellen. So verfügte auch das KDE-Projekt mit SuperKaramba über eine Widget-Engine. Gleichzeitig erlaubte Kicker es, Miniprogramme in die Taskleiste zu integrieren, die aber technisch inkompatibel zu den Widgets von SuperKaramba waren. Während der Entwicklung von KDE 4.0 entschieden sich einige KDE-Entwickler unter Führung des Kicker-Chefentwicklers Aaron J. Seigo dazu, die Desktop-Komponenten KDesktop, Kicker und SuperKaramba wieder in einer Anwendung zu vereinigen.\n\nIm Gegensatz zu den vorherigen Generationen erlaubt das flexible Design des technischen Fundaments, insbesondere Plasma, die Anpassung an unterschiedlichste Geräte-Typen und -Formfaktoren. Das KDE-Projekt nennt die daraus resultierenden unterschiedlichen Oberflächen \"Workspaces\".\n\n\"Plasma Desktop\" ist die Oberfläche, die als erstes fertiggestellt und als Technikvorschau mit KDE 4.0 mitgeliefert wurde. Sie richtet sich an Desktop-PCs und Notebooks, die in erster Linie mit einer Maus (Computer) oder ähnlichen Zeigegeräten bedient werden. Das Standard-Layout der Bedienelemente lehnt sich grob an die früheren \"K Desktop Environments\" und Windows an: Eine Taskleiste mit Uhr und Benachrichtigungsfeld am unteren Bildschirmrand, Icons können per „Ordner-Ansicht“-Element auf dem Bildschirmhintergrund abgelegt werden.\n\nAbgesehen von der Standard-Anordnung können die Bedienelemente aber fast völlig frei platziert werden.\n\n\"Plasma Netbook\" ist die zweite Oberfläche, die fertiggestellt wurde und sich an Netbooks richtet. Sie wird offiziell seit der im Februar 2010 erschienenen Version 4.4 ausgeliefert, wenn auch Kubuntu bereits im Oktober 2009 eine unfertige Technikvorschau auf Basis von SC 4.3 veröffentlichte.\n\nDie Netbook-Oberfläche besteht im Wesentlichen aus zwei Ansichten:\n\nDa Netbooks recht kleine Bildschirme haben, werden Anwendungen stets im Vollbild ausgeführt. Außerdem werden die Fensterrahmen samt Bedienelementen standardmäßig ausgeblendet, um Bildschirmplatz zu sparen.\n\n\"Plasma Active\", eine Oberfläche für Tablet-PCs und Tabletcomputer, wurde am 9. Oktober 2011 veröffentlicht. Die Anpassungen dieser Oberfläche an Smartphones erfolgt unter dem Namen \"Plasma Mobile\". Eine benutzbare Version planen die Entwickler für die KDE-Entwicklerkonferenz Akademy 2016.\n\nAn die Touchscreens dieser Geräte müssen auch Anwendungen angepasst werden. Der erste Schritt in diese Richtung war ein auf Basis von Calligra Suite/KOffice im Auftrag von Nokia entwickelter Dokumentenbetrachter für das N900.\n\nWeitere Schritte sind die Portierungen der Kontact-Anwendungen. Im Rahmen dieser Portierungsarbeit wird auch auf Basis der \"Qt Markup Language\" (QML) eine Oberflächenbibliothek entwickelt, die von anderen KDE-Anwendungen benutzt werden kann.\n\nKernkomponente der \"Plasma Workspaces\" ist das \"Plasma\" genannte Oberflächen-Framework, das jedoch für sich genommen keine Desktop-Umgebung ist. Weitere Kernkomponenten sind der Composition- und Fenstermanager \"KWin\" sowie der KDE Display Manager (KDM), welcher mit Plasma 5 jedoch nicht mehr weitergepflegt und bevorzugt durch SDDM ersetzt wurde. Darüber hinaus sind einige weitere Komponenten wie z. B. Daemons darin enthalten.\n\nPlasma wurde mit dem Ziel entworfen, nicht eine weitere Implementation einer Desktop-Oberfläche darzustellen, sondern ein allgemeines Framework zur Erstellung von Benutzerschnittstellen. Die tatsächliche Desktopoberfläche stellt aus diesem Blickwinkel lediglich eine Beispielimplementation dar. Tatsächlich wird Plasma auch in nicht mit dem Desktop zusammenhängenden Programmen verwendet, insb. für die Kontextansicht des KDE-Medienspielers Amarok (ab Version 2.0).\n\nDie Oberfläche in Plasma besteht aus \"Widgets\" (engl. für \"Miniprogramm\"), die in sich geschlossene Anwendungsfälle grafisch repräsentieren. (Synonym wird der Begriff \"Applet\", vereinzelt auch \"Plasmoid\", verwendet.) Auf einem Desktop ist zum Beispiel eine Uhr ein Widget, das zur Anzeige der aktuellen Uhrzeit dient.\n\nDie Anordnung der Widgets auf der Oberfläche wird durch spezielle übergeordnete \"Widgets\", sogenannte \"Containments\" (engl. für \"Behältnis\") bestimmt, die den Widgets bestimmte geometrische Vorgaben (\"Formfaktor\") aufzwingen können. Während Widgets zum Beispiel auf dem Desktophintergrund frei schweben und eine (fast) beliebige Größe haben können, sind sie in der Taskleiste in der Höhe stark beschränkt. Fast alle Widgets in Plasma passen ihre Form entsprechend dem äußeren Formfaktor an: Während zum Beispiel das Startmenü-Widget auf dem Desktop immer das komplette Startmenü zeigt, wird es in der Taskleiste zu einem Knopf, der das Startmenü beim Anklicken einblendet.\n\nEin zentraler Punkt bei Plasma ist die Trennung von Daten und Darstellung: Während sich im Idealfall ein Widget nur um die Darstellung von Daten kümmert, wird die Beschaffung und Aufbereitung von Daten von einer \"Data-Engine\" (engl. für \"Datenmaschine\") übernommen. Eine ähnliche Struktur ermöglicht die aktive Interaktion von Widgets mit webbasierten Diensten.\n\nObwohl die Arbeit an Plasma im Juni 2005 begann, war die Software zur Veröffentlichung von KDE 4.0 im Januar 2008 noch nicht so ausgereift wie erhofft. Über den ganzen Jahresverlauf bemängelten viele Benutzer häufige Abstürze von Plasma, Geschwindigkeitseinbußen insbesondere in Verbindung mit Nvidia-Grafikkarten, sowie das Fehlen vieler von KDesktop und Kicker aus KDE-3-Zeiten bekannter Funktionen.\n\nEine besonders intensive Kontroverse entbrannte über Dateisymbole auf dem Desktop: Die traditionelle Aufgabe des Desktops ist die Darstellung der Dateien, die in einem speziellen Desktop-Ordner auf der Festplatte gespeichert sind, durch frei platzierbare Desktop-Symbole. Diese Funktionalität stand in KDE 4.0 nur sehr beschränkt zur Verfügung. Für KDE 4.1 wurde die Übergangslösung komplett entfernt und durch \"Ordner-Ansicht\" ersetzt, die allerdings erst mit KDE 4.2 vollständig implementiert wurde.\n\nMit der Version 4.2 galt die Desktop-Oberfläche als ausgereift. Testberichte waren ab diesem Zeitpunkt größtenteils positiv. Während 4.0 in keiner bekannteren Linux-Distribution außer Fedora \"K Desktop Environment 3.5\" ersetzte, wurde 4.2 als reif genug empfunden, um selbst in den Stabilisierungszweig der eher konservativen Distribution Debian aufgenommen zu werden, anstatt weiter auf \"K Desktop Environment 3.5\" oder dessen Fortführung Trinity Desktop Environment zu setzen.\n"}
{"id": "5770739", "url": "https://de.wikipedia.org/wiki?curid=5770739", "title": "Snarl", "text": "Snarl\n\nSnarl ist ein globales Benachrichtigungssystem für Windows. Programme informieren den Benutzer mittels Snarl über wichtige Ereignisse. Die Form der Benachrichtigung kann der Benutzer vollständig konfigurieren. So müssen Softwareentwickler keine eigenen Benachrichtigungssysteme mehr entwerfen, sondern die Meldungen nur noch an Snarl weitergeben.\n\nSnarl ist ein auf der Grundidee von Growl basierend, welches auf dem Macintosh ein häufig verwendetes Tool ist. Dort wird der Benutzer ebenfalls systemweit darüber informiert, wenn ein Programm die Aufmerksamkeit des Benutzers benötigt.\n\nMit Snarl kompatible Programme senden kurze Signale, wie zum Beispiel „Download beendet“ oder den gerade gespielten iTunes-Song, die dann als Snarl-Benachrichtigung im vom Benutzer ausgewählten Stil angezeigt wird.\n\nSnarl bietet Schnittstellen für Entwickler, die die unterschiedlichsten Programmiersprachen unterstützen. Es sind mehrere verschiedene APIs für verschiedene Anwendungszwecke wie lokale Applikationen oder Netzwerkdienste vorhanden.\n\nMehr als 60 Programme nutzen Snarl bereits direkt oder mittels dafür verfügbarer Add-Ons bzw. Extensions. Im Folgenden eine Auswahl:\n\n"}
{"id": "5778182", "url": "https://de.wikipedia.org/wiki?curid=5778182", "title": "Unity (Benutzeroberfläche)", "text": "Unity (Benutzeroberfläche)\n\nUnity ist eine zunächst durch das Unternehmen Canonical entwickelte Desktop-Umgebung für Linux-Betriebssysteme, die besonders sparsam mit Bildschirmplatz umgehen soll. Im Gegensatz zu Gnome, KDE SC 4 oder auch Xfce ist Unity keine Programmsammlung und soll in erster Linie mit bereits existierenden GTK+-Programmen benutzt werden.\n\nUnity wird als freie Software unter den Bedingungen der dritten Versionen von GNU General Public License (GPL) und GNU Lesser General Public License (LGPL) veröffentlicht.\nSeitdem Canonical die Entwicklung von Unity im April 2017 eingestellt hat, wird Unity von der UBports-Community weiterentwickelt, die auch die Entwicklung von Ubuntu Touch übernommen hat.\n\nUbuntu nutzte bis zur im Oktober 2010 erschienenen Version \"10.10\" Gnome 2 als Standard-Desktop-Umgebung in der Variante für Desktop-PCs. Da das Gnome-Projekt keine spezielle Oberfläche für Netbooks mit ihren kleinen Bildschirmen anbietet und die aus gleichem Grund bereits entwickelte Netbook-Oberfläche von Moblin/MeeGo nicht für geeignet gehalten wurde, entwickelte Canonical eine eigene Oberfläche für diesen Gerätetyp. Diese erschien erstmals mit Ubuntu 10.10. Die Arbeit an dieser Desktop-Variante von Unity begann auf dem \"Ubuntu Developer Summit 2010\", in dessen Rahmen der Wechsel in Ubuntu von Gnome auf Unity bekanntgegeben wurde.\n\nVon Ubuntu 11.04 bis Ubuntu 17.04 wird Unity als Standard-Oberfläche genutzt. Die vormals existierende Netbook-Version mit Unity wurde daher eingestellt. Mit Version 11.10 wurde Gnome 2 als Alternative entfernt und für leistungsschwächere PCs eine 2D-Version von Unity eingesetzt, die ab Ubuntu 12.10 ersatzlos gestrichen wurde.\n\nDas Gnome-Projekt und Canonical hatten bereits in der Vergangenheit Differenzen zur Ausrichtung. So passte Canonical zum Beispiel ein von KDE entwickeltes neues Protokoll zur Steuerung von Benachrichtigungsfeldern an Gnome 2 an, welches jedoch wegen fehlender Kompatibilität zu Gnome 3 und – laut Gnome – mangelnder Kommunikationsbereitschaft der Canonical-Entwickler durch das Gnome-Projekt abgelehnt wurde. Laut Canonical-Eigentümer Mark Shuttleworth lehne das Gnome-Projekt auch die von Mac OS bekannte, globale Menüleiste ab. Als Folge dieser Differenzen entschied sich Canonical, die neue Oberfläche von Gnome 3 auch auf Ubuntu für Desktop-PCs nicht zum Einsatz zu bringen und auch die alte Gnome-2-Oberfläche nur noch als Ausweichoption anzubieten, für den Fall einer Inkompatibilität zur installierten Grafik-Hardware.\n\nAm 5. April 2017 gab Mark Shuttleworth bekannt, dass die Arbeiten an Unity eingestellt werden und ab Ubuntu 18.04 wieder Gnome die Standard-Desktop-Umgebung für Ubuntu wird. Letztlich wurde bereits mit Ubuntu 17.10 wieder Gnome als Standard-Desktop eingesetzt.\n\nNach der Einstellung der Entwicklung von Unity durch Canonical, hat die UBports-Community die Entwicklung von Unity 8 übernommen. Erste Alpha Versionen für Ubuntu 16.04 LTS und Ubuntu 18.04 LTS stehen zum Testen bereit.\n\nUnity ist Teil des Ayatana-Projektes, einer Initiative zur Verbesserung der sogenannten \"User Experience\" innerhalb von Ubuntu. Neben Unity sind hierunter bspw. auch die Projekte \"MeMenu\", das Benachrichtigungssystem \"NotifyOSD\" und die \"Application Indicators\" versammelt. Außerhalb von Ubuntu bekam Ayatana bisher auch vom openSUSE-Projekt Unterstützung.\n\nDie Unity-Version, die mit Ubuntu 10.10 mitgeliefert wurde, ist in der Programmiersprache Vala geschrieben und nutzt die von Intel stammende Programmbibliothek \"Clutter\" für die Oberfläche. Seit Ubuntu 11.04 basiert Unity jedoch auf Compiz. Diese Version ersetzt einen Großteil des Vala-Codes durch C++ und setzt eine Programmbibliothek namens \"Nux\" statt \"Clutter\" ein. Unity setzt einen kompatiblen 3D-Beschleuniger voraus.\n\nUnity nutzt Gnome-Anwendungen, baut auf Bibliotheken von Gnome und Middleware aus dem Freedesktop.org-Umfeld (unter anderem D-Bus, UPower, Udisks, ConsoleKit) und andere Frameworks wie zum Beispiel Zeitgeist.\n\nDarüber hinaus entwickelte Canonical eine „2D“-Variante auf Basis von Qt und QML, welche am 14. Januar 2011 in einer Entwicklungsversion veröffentlicht wurde. Für diese Version ist keine 3D-Beschleunigung notwendig. \"Unity 2D\" arbeitet mit Metacity zusammen. Mittlerweile wurde die 2D-Variante zugunsten der klassischen 3D-Variante verworfen, nachdem der Hauptprogrammierer von \"Unity 2D\" Canonical verlassen hatte und außerdem der primär von Red Hat für Gnome-Shell entwickelte Software-Renderer LLVMpipe ausreichend schnell genug für die Darstellung von Arbeitsoberflächen sei.\n\nAb Unity 8 wird standardmäßig nicht mehr X11 als Displayserver verwendet, sondern Canonicals Eigenentwicklung Mir. Unity 8 läuft bereits seit 2013 auf Ubuntu Touch, seit Ubuntu 16.10 kann es optional auch in der Desktop-Version verwendet werden.\n\nDa Unity zunächst ausschließlich vom Linux-Distributor \"Canonical\" entwickelt wurde, wird derzeit offiziell nur Linux unterstützt. Versionen für andere Unix-ähnliche Betriebssysteme sind derzeit nicht verfügbar.\n\nDie Entscheidung Canonicals, Unity als Compiz-Plugin zu entwickeln, wurde kontrovers aufgenommen. Der von Canonical angestellte Compiz-Entwickler Sam Spilsbury, zum Beispiel, begrüßte sie. Andere kritisierten sie aus verschiedenen Gründen, z. B. weil die erforderliche Rechenleistung hoch sei.\n\nCanonicals Vorgabe, dass Freiwillige zur Mitarbeit an Canonical-Projekten das eigene Urheberrecht abtreten müssen, um proprietäres Relizenzieren zu ermöglichen, wird ebenfalls kritisiert.\n\nSeit der Ubuntu-Version 12.10 in Verbindung mit Unity sind Probleme bezüglich des Datenschutzes bekannt geworden. Diese beziehen sich auf die voreingestellte Online-Weiterleitung von Suchbegriffen bei der Nutzung der „Dash“-Funktion. Ab Ubuntu 16.04 ist die Online-Suche im Dash standardmäßig deaktiviert.\n\n"}
{"id": "5779435", "url": "https://de.wikipedia.org/wiki?curid=5779435", "title": "Konferenz der Tiere (Film)", "text": "Konferenz der Tiere (Film)\n\nKonferenz der Tiere ist ein computeranimierter Trickfilm, der am 7. Oktober 2010 in den deutschen Kinos anlief. \n\nEr ist nach dem Zeichentrickfilm \"Die Konferenz der Tiere\" von Curt Linda aus dem Jahre 1969 der zweite Film, der sich inhaltlich an den Thesen des Romans Die Konferenz der Tiere von Erich Kästner orientiert.\n\nIn der afrikanischen Savanne wundern sich die Tiere, weil das Wasser nicht mehr wie sonst durch die große Schlucht kommt. Der Durst nach Wasser wird immer größer, so dass es Streit um den letzten Tropfen Wasser gibt. So verteidigen Büffel und Nashörner das einzige Wasserloch. Aufgrund dieser Tatsache ziehen Sokrates der vegetarische Löwe und Billy das tollpatschige Erdmännchen los, um sich auf die Suche nach Wasser zu machen. Hierbei treffen sie auf den gallischen Hahn Charles, der einen Tasmanischen Teufel, ein Känguru, eine Eisbärin und zwei Galapagos-Schildkröten nach Afrika geführt hat, da diese aus ihren zerstörten heimischen Regionen fliehen mussten und auf ein neues, besseres Leben im Okavangodelta hoffen.\n\nDoch auch hier haben die Menschen zugeschlagen: Der Hotelbesitzer Smith hat für die Wasserversorgung seines Hotels einen gewaltigen Staudamm bauen lassen, der nun den Fluss Wassers bis in die Savanne stoppt. Genau in diesem Hotel findet eine Konferenz für eine bessere Umwelt statt. Zunächst sind die tierischen Besucher über die enormem Wasservorräte in Büchsenform und den riesigen Swimmingpool begeistert, doch schon bald treffen sie auf den Sicherheitschef des Hotels, ein Waffenexperte namens Hunter. Sokrates ist entsetzt, als er in ihm den Jäger erkennt, der seinerzeit seinen Bruder Mambo tötete. Der tierische Hoteldiener, Schimpanse Toto, versucht die Gruppe vor Hunter zu verstecken. Auch die Maya, die Tochter des Hotelmanagers, ist auf der Seite der Wildtiere. Trotz aller Vorsicht wird Sokrates gefangen und seine Freunde aus dem Hotel vertrieben. Das wollen diese nicht hinnehmen und rufen ihrerseits eine Konferenz ein: \"die Konferenz der Tiere\". Die großen und kleinen Tiere der Savanne versammeln sich und beschließen gegen das Unrecht der Menschen vorzugehen. Sie ziehen allesamt in Richtung des Hotels und auch die eigensinnigen Büffel schließen sich am Ende an. Dort besiegen sie den Jäger Hunter, der wiederholt versucht die Tiere gewaltsam zu stoppen, beenden die Umweltkonferenz der Menschen und bringen schließlich mit vereinten Kräften den Staudamm zum Einsturz. So fließt das Wasser wieder in die Savanne. Dabei wird Hunter von Sokrates getötet, indem der Löwe ihn vom Staudamm stößt und so seinen Bruder rächt. Ausgelassen feiern die Tiere ihren Sieg in der wieder gründenden Savanne.\n\nNach diesem Erfolg ziehen die Tiere unter Mithilfe der Wale bis nach New York, wo gerade eine Klimakonferenz tagt. Sie belagern die gesamte Stadt und erinnern die Menschen daran, dass sie nicht allein auf diesem Planeten sind.\n\nKonferenz der Tiere ist der erste europäische computeranimierte Kinofilm in 3D. Produziert wurde der Film zwischen dem 22. November 2008 und dem 22. Juni 2010. Die Computeranimation stammt vom niedersächsischen Studio Ambient Entertainment, das mit \"Back to Gaya\" bereits den ersten komplett computeranimierten deutschen Kinofilm produziert hatte. In den deutschen Kinos hatte der Film über 1,5 Mio. Zuschauer. Europaweit waren es über 5 Millionen Besucher, darunter mehr als eine Million in Frankreich. Weltweit erreichte er ein Einspielergebnis von über 50 Mio. Dollar.\n\nDer Soundtrack wurde hauptsächlich von David Newman produziert. Bekannt wurde allerdings die Zusammenarbeit von Xavier Naidoo und Naturally 7, die zusammen die Titelmelodie \"Wild vor Wut\" aufnahmen.\n\n\n"}
{"id": "5786377", "url": "https://de.wikipedia.org/wiki?curid=5786377", "title": "SciPlore MindMapping", "text": "SciPlore MindMapping\n\nSciPlore MindMapping ist ein Computerprogramm, das sich in erster Linie an Wissenschaftler und Studenten richtet. Mittels Mind-Maps können die Anwender ihre Ideen, beispielsweise für wissenschaftliche Arbeiten, strukturieren. Zudem importiert SciPlore MindMapping Bookmarks aus PDF-Dateien und überwacht Verzeichnisse auf der Festplatte nach neuen Dateien, und ist somit geeignet große Dokumentensammlungen zu verwalten. Eine Integration mit Referenzmanagern wie JabRef ermöglicht zudem das Verwalten von Referenzen. Anwender können Ihre Mind Maps außerdem automatisch auf den Server von SciPlore sichern. Ein Herunterladen ist derzeit (Stand: November 2010) jedoch noch nicht möglich, da sich das Webinterface immer noch in der Entwicklung befindet.\n\nDie Software ist ein Fork der Mind Mapping Software FreeMind und bietet dementsprechend alle Features von FreeMind. Das Dateiformat ist ebenfalls kompatibel, sodass Mind Maps der einen Software auch in der anderen Software geöffnet werden können.\n\nDie Entwicklung wurde zugunsten des Nachfolgeprojektes Docear eingestellt, während FreeMind und der Fork FreePlane weiter entwickelt werden.\n\n"}
{"id": "5799395", "url": "https://de.wikipedia.org/wiki?curid=5799395", "title": "WinCDEmu", "text": "WinCDEmu\n\nWinCDEmu ist ein Windows-Programm (32 sowie 64 Bit), um optische Laufwerk zu emulieren. Das Programm wird seit 2008 von dem Russen Ivan Shcherbakov entwickelt. Die Quelltexte sind als Open Source unter der GNU Lesser General Public License (LGPL) frei verfügbar.\n\nWinCDEmu unterstützt in Version 3.4 folgende Formate: ISO, CUE, IMG, BIN, NRG, MDF/MDS, CCD und RAW Formate. WinCDEmu ist Bestandteil der Opensource-DVD 13.0 und war Software-Tipp des Tages bei Computer Bild am 23. Dezember 2009.\n\nWie andere Emulatoren dieser Art virtualisiert auch WinCDEmu optische Laufwerke (zum Beispiel für CDs oder DVDs). Dabei werden zuvor sogenannte Speicherabbilder der optischen Medien erstellt, um diese dann von der Festplatte in einem virtuellen Laufwerk wiederzugeben. WinCDEmu kann selbst solche Abbilder erstellen.\nNach der Installation von WinCDEmu genügt es, eine Datei in einem der unterstützten Formate doppelt anzuklicken, um sie als virtuelles Laufwerk zu „mounten“, das heißt als Laufwerk mit einem Buchstaben ansprechen zu können.\nUm CD/DVD-Abbilder wieder auszuwerfen, benötigt es kein System-Tray-Programm, sondern es genügt ein erneuter Doppelklick auf die betr. Datei, oder ein Rechtsklick auf das entsprechende Laufwerk und das Betätigen der Auswerfen-Funktion.\n\nDas virtuelle Laufwerk wird dabei so in das Betriebssystem eingebunden, dass es scheint, als ob sich ein zusätzliches Laufwerk im verwendeten Rechner befände. Für den Nutzer unterscheidet es sich in der Bedienung nicht von physischen Laufwerken. Besonders bei Notebooks kann dadurch Strom gespart werden, weil die Festplatte, auf der das virtuelle Laufwerk liegt, weniger Strom verbraucht als ein DVD-Laufwerk.\n\nChip.de urteilt: „WinCDEmu ist der wohl einfachste Weg, eine Image-Datei zu mounten und auszuführen.“\nJon L. Jacobi von der amerikanischen Computerzeitschrift PC World meinte, dass die Software sein höchstes Lob erhalten habe, dass er die Software nach dem Test auch auf seinen Hauptsystemen einsetze. „As a matter of fact, WinCDEmu has received the highest form of praise I can dole out--it's made the leap from my VMs and test bed onto my main systems.“\n\n"}
{"id": "5800279", "url": "https://de.wikipedia.org/wiki?curid=5800279", "title": "Windows Journal", "text": "Windows Journal\n\nWindows Journal ist ein von Microsoft entwickeltes Programm zur Erstellung von Notizbemerkungen, welches in zahlreichen Versionen von Windows XP bis Windows 10 bereits inbegriffen ist. Es ermöglicht dem Benutzer handschriftliche Notizen und Zeichnungen zu erstellen und diese zu verwalten. Diese handschriftlichen Notizen können sowohl mit einer gewöhnlichen Computermaus als auch mit einem Grafiktablett oder einem Tablet-PC verfasst werden.\n\nZur Markteinführung wurde Windows Journal nur in die Version von Windows XP Tablet PC Edition integriert. Zwischenzeitlich enthielten auch die Versionen Home Premium von Windows Vista und höher Windows Journal. Zu beachten war jedoch, dass das JNT-Format nicht offengelegt war, und man die JNT-Dateien nur solange öffnen konnte, wie Microsoft ein entsprechendes Programm zur Verfügung stellte.\n\nIm Rahmen des Windows Insider Programms wurde Windows Journal im Juli 2016 unangekündigt vollständig aus Windows 10 entfernt. Angesichts der mittlerweile sehr geringen Nutzung des Programms, das durch andere Notizprogramme – wie das Microsoft-Programm OneNote – unlängst verdrängt wurde, wird Windows Journal mit dem Anniversary Update am 2. August 2016 standardmäßig für alle Nutzer aus Windows 10 verschwinden. Windows Journal kann jedoch per Update nachinstalliert werden.\n\nWindows Journal Viewer war eine von Microsoft geschaffene Anwendung, die es ermöglichte, JNT-Dateien auf Systemen zu betrachten, auf denen keine Tablet-PC-Software installiert ist. Die letzte (v6.3 2014) war im Dezember 2015 noch für Windows 2000 bis Windows 10 verfügbar. Im Juli 2016 existierte der Eintrag im MSDN noch, die Download-Seite für den Microsoft Journal Viewer steht jedoch nicht mehr zur Verfügung.\n\n"}
{"id": "5814198", "url": "https://de.wikipedia.org/wiki?curid=5814198", "title": "Calibre", "text": "Calibre\n\nCalibre ist ein freies Programmpaket zur Verarbeitung, Konvertierung und Verwaltung von E-Books für Linux, macOS und Windows. In vielen Linux-Distributionen lässt sich die Software direkt aus den Standard-Paketquellen installieren.\n\nDer Inder Kovid Goyal begann mit der Entwicklung am 31. Oktober 2006 anlässlich der US-Markteinführung des E-Book-Readers PRS-500 der Firma Sony, anfangs ohne grafische Benutzeroberfläche und unter dem Namen „libprs500“. Um diesen Reader unter Linux nutzbar zu machen, rekonstruierte Goyal mit Unterstützung aus der MobileRead-Gemeinde das Kommunikationsprotokoll für den Zugriff auf das Gerät über USB und schrieb einen Konverter für das verwendete proprietäre Dateiformat \"LRF\".\n\nMitte 2008 wurde der Name zum heutigen „calibre“ geändert.\n\nDie Vielzahl (großteils auch schreibend) unterstützter Dateiformate enthält die meisten derzeit relevanten Formate, die sehr weitgehend konfigurierbar dargestellt, ausgedruckt und konvertiert werden können. Die Inhalte können dabei auch aufbereitet werden, beispielsweise durch Änderungen der zu verwendenden Schrift oder Einfügen eines automatisch erstellten Inhaltsverzeichnisses.\n\nCalibre bietet zahlreiche Funktionen zur Katalogisierung und Verwaltung von Sammlungen elektronischer Bücher. Sie können mit verschiedenen Eigenschaften und Metadaten versehen werden. Letztere können aus verschiedenen Quellen (ISBNdb.com, Google Books, Amazon, LibraryThing) auch automatisch ausgefüllt werden.\n\nDie Bücher können in Calibre importiert und auf diverse Mobilgeräte exportiert werden. Es ist möglich, Bücher und Metadaten zu synchronisieren, wobei sie automatisch in jeweils passende Datenformate konvertiert werden.\n\nMeldungen von Nachrichten-Websites (Web-Feeds) können automatisch aus dem Internet bezogen, in eine E-Book-Datei verpackt und an ein Mobilgerät übertragen werden.\n\nDie Unterstützung von Dateiformaten, Mobilgeräten, Nachrichten- und Metadatenquellen ist modular erweiterbar.\n\nInhalte der verwalteten Sammlung sind auch aus der Ferne über Internet, Webbrowser, Mobilgeräte usw. verfügbar oder können (beispielsweise abonnierte Inhalte) automatisch zugestellt werden („push“).\n\nVon Version 0.9.34 an können mittels Calibre Texte im Format docx in EPUB konvertiert werden.\n\nVon Version 1.15 an können mittels Calibre elektronische Bücher in den Formaten EPUB und AZW3 (Kindle) bearbeitet werden.\n\nVon Version 1.22 an besteht die Möglichkeit, E-Book-Dateien inhaltlich miteinander zu vergleichen.\n\nVon Version 2.0 an können E-Book-Dateien in den Formaten EPUB und AZW3 neu erzeugt und bereits vorhandene elektronische Bücher editiert werden.\n\nMit der Version 3.0 vom Juni 2017 wurde ein komplett neuer „Content-Server“ geschaffen, der es erlaubt, Bücher im Browser eines Smartphones oder Tablets im Offline-Modus zu lesen.\n\nDie Anwendung ist in den Programmiersprachen Python und C geschrieben und wird unter den Bedingungen von Version 3 der GNU General Public License (GPL) als freie Software auch im Quelltext veröffentlicht.\n\nZur Nachrichtenabfrage betätigt sich Calibre als RSS-Feedreader; für Fernzugriff enthält es E-Mail- und Webserver (HTTP).\n\nDie Software ist auch als portable Version verfügbar.\nVon Version 0.9.9 an gibt es auch eine 64-Bit-Version für Windows.\n\nDurch verschiedene Plug-ins (z. B. DeDRM oder EpubMerge) kann die Funktionalität erweitert werden.\n\n"}
{"id": "5824119", "url": "https://de.wikipedia.org/wiki?curid=5824119", "title": "Lightworks", "text": "Lightworks\n\nLightworks ist ein professionelles Videoschnittprogramm, das für Schnitt und Mastering von Kinofilmen in 2K und 4K wie auch von Fernsehproduktionen in PAL, NTSC und HD in 2D und 3D genutzt wird. Lightworks ist einer der Pioniere für computerbasierenden Filmschnitt und wird bereits seit 1989 entwickelt. Zahlreiche international bekannte und oskarpreisgekrönte Spielfilme, unter anderem Martin Scorseses Departed, , Shutter Island, Pulp Fiction, Braveheart oder Batman wurden auf Lightworks geschnitten. Das kommerziell erhältliche Programm sollte laut Ankündigung des Herstellers am 29. November 2011 als Open Source freigegeben werden, kurz vor der geplanten Veröffentlichung wurde dieses Vorhaben jedoch auf unbestimmte Zeit vertagt. Lightworks ist in einer im Funktionsumfang stark beschränkten, kostenlosen \"Free-\" und einer kostenpflichtigen \"Pro-Version\" für Windows, macOS und Linux verfügbar.\n\nDie Entwicklung von Lightworks begann um 1988/1989 in England. Das Design der Software wurde von Filmeditoren entworfen und von Programmierern umgesetzt. Dieser Ansatz unterschied das Schnittsystem von anderen Pionieren des nonlinearen Videoschnittes wie Adobe oder Avid, die damals weitgehend von Programmierern und Technikern entworfen wurden, und resultierte unter anderem darin, dass das Bedienkonzept von Lightworks sich bis heute stärker bei den klassischen Filmschnittmethoden wie dem Steenbeck-Schneidetisch anlehnt, als den bei computertypischen Methoden wie Dateidialoge.\n\nVon Anfang an unterstützte das System auch speziell entworfene Hardwarecontroller und Bedienfelder, die klassischen Bedienpulten von Schnitttischen und Fernsehmischern nachempfunden sind und somit im Vergleich zur alleinigen Nutzung von Maus und Tastatur die Arbeit mit dem System beschleunigen. Diese Ergänzungen sind jedoch bis heute optional.\n\nIn den 1990er Jahren fand das System schnell Verbreitung, insbesondere bei der Produktion von amerikanischen und englischen Spielfilmen mit sehr hohen Etats. Durch zahlreiche Aspekte, darunter dem sehr hohen Kaufpreis, hatte Lightworks außerhalb von Hollywood und der Kinoproduktion jedoch erheblich weniger Verbreitung als die erfolgreichsten Mitanbieter, die ihre Produkte sehr viel stärker auf den technisch erheblich weniger anspruchsvollen und zugleich größeren TV-Markt fokussierten.\n\n1994 wurde Lightworks von Tektronix erworben, einem Anbieter von ebenfalls sehr hochpreisigen Video- und Filmprodukten. 1999, nachdem der NLE-Markt immer größer wurde, kaufte das Management von Lightworks die Rechte an der Software Tektronix wieder ab, und Lightworks firmierte erneut eigenständig als Lightworks inc. Es folgten Kooperation, Vertrieb und Verkauf unter anderem an Fairlight, jedoch blieben die meisten Nutzer von Lightworks stets weiterhin größtenteils in der „High-End“-Nische der Spielfilmproduktion, weitgehend für Kino – obgleich konstant die Funktionalität für die TV-Produktion erweitert wurde.\n\n2009 wurde Lightworks von der amerikanischen Firma EditShare aufgekauft, die sich auf Produkte zur Vernetzung von Schnittsystemen aller Hersteller für TV wie Kino spezialisiert hat.\n\nIm April 2010 wurde angekündigt, dass die Freigabe von Lightworks als Open Source beabsichtigt sei. Dieses Versprechen wurde nicht eingehalten, Lightworks ist nach wie vor Closedsource, obwohl Editshare das Programm zu Marketingzwecken mitunter als Open Source bewirbt.\n\nSeit April 2010 befand sich Lightworks in der Betatestphase, deren Ende für den 29. November 2010 angesetzt war. In diesem Zeitraum registrierten sich laut Darstellung von Editshare rund 1.700 Entwickler (Firmen und Einzelpersonen) und über 250.000 Anwender. Gegenwärtig steht die stabile Version 14 für Windows, OS X und Linux als Download zur Verfügung.\n\nLightworks kann mit Tastatur und Maus bedient werden, professionelle Anwender benutzen oft eine Tastatur mit farbigen Tasten. Die interne Datenbank ist darauf ausgerichtet, dass auch bei extrem großen Projekten ein schnelles und sicheres Arbeiten möglich ist. Für den Einsatz in Arbeitsgruppen wie beispielsweise in TV-Sendern stehen Netzwerk-Lösungen zur Verfügung, die es ermöglichen, auf Bild- und Tonmaterial, Schnitte und Effekte gleichzeitig auch von mehreren Schnittplätzen aus zuzugreifen.\n\nUm Editoren, die Lightworks noch nicht nutzten, schnell effektives Arbeiten zu ermöglichen, kann eine zu Avid oder Final Cut Pro kompatible Tastaturbelegung geladen werden.\n\nSehr erfolgreiche Editoren, wie Thelma Schoonmaker, die mit Lightworks den Oscar für besten Schnitt gewann und viele von Martin Scorseses Filmen schnitt, oder Chris Gill, zu dessen Schnittarbeiten 28 Weeks Later zählt, stellen immer wieder öffentlich die Vorteile heraus, die sie zum Einsatz von Lightworks bewegt haben.\n\nLightworks bietet Editoren eine sehr umfangreiche Funktionalität.\n\n\n\nDas Bearbeiten von Bildern und Tönen, die mittels digitaler Kinokameras oder mit 35 mm und 70 mm Filmkameras zur Aufführung im Kino aufgezeichnet werden, erfordert sehr spezifische Werkzeuge. Insbesondere im Kopierwerk abgetastete Filmmaterialien und per RAW gedrehte Quellen bedürfen für Datei- und Video-basierenden Schnitt atypische Funktionalität. Da Lightworks traditionell in diesem Segment schwerpunktmäßig genutzt wird, werden hierzu ungewöhnlich umfassende Werkzeuge von der Software geboten, unter anderem:\n\nKlassische Schnittplätze wurden und werden oft „nur“ zum Schneiden von Inhalten genutzt. Auch heute wird bei vielen Schnittsystemen andere Software hinzugezogen, um Effekte zu erstellen. Jedoch verstärkt sich seit dem Ende der 1990er Jahre der Trend, dass insbesondere für anspruchsvollere Formate, wie beispielsweise Werbung, Spielfilm oder hochwertige Imagefilme, parallel zum Master im Schnitt zusätzlich alle Effekte endgefertigt werden. In diesem Fall wird im Branchenjargon der Film- und TV-Produktion dann typischerweise nicht von „Schnitt“, sondern anstelle dessen von „On-Line“ und „Finishing“ gesprochen. Die Grenzen sind hierbei fließend: Verschiedene Hersteller positionieren ihre Produkte entweder als Schnitt- oder als Finishingsystem, indem sie bei der gleichen Software Funktionalität reduzieren. Als ein typisches Beispiel hierfür sei stellvertretend der Hersteller Avid aufgeführt, der die gleiche Software als Finishingsystem namens „Symphony“ und mit leicht reduzierter Funktionalität „nur“ als Schnittsystem Media Composer vermarktet. Lightworks begann 1989 als pures Schnittsystem und wurde in den 2000ern dann auch im Effektbereich massiv ausgebaut, und bietet heute für Effekte zahlreiche Finishing-Funktionen, wie\nDedizierte VFX-Systeme, wie Combustion oder Nuke bieten noch mehr Funktionalität als Finishingsysteme wie Avid DS, Autodesk Smoke oder Lightworks, können jedoch nicht in Echtzeit schneiden. Die Finishingsysteme sind darauf ausgerichtet, die typischen Anforderungen möglichst schnell in hoher Güte zu erfüllen, dedizierte VFX-Systeme hingegen sind typischerweise auf maximale Komplexität und Funktionalität ausgerichtet und Echtzeitfähigkeit und Bearbeitungsgeschwindigkeit sind nachrangig.\n\nNeben den Effekten ist ein weiterer Schritt bei der Herstellung von Mastern die Farbkorrektur, die sowohl technisch wie auch kreativ genutzt wird. Lightworks bietet hierzu die klassischen hochwertigen Funktionen, wie Primäre Echtzeitfarbkorrektur mit Schatten-, Mitten-, Spitzen-Trennung und Sekundäre Echtzeitfarbkorrektur. Alle Finishingsysteme erreichen jedoch nicht ganz die Leistungsfähigkeit dedizierter Digital-Intermediate-Farbkorrektursysteme. Neben zahlreichen Farbfiltern ist für die Herstellung von TV-Sendemastern auch ein spezieller Filter zur Sicherung von sendefähigen Farben und Helligkeiten im Funktionsumfang.\n\nUm einen Schnittplatz zur Herstellung von technisch korrekten und sendefähigen Mastern zu befähigen, wurden ursprünglich externe Zusatzgeräte benötigt, wie beispielsweise Bildmesstechnik. Viele von diesen werden in jüngerer Zeit durch die gewachsene Leistung der Computertechnik nicht mehr extern, sondern durch die Software selbst intern realisiert. Auch Verbesserungen der Ergonomie und somit der Arbeitsgeschwindigkeit wie beispielsweise im Tonbereich werden zunehmend voll- oder teil-computerisiert betrieben, so bspw. Mischpult und Jog-Shuttle.\n\n\n\nFür einfache Schnittaufgaben ist die Medienverwaltung eine eher unwichtige Funktionalität. Umso größer, länger und umfassender Schnittprojekte werden, desto wichtiger wird diese jedoch. Da die Wurzeln der Lightworks-Software in der Verwendung für Spielfilmproduktionen liegen, werden von dem System sehr umfassende Datenbank und Medienverwaltungsfunktionen geboten, u.A.\n\nZur Erstellung von komplexen VFX und Titeln oder schlicht auch zur Arbeitsteilung zwischen mehreren Personen bietet das System Integration respektive Schnittstellen zu externen Programmen (z. B.: BorisFX, After Effects, Digital Fusion).\n\nIn den späten 1980er Jahren gab es vergleichsweise wenig Formate, die zur Herstellung von Schnitten genutzt wurden: typischerweise wurden über 90 % aller Schnitte über das Format BetacamSP oder direkt per Film realisiert. Im Laufe der folgenden 3 Jahrzehnte hingegen entstand eine Vielzahl an unterschiedlichen Formaten, von denen viele obendrein herstellerspezifisch sind. Das Lightworks-System unterstützt viele davon, und auch mittels unterschiedlicher Ein- und Ausgabemethoden (wie Band, Datei, HD-SDI-Schnittstellen). Verfügbar sind beispielsweise\n\nMit Lightworks arbeiten zahlreiche erfolgreiche und populäre Regisseure und Filmeditoren, u. a. Guy Ritchie, Danny Boyle, Miloš Forman, Peter Weir, Quentin Tarantino, Brian De Palma, Joel Schumacher und Gus Van Sant. Dementsprechend wurden in der über 20-jährigen Geschichte von Lightworks zahlreiche populäre Filme auf dem System geschnitten, beispielsweise Shutter Island, The Departed, Der gute Hirte, Bruce Almighty, Per Anhalter durch die Galaxis, Aviator, Bube, Dame, König, grAS, Moulin Rouge, 28 Days Later, Larry Flynt – Die nackte Wahrheit, Pleasantville, William Shakespeares Romeo + Julia, Die Truman Show, Pulp Fiction, Mrs. Doubtfire – Das stachelige Kindermädchen, Gangs of New York, Notting Hill, Braveheart, Batman Forever, Good Will Hunting, Der Pferdeflüsterer, , The King’s Speech oder Goodfellas.\n\n\n"}
{"id": "5826236", "url": "https://de.wikipedia.org/wiki?curid=5826236", "title": "Wallace-Tree-Multiplizierer", "text": "Wallace-Tree-Multiplizierer\n\nEin Wallace-Tree-Multiplizierer ist ein Multiplizierer, der in der Digitaltechnik eingesetzt wird. Das Verfahren ist benannt nach Christopher Stewart Wallace, welcher diesen Multiplizierer 1964 vorstellte.\n\nEin formula_1-Bit Wallace-Tree-Multiplizierer basiert wie der Dadda-Tree-Multiplizierer auf der Formel\n\nHierbei sind formula_3 und formula_4, formula_5 die Binärdarstellungen der zwei zu multiplizierenden Zahlen.\n\nDer Wallace-Tree-Multiplizierer geht in drei Schritten vor:\n\nIn Schritt 2 der obigen Schritte werden die Partialprodukte in einer Baumstruktur addiert.\n\nDabei werden zunächst die Partialprodukte in Spalten angeordnet, sodass in einer Spalte jeweils alle Partialprodukte formula_10 mit formula_11 stehen. Dann fasst man die Spalten der so entstandenen Tabelle in Dreiergruppen zusammen. Jede Spalte dieser Dreiergruppen wird als Eingang für einen Volladdierer verwendet, sofern in der Spalte drei Eingänge sind, für einen Halbaddierer, sofern zwei Einträge vorhanden sind, und gar nicht modifiziert, sofern nur ein Eintrag vorhanden ist. Der höher gewichtete Ausgang der Addierer wird dann jeweils der nächsten Spalte zugeordnet. Dieser Vorgang wird solange wiederholt, bis nur noch eine Dreiergruppe vorhanden ist, bei der in jeder Spalte nur zwei Einträge stehen. Diese beiden letzten Zeilen werden dann mittels eines normalen Addierwerks addiert.\n\nHier sieht man die obige Vorgehensweise für einen 8-Bit-Wallace-Tree-Multiplizierer. Die Punkte stehen dabei für die Partialprodukte bzw. für die Ausgänge der vormalig verwendeten Voll- und Halbaddierer, welche durch die dünnen Linien gekennzeichnet sind.\n\nOben wurde die Funktionsweise des Wallace-Tree-Multiplizierers unter Rückgriff auf Tabellen beschrieben. Jede dieser Tabellen steht dabei für einen Schritt, den ein elektronisches Signal durchlaufen muss. Um die Laufzeit des Wallace-Tree-Multiplizierers zu ermitteln, finden wir daher heraus, wie viele Tabellen es gibt.\n\nDa ein Volladdierer drei Signale in zwei verwandelt, und ggf. in einer Dreiergruppe (siehe oben) weniger Elemente als für einen Volladdierer benötigt werden vorhanden sind, gilt, wenn wir mit formula_12 die Höhe der j-ten Tabelle und mit formula_1 die Anzahl der Eingangsbits bezeichnen:\n\nHieraus kann man folgende Abschätzung herleiten:\n\nSomit folgt\n\nWählt man nun formula_19, so gilt\n\nEine Tabelle mit sieben Zeilen kann man jedoch nach obiger Vorgehensweise in konstant vielen Schritten reduzieren. Somit gilt für die Laufzeit formula_21 für eine konstante Schrittanzahl formula_22:\n\nformula_23\n\nDa die Laufzeit eines Addierwerks (der letzte Schritt beim Wallace-Tree-Multiplizierer) auch in formula_24 liegt, hat der Wallace-Tree-Multiplizierer dieselbe asymptotische Laufzeit wie ein Addierwerk und ist damit schneller als ein vorzeichenloser paralleler Multiplizierer, der eine asymptotische Laufzeit von formula_25 aufweist.\n\nDer Wallace-Tree-Multiplizierer ist ferner absolut gesehen langsamer als der Dadda-Tree-Multiplizierer, obwohl beide Multiplizierer dieselbe asymptotische Laufzeit von formula_24 besitzen.\n\n"}
{"id": "5827825", "url": "https://de.wikipedia.org/wiki?curid=5827825", "title": "Greeble", "text": "Greeble\n\nGreeble ist ein Begriff, der Einzug in die Computergrafik gefunden hat. Er bezeichnet ein hinzugefügtes Detail, das die monotone Oberfläche eines Objekts visuell interessanter erscheinen lässt. Die Funktion der Greebles ist, den Eindruck von \"Komplexität\" zu erhöhen, damit der Blick des Betrachters – aus Interesse für das Besondere – daran hängen bleibt. Solcherart veränderte Oberflächen lassen ein Objekt auch größer erscheinen, da Greebles als kleinere Details eines größeren Objekts wahrgenommen werden. Diese Details können aus einfachen geometrischen Körpern wie Zylindern, Würfeln oder anderen Platonischen Körpern bestehen, die in Kombination detaillierte, aber bedeutungslose Oberflächenstrukturen schaffen.\n\nBei visuellen Spezialeffekten in Filmen werden Greebles zum Beispiel eingesetzt bei der Gestaltung der Oberfläche von Raumschiffen, der Haut von prähistorischen Tieren oder um Gebäude fremd und „organisch“ aussehen zu lassen.\n\nDie derzeit erste dokumentierte Verwendung des Begriffs „Greeble“ stammt von den Mitarbeitern der Spezialeffekte-Gruppe, die für den Film Star Wars tätig war; aus dieser Gruppe ging später Industrial Light & Magic hervor. Sie beschrieben diese Design-Methode auch als „Eingeweide nach außen“ (\"guts on the outside\"). Der Plural von \"Greeble\" ist \"Greebles\"; ein Objekt mit Greebles zu versehen, wird als \"Greebling\" bezeichnet.\n\n\"Nurnie\" hat eine ähnliche Bedeutung und es wird angenommen, dass Ron Thornton diesen Begriff einführte, mit dem er ein CGI-Detail bezeichnete, die sein Unternehmen \"Foundation Imaging\" für die Science-Fiction-Serie Babylon 5 verwendete.\n\nBereits 1968, während der Produktion von , wurden sogenannte \"Wiggets\" ohne Hilfe von Computern auf die Oberfläche von Raumschiffmodellen aufgebracht, um den besonderen Effekt von Größe und Komplexität zu erzeugen.\n\nIn nicht-virtuellen Anwendungen können Greebles aus sehr unterschiedlichen Materialien bestehen, zum Beispiel aus Holz- oder Kunststoffteilen; einige Modellbausätze verwenden Bauteile mit \"ge-greeble-ter\" Oberfläche. Bei den Arbeiten zu \"Star Wars\" bestand das Original des \"Imperial Star Destroyer\" aus einem Sperrholzrahmen, der mit Polystyrol-Elementen umkleidet war. Strukturgebende Schnitte allein im Polystyrol ließen das Schiff aber \"kahl\" aussehen. Daher wurden Bausätze gekauft und Stücke davon direkt oder nach dem Zurechtschneiden auf die Oberflächen des Schiffes aufgebracht. Der letztendliche Effekt war, dass das Schiff durch diese Oberflächenveränderungen für den Betrachter \"realer\" und \"glaubwürdiger\" erschien. Die Greebles selber dienten keinem anderen Zweck als die leere Oberfläche zu füllen (obwohl später durch „technische Illustratoren“ oder in „Star-Wars-Spezialliteratur“ einigen dieser Greebles eine besondere „technische Funktion“ zugeordnet wurde).\n\nEin weiteres Beispiel für die Verwendung von Greebles war das Battlestar-Galactica-Modell für die ursprüngliche Serie in den 1970er Jahren, bei dessen Rumpfgestaltung Teile verschiedener Bausätze – darunter die des Apollo-Orbiters, der Saturn-Rakete, von F-16-Kampfflugzeugen und verschiedenen Panzern – verwendet wurden.\n\nIn diesen ersten Anwendungen wurde Greebling meist bei der Gestaltung von riesigen, fliegenden Städten vergleichbaren Raumschiffen verwendet. Bei Star Trek findet man diese Technik bei den würfelförmigen Schiffen der Borg und auch die Ausstattung und die Accessoires der Borg-Drohnen folgten dem gleichen Prinzip.\n\nIn der 3D-Computergrafik können Greebles durch spezielle Software automatisch eingefügt werden, um die zeitaufwendige manuelle Erstellung einer großen Anzahl von genau definiertenen Geometrien zu vermeiden. Die Automatisierung dieses langwierigen, sich wiederholenden Vorgangs lohnt sich besonders dann, wenn kein hohes Maß an Kontrolle erforderlich ist oder wenn die Greebles in der Finalversion der Grafik nicht besonders nahe gezeigt werden.\n\nDie meisten derartigen Computerprogramme arbeiten mit der Unterteilung der zu bearbeitenden Gesamtfläche in kleinere Unterbereiche, erzeugen dann darin neue Details und wiederholen diesen Vorgang der Auswahl, Veränderung und erneuter Auswahl in Rekursion, bis ein vorher festgelegtes „Detail-Niveau“ erreicht wird. Ähnliche Algorithmen werden bei der Erstellung von fraktalen Oberflächen verwendet.\n\n\n"}
{"id": "5830712", "url": "https://de.wikipedia.org/wiki?curid=5830712", "title": "Sammys Abenteuer – Die Suche nach der geheimen Passage", "text": "Sammys Abenteuer – Die Suche nach der geheimen Passage\n\nSammys Abenteuer – Die Suche nach der geheimen Passage (Originaltitel: \"Sammy’s avonturen: De geheime doorgang\") ist ein belgischer Computeranimationsfilm von Ben Stassen aus dem Jahr 2010.\n\nIn der Originalfassung sind unter anderem Melanie Griffith, Anthony Anderson, Isabelle Fuhrman und Yuri Lowenthal zu hören. Für die deutsche Synchronfassung konnten unter anderem Lena Meyer-Landrut, Matthias Schweighöfer, Axel Stein, Thomas Fritsch und Achim Reichel gewonnen werden.\n\nVon der Deutschen Film- und Medienbewertung (FBW) erhielt der Film das Prädikat \"Besonders Wertvoll\".\n\nNach der Deutschlandpremiere in Berlin in Anwesenheit von Lena, Axel Stein und Regisseur Ben Stassen am 17. Oktober 2010 kam der Film am 28. Oktober 2010 in einer Normalfassung und einer 3D-Fassung in die deutschen Kinos.\n\nDer Film beginnt in der Gegenwart, wo die Schildkrötenfreunde Sammy und Ray freudig darauf warten, Großväter zu werden. Währenddessen erzählt der alte Sammy von seiner Geburt, die 50 Jahre zuvor am selben Strand stattfand. Nachdem es Sammy mit Mühe geschafft hat, aus dem Ei zu schlüpfen, wird er von einer Seemöwe geschnappt. Sammy gelingt es, der Möwe Sand in die Augen zu spucken, worauf sie die Augen zukneift und ihn loslässt. In der Luft stößt die Seemöwe mit einer anderen zusammen, die ihrerseits das Schildkrötenmädchen Shelly im Schnabel trägt. Nach dem Zusammenstoß der Möwen fallen Sammy und Shelly in die Tiefe. Während Shelly auf den weichen Strand fällt und mit den anderen Schildkröten das Meer erreicht, bleibt Sammy auf dem harten Treibholz liegen, wo er vor Erschöpfung einschläft. Als er wieder aufwacht, treibt er im offenen Meer. Hier freundet er sich mit der Lederschildkröte Ray an.\n\n10 Jahre wandern die beiden durch den Pazifischen Ozean, wo sie zum ersten Mal auf Menschen treffen. Während einer Begegnung mit dem Kraken Slim bekommen sie mit, wie ein Öltanker ihr Gewässer verseucht. Einige Zeit später geraten Ray und Sammy in die Schleppnetze von Fischereitrawlern. Sie werden getrennt, und der stark geschwächte Sammy wird ins Meer zurückgeworfen. Von einem freundlichen Delfin wird er an die Küste Kaliforniens gebracht, wo er von Snow, einer Hippie-Frau, aufgepäppelt und zusammen mit der Schildkröte Vera und dem Kater Fluffy als Haustier gehalten wird. Als die Hippies bemerken, dass Sammy und Vera sich nicht paaren wollen, lassen sie Vera frei.\n\nAm Weihnachtsabend bekommt Sammy von den Hippies ein Friedenszeichen auf dem Panzer gemalt. Snow liest aus Jules Vernes \"Reise um die Erde in 80 Tagen\" vor und dabei bekommt Sammy mit, dass man durch eine geheime Passage um die Welt reisen kann. Während einer Razzia durch die Polizei muss die Hippiekommune fliehen und lässt Sammy zurück. Sammy entscheidet sich, ins Meer zurückzukehren. In der Meeresströmung verheddert sich Sammy mit dem Kopf in einer Plastiktüte und droht zu ersticken. Er wird aber von Vera gerettet, und beide schwimmen zu einem Algenwald. Plötzlich bemerken sie, wie ein junges Schildkrötenmädchen von einem Hai angegriffen wird und retten ihm das Leben. Dabei bemerkt Sammy, dass es sich bei dem Schildkrötenmädchen um Shelly, seine Jugendliebe, handelt.\n\nGemeinsam beschließen sie die geheime Passage zu suchen. Sie erreichen den Panamakanal, den Sammy für die geheime Passage hält. Nach bestandenen Abenteuern mit einer Riesenschlange, einem Krokodil, Piranhas und einem Greifvogel finden sie die Zone, wo die Schiffe durch den Kanal fahren. Shelly wird jedoch durch den Sog einer Schiffsschraube wieder von Sammy getrennt und ins Meer getrieben. Verzweifelt schwimmt Sammy ohne Shelly weiter. Einige Zeit später trifft er auf das ältere Schildkrötenpaar Günther und Angelika, das ihm erzählt, dass es Shelly getroffen habe. Sammy schöpft neue Hoffnung und beschließt, weiter nach Shelly zu suchen.\n\nAuf seiner Reise in Richtung Süden findet Sammy einen Kühlschrank, der von einem Frachter entsorgt wurde, und benutzt ihn als Fortbewegungsgelegenheit. Nach einer Weile trifft er auf eine Seemöwe, die ihm erzählt, dass sie Shelly auf dem Weg zum Eismeer gesehen hat, und anschließend auf einen Finnwal, der von Walfängern verfolgt wird. Sammy und der Wal entkommen knapp der Harpune, die in den Kühlschrank einschlägt und ihn zerstört. Sammy wird von Walfanggegnern aus dem eiskalten Wasser gerettet und auf ihr Boot gebracht, wo er ganz kurz Shelly sieht.\n\nSammy und Shelly landen in einem Tierheim, wo sie aufgepäppelt werden. Während Shelly nach kurzer Zeit wieder ins Meer entlassen wird, trifft Sammy Snow und Fluffy wieder. Nachdem auch Sammy wieder freigelassen ist, begegnet er zwei Schildkrötenmädchen, die ihn um Hilfe bitten. Sie schwimmen zu einem alten Seefrachtcontainer, der auf einem Abhang steht und abzustürzen droht. In diesem Container ist Sammys Freund Ray gefangen. Sammy gelingt es, die hinteren Türen zu öffnen und, kurz vor dem Absturz des Containers, Ray zu befreien. Anschließend schwimmen sie zum Wrack einer spanischen Galeere, wo Rays Freundin Rita lebt. Als Sammy Rita nach Shelly befragt, gibt sie ihm den Rat, in der Galeere nach ihr zu suchen. Hier muss er aber mit ansehen, wie Shelly mit dem Schildkrötenmännchen Robbie flirtet. Sammy erzählt Rita und Ray von seiner enttäuschenden Begegnung, die ihm daraufhin erklären, dass Robbie ein Playboy ist und bereits eine Freundin hat. Zusammen mit Ray und Albert, einem Hai, der seine Zähne verloren hat, täuschen sie einen Angriff auf Shelly vor. Sammy kann Shelly erneut retten und gewinnt endgültig ihr Herz. Wenig später findet die Hochzeit statt. In der Schlussszene hilft Sammy seinem Enkel, aus dem Eiablageloch zu kommen.\n\nDie deutsche Synchronfassung entstand im Juni 2010 in den Studios der Berliner Synchron in Lankwitz, für die Dialogregie war Martin Schmitz verantwortlich.\n\nNeben dem Score von Ramin Djawadi sind unter anderem \"Touch a New Day\" von Lena, \"Ain’t No Sunshine\" von Michael Jackson und \"California Dreamin’ \" von The Mamas and the Papas zu hören. Darüber hinaus befinden sich auf dem Soundtrack Lieder von Mika („\"Love Today\"“), Donavon Frankenreiter („\"Free\"“), Dry Spells („\"Happy People\"“), Mishon („\"Love will find a way\"“), Fibes, Oh Fibes! („\"Love Child\"“), Self („\"You’re not alone\"“) und VV Brown („\"Shark in the Water\"“). Am 29. Oktober 2010 erschien eine Hörspielfassung auf CD und MC mit den deutschen Synchronsprechern des Films und Thomas Karallus als Erzähler.\n\nEine etwa 15-minütige Kurzfassung des Films in „4D“ wurde in Deutschland im Hansa-Park und im Europa-Park gezeigt. In den Niederlanden lief dieser Kurzfilm im Attractiepark Slagharen. In der Freizeitpark-Version des Films sind andere Synchronsprecher zu hören als in der langen Kinofassung. Am 8. März 2011 erschien Sammys Abenteuer auf DVD und am 7. April 2011 auf Blu-ray Disc. 2012 wurde eine Fortsetzung von Sammys Abenteuer gedreht, bei der Detlev Buck, Axel Stein, Boss Burns, Hoss Power, Der Graf und Paul Panzer in der deutschen Synchronisation die Hauptrollen sprechen. Kinostart in Deutschland war der 20. Dezember 2012.\n\n2010 wurde Sammys Abenteuer in der Kategorie Bester Animationsfilm für den Europäischen Filmpreis nominiert. Daneben erhielt Ben Stassen im Februar 2011 die Trophée du film européen beim belgischen Filmfestival in Aubel.\n\n"}
{"id": "5831447", "url": "https://de.wikipedia.org/wiki?curid=5831447", "title": "Reduce (Computeralgebrasystem)", "text": "Reduce (Computeralgebrasystem)\n\nReduce ist ein Computeralgebrasystem, das sich als Allzwecksystem eignet und besonders mit Hinblick auf physikalische Anwendungen entwickelt wurde.\n\nSeit 2008 ist Reduce als Open-Source-Projekt freigegeben und unter einer modifizierten BSD-Lizenz bei SourceForge kostenlos erhältlich. Die Entwicklung steht seit den 1960er Jahren unter der Leitung von Anthony C. Hearn.\n\nReduce ist in einem eigenen Lisp-Dialekt (Standard LISP) implementiert. Die Anwendersprache ist RLISP, das eine ALGOL-ähnliche Syntax hat. Besonderes Gewicht wurde auf Portierbarkeit gelegt. Es existieren Versionen für die meisten Varianten von Unix, Linux, MS Windows und Apple Macintosh.\n\nAb der Version 4.2 bietet die Dynamische-Geometrie-Software (DGS) GeoGebra über ein separates Konsoleninterface den Zugriff auf MPReduce als internes Computeralgebrasystem.\n\n"}
{"id": "5833198", "url": "https://de.wikipedia.org/wiki?curid=5833198", "title": "Samsung Omnia 7", "text": "Samsung Omnia 7\n\nDas Samsung Omnia 7 (auch bekannt als Samsung GT-I8700) ist ein Smartphone des südkoreanischen Herstellers Samsung Electronics. Es nutzt das Betriebssystem Windows Phone 7.\n\nDas Samsung Omnia 7 ist Samsungs erstes Smartphone mit Microsofts Mobiltelefon-Betriebssystem Windows Phone 7 für den europäischen Markt. Das Schwestermodell Samsung Focus mit zusätzlichem SD-Kartenslot ist offiziell in Europa nicht erhältlich.\n\nAls Hardware-Basis kommt ein Snapdragon-System-on-a-Chip des Typs QSD8250 zum Zuge. Der mit 1 GHz getaktete Prozessorkern namens Scorpion ist ein \"ARM-Cortex-A8\", er wird von 512 MB Arbeitsspeicher unterstützt.Grafische Berechnungen übernimmt der Adreno 200-Chip von Qualcomm, der unter anderem den OpenGL ES 2.0- sowie Direct3D-Standard beherrscht.\nDas QSD8250 ist die erste Generation der Snapdragon-Produktelinie und unterstützt mehrere Mobilfunkstandards, darunter GPRS, EDGE, UMTS und HSPA.\nZudem enthalten alle Snapdragons Recheneinheiten zum Dekodieren von HDTV mit einer Auflösung von 720p und einen GPS-Empfänger.\n\nDas Omnia 7 hat einen 4,0 Zoll (10,2 cm) großen kapazitiven Multi-Touch-Screen, der mit 480 × 800 Pixel (WVGA) auflöst und eine Farbtiefe von 24 Bit anzuzeigen vermag, was rund 16,78 Millionen Farben entspricht (True Color). Das \"Samsung Omnia 7\" ist das einzige für den europäischen Markt freigegebene Windows-Phone-7-Smartphone der ersten Generation mit Super-AMOLED-Display.\n\nEntgegen anderen Modellen, wie etwa dem HTC HD7, kommt im \"Samsung Omnia 7\" anstatt eines internen SD-Kartenslot ein festgelöteter NAND-Speicher zum Zuge. Dies führt zum einen zwar dazu, dass es unmöglich ist, den internen Speicher zu erweitern, wie es beispielsweise bei den HTC-Modellen möglich ist. Die Verwendung des NAND-Speichers führt in der Praxis jedoch zu einer deutlich kürzeren Ladezeit von Programmen oder dem Betriebssystem selbst. Auf der Videoplattform YouTube ist ein Vergleich der Ladezeiten zwischen einem \"Samsung Omnia 7\" und einem hardwareseitig nahezu identischem HTC 7 Trophy zu sehen.\n\nDie integrierte Kamera kann Fotos mit einer Auflösung bis zu 5 Megapixel (2560 × 1920 Pixel) schießen. Zur Lichtmessung kommt ein aktiver Pixelsensor (auch bekannt als \"CMOS-Sensor\") zum Zuge. Bei schlechten Lichtverhältnissen erhält die Kamera zudem Unterstützung durch ein zuschaltbares LED-Licht. Filme können mit einer Auflösung bis zu 720p (1280 × 720 Pixel) aufgenommen werden bei einer Bildwiederholrate von 24 FPS. Außerdem stehen dem Nutzer verschiedene Aufnahmeprogramme zur Verfügung, darunter \"sepia\", \"antik\", \"mono\" und \"negativ\". Zur Aufnahme von entfernten Objekten existiert ein 4-facher-Digitalzoom. Fotos werden im weit verbreiteten JPEG-Format abgespeichert.\n\nDrahtlos kommuniziert das \"Samsung Omnia 7\" per WLAN-Standard 802.11 b/g/n, GPRS, EDGE, UMTS, HSPA und Bluetooth 2.1. Zudem ist eine A-GPS-Antenne eingebaut.Es werden die Bluetooth-Profile A2DP, AVRCP, HFP, HSP und PBAP unterstützt.\n\nDas Samsung Omnia 7 ist mit Beschleunigungssensor, digitalem Kompass, Näherungssensor und einem Umgebungslichtsensor ausgerüstet.\n\nDie Maße des Smartphones betragen 122,4 × 64,2 × 10,99 mm (H × B × T), wobei das Gerät auf ein Gewicht von 138 Gramm (mit Akku) kommt.\n\nSamsung verbaut einen Lithium-Ionen-Akku mit einer Nennkapazität von 1500 mAh.\n\nGemäß Angaben seitens Samsung reicht der Akkumulator im 2G-Netz für rund 520 Minuten (8,6 h) Gespräch oder 390 Stunden (entspricht rund 16 Tagen) im Standby. Im 3G-Netz verkürzt sich die Gesprächszeit nach offiziellen Angaben auf 370 Minuten (6,2 h) und die Standby-Zeit auf 330 Stunden (entspricht knapp 14 Tagen).\n\nIm Smartphone-Forum \"PocketPC.ch\" wurde eine Umfrage unter den \"Samsung Omnia 7\"-Benutzern durchgeführt, welche die durchschnittliche Akkulaufzeit ermitteln sollte.\nDie Umfrage ergab, dass bei häufiger Verwendung die Nutzdauer durchschnittlich um die zwei Tage beträgt, bei intensiver Nutzung muss das Smartphone täglich an die Steckdose. Diese Werte sind leicht überdurchschnittlich im Vergleich zu ähnlich leistungsfähigen Smartphones, was sowohl dem Umstand der großen Akkukapazität von 1500 mAh geschuldet ist wie auch der stromsparenden AMOLED-Display-Technologie.\n\nEin besonderes Ausstattungsmerkmal des \"Samsung Omnia 7\" ist der, herkömmlichen TFT-Displays technologisch überlegene, Super-AMOLED-Bildschirm, der ansonsten nur noch im Nokia Lumia 900 vorzufinden ist. Zudem verfügt das Gerät, gemeinsam mit dem LG Optimus 7, über den kapazitiv zweitgrößten Akkumulator aller \"Windows Phone 7\"-Smartphones hinter dem Nokia Lumia 900.\n\nKunden der deutschen Telekom bekommen kostenlos die Navigationslösung Navigon Select mit Karten von Deutschland, der Schweiz und Österreich.\n\nWird ein Windows-Phone-7-Gerät bei einem Provider gekauft, so sind die MMS-Einstellungen bereits ab Fertigung fest hinterlegt. Problematisch wird diese Tatsache, wenn das Gerät in einem anderen Netz genutzt werden möchte – Windows Phone 7 bietet bis dato keine Möglichkeit, die MMS-Einstellungen zu ändern. Da viele der im freien Handel erhältlichen Geräte, welche also ohne Abonnement verkauft werden, ebenfalls gebrandet sind, führt dies zwangsläufig zu Problemen bei der MMS-Nutzung. Dies betrifft insbesondere die in Deutschland erhältliche 16-GB-Versionen des \"Samsung Omnia 7\", da diese zwar im freien Handel verkauft werden, allerdings trotzdem über ein T-Mobile Branding verfügen.\nBetroffen von dieser Problematik sind sämtliche Gerätehersteller von \"Windows Phone 7\"-Smartphones, allerdings haben HTC und Samsung bereits ein Tool entwickelt, welches dem Problem entgegenwirkt.\n\nBeim \"Samsung Omnia 7\" können mit der Samsung-Anwendung \"Netzprofil\" die Provider-Einstellungen manuell hinterlegt werden. Zu finden ist das Programm im \"Windows Phone 7 Marketplace\" in der Kategorie \"Samsung Zone\". Mit dem Tool können auch eventuelle Verbindungsprobleme mit dem Internet behoben werden.\n\nAnfang Januar wurde von Microsoft ein erstes Update für Windows Phone 7 angekündigt, welches einige Neuerungen und Verbesserungen mit sich bringt – unter anderem die lang erwartete \"Copy&Paste\"-Funktion. Dieses Update trägt den Namen \"NoDo\" (\"No Donut\").\nAm 21. Februar 2011 wurde von Microsoft ein erstes Update freigegeben, dessen einzige Funktion darin bestand, die \"Windows Phones\" auf das kommende \"NoDo\"-Update vorzubereiten. Dieses führte bei vielen \"Windows Phones\" zu Problemen, betroffen waren insbesondere die \"Samsung Omnia 7\". Microsoft empfahl Nutzern des \"Omnia 7\" daraufhin, solange keine Updates durchzuführen, bis das Problem mit dem Fehler-Code 800705B4 behoben wurde. Geräte, auf welchen das Update bereits durchgeführt wurde und Probleme auftraten, konnten teilweise nicht mehr vollumfänglich benutzt werden. Microsoft bot den Betroffenen an, das fehlerhafte Gerät umtauschen zu lassen. Ein Microsoft-Mitarbeiter veröffentlichte kurz darauf einen Workaround für das \"Omnia 7\", mit dessen Hilfe einige Geräte wieder zum Laufen gebracht werden konnten. Da dieser Workaround allerdings nicht offiziell von Microsoft kommuniziert wird, geschieht die Durchführung auf eigene Gefahr.\n\nDurch die Probleme mit dem Vorbereitungs-Update verzögerte sich die für Ende Februar geplante Auslieferung des \"NoDo-Updates\". Ein überarbeitetes Update, welches Anfang März ausgeliefert wurde, sorgte auf den \"Samsung Omnia 7\" weiterhin für Probleme.\n\nBereits kurze Zeit nach der Auslieferung der ersten Geräte wurde bekannt, dass man mittels Anrufen einer bestimmten Netznummer einen \"Diagnose Modus\" starten kann. Über diesen Modus sind erweiterte Einstellungen möglich, welche Zugriffe auf das System zulassen, die so von Microsoft nicht angedacht waren. Solche Programme werden von Herstellern oftmals während der Entwicklungsphase zum Testen des Gerätes eingebaut und vor der Produktion wieder entfernt. Unklar ist, ob in diesem Fall von Samsung das Entfernen absichtlich vergessen wurde, um einigen der Restriktionen von Windows Phone 7 entgegenzuwirken.\n\nDie wohl mit Abstand wichtigste Funktion, welche sich über Telefoncodes aktivieren lässt, ist das Tethering (engl. Anbinden). Tethering bezeichnet die Verbindung eines Smartphones mit einem PC oder Notebook, um diesem eine Internetverbindung über das Funknetz (beispielsweise UMTS oder HSPA) zu ermöglichen. Das Mobiltelefon übernimmt damit die Rolle eines Modems. Tethering wurde offiziell von Windows Phone 7, im Gegensatz zum Vorgänger Windows Mobile nicht unterstützt. Mit Windows Phone 7.5 (Mango) ist es jetzt auf allen bisherigen Geräten möglich, sein Gerät als Hotspot einzurichten und so das eigene Internet mit anderen zu teilen bzw. für diese freizugeben.\n\nUm Tethering zu aktivieren müssen die folgenden Schritte befolgt werden:\n\nEs ist nun möglich eine Verbindung mit dem Internet per Wahlfunktion aufzubauen. Eventuell müssen noch Treiber für das Handy installiert werden, da das Handy nun als Modem erscheint. In diesem Modus ist es nicht möglich das Handy mit Zune oder einer anderen Software zu synchronisieren. Um die Sync-Funktionalität wiederherzustellen, müssen lediglich die oben genannten Schritte noch einmal ausgeführt werden und \"Zune Sync\" ausgewählt werden.\n\nZur Konfigurationen von Netzwerk-Komponenten wird oftmals die fixe MAC-Adresse eines Gerätes benötigt. Windows Phone 7 verfügt im Auslieferungszustand über keine Möglichkeit, diese Adresse anzuzeigen. Erst mit dem Update \"NoDo\" (Version 7.0.7390.0) wird unter den Einstellungen die MAC-Adresse angezeigt. Bei den älteren Versionen kann der Besitzer eines \"Samsung Omnia 7\" durch die Verwendung von \"Telefoncodes\" die Adresse erhalten. In dem auf Smartphone spezialisierten User-Forum \"PocketPC.ch\" wurde eine entsprechende Anleitung veröffentlicht.\n\nNeben der Aktivierung von Tethering und dem Anzeigen der MAC-Adresse ist es zudem möglich, mehrere Systemtests durchzuführen um Hardwarekomponenten auf ihre korrekte Funktion hin zu überprüfen. Zu den unterstützten Tests zählen unter anderem eine Multitouch-Diagnose, eine LCD-Diagnose inklusive Kompass und Helligkeit, ein Test des Akkumulators und weitere. Eine Übersicht über alle Diagnosemöglichkeiten und eine Auflistung der zugehörigen Codes finden sich in dem Smartphone-Forum \"PocketPC.ch\".\n\nIn den weltweiten Rezensionen wurde insbesondere das – herkömmlichen LC-Displays deutlich überlegene – Super-AMOLED-Display des \"Samsung Omnia 7\" gelobt. Auch die Verarbeitungsqualität des in einem Metallgehäuse eingefassten Smartphones wurde häufig positiv hervorgehoben sowie die überdurchschnittliche Akkukapazität von 1500 mAh. Kritik wurde hauptsächlich bei dem mit 8 GB, gegenüber Konkurrenten wie dem iPhone, unterdimensionierten Speicherplatz geäußert. Die übrige Kritik betraf hauptsächlich das Betriebssystem Windows Phone 7, da dieses in seiner ersten Version noch manche Funktionen vermissen lässt, welche bei anderen mobilen Betriebssystemen bereits zum Standard gehören. In Fachmagazinen gilt das \"Samsung Omnia 7\" als die beste Wahl unter den Geräten der ersten Generation von \"Windows Phones\".\n\nIn den folgenden Kritikausschnitten wird nur auf das Gerät selbst, jedoch nicht auf das Betriebssystem Windows Phone 7 eingegangen. Dieses wird in einem separaten Artikel behandelt.\n\n"}
{"id": "5835276", "url": "https://de.wikipedia.org/wiki?curid=5835276", "title": "Lookeen", "text": "Lookeen\n\nLookeen ist ein Desktop- und E-Mail-Suchprogramm. Es unterstützt die Suche nach Dateien, E-Mails, Kontakten und Dateianhängen etc. auf dem eigenen Computer, Microsoft Exchange Server und Applikations- sowie Terminalserver.\n\nSeit der Einführung von Lookeen 10 handelt es sich bei der Shareware um ein eigenständiges Desktop-Suchtool. Nach der Installation und der ersten Indexierung gestattet Lookeen ein schnelles und einfaches Durchsuchen der persönlichen Dateien auf dem Desktop und in Outlook. Die Indexdatei wird dabei zum Schutz der Daten ausschließlich im lokalen Netzwerk gespeichert; auch in Unternehmens- und Virtuellen-Desktop-Infrastructure-Umgebungen (VDI) wird die Indexdatei nur im Unternehmensnetzwerk – und nicht etwa in einer Cloud – gespeichert.\n\nDie Anwendung wird über das zweimalige Drücken der -Taste oder über das Startmenü aufgerufen. Lokale Dateien können direkt in der Vorschau bearbeitet und gespeichert werden, ohne dass Microsoft Word oder Microsoft Excel separat gestartet werden müssen.\n\nDie Vorgängerversion, Lookeen 8, musste als reine Outlook-Erweiterung nach dem Outlook-Add-on-Konzept noch direkt in Microsoft Outlook integriert werden. In Lookeen 10 ist diese Erweiterung optional. Gegenüber herkömmlichen E-Mail-Client-Suchmaschinen beinhaltet der Index von Lookeen auch die gesamte Ordnerstruktur Outlooks.\n\nDie Gestaltung der ersten Versionen ähnelte sehr stark der E-Mail-Suchsoftware \"Lookout\" des Silicon-Valley-Startups Lookout Soft Inc. Lookout wurde 2004 von Microsoft für angeblich 6 Mio. US-Dollar übernommen, um dann in die Windows Desktop Search integriert zu werden. Lookout selbst wurde weiterhin als Freeware gehandelt, aber war ab Outlook-Version 2007 nicht mehr oder nur noch unter erheblichen Modifizierungen installierbar.\nIm Januar 2007 startete Axonic die Entwicklung eines Nachfolgermodells für Lookout, das mit dem Release von Microsoft Windows Vista im Januar 2007 nicht mehr eingesetzt werden konnte. Im Januar 2008 brachte Axonic mit Lookeen schließlich eine Lösung für professionelle Daten- und E-Mail-Suche auf den Markt und verkaufte dieses innerhalb von acht Monaten in über 40 Länder. Im März 2010 gewann Lookeen den Award für das “Best Outlook Add-on 2010” der US-Webseite About.com. Heute wird Lookeen nach Angaben des Herstellers in über 100 Länder verkauft. 2013 wurde die Version Lookeen 8 zusammen mit einer neuen Enterprise Search Version veröffentlicht. Seit der Veröffentlichung von Lookeen 10 im Frühjahr 2015 steht die Desktopsuche nicht mehr nur Outlook-Nutzern zur Verfügung, sondern kann unabhängig in allen Windows-Betriebssystemumgebungen als Alternative zur Windows Desktop Search genutzt werden.\n\nDie Software setzt bei ihrer Suche auf das freie Projekt Lucene 3.0, die Typenbibliothek Outlook Redemption und das Outlook Object Model.\n\n\nLookeen 10 unterstützt die zentrale Indizierung geteilter Ressourcen im Netzwerk (z. B. Netzwerkdateien und Öffentliche Ordner). Dabei wird ein einziger geteilter Index angelegt und zentral gespeichert. Dieser Index kann über eine URL im Netzwerk von allen Clienten im Netzwerk erreicht werden. Dadurch sollen Netzwerk- und Serverkapazitäten sowie der lokale Speicherbedarf geschont werden.\n\nSchon seit Lookeen 8 werden Group Policies unterstützt, die die gleichzeitige Verteilung der Software an mehreren Arbeitsplätzen im Unternehmen erlauben. Dabei können viele Optionen (z. B. der Speicherort des Indexes und der Einstellungsdateien, sowie Indexintervalle und Lizenzschlüssel) zentral vom Administrator gesteuert werden. Diese Erweiterung erleichtert den Einsatz von Lookeen auf großen Terminalservern oder Citrix Umgebungen.\n\nDie Desktop Search wird zurzeit von den Betriebssystemen Windows 2000, XP, Vista, Windows 7, Windows 8 sowie Windows 10 unterstützt – letztere sowohl in der 32- als auch der 64-Bit-Version. Die aktuelle Version wurde noch vor Release von Windows 10 auf den Markt gebracht und komplett überarbeitet. Lookeen ist integrierbar in Microsoft Office 2013, 2010, 2007, 2003 oder 365. Die Software ist kompatibel mit virtuellen Umgebungen (VDI) wie Citrix, Terminalserver und VMware.\n\nIm Juli 2011 wurde der Lookeen Server als Enterprise Search Lösung veröffentlicht. Dieser unterstützt globale Indizierungsfunktionen und erlaubt die volle Kontrolle über alle Clients und den Server mittels Windows Gruppenrichtlinienverwaltung. Die Sicherheit der Daten wird durch Berücksichtigung der Windows-Berechtigungsstruktur und durch SSL- und interne Verschlüsselung gewährleistet.\n\n"}
{"id": "5840516", "url": "https://de.wikipedia.org/wiki?curid=5840516", "title": "Open Source Tripwire", "text": "Open Source Tripwire\n\nOpen Source Tripwire ist eine freie Software für POSIX-kompatible (Unix-)Betriebssysteme, welche durch die Überwachung und Anzeige bestimmter Datenänderungen die Sicherheit und Datenintegrität auf diversen Systemen gewährleistet.\n\nOpen Source Tripwire basiert auf Programmcode, der im Jahre 2000 von Tripwire, Inc. zur Verfügung gestellt wurde, und wird seitdem als freie Software unter den Bedingungen der GNU General Public License (GPL) verbreitet.\n\nAndere Open-Source-Projekte bieten ähnliche Funktionen, wie beispielsweise OSSEC, AIDE und Samhain.\n\nOpen Source Tripwire arbeitet als hostbasiertes Intrusion Detection System und überwacht Objekte des Dateisystems auf Veränderungen.\n\nBei der ersten Inbetriebnahme führt Open Source Tripwire einen Scan des Dateisystems nach Vorgaben des Administrators durch und speichert Informationen für jede gescannte Datei in einer Datenbank. Zu späteren Zeitpunkten werden die Dateien erneut gescannt und mit den früheren Ergebnissen in der Datenbank verglichen. Änderungen werden dem Nutzer bekannt gegeben. Open Source Tripwire verwendet Prüfsummen, um Dateiänderungen zu erkennen, ohne dafür eine vollständige Kopie der Datei anlegen zu müssen.\n\nOpen Source Tripwire erkennt Angriffe vor allem, nachdem sie geschehen sind, kann aber auch für andere Zwecke verwendet werden, wie Integritätsprüfungen, Change Management und die Einhaltung von Richtlinien (Policy Compliance).\n\n"}
{"id": "5844316", "url": "https://de.wikipedia.org/wiki?curid=5844316", "title": "K 1600", "text": "K 1600\n\nK 1600 war eine Familie von Mikrocomputern mit den Varianten K 1620 und K 1630. Die Chiffren im System der Kleinrechner (SKR) der früheren Länder des RGW (Comecon) waren \"CM 1620\" bzw. \"CM 1630\". Sie wurden ab 1978 in der DDR vom VEB Robotron-Elektronik Dresden in Dresden entwickelt und 1981 in die Serienproduktion überführt.\n\nDie Rechner der K 1600-Familie waren die ersten Mikrocomputer der DDR, die nach den im SKR festgelegten Operationsprinzipien arbeiteten, welche sich an der Rechnerarchitektur PDP-11 der Firma Digital Equipment Corporation (DEC) orientierten. Als Nachfolger der K 1600 wurde ab Ende 1979 ein 16-Bit-Mikrorechnersystem mit der Bezeichnung K 1700 nach dem Vorbild der PDP-11/44 auf Basis eines neuen, vorbildfreien Schaltkreissystems U84x entworfen. Diese Entwicklung wurde 1982 abgebrochen und erst die VAX-kompatiblen Modelle K 1820 und K 1840 sollten den Bedarf an Rechnern höherer Leistungsklasse Ende der 1980er Jahre decken.\n\nDie wichtigsten Einsatzgebiete lagen im Bereich der automatisierten Produktionssteuerung, der Labor- und Prüffeldautomatisierung für Industrie, Forschung und Entwicklung sowie universeller Informationsverarbeitungssysteme.\n\nDie Rechnerkerne der Modelle K 1620 und K 1630 gründeten sich auf die dafür gemeinsam mit dem ZFTM des Kombinats Mikroelektronik und einem Betrieb des sowjetischen Ministerium für Elektroindustrie (MEI) entwickelten Schaltkreise der Reihe U830C in LSI-NMOS-Technik. Als Speicherschaltkreise wurden 4 und 16 KBit DRAMs verwendet, die weitere Logik war in TTL-MSI-Technik wie bei den ESER-Zentraleinheiten des Kombinates Robotron realisiert.\n\nDas System K 1600 war auf der Grundlage der 19″-Einschubbauweise hinsichtlich des Arbeitsspeichers und der Anschlusssteuerungen ähnlich wie das Mikrorechnersystem K 1520 äußerst modular ausgelegt. Auf Basis des K 1600-Systems wurden u. a. die Finalprodukte\nverkauft.\n\nDie Produktion des K 1620 und der daraus abgeleiteten Anwendungssysteme begann 1981, ein Jahr später ging der K 1630 in Serie. Vom K 1620 wurden bis 1987 280 Geräte und bis 1989 1.845 Einheiten vom K 1630 produziert.\n\nVom K 1620 befindet sich ein Exemplar in den Technischen Sammlungen Dresden. Vermutlich ist es das letzte vorhandene Gerät dieser Variante. Von der K 1630 existieren (Stand 04/2016) noch 5 Maschinen. Diese befinden sich hier:\n\nDie Mikrorechnerfamilie K 1600 besteht aus den Rechnern K 1620 und K 1630, dem gemeinsamen Modellbestand an peripheren Geräten und der zum Betrieb erforderlichen Software. Die Rechner sind modular in 19″-Einschubtechnik aufgebaut.\nNeben dem sich unterscheidenden Rechnerkernen nutzen beide Rechner ein Spektrum an gemeinsamen Funktionseinheiten, nämlich\nDurch Einbindung spezieller peripherer Geräte und Ergänzung mit spezifischen Softwaremodulen entstanden Finalerzeugnisse (z. B. Prozessrechner durch den Anschluss der Prozessein- und -ausgabeeinrichtung, Betriebsdatenerfassungssysteme durch die Integration von manuellen und maschinenabhängigen Dateneingabeplätzen, CAD/CAM-Arbeitsplätze für Konstrukteure und Technologen durch die Einbindung von Grafikterminals, Digitalisiergeräten und Plotter usw.), für die dann unterschiedliche Robotron-Vertriebsbetriebe verantwortlich zeichneten.\n\nDer Rechnerkern des K 1620\nwird durch die Zentrale Verarbeitungseinheit (ZVE) K 2662 mit 64 KB Adressraum und einer Rechenleistung von ca. 0,3 MIPS gebildet. Sie besteht im Wesentlichen aus vier Mikroprozessorchips U830C (К1883ИА0) mit je 8 Bit Verarbeitungsbreite, dem Mikroprozessorsteuerwerk und der Bussteuerung mit folgenden Funktionen:\n\nDer Rechnerkern des K 1630\nbildet sich aus der (ausgehend vom K 1620 erweiterte) ZVE K 2664 mit 256 KB Adressraum und wahlweise noch dem Arithmetikprozessor ARP K 2061 (Basis: sowjetischer Mikroprozessor КР1804ВС1=AМ2901). Zusätzlich zu den Funktionen der ZVE K 2662 sind der K 2664\nund mit der integrierten Speichervermittlungseinheit SVE die Funktionen\nzuzuordnen.\n\nDen Rechnerkernen konnten Speicherbaugruppen – je nach Konfiguration mit oder ohne Fehlerkorrektur – mit bis 248 KB DRAM sowie mit programmierbaren Festwertspeichern (PROM) von bis zu 16 KB hinzugefügt werden. Hier kamen DRAM-Schaltkreise mit 4 KBit (KP565PY1=2107) oder 16 KBit (KP565PY3=U256=4116) bzw. PROMs mit 2 KBit (U555=2708) zu Einsatz.\nZur Nutzung vorhandener Software des Vorgängers Robotron R 4000 (Honeywell DDP 516) wurde ein Emulatorprozessor K 2063 auf Basis des sowjetischen Nachbaus К589ИКxx der Bit-Slice-Prozessorfamilie Intel 3000 entwickelt.\n\nFür die Rechner der K 1600-Familie standen verschiedene Magnetband-, Disketten-, Festplatten- und Wechselplattensysteme aus eigener Produktion oder aus dem SKR/ESER-Verbund zur Verfügung. Die Schaltkreisfamilie К589ИКxx wurde auch bei der Anschlussteuerung für Kassettenplattenspeicher („Winchester“-Wechselplatten analog IBM 3440) K 5160 (K 5164) verwendet. Für die Anschlusssteuerung für Disketten- und Festplattenlaufwerke K 5161 (K 5163) bzw. K 5165 wurde die U83x-Schaltkreisfamilie genutzt.\n\nJe nach Kundenwunsch konnten verschiedene Anschlusssteuer-Baugruppen (V.24, IFSS, IFSP, IFLS, IMS) zum Anschluss peripherer Geräte (Terminals, Drucker, Plotter, Digitalisiergeräte), zum Mehrrechnerverbund (Rechnerkopplung) oder zur Labor- oder Prozessautomatisierung (z. B. CNC-Steuerung CNC H645) hinzugefügt werden. Über die IFSS-Schnittstelle wurden die Terminals K 8911, K 8912 oder K 8917 zur Bedienung der K 1600-Systeme angeschlossen.\n\nBei allen Baugruppen wurde zur Anbindung des K 1600-Systembusses an die Mikroprozessoren oder LSI-Interfaceschaltkreise ein speziell entwickelter Bussteuerschaltkreis U834 (К1883ВА4) verwendet. Zur Anbindung des K 1600-Systembusses an den SKR-Einheitsbus wurde ein Busumsetzer BUM K 4162 eingesetzt. Über einen speziellen Controllereinschub namens „C-RES“ konnten außerdem Baugruppen westlicher PDP 11-Rechner (mit DEC-UNIBUS) benutzt werden.\n\nIm Gegensatz zu anderen Ostblock-PDP11-Clones entwickelte die DDR eine komplett eigenständige Plattform mit eigenem Formfaktor, Steckverbindern, Bus- und Prozessorstruktur, Systemterminal-Anbindung und Bootloader-ROMs. Hierdurch sind die K1600-System nicht 1:1 kompatibel zu DIGITAL PDP11 und auf DDR-Betriebssysteme angewiesen.\n\nAls Betriebssysteme wurden das modulare Betriebssystem MOOS 1600 (teilkompatibel zu RSX 11M von DEC), dessen Nachfolger OMOS 2.0, das Betriebssystem zur Laborautomatisierung LAOS 1600 (teilkompatibel zu RT11 von DEC) sowie der Unix V-Klon MUTOS 1630 vertrieben. Für die K 1600 waren Compiler für die Programmiersprachen BASIC, Fortran IV sowie für C, COBOL, Pascal und CDL verfügbar.\nFür zahlreiche Projekte wurde spezielle problemorientierte Anwendungssoftware zur Prozessautomatisierung mit dem K 1630 geschaffen. Beispielsweise wurden\nrealisiert.\n\n\n"}
{"id": "5846473", "url": "https://de.wikipedia.org/wiki?curid=5846473", "title": "Rekonq", "text": "Rekonq\n\nrekonq (Abkürzung für , \"Rückeroberer\") ist ein innerhalb von KDE entwickelter Webbrowser. Er nutzt WebKit als HTML-Rendering-Engine und erbt damit dessen hohe Kompatibilität zu Webstandards. Er gilt als intuitiv bedienbarer, konkurrenzfähiger Browser, der ressourcenschonend und schnell ist.\n\nEr ist (wie bei KDE-Anwendungen üblich) in C++ geschrieben und wird als freie Software auch im Quelltext unter den Bedingungen von Version 3 der GNU General Public License (GPL) verbreitet. Er integriert sich in die KDE Plasma Workspaces.\n\nrekonq teilt mit Konqueror ein gemeinsames Cookie- und Lesezeichen-System, speichert Kennwörter in der zentralen Kennwortverwaltung \"KWallet\" und greift für Downloads auf KGet zurück.\nDie minimalistische Benutzerschnittstelle lehnt sich in vielen Aspekten stark an Konzepte von Chrome an.\nIn Entwicklung ist eine Schnittstelle für Erweiterungen, die mit Chrome kompatibel ist. Eine Funktion zum Blockieren von Reklame ist bereits integriert. Funktionen zur selektiven Vermeidung („Privater Modus“) oder zur Löschung von Surfdaten („Private Daten löschen“) stehen zur Verfügung.\n\nrekonq baut auf QtWebKit auf, einem Modul des der gesamten KDE Software Compilation zugrunde liegenden Benutzerschnittstellen-Toolkits \"Qt\", das Qt-Anwendungen Rendering und Interaktion mit Webseiten mittels WebKit ermöglicht. Es nutzt KDE-Input/Output-System (KIO) und greift für zahlreiche Funktionen auf die Standardwerkzeuge der KDE Software Compilation zurück.\n\nrekonq wurde als Abspaltung der von Nokia erstellten Qt-Demonstrationsanwendung „QtDemoBrowser“ entwickelt.\nAm 25. Mai 2010 wurde es in die „Extragear“-Abteilung von KDE aufgenommen. Von Version 10.10 bis 13.10 war rekonq Standardbrowser bei Kubuntu. rekonq ist mittlerweile Standard bei Chakra GNU/Linux.\n"}
{"id": "5847703", "url": "https://de.wikipedia.org/wiki?curid=5847703", "title": "Day &amp; Night", "text": "Day &amp; Night\n\nDay & Night ist ein Animations-Kurzfilm aus dem Jahr 2010 von Regisseur Teddy Newton für die Pixar Animation Studios und die Walt Disney Company. Der Film wurde als Vorfilm zu \"Toy Story 3\" gezeigt. \n\nDay ist eine Cartoonfigur, auf dessen Körperoberfläche sich Szenen im Tageslicht abspielen. Wenn Day seine Position verändert, verändert sich auch die Projektion auf seinem Körper.\nNight ist eine gleiche Figur, auf deren Körperoberfläche sich Szenen der Nacht abspielen. Beide Figuren zeigen über die Szenen auch ihre Emotionen, womit sie ihre jeweils angedeuteten Handlungen zusätzlich unterstreichen. Die Figuren selbst sprechen nicht, sondern betreiben Pantomime, welche durch Musik und Geräusche der Projektionen verstärkt wird. \n\nDay begegnet während eines Spazierganges dem schlafenden Night. Zur Abstraktion projiziert Day eine Sonne und Night einen Mond, inklusive kleiner Schäfchen, die über einen Zaun springen. Nachdem Night von Day geweckt wurde, staunen beide über den jeweils anderen. Was immer der eine auf sich projiziert, zeigt der andere als gegensätzliche Szene. Zum Beispiel zeigt Day eine sonnenbadende Frau am Strand, wogegen Night dieselbe Szene in der Nacht zeigt, ohne Frau, dafür mit etwas Müll als Hinterlassenschaft.\n\nBeide stauen Aggressionen auf und es kommt zu einem Schlagabtausch, bei dem es keinen Sieger gibt. Als sie das erkennen, beginnen sie einander ihre besten Szenen vorzuführen, was in dem jeweils anderen für große Begeisterung sorgt. In einer Radioausstrahlung der Projektion hört man die hintergründige Botschaft des Films: „Alles Neue lehne ich ab, weil es mir Angst macht“. \n\nBeide umarmen sich als es bei Night zum Sonnenaufgang und bei Day zum Sonnenuntergang kommt. Die halben Sonnen beider Figuren treffen sich und erscheinen für einen Augenblick vereint. Danach wechselt Night zum Tag und Day zur Nacht. Beide freuen sich und beginnen die besten Szenen des anderen auf sich selbst zu projizieren.\n\n\n\"Day & Night\" wurde für die Oscarverleihung 2011 in der Kategorie \"Bester animierter Kurzfilm\" nominiert.\n\n"}
{"id": "5849596", "url": "https://de.wikipedia.org/wiki?curid=5849596", "title": "Die Chubbchubbs!", "text": "Die Chubbchubbs!\n\nDie Chubbchubbs! ist ein US-amerikanischer Computeranimations-Kurzfilm von Eric Armstrong aus dem Jahr 2002.\n\nDer Alien Meeper ist eine Reinigungskraft in dem Alienpub Ale-E-Inn. Gerne wäre er an Stelle der Sängerin, die in der Bar \"Respect\" von Aretha Franklin karaokesingt und verwandelt seinen Wischmop in einen Mikrofonständer – während seines Fantasiegesangs stößt er den Wassereimer um und bringt die Technik zum Erliegen, sodass die Sängerin ihren Auftritt beenden muss. Meeper wird entlassen. Draußen trifft er auf einen sterbenden Alien, der ihn kurz vor seinem Tod warnt, dass die Chubbchubbs im Anmarsch seien. In der Ferne wird eine riesige Staubwolke sichtbar, die näher kommt. Mehrere Versuche, die Pubgäste vor den Chubbchubbs zu warnen, schlagen fehl, da Meeper jedes Mal die Sängerin aus Versehen k.o. schlägt.\n\nErst ein fremder Alien warnt die Gäste vor den Chubbchubbs, die daraufhin panisch das Weite suchen. Auch Meeper will fliehen, sieht jedoch unweit seines Wischeimers ein paar kleine, flauschige Küken. Eilig versteckt er sie in seinem Eimer, verliert dadurch Zeit und steht schließlich den riesigen Monstern gegenüber, die sich mit der Staubwolke angekündigt hatten. In seiner Not singt er ihnen den Titel \"Wolln wir Freunde sein\" vor und ein Monster stimmt sogar mit ein. Bei seinem Tanz wirft Meeper unabsichtlich den Eimer um, in dem die Küken versteckt sind. Die Monster reagieren panisch, da es sich bei den Küken um die Chubbchubbs handelt. Die zeigen mit einem Mal Zähne und fallen über die Monster her, verspeisen sie samt Rüstung und kehren anschließend gurrend zu Meeper zurück.\n\nWenig später sieht man Meeper im Pub. Er singt \"Respect\", seine Backgroundsänger sind die Chubbchubbs. Nach Ende des letzten schiefen Tons herrscht Schweigen im Pub. Erst, als die Chubbchubbs demonstrativ ihre Zähne zeigen, beginnt das Publikum eifrig zu klatschen.\n\n\"Die Chubbchubbs\" war der erste, vollständig computeranimierte Kurzfilm, der von Sony Pictures Imageworks produziert wurde.\n\n\"Die Chubbchubbs!\" kam am 3. Juli 2002 in die US-amerikanischen Kinos. Er lief zunächst als Vorfilm zu \"Men in Black II\" und wurde wegen seines Erfolgs ab 19. Juli 2002 auch als Vorfilm von \"Stuart Little 2\" gezeigt. Im Jahr 2003 erschien er trotz seiner Gesamtlänge von nur etwas mehr als fünf Minuten einzeln und ohne Zusatzmaterial auf DVD.\n\n\"Die Chubbchubbs!\" enthält zahlreiche Anspielungen an andere Science-Fiction- und Alien-Filme, so sind Darth Vader und Yoda beim Armdrücken zu sehen (\"Das Imperium schlägt zurück\"), ein Außerirdischer flieht auf einem fliegenden Fahrrad vor den Chubbchubbs (\"E. T. – Der Außerirdische\") und ein sterbender Alien, der Meeper vor den Chubbchubbs warnt, ähnelt in seinem Äußeren Jar Jar Binks (\"\"). In der deutschen Synchronfassung ist zudem ein weibliches Alien zu hören, das zu ihrem Freund sagt: „Und du bleibst auch weiter Solo, Han“.\n\nIm Film sind die Titel \"Why Can’t We Be Friends\" von War, gesungen von Darryl Phinessee, Dorian Holley und Marlena Jeter, sowie Otis Reddings \"Respect\", gesungen von Mortonette Jenkins, zu hören.\n\nEine Fortsetzung des Films erschien unter dem Titel \"The ChubbChubbs Save Xmas\" am 8. August 2007 als Vorfilm zu \"\".\n\n\"Die Chubbchubbs!\" gewann bei der Oscarverleihung 2003 den Oscar in der Kategorie „Bester animierter Kurzfilm“.\n\nDer Film war 2003 für einen BAFTA Award in der Kategorie „Bester animierter Kurzfilm“ nominiert, verlor jedoch gegen \"Fish Never Sleep\". Auf der Berlinale 2003 unterlag der Film in der Kategorie „Bester Kurzfilm“ dem slowenischen Beitrag \"(A)Torzija\".\n"}
{"id": "5851959", "url": "https://de.wikipedia.org/wiki?curid=5851959", "title": "Freemake Video Converter", "text": "Freemake Video Converter\n\nDer Freemake Video Converter ist ein kommerzielles Umwandlungsprogramm der Digital Wave Limited Company. Das Programm ist für die Umwandlung von Videos, Musik, DVDs und Blu-rays in neue Formate geeignet. Außerdem kann man mit dem Video Converter DVDs rippen und brennen, Diashows aus Fotos und Musikvisualisierungen erstellen und Dateien auf YouTube hochladen.\n\nDer Freemake Video Converter kann Videos aus über 200 Formaten und von mehr als 50 Videoportalen importieren und Container/Formate wie AVI, MP4, WMV, MKV, Flash, 3gp, DVD oder MP3 konvertieren. Das Programm erzeugt Videos für die problemlose Wiedergabe auf verschiedenen Multimediageräten, wie etwa auf dem iPod, dem iPhone, dem iPad, der Xbox, der PSP, dem Blackberry, auf Nokia, Samsung und Geräten mit dem Android-Betriebssystem. Ebenso ist es möglich, Videos, Fotos und Musik auf eine DVD oder auf eine Blu-ray Disc zu brennen. Ein eingebauter Player hilft bei der Videobearbeitung. Hiermit lassen sich Filme schneiden, drehen, spiegeln und mehrere Videos in eine längere Datei zusammenfügen. Bei der Konvertierung lassen sich die maximale Größe der Ausgabedatei, der verwendete Video- und Audio-Codec, die Auflösung, die Bildfrequenz, die Audio- und Video-Bitrate, die Anzahl der Audiokanäle und die Abtastrate frei wählen oder nach voreingestellten Profilen festlegen. Außerdem ermöglicht das Programm Diashows aus Fotos zu erstellen und mit einer passenden Musik zu hinterlegen. Alle Dateien lassen sich direkt aus der Software heraus zu YouTube hochladen.\nDie Benutzeroberfläche vom Freemake Video Converter beruht auf der Windows Presentation Foundation Technologie. Von der Version 1.2.0 an unterstützt das Programm die CUDA-Technik von NVIDIA für die H.264-Verschlüsselung.\nVon der Version 2.2.0 an wird auch DXVA 2.0 Hardwarebeschleunigung unterstützt. Von Version 3.0 an konvertiert das Programm Videos in drei für HTML5 nötige Formate WebM, OggTheora und H.264 und erzeugt automatisch einen Code fürs Einbetten.\n\nDie FFmpeg-Entwickler werfen Freemake Video Converter vor, ihre Urheberrechte zu verletzen, indem FFmpeg-Derivate verbreitet werden, ohne die Regeln der GPL zu befolgen.\n\nVon Version 4 an wird Malware nachinstalliert, wenn man bei der Installation die Vereinbarungen nicht genau durchliest. Die entsprechenden Checkboxen sind ausgegraut, als wenn man sie nicht anklicken könnte, obwohl man die zusätzlichen Installationen damit abwählen kann.\n\n"}
{"id": "5856773", "url": "https://de.wikipedia.org/wiki?curid=5856773", "title": "Werkzeugverwaltung", "text": "Werkzeugverwaltung\n\nDie Werkzeugverwaltung wird in der zerspanenden Fertigung benötigt, um die Informationen über die vorhandenen Werkzeuge einheitlich zu organisieren und im Umfeld zu integrieren. Die Werkzeugdaten sind dabei in einer Datenbank gespeichert und werden mit der Werkzeugverwaltungs-Software erfasst und verwendet. Im Unterschied zu einer allgemeinen Lösung für die Verwaltung der Betriebsmittel beinhaltet eine Werkzeugverwaltung spezialisierte technische Datenfelder, Grafiken und Parameter, die für den Einsatz im Fertigungsprozess erforderlich sind.\n\nEin Werkzeug in der CNC-Fertigung besteht normalerweise aus mehreren Einzelteilen. Der korrekte Zusammenbau der einzelnen Komponenten zu einem solchen Komplett-Werkzeug ist Voraussetzung für eine fehlerfreie Wertschöpfungskette. Für die Bearbeitung eines Teils mit der CNC-Maschine (Arbeitsgang) sind jeweils mehrere Komplett-Werkzeuge erforderlich, die in einer Werkzeugliste dokumentiert werden. Jede Komponente, jedes Komplett-Werkzeug und jede Werkzeugliste hat eine Identifikation, unter welcher die zugehörige Spezifikation gefunden wird.\n\nDie Werkzeugverwaltung gliedert sich in die Dokumentation der Werkzeuge (Stammdaten) und die Logistik (Bewegungsdaten).\n\nDie Dokumentation umfasst mindestens alle Informationen, die für einen reibungsfreien und nachvollziehbaren Fertigungsprozess benötigt werden. Zudem können damit Ersatzteile, Erfahrungswerte für den Einsatz und zugehörige Dateien verwaltet werden. Es stehen Funktionen zur Verfügung um die Daten zu pflegen, zu verarbeiten, zu drucken und mit anderen Anwendungen auszutauschen.\n\nDie Logistik befasst sich mit der Bedarfsplanung, dem Bestand und dem Aufenthaltsort der Werkzeuge. Sie umfasst einerseits die Lagerhaltung und den Einkauf der Einzelteile mit entsprechender Auswertung des Verbrauchs. Anderseits können damit die Bewegungen der zusammengebauten Komplett-Werkzeuge innerhalb des Unternehmens geplant und koordiniert werden.\n\nDie Stammdaten beschreiben die Werkzeuge bezüglich der geometrischen Eigenschaften, des Aufbaus und der Verwendungsmöglichkeit. Die Informationen gliedern sich in die eigentliche Beschreibung der Werkzeuge (Spezifikationen), die Vorschriften für deren Verwendung durch Personen (Arbeitsanweisungen) und die Angaben für die Verwendung durch Maschinen (Instruktionen). Die Stammdaten beschreiben ein Werkzeug in qualitativer Hinsicht vollständig, aber ohne sich um die Verfügbarkeit der realen Exemplare zu kümmern.\n\n Die Komponenten sind Einzelteile, welche zu Komplett-Werkzeugen kombiniert werden. Komponenten werden als Einheit eingekauft und in der Werkzeugausgabe gelagert. Es wird unterschieden zwischen schneidenden Komponenten (z. B. Wendeschneidplatte) und nicht schneidenden Komponenten (z. B. Spannzangen). Schneidende Komponenten werden beim Einsatz verschlissen und müssen daher periodisch ersetzt und eingekauft werden. Nicht schneidende Komponenten sind bei normalem Gebrauch praktisch unbeschränkt einsetzbar. Sie werden meist zusammen mit einer neuen Werkzeugmaschine beschafft. Spannmittel werden wie nicht schneidende Komponenten behandelt.\n\n\n\n\n\nDie Komplett-Werkzeuge sind aus mehreren Komponenten aufgebaut. Am hinteren Ende befindet sich die Komponente, welche zur Werkzeugaufnahme der Maschine passt, auf der anderen Seite befindet sich die schneidende Komponente (z. B. Bohrer oder Wendeplatte). Dazwischen werden unterschiedliche Komponenten (z. B. Verlängerung, Spannzange) verwendet, um die gewünschte Geometrie des Komplett-Werkzeugs zu erreichen. Die Dokumentation des Komplett-Werkzeugs beschreibt, wie die Komponenten zusammengebaut werden müssen, damit Missverständnisse oder Fehler vermieden werden und gewährleistet ist, dass die im CAM-System verwendete Geometrie mit jener des realen Werkzeugs in der Werkstatt übereinstimmt.\n\n\n\n\n\n\nIn der Werkzeugliste sind alle Komplett-Werkzeuge aufgeführt, die für einen Arbeitsgang benötigt werden. Sie wird als Rüstliste ausgedruckt und dient der Kommissionierung und Bereitstellung der Komplett-Werkzeuge. Meist sind auch Anweisungen und Informationen darin enthalten, die nicht in direktem Zusammenhang mit den Werkzeugen stehen (z. B. Spannmittel, Aufspann-Pläne, NC-Programm, Spanndruck usw.), damit alle Unterlagen gemeinsam abgerufen werden können.\n\n\n\n\nNeben den eigentlichen Werkzeugdaten vereinfachen Hilfstabellen die Datenerfassung indem Werte aus einer Tabelle ausgewählt werden, statt sie erfassen zu müssen. Gegenüber einer manuellen Eingabe gewährleistet dies eine komfortablere und einheitliche Datenerfassung.\n\n\n\n\n\n\n\nDie Logistik befasst sich mit den Beständen, den Lagerorten und der Beschaffung von Werkzeugen. Innerhalb der Logistik wird unterschieden zwischen den einzelnen Komponenten und den daraus zusammengebauten Komplett-Werkzeugen. Bei den Komponenten ihrerseits wird unterschieden zwischen dem betriebsinternen Materialfluss und der Beschaffung bei externen Lieferanten (Lagerhaltung).\n\nDie Logistik der Komponenten umfasst in erster Linie die Bestandsführung, die Planung des Bedarfs und die Überwachung des Mindestbestands. Dabei wird bei Erreichen des Mindestbestands von der Werkzeugverwaltung ein Beschaffungsvorgang ausgelöst, der vom Einkauf mit dem ERP-System abgewickelt wird. Die Logistik der Werkzeugverwaltung verfügt über eine auf das Umfeld des Einsatzes abgestimmte Bedienung und über geeignete Schnittstellen zu Lagersystemen und anderen Einrichtungen innerhalb des Unternehmens. Voraussetzung für eine koordinierte Lagerhaltung der Komponenten ist eine zentrale Organisation der Werkzeuge, bei der alle Komponenten einer Fertigungseinheit an möglichst nur einer Stelle gelagert werden und jede Entnahme zuverlässig gebucht wird.\n\nBei der innerbetrieblichen Logistik interessiert vor allem, an welchem Ort sich eine gesuchte Komponente befindet und an welcher Kostenstelle sie verbraucht wurde. Verbraucht werden dabei nur die Verschleißteile (Schneiden), die andern Komponenten (Grundkörper, Spanmittel) werden lediglich zwischen Lager, Werkzeugausgabe und Maschinen verschoben. Die Buchung der Komponenten an die einzelnen Kostenstellen und Orte erfolgt gleichzeitig mit der Entnahme / Einlagerung im Lager. Die Bereitstellung von Werkzeugen und Betriebsmitteln wird mit einem Fertigungsauftrag ausgelöst, der sich auf eine Werkzeugliste in den Stammdaten bezieht, in welcher alle benötigten Komponenten aufgeführt sind. Die Komponenten werden vor dem Einsatz auf der Maschine entsprechend den Angaben in der Werkzeugliste zu Komplett-Werkzeugen zusammengebaut. Beim Einplanen der Fertigungsaufträge wird für jede Komponente geprüft, ob der verfügbare Bestand zur Bestückung der Maschinen ausreicht.\n\nDie Komplett-Werkzeuge werden aus Komponenten aufgebaut und nach Gebrauch meist wieder in die Einzelteile zerlegt. Von einem Komplett-Werkzeug können gleichzeitig mehrere Exemplare zusammengebaut werden, sofern die Komponenten in ausreichender Anzahl verfügbar sind. Die Logistik der Komplett-Werkzeuge bezieht sich auf den Zustand und Aufenthaltsort der Exemplare.\nDie Komplett-Werkzeug-Exemplare können typischerweise in drei verschiedenen Zuständen vorliegen:\nBeim Einplanen eines Fertigungsauftrags sind die für den Arbeitsgang benötigten Komplett-Werkzeuge anhand der zugehörigen Werkzeugliste bekannt. Ebenso ist bekannt, welche Komplett-Werkzeuge sich auf der für die Bearbeitung vorgesehenen CNC-Maschine befinden. Die benötigten, aber noch nicht auf der Maschine vorhandenen Komplett-Werkzeuge werden in einer Netto Beladeliste ausgedruckt. Sie müssen entweder neu zusammengebaut oder aus dem Zwischenlager entnommen werden. Mit einer koordinierten Logistik der Komplett-Werkzeuge wird der Aufwand für die Bereitstellung der Werkzeuge und das Einwechseln in der Maschine reduziert.\n\nDie Werkzeugverwaltung dient dem Ziel, einen effizienten und fehlerfreien Auftragsablauf in der Fertigung zu gewährleisten. Vorhandenes Wissen wird allgemein verfügbar gemacht und die in den Stammdaten festgehaltenen Vorgaben werden beachtet. Damit dies möglich ist, müssen die Informationen für die unterschiedlichen Aufgaben an den jeweiligen Arbeitsplätzen verfügbar sein. Die Integration der Werkzeugdaten ermöglicht anderen Anwendungen die Verwendung der Werkzeugdaten, die mit der Werkzeugverwaltung gepflegt werden. Dabei greifen diese Anwendungen entweder direkt auf die Datenbank der Werkzeugverwaltung zu, oder die Daten werden über Schnittstellen ausgetauscht. Speziell in der CNC-Fertigung, wo mehrere Personen am Fertigungsprozess beteiligt sind, vermeidet die Integration Fehler, Verzögerungen und mehrfache Datenerfassung. Nachfolgend die Beschreibung, in welchem Bezug einige der wichtigsten Anwendungen mit der Werkzeugverwaltung stehen.\n\nIm PPS-System wird zu jedem Bauteil der Arbeitsplan gespeichert, welcher die Beschreibung der Arbeitsgänge und die Liste der benötigten Ressourcen enthält. Die Beschreibung der Ressourcen erfolgt mit der Werkzeugverwaltung, weil diese im PPS-System nicht ausreichend oder untergebracht werden kann. Soll ein Bauteil hergestellt werden, wird mit dem PPS-System ein Fertigungsauftrag erstellt, der den Arbeitsplan enthält. Die benötigten Ressourcen wie Zeichnungen, NC-Programme, Werkzeuglisten und Anweisungen werden in der Fertigung aus der Werkzeugverwaltung abgerufen. Die Integration bedeutet, dass über eine Schnittstelle sichergestellt ist, dass die Information in der Werkzeugverwaltung auch wirklich vorhanden ist, wenn vom PPS-System in einem Arbeitsgang darauf verwiesen wird. Voraussetzung für eine Integration ist eine systematische Nummerierung der Dokumente und Betriebsmittel.\n\nDas ERP-System plant Rohmaterial, Verbrauchsmaterial und andere Ressourcen. Es ist eng mit dem PPS-System verbunden und übernimmt die Aufgaben der Materialwirtschaft und Logistik. Auf die Werkzeuge bezogen betrifft dies die Verschleißteile (schneidende Teile), die bei Erreichen des Mindestbestands beschafft werden.\n\nWenn der Lagerbestand der Komponenten mit der Werkzeugverwaltung geführt wird, werden nicht Bestellungen an den Lieferanten geschickt, sondern Bestellanforderung (BANF) an das ERP-System übermittelt, welches die tatsächliche Bestellung übernimmt. Voraussetzung ist dabei, dass die Artikel in beiden Systemen mit derselben Nummer erfasst sind. Zusätzlich können mit der Integration auch alle internen Lagerbewegungen der Werkzeugkomponenten für die Kostenrechnung ans ERP-System übergeben werden.\n\nMit dem CAM System werden die Bearbeitungsbefehle (NC-Programm) für die CNC-Maschinen erstellt. Geometrie, Bezeichnung und Schnittwerte der benötigten Komplett-Werkzeuge werden direkt aus der Werkzeugverwaltung übernommen. Dadurch ist sichergestellt, dass alle verwendeten Werkzeuge dokumentiert sind und mit der Realität in der Werkstatt übereinstimmen.\nAlle in einem NC-Programm verwendeten Werkzeuge werden aus dem CAM System automatisch als Werkzeugliste in der Werkzeugverwaltung gespeichert. Dadurch ist bei der Vorbereitung des Arbeitsgangs bekannt, wie welche Werkzeuge gerüstet und eingesetzt werden müssen.\n\nNeben den herkömmlichen Werkzeugschränken werden oft Lagersysteme eingesetzt, die dem Bediener das Regal mit dem gewünschten Artikel bereitstellen. Der Zusammenhang zwischen der Artikelnummer und dem Lagerplatz wird in der Werkzeugverwaltung gespeichert. Beim Buchen einer Werkzeugentnahme im Logistik-Bereich der Werkzeugverwaltung wird das Lagersystem automatisch angesteuert. Alternativ kann die Zuordnung der Lagerplätze im Lagersystem konfiguriert sein. Die Entnahme wird dann am Lagersystem vorgenommen und die Bestandsänderung an die Werkzeugverwaltung übermittelt.\n\nDie CNC-Maschine benötigt bei der Bearbeitung zur Positionierung der Werkzeuge deren genaue Abmessungen. Beim Einsetzen der Komplett-Werkzeuge in die Maschine muss deshalb deren Länge und Durchmesser eingegeben werden. Diese Einstellwerte der Werkzeuge können mit einem externen Voreinstellgerät gemessen werden.\nKomfortable Voreinstellgeräte übernehmen die Sollwerte, Bezeichnung und Toleranzen aus der Werkzeugverwaltung und übergeben die gemessenen Ist-Werte direkt an die Steuerung der CNC-Maschine. Die Integration der Werkzeugverwaltung mit den Voreinstellgeräten erfolgt im Austauschformat der jeweiligen Gerätehersteller und beinhaltet auch die Grafiken und Angaben zur Messmethode.\n\nUm den Aufwand der erstmaligen Erfassung der Komponenten in der Werkzeugverwaltung zu reduzieren, stellen die Werkzeughersteller Daten und Grafiken in entsprechend aufbereiteter Form zur Verfügung. Für die technischen Daten der Werkzeuge werden derzeit das DIN 4000 und das ISO 13399 Austauschformat verwendet. Die 2D Grafiken werden dabei, soweit erforderlich, entsprechend dem DIN Standard bereitgestellt. Für 3D Grafiken werden meist STL und STEP Format angeboten und die Achslage wird entsprechend dem Einsatz auf der Maschine gewählt.\n\n"}
{"id": "5863949", "url": "https://de.wikipedia.org/wiki?curid=5863949", "title": "Visual Analytics", "text": "Visual Analytics\n\nVisual Analytics ist ein interdisziplinärer Ansatz, der die Vorteile aus unterschiedlichen Forschungsgebieten verbindet. Das Ziel der Visual-Analytics-Methode ist, Erkenntnisse aus extrem großen und komplexen Datensätzen zu gewinnen. Der Ansatz kombiniert die Stärken der automatischen Datenanalyse mit den Fähigkeiten des Menschen, schnell Muster oder Trends visuell zu erfassen. Durch geeignete Interaktionsmechanismen können Daten visuell exploriert und Erkenntnisse gewonnen werden. Er wurde 2004 eingeführt und ein Jahr später in dem Buch \"Illuminating the Path\" beschrieben.\n\nDie stetig wachsende Menge an zu verarbeitenden Daten hat dazu geführt, dass immer größere Speichermedien entwickelt wurden. Häufig wird die gesammelte Datenmenge für die spätere Verarbeitung allerdings weder gefiltert noch bereinigt, sondern als Rohdaten abgespeichert. Diese Daten sind für sich genommen nutzlos, können allerdings wichtige Informationen beinhalten. Mit Hilfe des Visual-Analytics-Ansatzes wird diese Datenflut elektronisch analysiert, wobei der Mensch stets Einfluss auf die automatisch generierten Ergebnisse hat. Mittels geeigneter interaktiver Visualisierungen kann der Mensch den Analyseprozess beliebig lenken. Im Gegensatz zur reinen Informationsvisualisierung werden dem Menschen also nicht nur Resultate präsentiert, sondern darüber hinaus wird ihm die Möglichkeit gegeben, in die Analyse einzugreifen und die Algorithmen zu beeinflussen.\n\n\"Data:\" Heterogene Datenquellen müssen vor der visuellen oder automatischen Analyse zuerst vorverarbeitet werden (z. B. bereinigt, normalisiert, etc.).\n\n\"Models:\" Mit Hilfe von Data-Mining-Techniken werden Modelle der Originaldaten generiert, welche daraufhin zu Evaluationszwecken oder für weitere Verbesserungen visualisiert werden.\n\n\"Visualization:\" Um die Modelle durch einen Benutzer zu überprüfen, werden Visualisierungen generiert, welche mit Interaktionstechniken für eine Analyse angereichert werden.\n\nDie Vorgehensweise orientiert sich dabei an folgendem Paradigma:\n\n„\"Analyse First – Show the Important – Zoom, Filter and Analyse Further – Details on Demand\"“\n\nDabei ist ein stetiger Wechsel zwischen visuellen und automatischen Vorgängen eine wichtige Eigenschaft des Visual-Analytics-Prozesses. Verfälschte Resultate können dadurch frühzeitig erkannt werden, um ein besseres und vertrauenswürdigeres Endergebnis zu erhalten.\n\nAnwendungsbereiche, in denen große Mengen an Daten verarbeitet und visualisiert werden müssen, profitieren von Visual Analytics.\n\nDas sind zum Beispiel:\n\nDie Forschung um Visual Analytics untersucht zahlreiche interdisziplinäre Aspekte von der Datenanalyse bis hin zur visuellen Wahrnehmung und Mensch-Computer Interaktion.\n\nDiese sind zum Beispiel:\n\n\n"}
{"id": "5866454", "url": "https://de.wikipedia.org/wiki?curid=5866454", "title": "Caffeine", "text": "Caffeine\n\nCaffeine (nicht: Kaffeine) ist ein freies Programm zum Manipulieren systemweiter Energiespar-Einstellungen. Es wird unter der GNU General Public License (GPL) bereitgestellt.\n\nUrsprünglich wurde Caffeine für Mac OS X entwickelt. Mitte 2009 wurde das Programm erstmals mit Hilfe der Programmiersprache Python auf Linux portiert.\n\nCaffeine ist ein System- oder Hilfsprogramm mit sehr speziellem und relativ beschränktem Funktionsumfang. Hauptfunktion des Programmes ist, die Aktivierung des Bildschirmschoners und anderer automatischer Energiesparfunktionen wie den Sleep-Modus zu unterdrücken. So wird verhindert, dass die Wiedergabe eines Videos oder die Vorführung einer Präsentation unerwünscht unterbrochen wird. Dies erwies sich unter Linux-Distributionen oft als notwendig, da das korrekte Funktionieren der Energieverwaltung dort häufig durch verschiedene Bugs beeinträchtigt wurde.\n\nAuch Ermittlungsbehörden verwenden derartige Programme bei Hausdurchsuchungen, wenn Beweismittel auf den Rechnern des Beschuldigten vermutet werden und das System vom Nutzer mit seinem Passwort zur Zeit der Durchsuchung freigeschaltet ist. Hierbei geht es nicht primär um das Fernhalten des Bildschirmschoners, sondern es soll eine zeitgesteuerte Abmeldung des Benutzers vom System, die auf Grund von Inaktivität ausgelöst wird, verhindern. Damit kann eine (bei Abmeldung des Benutzers) eventuell greifende Verschlüsselung vermieden und der Zugriff auf das vom Nutzer mit seinem Passwort freigeschaltete System nicht verloren werden, wodurch das Sammeln von Beweisen ggf. ermöglicht und/oder erleichtert wird.\n\nAußer dem Einstellungsdialog ist keine weitere grafische Oberfläche vorhanden. Durch die Darstellung einer entweder leeren oder gefüllten Kaffeetasse im Benachrichtigungsfeld wird die (In-)Aktivität des Programmes symbolisiert. Per Klick auf die Tasse wird Caffeine komplett aktiviert oder deaktiviert.\n\nWeiterhin ist es möglich, Caffeine automatisch zu aktivieren, sobald ein bestimmtes Programm gestartet wird. Über die Einstellungen lässt sich Caffeine auch für Flash-Videos sowie das Online-Spiel Quake Live automatisch einschalten.\n\nCaffeine-ng ist ein Fork der Caffeine-2.4-Serie. Er wurde geschaffen, als Caffeine auf vollautomatische Vollbilderkennung ohne manuelle Einstellmöglichkeit umgestellt wurde.\n\n"}
{"id": "5866743", "url": "https://de.wikipedia.org/wiki?curid=5866743", "title": "HTC 7 Trophy", "text": "HTC 7 Trophy\n\nDas HTC 7 Trophy ist ein Smartphone des taiwanischen Herstellers HTC Corporation, welches mit Windows Phone 7 betrieben wird. Es wurde im Oktober 2010 vorgestellt und ist in Deutschland über Vodafone zu haben. Verwandte Geräte sind das HTC HD7 und das HTC 7 Mozart.\n\nHTC teilte seine Launch-Geräte für Windows Phone 7 in verschiedene Kategorien ein, wobei sich das \"HTC 7 Trophy\" besonders für Videospiele eignen soll. Der offizielle Slogan für das \"HTC 7 Trophy\" lautet \"„Die Power von XBOX Live in Ihrer Hand“\" und spielt auf die Integration von Xbox Live an, welche jedoch in jedem \"Windows Phone\" existent ist.\n\nInwieweit das \"HTC 7 Trophy\" besser für Videospiele geeignet sein soll als die – hardwareseitig nahezu identischen – Schwesternmodelle HTC HD7 oder HTC 7 Mozart wurde seitens HTC nie ausgeführt.\n\n"}
{"id": "5867815", "url": "https://de.wikipedia.org/wiki?curid=5867815", "title": "Comix (Software)", "text": "Comix (Software)\n\nComix ist ein Bildbetrachter für Linux und BSD, der speziell für das Anschauen von Comic-Book-Archiven entwickelt wurde. Comix ist in der Programmiersprache Python verfasst und nutzt das freie GUI-Toolkit GTK+. Das Programm ist freie Software und wird unter der GNU General Public License (GPL) kostenlos angeboten.\n\nComix arbeitet mit den speziellen Dateiformaten CBZ (Comic Book Zip), CBR (Comic Book RAR) und CBT (Comic Book TAR). Bei diesen handelt es sich um komprimierte Dateiarchive, die sich im Prinzip nicht von den bekannten ZIP, RAR und TAR unterscheiden und auch mit anderen Programmen geöffnet werden können. In diesen Dateiarchiven befinden sich die jeweiligen Comics, die gewöhnlich in mehrere JPEG- oder PNG-Dateien mit durchlaufender Nummerierung unterteilt sind. Daneben kann Comix auch alle gängigen Archive, gzip, bzip2 und tar öffnen sowie unkomprimierte Bilder anzeigen.\n\nAb Version 2.7 vom 29. Januar 2006 liegt Comix in einer deutschen Übersetzung vor.\n\n"}
{"id": "5870492", "url": "https://de.wikipedia.org/wiki?curid=5870492", "title": "Gwibber", "text": "Gwibber\n\nGwibber ist ein Mikroblogging-Client für die Desktop-Umgebung Gnome. Das Computerprogramm läuft unter Linux, ist in Python geschrieben und wird als freie Software kostenlos unter der GNU General Public License (GPL) bereitgestellt. Ab Ubuntu 10.04 ist Gwibber in den offiziellen Paketquellen enthalten.\n\nGwibber ermöglicht die Nutzung unterschiedlicher Mikroblogging-Anbieter, Social-Bookmark-Dienste und Online-Communities, ohne dass dafür ein Browser benötigt wird. Auf diese Weise können beispielsweise Statusmeldungen von Twitter empfangen und gesendet oder Nachrichten auf Facebook gestellt werden.\n\nIn früheren Versionen der Software war es zudem möglich, RSS- und Atom-Feeds zu abonnieren und den Status von Pidgin aus Gwibber heraus zu ändern.\n\n\n"}
{"id": "5878232", "url": "https://de.wikipedia.org/wiki?curid=5878232", "title": "Kaltstartattacke", "text": "Kaltstartattacke\n\nDie Kaltstartattacke oder der Kaltstartangriff () bezeichnet in der Kryptologie eine Seitenkanalattacke, bei der ein Angreifer mit physischem Zugang zum Zielrechner Inhalte des Arbeitsspeichers ausliest, nachdem das System abgeschaltet wurde.\n\nSie basiert auf der Datenremanenz in gängigen RAM-Modulen, in denen sich Ladung unter bestimmten Bedingungen (oder schon allein durch Fertigungstoleranzen bedingt) nicht innerhalb von Millisekunden, sondern nach und nach langsam über Sekunden bis Minuten verflüchtigt und die Dateninhalte aus den Speicherzellen eventuell nach einigen Minuten noch erfolgreich vollständig ausgelesen werden können. Je nach Rechner können solche Reste nach mehreren Sekunden bis Minuten ohne Strom aufgefunden werden. Kühlung der Speichermodule verlängert die Remanenzzeit drastisch. Nach einer Behandlung der Module mit Kältespray halten sich die Inhalte viele Minuten lang.\n\nBei einem im Juli 2008 auf der USENIX-Konferenz vorgestellten Angriff gelang es Forschern der Princeton-Universität, direkt nach einem Kaltstart Daten noch forensisch auszulesen.\nFür den Angriff wird der Zielrechner mit einem minimalen Betriebssystem kalt neugestartet. Weil dieses Mini-System nur wenig Speicher verbraucht, lässt es einen größtmöglichen Teil des Speichers unberührt, wodurch der unbenutzte Speicher noch genau das enthalten kann, was vor dem Neustart dort gespeichert war.\n\nAus den ausgelesenen Daten können dann die kryptographischen Schlüssel zu verschlüsselten Daten extrahiert werden, auf die im Moment des Systemabsturzes gerade Zugriff bestand. Das könnten zum Beispiel die Schlüssel von Full-Disk-Encryption-Systemen sein.\n\nAls Best Practice zur Minderung der Angriffschancen gilt das Überschreiben der Schlüssel beim Aushängen des Datenträgers (zum Beispiel beim Herunterfahren des Systems), womit die Daten zumindest danach sicher sind.\nDie Trusted Computing Group empfiehlt als Gegenmaßnahme in der „TCG Platform Reset Attack Mitigation Specification“, dass das BIOS Inhalte des Arbeitsspeichers beim power-on self-test leert, wenn ein unsauberes Beenden des Betriebssystems erkannt wurde. Dies verhindert allerdings höchstens, dass ein konformer Rechner selber zum Auslesen benutzt wird.\n\nEine Möglichkeit, das zugrundeliegende Problem zu beheben, ist, Schlüssel und ähnliches nur im Prozessor-Cache vorzuhalten. Dieser ist in einem Gesamtchip eingebettet, dem er nicht leicht zu entnehmen ist und welcher bei Einschalten eine Initialisierung durchläuft, die die Speicherinhalte vernichtet. Dabei muss sichergestellt werden, dass der Cache-Inhalt nicht wie üblich mit dem Hauptspeicher synchronisiert wird („no-fill“-Modus). In der Praxis bremst die Methode den Prozessor zur Unbenutzbarkeit.\n\nEin weiterer Ansatz ist es, den Schlüssel ausschließlich in den Registern des Prozessors vorzuhalten. Für Linux-Betriebssysteme auf x86-64-Systemen und Android auf ARM-Systemen ist eine Implementierung dieses Ansatzes als Teil des Kernels in Form eines Patchs verfügbar. Für sonstige x86-64-Betriebssysteme (z. B. Microsoft Windows) kann diese Art der Registerspeicherung durch den Einsatz einer geeigneten Hypervisor-Software erreicht werden. Auf einem 64-Bit-Prozessor mit AES-Befehlssatzerweiterung, ab Core-i-'Westmere'-Prozessoren seit 2010 sind die Leistungseinbußen nach Aussage der Entwickler zu vernachlässigen.\n"}
{"id": "5879142", "url": "https://de.wikipedia.org/wiki?curid=5879142", "title": "Grundy NewBrain", "text": "Grundy NewBrain\n\nDer Grundy NewBrain war ein Heimcomputer, der Anfang der 1980er Jahre von dem britischen Unternehmen Grundy Business Systems Ltd aus Teddington und Cambridge vertrieben wurde.\nZwei verschiedene Modelle wurden veröffentlicht. Modell A konnte entweder an einen Fernseher oder an einen Monitor angeschlossen werden. Das Modell AD hatte zusätzlich noch einen Ein-Zeilen-Display im Gerät eingebaut, auf dem Ergebnisse des Rechners auch ohne angeschlossenen Fernseher oder Monitor ausgegeben werden konnten. \nDer nicht erweiterte NewBrain hatte im ROM einen BASIC-Interpreter gespeichert. Es gab aber auch Geräte in deren ROM z. B. Mathematik oder Grafikanwendungen enthalten waren.\n\n"}
{"id": "5883153", "url": "https://de.wikipedia.org/wiki?curid=5883153", "title": "Megamind", "text": "Megamind\n\nMegamind ist ein CGI-Animationsfilm von DreamWorks Animation. Regie führte Tom McGrath (Madagascar, Madagascar 2). Der Film erschien am 5. November 2010 in den USA und am 2. Dezember in Deutschland.\n\nDa sein Heimatplanet kurz vor der Vernichtung durch ein schwarzes Loch steht, schicken seine Eltern Megamind als Säugling in einem Raumschiff fort. Auf dem Nachbarplaneten ereilt Metro Man das gleiche Schicksal. Beide landen auf der Erde in Metro City und wachsen unter völlig unterschiedlichen Umständen auf. Metro Man wird von einem wohlhabenden Paar adoptiert und entwickelt sich dank seiner Superkräfte zu einem Superhelden. Megamind wächst in einem Gefängnis zu einem Superschurken mit außergewöhnlicher Intelligenz heran. Unterstützt wird er dabei von seinem treuen Gehilfen Minion, einem Fisch mit einem gorillaähnlichen Roboterkörper.\n\nLange Jahre bekämpfen sich die beiden stets nach dem gleichen Schema: Megamind bricht aus dem Gefängnis aus, entwirft einen teuflischen Plan, entführt die attraktive Reporterin Roxanne und wird von Metro Man besiegt. Eines Tages jedoch lockt er Metro Man in eine Sternwarte, um einen gebündelten Lichtstrahl auf ihn abzufeuern. Scheinbar hemmt die kupferne Kuppel Metro Mans Superkräfte und der Lichtstrahl verbrennt ihn bis auf die Knochen. Nun ist Metro City in Megaminds Hand, doch ohne Gegenspieler langweilt er sich bald. Er fasst den Entschluss, aus den DNA-Spuren von Metro Man einen neuen Superhelden zu schaffen. Eher zufällig wird der trottelige Kameramann Hal, der in Roxanne verliebt ist, zum vermeintlichen Metro-Man-Nachfolger. In Verkleidung mimt er Hals Mentor und gibt ihm den Namen „Titan“, den dieser als „Tighten“ (deutsch: „festziehen“) missversteht. Dieser entpuppt sich jedoch als Egoist, der lieber selbst Verbrechen begeht als sie zu bekämpfen.\n\nZugleich entdeckt Megamind seine Zuneigung zu Roxanne, der er sich in Verkleidung annähert und dabei ihr Herz gewinnt. Als Tighten dies entdeckt, terrorisiert er die Stadt und will Megamind töten. Nun liegt es an Megamind selbst in die Rolle des Helden zu schlüpfen. Dabei stellt sich auch heraus, das Metro Man seinen Tod nur vorgetäuscht hat, da er von der Rolle des Helden genug hat und lieber als Musiker Music Man unterwegs sein möchte. Als Megamind und Roxanne dahinter kommen, fordern sie Metro Man auf die Stadt vor Tighten zu schützen. Doch Metro Man lehnt ab. So muss Megamind mit Hilfe von Roxanne und Minion gegen Tighten kämpfen. Er kann Tighten schließlich die Superkräfte wieder entziehen und wird von der Bevölkerung als neuer Superheld gefeiert.\n\nDie Interopa Film GmbH in Berlin führte die Synchronisation durch. Alexander Löwe schrieb das Dialogbuch, Axel Malzacher führte die Dialogregie.\nDer Soundtrack des Films wurde überwiegend von Hans Zimmer und Lorne Balfe komponiert.\n\nWeitere Titel im Film sind:\n\nDer Film wurde überwiegend positiv aufgenommen. Rotten Tomatoes verzeichnet eine positive Wertung von 72 %, basierend auf 156 Kritiken.\n\nVor allem loben viele Kritiken die originelle Geschichte. So schreibt Michael Föls für Filmering.at: „Megamind ist eine sehr gelungene Superheldenpersiflage, die den Spieß umkehrt und den Bösewicht in den Mittelpunkt rückt. Der Unterhaltungswert ist hoch, die Actionszenen gelungen und speziell zu Beginn funktioniert alles herausragend. Etwas schade ist jedoch, dass das letzte Drittel arg konventionell geworden ist. Am durchgehend recht hohen Spaßfaktor ändert aber auch das nichts.“\n\nEbenso lobt Arne Hübler die komplexe Geschichte: „Trotz des gewohnt kindischen und manchmal nervigen Humors überrascht das Animationswerk mit einer für das Kassen-trächtige Genre ungewohnt komplexen Geschichte, die bereitwillig Haken schlägt. Selbstredend wird im Film aus dem reichen Fundus der Strumpfhosen-Helden geschöpft: Die Macher zitieren ‚Batman‘ und ‚Superman‘ gebührend. Musikalisch wird auf ganz dicke Hose gemacht.“\n\nSofahelden.com findet auch die Animation lobenswert: „Die Geschichte ist endlich mal etwas anderes, der Schwenk vom Bösewicht zum braven Weltenretter ist genial inszeniert. Die Zeichnungen und Animationen sind der Hammer, langsam geht diese Art der Filme in Richtung Realismus. Alleine die Regenszene in der Stadt ist der Wahnsinn. Die Gags zünden und auch die verschiedenen Charaktere sind liebe- und humorvoll gestaltet.“\n\nAm Startwochenende spielte die 130 Millionen US-Dollar teure Produktion bereits 46 Millionen US-Dollar ein. Insgesamt beliefen sich die weltweiten Einnahmen auf fast 322 Millionen US-Dollar, davon etwa 4,4 Millionen in Deutschland. Damit belegt der Film Platz 14 auf der Liste der Dreamworks-Computeranimationsfilme. Gleichzeitig ist er der größte internationale Erfolg der Hauptdarsteller Will Ferrell und Tina Fey.\n\n"}
{"id": "5883265", "url": "https://de.wikipedia.org/wiki?curid=5883265", "title": "Recuva", "text": "Recuva\n\nRecuva ist ein kostenloses Programm zur Datenwiederherstellung für Festplattenlaufwerke und Wechseldatenträger. Es ist mit Windows ab Windows XP kompatibel und unterstützt auch 64-Bit-Systeme.\n\nDer Hersteller gibt an, dass das Programm verloren gegangene Dateien sowohl auf Windows-Computern als auch auf Speicherkarten und MP3-Playern wiederherstellt.\n\nEs stehen verschiedene Versionen des Programms zum Download zur Verfügung. Es kann neben der normalen Version auch eine portable Version heruntergeladen werden.\n\nBei chip.de wurde das Programm 4,4 Millionen Mal heruntergeladen.\n\n\nRecuva hat von der Website \"Softpedia\" 4,4 von 5 Wertungspunkten erhalten. In einem Test von Computer Bild erhielt es die Note \"ausreichend\". Gelobt wurde die sehr gute Datenrettung auf NTFS-Festplatten, bemängelt wurde die Rettung auf FAT-Festplatten sowie auf externen Datenträgern.\n\n"}
{"id": "5887935", "url": "https://de.wikipedia.org/wiki?curid=5887935", "title": "CLUMEQ", "text": "CLUMEQ\n\nDer Supercomputer CLUMEQ wurde von Sun Microsystems 2009 fertiggestellt und befindet sich in Québec, Kanada. Die Basis für das neue Datenzentrum des bildet ein Silo, in dem bis vor kurzem ein Teilchenbeschleuniger untergebracht war.\n\nDer Aufbau eines Datenzentrums in einem Silo war eine ganz neue Aufgabe für die Entwickler. Vorteil dieser Bauform ist, dass man die Systeme viel besser kühlen kann, als in einem herkömmlichen Datenzentrum. Die Rechner wurden ringförmig auf drei Etagen angeordnet. Dadurch entsteht an der Außenseite des runden Bauwerkes eine Kaltluftzone. \n\nDer Rechnertyp gehört zu Sun Blade System (Model Sun Blade 6048). Der Hauptspeicher hat eine Größe von 19200 GB, beim Prozessor handelt es sich um einen Intel EM64T Xeon X55xx (Nehalem-EP) 2800 MHz (11.2 GFlops).\n\nDer CLUMEQ Supercomputer wird für Forschungen und Analysen in den u. a. in folgenden Bereichen genutzt:\n\n\n"}
{"id": "5887983", "url": "https://de.wikipedia.org/wiki?curid=5887983", "title": "LIO Unified Target", "text": "LIO Unified Target\n\n„LIO Unified Target“ ist ein multiprotokollfähiges SCSI-Target-Modul für den Linux-Kernel ab Version 2.6.38.\nEs ersetzt damit das bisherige STGT-Target.\n\"LIO\" unterstützt aktuell die Protokolle iSCSI, Fibre Channel, FCoE und InfiniBand (SRP und iSER). Neben der x86-Mikroprozessor-Architektur werden IA-64, ARM, MIPS und IBM POWER unterstützt. Das Konzept des Unified-Target-Modul wird vor allem für den Zugriff auf eine Vielzahl von Speichermedien über eine Vielzahl von Protokollen benötigt. \"LIO\" als Unified-Target-Modul greift dabei weder selbst auf Daten zu, noch kommuniziert es direkt mit den Applikationen. Aufgabe von \"LIO\" ist es, die Semantik verschiedener SCSI-Targets nahtlos zu abstrahieren.\n\n\"LIO\" ist modular um ein zentrales SCSI-Target-Modul aufgebaut. Der Begriff SCSI-Target wird in diesem Zusammenhang nicht nur für dienstleistende Geräte an einem SCSI-Bus verwendet, sondern ganz allgemein für die Befehle empfangende Seite einer SCSI-Verbindung, also auch von SCSI-Verbindungen, die über Netzwerke völlig ohne physikalischen SCSI-Bus arbeiten. Für diese Verbindungen ist das SCSI-Target-Modul in diesem Fall der dienstleistende Server.\n\nUm diese Dienstleistung erbringen zu können, benötigt das SCSI-Target-Modul Speichermedien, die je nach Ausführung ihrerseits SCSI-Targets sein können, aber nicht müssen. Die Verbindung zu einer Vielzahl unterschiedlicher Speichermedien wird von sogenannten \"Backstores\" geleistet, die als \"Backend\" am SCSI-Target-Modul arbeiten.\n\"Backstores\" können über eine Schnittstelle zur Abstraktion von Speichergeräten des \"Storage Hardware Abstraction Layer\" (S-HAL) im Linux-Kernel mit dem SCSI-Target-Modul verbunden werden. Das SCSI-Target-Modul unterstützt dabei den SCSI-3 Standard für sämtliche \"Backstores\". Ein spezielles Loopback-Modul erlaubt die Integration von RAM-Disks oder SSD-Speicher. Über das FILEIO-Modul können Dateien aus beliebigen Dateisystemen als Speichermedium eingebunden werden.\n\nEin \"Fabric-Modul\" (eng. „Gewebe“ oder „Gefüge“) stellt die Dienste des SCSI-Target-Modul über ein konkretes Protokoll zur Verfügung. Es gibt \"Fabric-Module\" für Fibre Channel, FCoE (Fibre Channel over Ethernet) SCSI über IP-Netze und andere. Damit lassen sich sogenannte Storage Area Networks (SAN) aufbauen.\n\nNeben dem SCSI-Target wird von \"Datera\" auch noch ein Open Source iSCSI-Initiator names \"Core-iSCSI\" bereitgestellt. Ein besonderes Merkmal ist die Unterstützung mehrerer Verbindungen pro Session (Multiple iSCSI connections per iSCSI session – MC/S). Auf diese Weise wird eine verbesserte Verfügbarkeit und Durchsatz ermöglicht. Der Standard-Linux-iSCSI-Initiator unterstützt dieses Feature nicht. \"Core-iSCSI\" erlaubt darüber hinaus das Booten von Servern über ein iSCSI-SAN (diskless boot).\n\n\"LIO\" unterstützt den iSCSI-Standard sowie \"Persistent Reservations\" und \"ALUA\"s (Asymmetric Logical Unit Assignment) des \"SPC-4\" SCSI-Standards.\n\nZusammen mit der Replikationssoftware DRBD und der Clustersoftware Corosync lassen sich hochverfügbare Speichersysteme aufbauen. Der \"RTSdirector\" implementiert ein eigenes Multinode-Cluster mit linearer Skalierbarkeit.\n\nDie Konfiguration erfolgt über das Linux configfs, die Administration über ein Kommando-Zeilen-Tool (RTSadmin). Mit Erscheinen der Version 2 ist es möglich, Fibre Channel, FCoE und InfiniBand Konfigurationen zu administrieren. Die Version 2 wurde dual lizenziert und die Community Version 'targetcli' ist unter der AGPL erschienen.\n\n\"LIO\" wurde von der Firma \"Datera\" entwickelt und wird von einigen Herstellern von Speichersystemen (engl.: „storage appliances“) integriert (Buffalo, Netgear, Pure Storage, QNAP, Synology, etc.).\n\n"}
{"id": "5888685", "url": "https://de.wikipedia.org/wiki?curid=5888685", "title": "Katedra (Film)", "text": "Katedra (Film)\n\nKatedra (dt. \"Kathedrale\") ist ein polnischer computeranimierter Kurzfilm von Tomasz Bagiński aus dem Jahr 2002.\n\nEin Pilger kommt an eine monumentale Kathedrale, die aus organischem Material zu bestehen scheint. Er öffnet das riesige Tor und tritt in das Gebäude ein – das Tor schlägt hinter ihm zu. Mithilfe seines Pilgerstabs leuchtet sich der Pilger den Weg. Es wird deutlich, dass der Bau aus baum- oder wurzelähnlichen Strukturen besteht, in die Gesichter verwoben sind. Sie blicken dem Pilger teilweise nach.\n\nDer Pilger erreicht das Ende der Kathedrale. Sie ist unvollendet und steht offen an einer Klippe. Der Pilger schaut den Abgrund hinunter, wo sich Flächen mit Baumstümpfen zeigen. Er verweilt. Ein riesiger Planet bewegt sich langsam zur Seite; ein sonnenähnlicher Planet dahinter lässt gleißendes Licht auf die Kathedrale scheinen. Das Licht trifft auf die Gesichter der Kathedrale, die sich abwenden, und erreicht schließlich den Pilger. Sein Arm wird von dem Pilgerstock gerissen, aus ihm selbst schlagen wurzelähnliche Schlingen. Kurze Zeit später ist der Pilger mit der Kathedrale verwachsen.\n\n\"Katedra\" war nach \"Rain\" (1998) Bagińskis zweiter Film und der erste, den er als Mitarbeiter der CGI-Firma Platige Image fertigstellte. Für \"Katedra\" arbeitete er mit Science-Fiction-Autor Jacek Dukaj zusammen, der seine gleichnamige Kurzgeschichte aus dem Jahr 2000 für den Film auf einen Handlungsstrang kürzte.\n\n\"Katedra\" wurde im April 2002 beendet und erlebte seine Erstaufführung am 16. Oktober 2002. Der Film wurde positiv aufgenommen und später in polnischen Kinos als Vorfilm vor \"Minority Report\" und \"Signs – Zeichen\" gezeigt.\n\n\"Katedra\" wurde 2003 für einen Oscar in der Kategorie „Bester animierter Kurzfilm“ nominiert, konnte sich jedoch nicht gegen \"Die Chubbchubbs!\" durchsetzen.\n"}
{"id": "5889301", "url": "https://de.wikipedia.org/wiki?curid=5889301", "title": "Tauch, Timmy, Tauch", "text": "Tauch, Timmy, Tauch\n\nTauch, Timmy, Tauch! ist eine amerikanisch-irisch-australische Computeranimationsserie aus dem Jahre 2005. Die Serie behandelt in den jeweiligen Folgen verschiedene Abenteuer des U-Boots Timmy.\n\nDas junge U-Boot Timmy lernt bei seinem Tauchlehrer Tom das Tauchen im Meer, um eines Tages ein richtiges Forschungs-U-Boot zu werden. Dabei erleben Timmy und seine Freunde viele Abenteuer.\n\nDie Serie wurde 2005 unter der Regie von Bob Doucette, Gary Hurst und Jane Schneider produziert. Die Idee stammt von Andrew Ross und Ian Ross, die Musik komponierte Ceiri Torjussen. Die künstlerische Leitung hatte Bob Doucette inne. \n\nDie Erstausstrahlung erfolgte 2005 bei 7 Network in Australien. Es folgte eine Ausstrahlung bei Voom HD LAB in den USA 2006. Ab dem 15. Oktober 2007 wurde die Serie vom KI.KA in Deutschland gesendet. Außerdem erfolgten Übersetzungen ins Polnische und Griechische.\n\nDie Deutschen Dialogbücher wurden von Masen Abou-Dakn geschrieben. \nDialogregie bei der 1. Staffel (2005) führte Hans-Jürgen Dittberner bei der 2. Staffel (2010) Andreas Pollak.\n\n"}
{"id": "5890559", "url": "https://de.wikipedia.org/wiki?curid=5890559", "title": "Freemake Video Downloader", "text": "Freemake Video Downloader\n\nDer Freemake Video Downloader ist ein kostenloser Download-Manager von Ellora Assets Corporation. Das Programm lässt eingebettete Videos in Formaten FLV, MP4 oder 3gp von mehr als 10000 Websites herunterladen. Die Software kann alle online vorliegenden Videoformate und Auflösungen zum bestimmten Video finden und lässt dann Web-Videos in AVI, Matroska, MP3, 3gp und für den iPod, das iPhone, die PSP und die Geräte mit Android-Betriebssystem umwandeln.\n\nFreemake Video Downloader kann Online-Videos von solchen Video-Portalen wie YouTube, Facebook, Google Video, Dailymotion, Vimeo, Veoh, Break, Stupidvideos, LiveLeak, Photobucket, MyVideo und Nico Nico Douga herunterladen.\nDas Tool nennt sämtliche online vorliegenden Videoformate FLV, MP4 oder 3gp und vorhandene Auflösungen 4096p, 1080p, 720p, 480p, 360p oder 240p zu einem Video. Das Video lässt sich während des Downloads in Formate AVI, MP3, Matroska, 3gp und für den iPod, das iPhone, die PSP und die Geräte mit Android-Betriebssystem umwandeln. Eine Tonspur vom Online-Video kann ohne Qualitätsverlust extrahiert werden. Das Programm lädt auch Videos mit den Privatsphäre-Einstellungen von YouTube und Facebook herunter, wenn der Anwender Benutzername und Passwort richtig eingegeben hat. Die Software ermöglicht, einen Proxy-Server zu verwenden.\nDie Benutzeroberfläche vom Freemake Video Downloader beruht auf der Technologie der Windows Presentation Foundation. Seit der Version 3.0 unterstützt der Downloader mehr als 10.000 Webseiten, nimmt abgebrochene Downloads wieder auf und speichert die Downloadsgeschichte im Programm.\n\nCHIP Online bemängelt (Stand: Ende Oktober 2015): „Der Software-Installer bringt Adware mit, die sich teilweise nicht abwählen lässt. Daneben versucht der Downloader weitere unnötige Software mitzuinstallieren und Änderungen am Browser vorzunehmen.“\n\nSeit der Version 3.8.1 ist die Länge des herunterzuladenen Videos auf unter 3 min beschränkt. Wer längere Videos herunterladen möchte, muss hierfür ein kostenpflichtiges Premiumpaket kaufen. Dieser Kauf kann jedoch nur über eine Kreditkarte oder Paypal (zuzüglich Gebühren für den Wechselkursumrechnung / Stand Februar 2018) durchgeführt werden. Die Preise für dieses Premiumpaket bewegen sich zwischen 9 USD für ein Jahr und 19 USD für \"unlimited\". Jedoch kommen hierzu aus Deutschland, Austria oder der Schweiz noch Gebühren für den Devisentausch (Wechselkursumrechnung) hinzu. Beispiel Stand Februar 2018 für das Unlimited-Paket fallen neben 19 USD noch 3,61 USD Gebühren an, so dass ein Endpreis von 22,61 USD verrechnet wird. Bei diesem Beispiel wäre laut Paypalwährungsrechner der zu bezahlende Betrag daher ca. 17,89 EUR (Stand 13. Feb. 2018).\n\nAuf der Seite von Digital Wave LTD, den Entwicklern von Freemake, wird auf diesen Umstand jedoch nicht hingewiesen. Erst nach der Installation des Programms und dem Versuch einen Download mit einer Länge über 2,59 min durchzuführen, bekommt man eine diesbezügliche Information per POP-UP Fenster mitgeteilt.\n\n"}
{"id": "5892413", "url": "https://de.wikipedia.org/wiki?curid=5892413", "title": "Zero Install", "text": "Zero Install\n\nUnter Zero Install werden Tools zusammengefasst, die nicht installiert werden müssen. Verwandte Konzepte sind einerseits \"Portable Software\" als auch Applikations-\"Virtualisierung\" bzw. \"Sandboxing\", welche meistens die Charakteristik der Installationsfreiheit (im Sinne von Systemintegration) teilen. Auch Emulatoren stellen aus anderen Gründen eine Umgebung zur Verfügung auf der Programme ohne Auswirkung auf das System installiert werden.\n\nZero install ist auch ein ursprünglich für Linux geschriebenes Installationssystem, das Zero-Install-Tools zur Verfügung stellt. Weitere Anwendungsfälle sind laut Hersteller u. a. die dezentrale Distribution von Software direkt durch die Hersteller als auch die Root-Rechte freie Installation von Software durch den Anwender. Seit Oktober 2010 existiert auch eine Windowsversion der Software.\n\n\n"}
{"id": "5906603", "url": "https://de.wikipedia.org/wiki?curid=5906603", "title": "Baumbank (Linguistik)", "text": "Baumbank (Linguistik)\n\nEine Baumbank (), auch geparstes Korpus, ist ein Textkorpus, in dem jeder Satz geparst, also mit syntaktischer Struktur annotiert wurde. Der Begriff Baumbank bezieht sich darauf, dass die syntaktische Struktur gewöhnlich als eine Baumstruktur repräsentiert wird.\n\nBaumbanken werden oft auf Korpora erstellt, die bereits mit Part-of-speech-Tags annotiert wurden. Zudem werden Baumbanken manchmal mit semantischer oder anderer linguistischer Information erweitert.\n\nBaumbanken können \"manuell\" erstellt werden, indem Linguisten jeden Satz mit syntaktischer Struktur annotieren, aber auch \"halbautomatisch\", so dass ein Parser automatisch syntaktische Struktur zuordnet, die dann von einem Linguisten geprüft und, wenn nötig, korrigiert wird. In der Praxis ist das komplette Überprüfen und Parsen von natürlichsprachlichen Texten ein arbeitsintensiver Prozess.\n\nEinige Baumbanken folgen in ihrer syntaktischen Annotation einer bestimmten linguistischen Theorie (z. B. die BulTreeBank mit HPSG), aber die meisten sind weniger theoriespezifisch. Trotzdem lassen sich im Wesentlichen zwei Gruppen unterscheiden: Baumbanken, die Phrasenstruktur annotieren (z. B. \"Penn Treebank\" oder \"ICE-GB\"), und solche, die Abhängigkeitsstruktur annotieren (z. B. \"Prague Dependency Treebank\" oder die \"Quranic Arabic Dependency Treebank\").\n\n\n"}
{"id": "5907415", "url": "https://de.wikipedia.org/wiki?curid=5907415", "title": "Themenentdeckung und -verfolgung", "text": "Themenentdeckung und -verfolgung\n\nDas Forschungsfeld der Themenentdeckung und -verfolgung (\" \", TDT; auch ) befasst sich mit der Entwicklung von Technologien, die es ermöglichen, Nachrichten aus dem Fernsehen, dem Internet oder Radio zu erfassen und diese dann in einzelne Meldungen zu trennen und in bestimmte Themengebiete oder ein Themengebiet einzuordnen. Sie finden zum Beispiel beim Nachrichtendienst Google News Anwendung.\n\nDie Forschung wurde von der DARPA mit dem Ziel vorangetrieben, Nachrichtenanalysten den Umgang mit der wachsenden Informationsflut zu erleichtern.\n\nIm Gegensatz zur traditionellen Aufgabe des Information Retrieval wird kein eindeutiger Informationsbedarf eines Suchenden vorausgesetzt, sondern das Erkennen neuer Themen angestrebt.\n\nDas Problem wird in fünf Aufgaben unterteilt\n\nZur Bewältigung der Aufgaben werden Techniken des Information Retrieval, des Text Mining und der Computerlinguistik eingesetzt.\n\n"}
{"id": "5909615", "url": "https://de.wikipedia.org/wiki?curid=5909615", "title": "Mac App Store", "text": "Mac App Store\n\nDer Mac App Store ist eine vom US-amerikanischen Unternehmen Apple betriebene Onlineplattform zum Vertrieb von Software für das hauseigene Betriebssystem \"macOS\". Die angebotene Software stammt dabei zu einem großen Teil nicht von Apple selbst, sondern von Dritten, Unternehmen wie auch freie Softwareentwickler.\n\nDie Vertriebsplattform selber ähnelt dem bereits 2008 eröffneten \"App Store\" für das ebenfalls eigene Betriebssystem \"iOS\".\n\nAngekündigt wurde der Mac App Store am 20. Oktober 2010 im Rahmen der Veranstaltung „Back to the Mac“. Seit dem 3. November 2010 konnten in der Apple Developer Connection (ADC) registrierte Softwareentwickler Software für die Vertriebsplattform einreichen. Die Version 1.0 wurde am 6. Januar 2011 gemeinsam mit Mac OS X 10.6.6 veröffentlicht. Am ersten Tag meldete Apple mehr als eine Million heruntergeladene Programme.\n\nDas Betriebssystem Mac OS X Lion war nach dem Erscheinen im Juli 2011 zunächst nur über den Mac App Store erhältlich, erst einige Wochen später erschien es auf einem physischen Medium.\n\nAm 12. Dezember 2011 gab Apple bekannt, dass mehr als 100 Millionen Apps aus dem Mac App Store heruntergeladen wurden. OS X Lion sowie Aktualisierungen bereits heruntergeladener Programme wurden dabei nicht mitgezählt.\n\nMit der Veröffentlichung von MacOS Mojave am 24. September 2018 brachte Apple einen überarbeiteten Mac App Store heraus.\n\nDas Design wurde mehr dem von iOS angepasst und auch einige Funktionen wurden übernommen. So ist es Entwicklern nun möglich, Videos in die App-Beschreibung einzubetten und auf Rezensionen im Mac App Store zu antworten. Des Weiteren stellt ein Redaktionsteam von Apple neue Apps vor und gibt Tipps zu dessen Verwendung. \n\nDiese Änderungen brachte einige Entwickler dazu, wieder ihre Apps im Store anzubieten, da viele davor unzufrieden mit der Handhabung durch Apple waren.\n\nApple bietet die Entwicklungsumgebung Xcode kostenlos an, zum Veröffentlichen eines Programms im Mac App Store ist jedoch eine kostenpflichtige Registrierung beim \"Mac Developer Program\" notwendig. Apple unterzieht jedes eingereichte Programm einer Überprüfung und entscheidet über die Freigabe.\n\nMittels \"iTunes Connect\" können Entwickler die Käufe und Downloadzahlen ihres Artikels im Überblick behalten.\n\nProgramme können kostenlos oder kostenpflichtig angeboten werden. Der Preis wird vom Entwickler bestimmt, dabei folgen die Preise einem von Apple vorgegebenen Stufenschema (\"price tiers\"). Vom erzielten Umsatz werden 30 % als Gebühren von Apple einbehalten.\n\n"}
{"id": "5910924", "url": "https://de.wikipedia.org/wiki?curid=5910924", "title": "KMyMoney", "text": "KMyMoney\n\nKMyMoney ist eine KDE-Software zur Verwaltung persönlicher Finanzen. Das Programm funktioniert ähnlich wie Quicken und Microsoft Money. Es unterstützt verschiedene Konto-Typen, Kategorisierung von Einnahmen und Ausgaben, die Abstimmung von Bankkonten und das Importieren/Exportieren von Daten im QIF- und OFX-Format.\n\nKMyMoney untersteht der GNU General Public License und ist damit freie Software.\n\n\n"}
{"id": "5912582", "url": "https://de.wikipedia.org/wiki?curid=5912582", "title": "ALZip", "text": "ALZip\n\nALZip (koreanisch: 알집) ist ein proprietäres Packprogramm und Datenkompressionswerkzeug von dem südkoreanischen Software-Hersteller \"ESTsoft\" für Microsoft Windows.\nEs ist hauptsächlich in Korea und Japan verbreitet.\n\nEs ist in der Programmiersprache \"Delphi\" geschrieben und wurde lange Zeit bis auf die kostenlose koreanischsprachige Version als kostenpflichtige Shareware vertrieben. Im August 2012 veröffentlichte der Hersteller auf der Webseite altools.com einen universellen Freischaltcode, so dass das Programm nunmehr wieder kostenlos erhältlich ist.\n\nDas proprietäre, erweiterbare Standarddateiformat bietet Unterstützung für Unicode, das moderne Kompressionsverfahren LZMA, starke Verschlüsselung mit AES und progressive Kompression („solid“). Die vorgesehene Dateinamenserweiterung ist codice_1, der MIME-Type ist codice_2.\n\nDas frühere Standardformat orientierte sich eng am Zip-Dateiformat, hob dessen Größenbeschränkung praktisch auf und erlaubte die Verwendung der Kompressionsverfahren Deflate und bzip2. Die vorgesehene Dateinamenserweiterung ist codice_3, der MIME-Type ist codice_4. Die Struktur dieses proprietären Formates wurde erst durch Reverse Engineering offengelegt und der Hersteller bietet auch keine Entpacker-Programmbibliotheken an. Die Dateien können unter Linux von dem Archivverwaltungswerkzeug \"File Roller\" der Arbeitsumgebung \"GNOME\" gelesen werden.\n\nDie aktuelle Version 8.51 liest 40 Kompressionsformate und kann in 8 Formate speichern.\n\nDaneben bietet das Programm die Verschlüsselung von Archivdateien mittels zip-2.0, AES-128 oder AES-256 an und kann gesplittete Archive erstellen. Diese Funktionen sind u. a. kompatibel mit Winzip (bei Verwendung des zip-Formats).\n\nUrsprünglich wurde ALZip 1999 bei ESTsoft aus Frustration der Mitarbeiter beim Umgang mit der englischsprachigen Benutzeroberfläche von WinZip entwickelt.\nDie koreanische Oberfläche wurde sehr gut aufgenommen und die Anwendung später im selben Jahr veröffentlicht.\n\nSie wurde in Korea innerhalb von knapp einem Jahr zur populärsten Pack- und Datenkompressionsanwendung sowie bis Dezember 2001 zur meistheruntergeladenen Software.\n2002 wurde erstmals eine englischsprachige Version veröffentlicht; Unterstützung für über 20 weitere Sprachen folgte. 2004 wurde in Südkorea ein Marktanteil von 70 % erreicht.\n\nALZip wurde zunächst zur kostenlosen Nutzung für jedermann als Freeware veröffentlicht. Ab Oktober 2001 deckte die kostenlose Nutzungslizenz nur noch den privaten Gebrauch ab und die Software wurde für den Einsatz in Regierungen ab sofort kostenpflichtig, ebenso wie für den – ab April 2002 vorgesehenen – kommerziellen Einsatz.\nMit der 2007 erschienenen Version 7 wurde das Lizenzmodell von Freeware auf Adware umgestellt. Die Software lud nun zur Laufzeit Werbebanner aus dem Internet nach und zeigte sie in der Benutzeroberfläche an. Ab dem 1. Dezember 2008 waren alle Versionen bis auf die koreanischsprachige nur noch kostenpflichtig als Shareware erhältlich. Seit August 2012 wird das Programm weltweit wieder kostenfrei zur Verfügung gestellt.\n\nBis zur 2001 erschienenen Version 4.9 wurde standardmäßig nach dem bzip2-Verfahren komprimiert; nach Aufdeckung dieser Tatsache wurde ab Version 5 nur noch der weniger effiziente Deflate-Algorithmus eingesetzt. 2003 führte die Geheimhaltung der Dateiformatstruktur und der Ausschluss von Drittentwicklern von der Nutzung des Formates zu Kontroversen.\nDie Struktur der ALZ-Dateien wurde durch Reverse Engineering erschlossen und am 22. Oktober 2004 erstmals ein nachkonstruiertes Entpackprogramm für das ALZ-Format unter der freien zlib-Lizenz veröffentlicht. In der Folge implementierten auch verschiedene konkurrierende Anwendungen Leseunterstützung für das Format.\nMit Version 8 wurde 2010 abermals ein neues Dateiformat (EGG) eingeführt, das nun in Voreinstellung verwendet wird und nun auch vom Hersteller offen dokumentiert ist.\n\n"}
{"id": "5916795", "url": "https://de.wikipedia.org/wiki?curid=5916795", "title": "SciNet Consortium", "text": "SciNet Consortium\n\nDas SciNet Consortium betreibt einen Supercomputer in Toronto, Kanada. Zu dem Konsortium gehören die University of Toronto sowie deren angeschlossenen Krankenhäuser. Die SciNet-Einrichtungen befinden sich auf dem Campus der University of Toronto. Das Datenzentrum befindet sich ca. 30 km nördlich des Campus in Vaughan. Auf der TOP500-Liste, welche die schnellsten 500 Computer der Welt aufzeichnet, befindet sich SciNet auf Platz 39 (2010).\n\nDas System basiert auf dem IBM System x iDataPlex Supercomputer. Das System arbeitet mit 30.240 Intel 5500 Series 2.53 GHz Prozessoren. Der Computer verbraucht soviel Strom, wie 4000 normale Computer zusammen. Das ganze System ist wassergekühlt. Bei kühleren Temperaturen wird das System automatisch auf Luftkühlung geschaltet um Energie zu sparen. Der Supercomputer benötigt eine Standfläche von 280 m. Der Supercomputer ist der größte Intel- Prozessor basierende Rechner weltweit.\n\n\nDas System wird genutzt für Astronomie und Astrophysik, Raumfahrt sowie Ingenieursforschungen, biomedizinische Forschungen, physikalische Forschungen für Hochenergie-Partikel, für planetarische Physik, für integrative Bioinformatik und für die chemische Physik.\n\n"}
{"id": "5916933", "url": "https://de.wikipedia.org/wiki?curid=5916933", "title": "Mattel Aquarius", "text": "Mattel Aquarius\n\nDer Mattel Aquarius war ein von der Firma Radofin aus Hongkong entwickelter Heimcomputer, der im Jahre 1983 von der US-amerikanischen Firma Mattel auf den Markt gebracht wurde. Der Rechner enthielt einen Zilog-Z80-Microprozessor, eine Gummitastatur, einen Arbeitsspeicher von 4K RAM und eine Version des Microsoft BASIC im ROM. Der Rechner wurde an einen handelsüblichen Fernseher angeschlossen, und man benutzte Compact Cassetten als Speichermedium. Es wurden einige Peripheriegeräte entwickelt: ein 40-Spalten-Thermodrucker, ein Vier-Farben-Drucker/Plotter und ein 300-Baud-Modem.\n\nDas Zubehör Mini Expander bot einen zusätzlichen Steckplatz für Module. Es wurde zwar in den Cartridge-Schacht geschoben, brachte aber zwei Steckplätze mit. Auf diese Weise konnten gleichzeitig ein Programm-Modul und eine Speichererweiterung genutzt werden. Es erweiterte den Computer außerdem um zwei Game-Controller und einen leistungsfähigeren Soundchip.\n\nEs gab eine Reihe von Spielen, die auch auf Modul erschienen, darunter „Tron: Deadly Discs“ und „Utopia“ – beides Titel, die parallel für Mattels Konsole Intellivision erschienen (Siehe Bild rechts unten). Charakteristisch waren Schablonen für die Tastatur und die Gamepads, auf denen die Tastenbelegung für das jeweilige Spiel abgedruckt war.\n\n\n"}
{"id": "5918464", "url": "https://de.wikipedia.org/wiki?curid=5918464", "title": "Guitarix", "text": "Guitarix\n\nGuitarix ist eine freie Software für Linux, die das Verhalten und die Fähigkeiten eines Gitarrenverstärkers nachbildet. Zusätzlich zur Verstärkeremulation bietet Guitarix diverse Effekte, darunter einen teilparametrischen Grafik-Equalizer, Kompressor, Distortion, Overdrive, Echo, Chorus, Phaser, Flanger, Reverb und Wah-Wah. Im Verstärkermodul lassen sich verschiedene Röhren- und Lautsprecheremulationen auswählen. Guitarix bindet außerdem die Convolver-Software zita-convolver von Fons Adriaensen ein. Neben den Sound-Effekten bietet Guitarix ein Stimmgerät, eine detaillierte, konfigurierbare Signalstärkeanzeige und ein Modul, das die gespielten Töne in MIDI-Noten umwandeln kann. Die Bedienoberfläche lässt sich von einem MIDI-Controller aus fernsteuern.\n\nIntern rechnet Guitarix mit Hilfe der an der Stanford University entwickelten Signalverarbeitungs-Software \"Faust\". Neben der eigenständigen Variante bietet Guitarix auch eine gx_head genannte Bedienoberfläche, die sich optisch stärker an realen Verstärkern orientiert sowie die Verstärkeremulation und die Effekte als einzelne LADSPA- und LV2-Plugins.\n\nGuitarix benutzt das Pro-Audio-System JACK.\n\nGuitarix ist unter der GNU General Public License frei verfügbar.\n\n\n"}
{"id": "5922057", "url": "https://de.wikipedia.org/wiki?curid=5922057", "title": "Loop Subdivision Surface", "text": "Loop Subdivision Surface\n\nLoop Subdivision Surface ist ein Unterteilungsschema für Dreiecksnetze, entwickelt von Charles Loop.\n\nDabei wird jedes Dreieck in vier neue Dreiecke unterteilt, wodurch auch neue Punkte entstehen.\n\n"}
{"id": "5931685", "url": "https://de.wikipedia.org/wiki?curid=5931685", "title": "Across Language Server", "text": "Across Language Server\n\nDer Across Language Server ist eine Softwareplattform zur computergestützten Übersetzung, die über zusätzliche Programmmodule zur Projektverwaltung und Terminologiemanagement verfügt.\n\nDie Software wird von dem Unternehmen Across Systems GmbH aus Karlsbad bei Karlsruhe – 2005 als Spin-Off der Nero AG gegründet – und Glendale bei Los Angeles entwickelt, hergestellt und vertrieben.\n\nDie Software arbeitet ähnlich wie SDL Trados Studio, OmegaT oder MemoQ. Wie bei den Serverlösungen dieser beiden Programme werden auch beim Across Language Server Übersetzungseinheiten und Terminologie-Einträge (je nach Konfiguration des Projekts) in einer lokalen oder in einer zentralen MSSQL-Datenbank gespeichert.\n\nNeben dem Server, der in verschiedenen Versionen genutzt werden kann, gibt es noch eine Einzelplatzversion namens \"Across Translator Edition\" mit lokaler MSSQL-Datenbank. Mit der \"Across Translator Edition\" kann eine Anbindung an den Server hergestellt werden. Damit ist sowohl die Bearbeitung lokaler Projekte als auch der Zugriff auf Across-Server möglich.\n\nDie Software des Across Language Server wird unter einer proprietären Lizenz veröffentlicht und ist grundsätzlich kostenpflichtig. Die Einzelplatzversion ist für Freiberufler in der \"Basic Edition\" kostenlos. Das \"Auschecken\" einer Übersetzung (z.B. Rückumwandlung in ein Microsoft-Word-Dokument) ist mit der Basic-Version jedoch nicht möglich, so dass diese Version für einen einzeln arbeitenden Übersetzer ohne Anbindung an einen Auftraggeber mit Across Language Server ungeeignet ist. Die Premium-Version, mit der Auschecken möglich ist, ist im Monatsabonnement kostenpflichtig.\n\nDer Across Language Server wurde 2009 als Version 5 eingeführt. Seit Juli 2014 ist Across in der Version 6 verfügbar. Die Version 6.3 erschien am 26. November 2015. Die Version 7.0 erschien am 13. Februar 2019. In dieser Version wurde die Anbindung an maschinelle Übersetzungssysteme (z.B. DeepL oder SYSTRAN) eingeführt. Außerdem ließen sich ab Version 7 mehrere Aufgaben innerhalb eines Projektes gleichzeitig öffnen und bearbeiten.\n\n"}
{"id": "5931774", "url": "https://de.wikipedia.org/wiki?curid=5931774", "title": "Windows-Leistungsindex", "text": "Windows-Leistungsindex\n\nDer Windows-Leistungsindex () ist ein Modul von Windows Vista, 7, 8 und 10, welches anhand einer Punkteskala Auskunft über die Leistungsfähigkeit der individuellen Komponenten und des Gesamtsystems eines Personal Computers gibt (Benchmark-Software).\n\nDie Funktion soll dem Nutzer dabei helfen, die Leistungsfähigkeit seines System zu bewerten. Ursprünglich sollte ein Nutzer auch erkennen können, ob eine Software mit einer erforderlichen, vom Hersteller vergebenen Leistungszahl, auf einem gegebenen System läuft. Zudem soll einfacher erkennbar sein, bei welcher Hardware-Komponente das Aufrüsten sinnvoll ist.\n\nUnter Vista kann die Funktion durch einen gleichzeitigen Druck auf die Windows- und Pause-Tasten, oder über die Systemsteuerung unter „Leistungsinformationen und -tools“, aufgerufen werden.\n\nAb Windows 8.1 kann der Leistungsindex nicht mehr über die Benutzeroberfläche berechnet oder angezeigt werden, sondern nur noch über das Kommandozeilenprogramm \"WinSAT\" (\"Windows System Assessment Tool\"), das als Administrator in der Kommandozeile ausgeführt werden muss:\n\nDas Ergebnis wird als XML-Datei abgelegt in:\n\nin einer Datei mit dem Namen \"Formal.Assessment (Recent).WinSAT.xml\" und einer Datums- und Zeitangabe.\n\nProgramme legen anhand der Bewertung den verfügbaren Leistungsumfang fest, geben Warnmeldungen aus oder verweigern die Installation, daher gibt es auch Programme um den Index zu manipulieren.\n\nDer Index zeigt die Leistungsfähigkeit der einzelnen Computerkomponenten wie Prozessor, Arbeitsspeicher, Grafikkarte sowie Festplatte an und kann auch abhängig von der installierten Software wie zum Beispiel Updates des Betriebssystems sein. Die Ergebnisse des Test werden als Zahlenwerte dargestellt. In Vista reicht die Leistungsskala von 1,0 (niedrigster Wert, geringe Leistung) bis 5,9 (maximale Punktzahl, hohe Leistung), in Windows 7 von 1,0 bis 7,9 und in Windows 8 und Windows 10 von 1,0 bis 9,9. Die Gesamtbewertung der Computerleistung ergibt sich aus der niedrigsten Teilbewertung. Besonders niedrige Ergebnisse können auf veraltete Hardware oder Computerprobleme (z. B. defekte Hardware oder fehlende/falsche Gerätetreiber) hinweisen.\n\n\n"}
{"id": "5931840", "url": "https://de.wikipedia.org/wiki?curid=5931840", "title": "OSF.8759", "text": "OSF.8759\n\nOSF.8759 ist ein Computervirus, der ELF-Binärdateien auf Linux-Systemen infiziert.\n\nDer Virus vergrößert die infizierten Dateien um jeweils 8759 Bytes, 4662 davon sind eine Backdoor, die hinten an die Binärdatei angefügt ist. Laut Viruslist.com ist die Backdoor dafür ausgelegt, dass sie nicht zur ELF-Dateistruktur passt. Dadurch können später veränderte Versionen in den Code eingefügt werden.\n\nDer Virus versucht alle Dateien in seinem Verzeichnis rekursiv zu infizieren. Sobald er mit Root-Konto-Rechten gestartet wird, versucht er alle Dateien im \"/bin\" Verzeichnis zu kompromittieren. In jedem Fall werden jedoch maximal 200 Dateien in einem Programmlauf infiziert. Dateien aus den Verzeichnissen \"/dev\" und \"/proc\" und alle Dateien mit der Endung \"ps\" wie in \"maps\" werden nicht angegriffen. Die Backdoor liest das UDP auf Port 3049 aus und stellt Befehle zur Verfügung, die Binärdateien auf dem Zielsystem ausführen. Während der Ausführung probiert der Virus, die Firewall-Regeln zu verändern, um die Backdoor nicht zu stören. Er startet außerdem einen eigenen Debugger, um Debugging auf dem System zu verhindern. Sollte der Debugger nicht starten können, ist es möglich, dass vom System schon ein Debugger gestartet wurde. In diesem Fall beendet sich das Programm.\n\n"}
{"id": "5935185", "url": "https://de.wikipedia.org/wiki?curid=5935185", "title": "Donkey Kongs Abenteuer", "text": "Donkey Kongs Abenteuer\n\nDonkey Kongs Abenteuer ist eine computeranimierte Fernsehserie, die auf den Figuren der Spieleserie \"Donkey Kong Country\" basiert.\n\nDie seltene, wertvolle und machtvolle \"Kristallkokosnuss\" hat Donkey Kong als zukünftigen Herrscher von \"Kongo Bongo\" auserwählt. Bis zum Zeitpunkt seiner offiziellen Ernennung zum Herrscher hat er die ehrenvolle Aufgabe, die Kristallkokosnuss zu beschützen, denn aufgrund ihrer Macht versuchen Diebe immer wieder, diese zu stehlen. Meist ist dies \"King Kroko\", ein böswilliges, aber intelligentes Krokodil, das die Macht der Kokosnuss nutzen will, um selbst Herrscher von \"Kongo Bongo\" zu werden. Die Versuche, in den Besitz der Kokosnuss zu kommen, werden aber stets von \"Donkey Kong\" vereitelt. Zudem hat \"King Kroko\" mit dem fehlenden Intellekt seiner Truppen zu kämpfen, was die Angriffe gegen Donkey Kong und dessen Freunde zusätzlich erschwert.\n\n\n\nInsgesamt wurden 40 Folgen von \"Donkey Kongs Abenteuer\" in zwei Staffeln produziert. Allerdings wurde nur Staffel 2 in die deutsche Sprache übersetzt.\n\n<nowiki>*</nowiki> in Deutschland nicht erschienen\n\nProduziert und veröffentlicht wurde \"Donkey Kongs Abenteuer\" bzw. \"La Planète de Donkey Kong\" (Originaltitel) von Nelvana Limited und dem französischen Fernsehsender France 2. Die Idee zu der Serie stammt von Jacques Goldstein und Philippe Percebois. Die Titelmusik und der Soundtrack wurden von Pure West produziert. In Deutschland wurden Donkey Kongs Abenteuer von den Fernsehsendern Super RTL und Das Vierte ausgestrahlt. \n\nDie Serie basiert auf der von Rare und Nintendo veröffentlichten Donkey-Kong-Reihe, dabei speziell auf Donkey Kong Country, das 1994 unter der Leitung von Tim Stamper und Gregg Mayles für den Super Nintendo veröffentlicht wurde. Das Aussehen der Figuren der Serie wurde größtenteil dem des SNES-Spiels nachempfunden. Nur Dixie Kongs Kleidung wurde in einer anderen Farbe gestaltet und das Aussehen von Candy Kong wurde insgesamt leicht verändert. Zudem wurden Cranky Kong und King K. Rool in \"Bubbels\" bzw. \"King Kroko\" umbenannt. In anderssprachigen Versionen der Serie tragen die beiden aber ihren gewöhnlichen Namen.\n\nNach dem Erfolg der französischen und amerikanischen Staffeln wurde \"La Planète de Donkey Kong\" (Frankreich) bzw. \"Donkey Kong Country\" (USA) nach und nach in diverse Sprachen übersetzt und in vielerlei Ländern, wie Frankreich, Kanada, USA, Großbritannien, Finnland, Schweden, Japan, Italien, Deutschland, Spanien, Australien, Brasilien, Portugal oder Spanien ausgestrahlt.\n\nDie Serie ist in bestimmten Sprachen auch auf DVD erhältlich. In deutscher Sprache erschienen zunächst drei DVDs, die je zwei Episoden der Serie beinhalten.\n\nAm 18. August 2017 wurde erstmal die gesamte zweite Staffel mit den 14 deutsch-synchronisierten Folgen auf DVD veröffentlicht.\n\n1999 gewann die französische Version von Donkey Kongs Abenteuern, \"La Planète de Donkey Kong\", den \"7 d'Or Award\" für das beste Zeichentrick- und Jugendprogramm (Originalauszeichnung: „Meilleure émission d'animation et de jeunesse“).\n\n\n"}
{"id": "5936614", "url": "https://de.wikipedia.org/wiki?curid=5936614", "title": "Windows SideShow", "text": "Windows SideShow\n\nWindows SideShow ist eine inzwischen eingestellte Technologie, die mit Windows Vista eingeführt wurde. Sie ermöglichte es Windows-PCs eine Vielzahl an Hilfsgeräten zur Anzeige zu betreiben, die an den Haupt-PC angeschlossen sind. Diese Geräte können getrennt oder integriert in den Haupt-PC sein (z. B. ein Display in der Außenseite eines Notebook-Displays), und den Zugang zu Informationen und Medien ermöglichen, auch wenn der Computer selbst ausgeschaltet ist. SideShow kann ebenfalls das Anzeigen von PC-Daten auf Handys oder anderen, über WLAN oder Bluetooth angeschlossenen Geräten, ermöglichen.\n\nSideShow-Anzeigegeräte können mit einer Vielzahl an unterschiedlichen Informationen versorgt werden, wie z. B. Kontakte, Karten, Terminen oder E-Mail-Nachrichten. Diese können benutzt werden, wenn der PC ausgeschaltet ist. Seit die darunterliegende Plattform so energieeffizient ist, können SideShow-Displays, die in Notebooks integriert sind, hunderte Stunden laufen, ohne die Batterie des Notebooks zu leeren, während die ganze Zeit Zugang zu Daten und Multimedia-Inhalten zur Verfügung gestellt wird.\n\nSideShow ist verbunden mit Windows Sidebar (Microsoft Gadget) und diese können leicht so erweitert werden, sodass sie kompatibel zu SideShow-Displays sind. Auf jeden Fall können Hardware- und Chip-Anbieter auch Fähigkeiten zur Verfügung stellen, um Multimedia-Applikationen wie Texte, Bilder, Audio und Video zu ermöglichen. Zum Beispiel kann ein Notebook mit einem zusätzlichen Display als MP3-Player genutzt werden, während es selbst ausgeschaltet ist und der Notebook-Akkumulator hunderte Stunden Strom für die Wiedergabe liefert, da die SideShow-Plattform nicht so viel Strom verbraucht, wie das angeschaltete Notebook selbst.\n\nEin Windows SideShow-Gadget wird durch Programmierung mit der Windows-APIs geschrieben, einer mit Windows Vista verfügbaren API. Ebenfalls ist eine API für .NET-Entwickler erschienen, die Vorlagen für Microsoft Visual Studio 2005/2008 zur Demonstration, wie man SideShow-Gadgets programmiert, enthält.\n\nWindows SideShow-Geräte haben andere Hardwareeigenschaften als Geräte wie Handys oder PDAs. Windows SideShow-Geräte haben ihren eigenen Prozessor; sie müssen sich nicht allein auf den Computer verlassen, um Aufgaben auszuführen. Es gibt Online- und Offline-Fähigkeiten, die es dem Gerät erlauben, größere Komponenten auf dem angeschlossenen Computer zu betreiben. Die folgende Liste enthält typische Display-Typen und -Technologien:\n\nHardware-spezifische Applikationen, die Medien wie Audios oder Videos zur Verfügung stellen, können über das SideShow User Interface gesteuert werden, was das SDK des spezifischen Plattform-Herstellers benötigt. Zum Beispiel stellt PortalPlayer Inc. die “Preface”-Plattform zur Verfügung, die über Fähigkeiten wie das En-/Decodieren von MP3, AAC oder MPEG-4 und anderen Formaten verfügt.\n\nSideShow wurde nur wenig enthusiastisch durch die OEMs angenommen. Manche sehen SideShow als Versuch von Microsoft, dass die Hersteller Hardware produzieren, die nur mit Microsoft-Betriebssystemen kompatibel ist.\n\nAm 1. Februar 2010 stellte Ikanos Consulting Threemote vor, eine Suite SideShow-kompatibler Produkte für Embedded-Plattformen, einschließlich Golden-i, Google Android und Microsoft Windows Mobile.\n\nEs war schließlich Microsoft selbst, welche 2012 das Ende der Gadgets und damit der SideShow besiegelt haben. Man wollte sich mehr auf Windows 8 und dessen Live-Tiles fokussierenm, zudem wurden die Gadgets inzwischen als nicht zu behebendes Sicherheitsproblem betrachtet, womit man sich für deren Entfernung aus Windows Vista und 7 per FixIt-Tool entschied.\n\n\n"}
{"id": "5938516", "url": "https://de.wikipedia.org/wiki?curid=5938516", "title": "Windows MultiPoint Server", "text": "Windows MultiPoint Server\n\nWindows MultiPoint Server (WMS) ist eine Variante des Betriebssystems Windows Server des Softwareherstellers Microsoft zur Bereitstellung mehrerer unabhängiger Arbeitsplätze auf einem einzelnen Computer. Die Verbindung der Nutzer-Terminals kann dabei direkt über USB- und Videokabel, über eine Netzwerkverbindung, sowie Remote-Desktop Dienste erfolgen.\n\nDas System wurde erstmals in der Version 2010 von Microsoft Indien für den kostengünstigen Einsatz in Bildungseinrichtungen entwickelt.\n\n\"Windows MultiPoint Server 2010\" war die erste Generation des Systems auf Basis von Windows Server 2008 R2. Anders als die Bezeichnung Server vermuten lässt, ist diese Generation nicht nach dem Client-Server-Modell auf die Kommunikation mit Clients ausgerichtet. Die einzelnen Arbeitsplätze können über kurze Distanz direkt mit dem Hostsystem verbunden werden, üblicher Weise mittels USB für die Eingabegeräte und Videokabel direkt an eine Grafikkarte. Alternativ können Thin Clients über eine Netzwerkverbindung verwendet werden.\n\nNeben Lizenzen für Bildungseinrichtungen wurden Lizenzen für OEM angeboten, die keine Verwaltung durch einen Domain Controller zulassen. \n\n\"Windows MultiPoint Server 2011\" ist die zweite Generation und erlaubt als wesentliche Änderung die zusätzliche Anbindung von RDP-Clients durch den Einsatz als Terminalserver. Es basiert auf Windows Server 2008 R2 SP1 und wurde im März 2011 veröffentlicht.\n\nDas System steht in zwei Varianten zur Verfügung, die \"Standard Edition\", sowie die \"Premium Edition\", welche Verwaltung durch einen \"Domain Controller\" zulässt, sowie die maximal zulässigen Ressourcen und Verbindungen erhöht.\n\nIm November 2012 veröffentlichte Microsoft mit \"Windows MultiPoint Server 2012\" die dritte Generation des Systems. Es basiert auf Windows Server 2012 und bietet den Nutzern einen Windows 8 Desktop, sowie die Möglichkeit mit virtuellen Maschinen zu arbeiten.\n\nMit der Veröffentlichung von Windows Server 2016 im Oktober 2016 ist MultiPoint nicht mehr als eigenständiges Produkt erhältlich, sondern wird in Windows Server 2016 als Serverrolle bereitgestellt.\n\nIn Windows Server 2019 wird MultiPoint bei Neuinstallationen nicht mehr Bestandteil von Windows Server sein, sondern lediglich bei einer Update-Installation von einer vorherigen Windows-Server-Version installiert bleiben.\n"}
{"id": "5939250", "url": "https://de.wikipedia.org/wiki?curid=5939250", "title": "Choqok", "text": "Choqok\n\nChoqok ist eine Mikroblogging-Anwendung für die KDE Software Compilation 4 und läuft ab Version 1.6 mit dem KDE Frameworks 5.\n\nDas Programm gilt als übersichtlich und schlicht, obwohl es vergleichsweise viele Funktionen beinhaltet.\n\nChoqok wird von Mehrdad Momeny und Andrey Esin in der Programmiersprache C++ im Rahmen des KDE-Projektes entwickelt und als freie Software auch im Quelltext unter den Bedingungen von Version 3 der GNU General Public License (GPL) verbreitet.\nDer Name ist das altpersische Wort für Sperling.\n\nDie Software unterstützt Twitter, Friendica und Identi.ca, sowie verschiedene Dienste zum Kürzen von URLs. Eine Vorschau für Bilder auf Twitpic und Videos auf YouTube ist ebenso vorhanden wie die Möglichkeit, Passwörter in KWallet zu speichern.\n\n"}
{"id": "5941853", "url": "https://de.wikipedia.org/wiki?curid=5941853", "title": "Canaima GNU/Linux", "text": "Canaima GNU/Linux\n\nCanaima ist eine Linux-Distribution mit ausschließlich freier Software und basiert auf Debian.\n\nSeit 2004 fördert Venezuela die Nutzung freier Software in öffentlichen Einrichtungen. Das \"\"Nationale Zentrum für Informationstechnologie (CNTI)\"\" unterstützt dieses Ziel mit der Entwicklung einer eigenen venezolanischen Debian-basierten Linux-Variante \"Canaima GNU/Linux\".\n\nDie Installation – in spanisch – der Download-Datei ist im Bootmodus möglich. In einem Testbericht werden Installation und Systemstart als langsam beschrieben. Nach der Installation sind alle OpenOffice-Programme installiert, außerdem auch FreeMind, OpenProj und XChat. Ein venezuela-spanisches Wörterbuch ist enthalten und in die Programme integriert.\n\n2008 wurden Classmate PCs vom portugiesischen Hardwarehersteller \"JP Sá Couto\" bestellt, die mit diesem Linux ausgeliefert werden. Heute werden diese PCs als \"\"Magellan\"\" von \"Venezolana de Industrias Tecnológicas\" selbst hergestellt. Canaima setzt wegen dieser beschränkten Zielhardware auf einen monolithischen Kernel.\n"}
{"id": "5945212", "url": "https://de.wikipedia.org/wiki?curid=5945212", "title": "Triangle Strip", "text": "Triangle Strip\n\nEin Triangle Strip besteht aus miteinander verbundenen Dreiecken. Er wird durch eine Folge von Eckpunkten für die Dreiecke definiert, wobei jede Gruppe von drei aufeinander folgenden Eckpunkten ein Dreieck beschreibt.\n\nTriangle Strips kommen in der Computergrafik bei der effizienten Darstellung dreidimensionaler Objekte zum Einsatz. Sie werden in Programmierschnittstellen wie OpenGL und DirectX direkt unterstützt.\n"}
{"id": "5953908", "url": "https://de.wikipedia.org/wiki?curid=5953908", "title": "IFilter", "text": "IFilter\n\nIFilter definiert eine COM-Programmierschnittstelle, über die Zusatzprogramme den Windows-Indexierungsprogrammen und dem neuen Windows Desktop Search Metadaten über verschiedene Dateiformate bereitstellen, so dass diese transparent indiziert werden können.\n\nDas IFilter-Interface wird auch bei der Volltextsuche des Microsoft SQL Server verwendet.\n\n\n"}
{"id": "5954515", "url": "https://de.wikipedia.org/wiki?curid=5954515", "title": "Linux Assigned Names and Numbers Authority", "text": "Linux Assigned Names and Numbers Authority\n\nDie Linux Assigned Names and Numbers Authority (LANANA) ist eine zentrale Registrierungsstelle für Namen und Nummern, welche innerhalb Linux benutzt werden. Damit können bei konformer Benennung Namenskollisionen vermieden und die Interoperabilität innerhalb der gesamten Linux-Landschaft gefördert werden.\nDie LANANA pflegt Verzeichnisse von Namen von Installationspaketen, init-Skripts, cron-Skripts, Gerätenamen und anderem.\nSie ist Teil der Free Standards Group und der Linux Foundation.\n\nIm Jahr 1992 wurde die Linux-Geräteliste von Rick Miller geschaffen und bis 1993 gepflegt. 1995 wurde die Pflege von Hans Peter Anvin übernommen. 2000 gründete er dazu die LANANA, die neben dieser zukünftig noch weitere ähnliche Listen pflegen sollte. Der Name wurde als Anspielung auf die IANA gewählt, der Registrierungsstelle für Namen und Nummern für das Internet. 2002 wurde die LANANA offizielle Arbeitsgruppe der Free Standards Group.\n\n"}
{"id": "5958071", "url": "https://de.wikipedia.org/wiki?curid=5958071", "title": "Der Grüffelo (Film)", "text": "Der Grüffelo (Film)\n\nDer Grüffelo ist ein Fernsehfilm aus dem Jahr 2009. Regie führten Max Lang und Jakob Schuh. Die Coproduktion von BBC und ZDF wurde erstmals zu Weihnachten 2009 bei der BBC und auf Deutsch an Heiligabend 2010 im ZDF ausgestrahlt.\n\nDie Rahmenhandlung beschreibt ein Eichhörnchen, welches seinen Kindern eine Geschichte erzählt. Im Kern geht es darum, dass sich eine Maus ein Monster, den Grüffelo, erfindet. Diesen gibt sie als besten Freund und Beschützer aus, um nicht gefressen zu werden, aber schließlich trifft die Maus diesen auch in Wirklichkeit.\n\nDas Kinderbuch \"The Gruffalo\" (Deutsch: Der Grüffelo) von Julia Donaldson (illustriert von Axel Scheffler) aus dem Jahr 1999 wurde über vier Millionen Mal verkauft. 2011 erschien die Fortsetzung \"Das Grüffelokind\".\n\nDer Film wurde beim Prix Jeunesse mit zwei Preisen ausgezeichnet.\n\n2010 erhielt der Film beim Trickfilmfestival Stuttgart den Tricks for Kids Award für den besten Kindertrickfilm.\n\nDer Film wurde für den Oscar 2011 in der Kategorie Bester animierter Kurzfilm nominiert.\n\n\"Der Grüffelo\" wurde für den British Academy Film Award 2010 in der Kategorie Bester animierter Kurzfilm nominiert.\n\n"}
{"id": "5960708", "url": "https://de.wikipedia.org/wiki?curid=5960708", "title": "Demosaicing", "text": "Demosaicing\n\nAls (auch ) bezeichnet man in der Digitalfotografie die Rekonstruktion einer farbigen Rastergrafik aus den unvollständigen Farbwerten eines mit Mosaik-Farbfiltern überlagerten Bildsensors.\n\nDie Bildsensoren der meisten Digitalkameras basieren auf Bayer-Sensoren. Dabei handelt es sich um CMOS-Sensoren, die mit einer Matrix aus regelmäßig angeordneten Rot-, Grün- und Blaufiltern überzogen sind. Da jedes Pixel nur den Wert eines Farbkanals aufnehmen kann, ist die Farbinformation unvollständig. Zur Erzeugung einer Rastergrafik, die vollständige RGB-Werte für jedes Pixel speichert, müssen benachbarte Grundfarben-Werte interpoliert werden.\n\nNeben den Bayer-Sensoren gibt es noch Bildsensoren mit RGBE (Rot, Grün, Blau, Cyan)- oder CYGM (Cyan, Gelb, Grün, Magenta)-Filtern, die ebenfalls Demosaicing erfordern. Beim Foveon-X3-Direktbildsensoren oder Three-Shot-Sensoren werden für jedes Pixel die Werte aller drei Grundfarben aufgenommen; hier ist kein Demosaicing nötig.\n\nDas Demosaicing kann sowohl durch die Firmware der Kamera erfolgen, wobei meist ein JPEG- oder TIFF-Bild erzeugt wird, als auch später als Software auf ein Bild im Rohdatenformat angewandt werden.\n\nEine einfache Möglichkeit des Demosaicing ist die Interpolation mittels eines Rekonstruktionsfilters, zum Beispiel mittels bilinearer Filterung (siehe auch Skalierung). Hierbei kann es zu Unschärfe und anderen Bildartefakten kommen:\n\nEs wurden zahlreiche weitere Demosaicing-Verfahren entwickelt, mit dem Ziel, diese Artefakte zu vermindern oder zu eliminieren. Dazu gehören:\n\n"}
{"id": "5964208", "url": "https://de.wikipedia.org/wiki?curid=5964208", "title": "LTspice", "text": "LTspice\n\nLTspice ist eine kostenlose Software des ehemaligen Halbleiterherstellers Linear Technology (Seit 2017: Analog Devices) zur Schaltungssimulation. Es basiert auf SPICE, ist dazu kompatibel und besonders zur Simulation von Schaltnetzteilen geeignet. Entwickelt und gepflegt wird es von Mike Engelhardt.\n\nLTspice ging 1999 aus SwitcherCAD hervor, wodurch es auch seinen zweiten Namen hat, und wird seitdem beständig weiterentwickelt.\nDas Programm wurde inklusive der Vorgängerversion SwitcherCAD bereits (2011) über drei Millionen Mal heruntergeladen.\nInzwischen kann es in manchen Fällen auch mehrere Prozessoren nutzen.\nDie Windows-Version wird vom Autor auf Kompatibilität unter Wine getestet, so dass man es auch unter Linux nutzen kann. Für macOS gibt es eine eigenständige Version.\n\n2016 wurde von Linear Technology LTspiceXVII für Windows 7, 8 und 10 vorgestellt.\n\nMit LTspice werden Modelle für sehr viele Bausteine von Linear Technology mitgeliefert und optimal unterstützt. Enthalten ist auch eine – relativ kleine – Bibliothek von diskreten Bauelementen und integrierten Schaltungen anderer Hersteller.\n\nZeitverläufe – inklusive Parametervariationen – lassen sich berechnen und darstellen, darüber hinaus kann man diese auch in den Frequenzbereich transformieren. Weiterhin kann man eine Kleinsignalanalyse vornehmen und eine Monte-Carlo-Simulation durchführen. Zusätzlich zu analogen Bauteilen werden auch idealisierte digitale Gatter in den Bibliotheken mitgeliefert.\n\nDurch die Kompatibilität mit SPICE können Modelle aus anderen Quellen relativ einfach übernommen und verwendet werden.\n\nLTspice ist Freeware. Die Software darf nicht verändert, jedoch von jedermann kostenfrei genutzt werden. Halbleiterhersteller dürfen sie jedoch nicht im Rahmen der Vermarktung ihrer Produkte nutzen.\n\nEs gibt eine Vielzahl von Programmen, die SPICE zur Simulation verwenden, darunter viele kommerzielle Programme.\n\n\n"}
{"id": "5969947", "url": "https://de.wikipedia.org/wiki?curid=5969947", "title": "JMP (Software)", "text": "JMP (Software)\n\nJMP (sprich „jump“) ist ein Computerprogramm für Statistik, das vom JMP-Geschäftsbereich der SAS Institute entwickelt wurde. Es wurde in den 1980er Jahren für die grafische Benutzeroberfläche des Macintosh entwickelt. Es wurde seitdem verbessert und auch für Windows verfügbar gemacht. JMP wird in Applikationen wie Six Sigma zur Qualitätskontrolle und technischen Planung, Versuchsplanung (DOE) und wissenschaftlichen Forschung verwendet.\nDie Software besteht aus fünf Produkten: JMP, JMP Pro, JMP Clinical, JMP Genomics und JMP Graph Builder App für das iPad; es steht auch eine Skriptsprache (JSL) zur Verfügung. Die Software hat ihren Schwerpunkt in der explorativen Analyse, bei der Benutzer Daten visuell untersuchen und erforschen.\n\nJMP wurde in den 1980er Jahren von John Sall und einem Entwicklerteam entwickelt, um die 1984 von Apple Macintosh eingeführte grafische Benutzeroberfläche zu nutzen. Das Akronym stand anfangs für „John’s Macintosh Project“ und wurde erstmals im Oktober 1989 herausgegeben. Es wurde hauptsächlich von Wissenschaftlern und Ingenieuren für die Versuchsplanung, für Qualitäts- und Produktivitätsupport (Six Sigma) und Zuverlässigkeitsbewertungen verwendet. Halbleiterhersteller befanden sich ebenfalls unter den frühen Interessenten.\n\nInteraktive Grafiken und weitere Funktionen wurden 1991 mit der Version 2.0 hinzugefügt. Version 2 war doppelt so groß wie das Original, wurde jedoch weiterhin auf einer Diskette ausgeliefert. Es benötigte 2 MB Speicherplatz und enthielt eine Dokumentation von 700 Seiten. Der Support für Microsoft Windows wurde 1994 hinzugefügt. JMP [9] wurde 1999 mit Version 3 neu programmiert. Version 4, die 2002 erschien, konnte Daten aus einer breiteren Palette von Datenquellen importieren und enthielt außerdem Support für Oberflächendarstellungen. Mit Version 4 wurden auch Extrapolationen von Zeitreihen und neue Glättungsfunktionen, wie die saisonale Glättung, die sogenannte Winter-Methode und der ARIMA (Autoregressive Integrated Moving Average) hinzugefügt.\n\n2005 wurden in Version 5 Data-Mining-Tools, wie ein Entscheidungsbaum und ein neuronales Netz sowie Linux-Support, der später mit Start von JMP 9 wieder zurückgezogen wurde, hinzugefügt. Später im selben Jahr wurde JMP 6 eingeführt. JMP begann die Integration mit den übrigen SAS-Produkten mit Version 7.0 in 2007 und in zunehmendem Maße mit jeder seitdem erschienenen Version. Seitdem können Anwender SAS-Code in JMP schreiben, eine Verbindung mit SAS-Servern herstellen und SAS-Ergebnisse wieder einlesen und weiter bearbeiten. Support für Blasendiagramme wurde in Version 7 hinzugefügt. In der Version 7 wurden außerdem Datenvisualisierung und Diagnostik verbessert.\n\nDie Version 8 wurde 2009 mit neuen Drag- und Drop-Funktionen und einer 64-Bit-Version herausgegeben, um von den Vorteilen des Mac-Betriebssystems zu profitieren. Außerdem wurde eine neue Benutzeroberfläche zur Erstellung von grafischen Darstellungen, Tools für Entscheidungsmodelle und Lebensdaueranalysen hinzugefügt. Laut Scientific Computing gab es bei der Software Verbesserungen bei den „Grafiken, der QS, Benutzerfreundlichkeit, SAS-Integration und in Bereichen der Datenverwaltung.“ JMP 9 fügte 2010 eine neue Schnittstelle für die Verwendung der R-Programmiersprache in JMP und ein Add-In für Excel hinzu. Der Hauptbildschirm wurde neu gegliedert und es wurden Verbesserungen bei der Simulation, bei Grafiken und einer neuen Degradation-Plattform zur Analyse von Abbau- und Zersetzungsprozessen durchgeführt. Im März 2012 verbesserte Version 10 das Data-Mining, prädiktive Analysen und die automatisierte Modellerstellung.\n\nJMP besteht aus JMP, JMP Pro, JMP Clinical und JMP Genomics sowie der Graph Builder iPad App. JMP Clinical und JMP Genomics verbinden JMP und SAS-Software.\n\nDie JMP-Software hat ihren Schwerpunkt in der explorativen Datenanalyse und Visualisierung. Sie wurde für Benutzer entwickelt, die eher neue Erkenntnisse aus Daten gewinnen wollen, als eine Hypothese zu bestätigen. JMP verknüpft Daten mit Statistiken und Grafiken, damit Benutzer die Daten und ihre verschiedene visuellen Darstellungen per Drill-Down oder Drill-Up ansehen können.<ref name=\"doi10.1002/wics.162\"></ref> Seine Hauptanwendungen liegen in der Versuchsplanung und der Analyse von statistischen Daten industrieller Prozesse.\n\nJMP ist eine Desktop-Applikation mit einer Assistenten-basierten Benutzeroberfläche, während SAS auf Servern installiert werden kann. Es wird im Arbeitsspeicher statt auf dem Plattenspeicher ausgeführt. Nach einer Bewertung in Pharmaceutical Statistics wird JMP oft als grafisches Front-End-Tool für ein SAS-System verwendet, das die statistische Analyse und Tabellierungen durchführt. JMP Genomics, das für die Analyse und Visualisierung von Genom-Daten verwendet wird, erfordert zum Betrieb eine SAS-Komponente und kann auf SAS/Genetics- und SAS/STAT-Verfahren zugreifen oder SAS-Macros aufrufen. JMP Clinical, das für die Analyse der Daten von klinischen Studien verwendet wird, kann SAS-Code innerhalb der JSL-Skriptsprache verpacken und SAS-Code in JMP umwandeln.\n\nJMP ist auch der Name des Geschäftsbereichs des SAS-Institute, das JMP entwickelt. Im Jahr 2011 hatte JMP 180 Mitarbeiter und 250.000 Benutzer.\n\nDie JMP Skriptsprache (JSL) ist eine interpretierte Sprache zur Neuerstellung von analytischen Ergebnissen und zur Automatisierung oder Erweiterung der Funktionalität der JMP-Software. JSL wurde erstmals 2000 in JMP Version 4 eingeführt. JSL hat eine Java-ähnliche Syntax, die als eine Reihe von Ausdrücken strukturiert ist. Datentabellen, Anzeigeelemente und Analysen werden durch Objekte in JSL dargestellt, die mit benannten Nachrichten manipuliert werden. Benutzer können JSL-Skripts schreiben, um Analysen und Visualisierungen durchzuführen, die in der Point- und Click-Oberfläche nicht verfügbar sind, oder um eine Reihe von Befehlen, wie wöchentliche Berichte, zu automatisieren. SAS- und R-Code kann ebenfalls unter der Verwendung von JSL ausgeführt werden.\n\n2007 begann eine Überwachungsorganisation für freilebende Tiere, WildTrack, JMP mit dem Footprint Identification Technology (FIT)-System zu verwenden, um einzelne gefährdete Tiere über ihre Fußabdrücke zu identifizieren. 2009 verwendete Chicago Botanic Garden JMP, um DNA-Daten von tropischen Brotfrüchten zu analysieren. Forscher stellten fest, dass die kernlose, stärkehaltige Frucht durch absichtliche Hybridisierung von zwei Früchten, der Brotnuss und der Dug Dug, erschaffen wurde. Das Herzenberg Laboratory in Stanford hat JMP mit dem Fluorescence Activated Cell Sorter (FACS) integriert. Das FACS-System wird verwendet, um HIV, Krebs, Stammzellen und die Ozeanografie zu erforschen.\n\n"}
{"id": "5985794", "url": "https://de.wikipedia.org/wiki?curid=5985794", "title": "Viber", "text": "Viber\n\nViber ist ein kostenloser Chat-Dienst für Smartphones und Desktop-Computer mit, laut eigenen Angaben, rund 900 Millionen Nutzern in 193 Ländern. Das Programm ermöglicht IP-Telefonie und Nachrichtensofortversand zwischen Viber-Nutzern über das Internet. Es sind auch ausgehende Anrufe in Fest- oder Handynetze möglich. Im Gegensatz zu anderen VoIP-Anbietern wie Skype benötigt Viber keine Benutzernamen, sondern verwendet die vorhandenen Telefonnummern. Viber setzt voraus, dass die Software auf beiden Endgeräten installiert ist.\n\nDer Dienst wurde ursprünglich von vier israelischen Entwicklern gegründet, von denen Talmon Marco und Igor Magazinnik die bekannteste sind. An der Universität Tel Aviv erlangte er im Jahr 1999 den Bachelor-Abschluss in Informatik und Management.\n\nFrüher wurde für den Dienst Vermittlungssoftware von dem Unternehmen \"Spirit DSP\" lizenziert. Nachdem deren Konkurrent \"Global IP Solutions\" von Google Inc. übernommen und deren Software als Freie Software veröffentlicht worden war, wechselte Viber auf diesen lizenzkostenfreien Softwarestack.\n\nViber wurde im Frühjahr 2014 vom japanischen Unternehmen Rakuten übernommen.\n\nDas Büro für technische Entwicklung und Kundenbetreuung befindet sich in Minsk und Brest.\n\nDie Nutzung der Viber-Dienste bei der Kommunikation mit anderen Viber-Nutzern ist kostenfrei. Ausgehende Anrufe sind kostenpflichtig („pre-paid-credit“). Die Gesprächskosten können auf der Internetseite ermittelt werden.\n\nViber steht wegen seines schlechten Datenschutzes in der Kritik. Viber sammelt Daten in erheblichen Mengen, die bei Weitem über das übliche Maß anderer VoIP-Anbieter hinausgehen (zum Beispiel Skype), und zwar sowohl von Nutzern als auch von Nicht-Nutzern des Dienstes. Viele dieser Daten werden ohne die Zustimmung und ohne das Wissen der jeweils betroffenen Personen gespeichert und verstoßen somit gegen EU-Datenschutzrecht.\n\nViber hält sich mit Details zu dem Unternehmen sehr bedeckt. Somit ist unklar, wo und gegebenenfalls zu welchem Zweck die erhobenen Daten gespeichert werden beziehungsweise in wessen Hände sie gelangen. Der neue japanische Eigner \"Rakuten\" versprach im April 2016 die Einführung der Ende-zu-Ende-Verschlüsselung.\n\n\n"}
{"id": "5993288", "url": "https://de.wikipedia.org/wiki?curid=5993288", "title": "Mastercam", "text": "Mastercam\n\nMastercam bezeichnet eine CAD/CAM-Software des US-amerikanischen Herstellers \"CNC Software\" mit Sitz in Tolland, Connecticut.\nMastercam war im Jahr 2016 mit über 224.000 Installationen, gemessen an den installierten Lizenzen, das weltweit meisteingesetzte System auf dem Markt PC-basierter CAM-Software zur Steuerung von CNC-Maschinen.\n\nMastercam umfasst die Funktionen Fräsen in 2 bis 5 Achsen, Drehen, Drahterodieren, künstlerische Reliefbearbeitung, 2D- und 3D-Design, Flächen- und Solidmodeling. Das Einsatzgebiet der Software findet sich hauptsächlich im Bereich des Werkzeug-, Formen- und Maschinenbaus sowie der Medizintechnik. Weiterhin kommt Mastercam auch im Bereich der Holz-, der Stein- und Kunststoffbearbeitung sowie bei künstlerischen Bearbeitungen zum Einsatz.\n\nDas 1983 gegründete Unternehmen ist eines der ältesten Unternehmen in der PC-basierten CAD/CAM-Industrie. Das Unternehmen wurde auf dem Konzept aufgebaut, ein auf dem Personal Computer basierendes CAM-System zu liefern. Dies geschah zu einem Zeitpunkt, als die meisten anderen Systeme weitestgehend CAD-orientierte Produkte darstellten. Mastercam war eines der ersten mikrobasierten CAM-Pakete, das CAD-Fähigkeiten enthielt, dem Anwender eine schnelle und einfache Konstruktion eigener Teile erlaubte und sowohl für Maschinenarbeiter als auch für Ingenieure gestaltet wurde. Die ursprüngliche Version von Mastercam gründete in zweidimensionalem (2D) CAM.\n\nKurz nachdem CNC Software 1983 in Massachusetts begonnen hatte, verlegte die Gesellschaft den Ausgangspunkt ihrer Tätigkeit in ein Büro in Vernon, Connecticut. Heute befinden sich der Hauptsitz und die Schulungseinrichtung gemeinsam in einem firmeneigenen 5.000 m² großen Gebäude in Tolland, Connecticut. Zusätzlich zu den mehr als 150 Beschäftigten dort betreibt CNC Software noch ein Büro in Washington, D.C. für den Bildungsmarkt. Der Vertrieb der Software Mastercam erfolgt weltweit ausschließlich über autorisierte Reseller und Vertriebspartner.\n\nDie \"InterCAM-Deutschland GmbH\" ist Distributor der gesamten Produktpalette von Mastercam in Deutschland und hat ihren Firmensitz in Bad Lippspringe. Die Gründung erfolgte 1991 durch Andreas Stute. Das Verkaufsgebiet für Mastercam-Produkte umfasst Deutschland, Österreich, Belgien, Luxemburg und die Niederlande. Im Jahr 2016 betreute die InterCAM-Deutschland GmbH über 5.500 Mastercam-Lizenzen bei mehr als 3.600 Kunden. Die InterCAM-Deutschland GmbH war im Jahr 2016 der weltweit drittgrößte Mastercam-Reseller. Die Software wird über ein Netzwerk autorisierter Vertriebspartner angeboten und supportet. Zu den Tätigkeiten gehören neben der Betreuung der Vertriebspartner auch die Entwicklung neuer Technologien, die Lokalisierung und Übersetzung der Software, sowie die Zusammenarbeit mit OEM’s, Maschinen- und Werkzeugherstellern. Zudem engagiert sich der deutsche Mastercam-Distributor seit vielen Jahren bei den nationalen und internationalen Berufswettbewerben, den „WorldSkills Germany“, „WorldSkills Europe“ und „WorldSkills International“. Gemäß dem Motto „Mastercam – Wir fördern Talente“ stellt die InterCAM-Deutschland GmbH für den Wettbewerb die CAD/CAM-Software zur Verfügung und schult die jungen Teilnehmer im Vorfeld. Gut ausgebildeter Nachwuchs war und ist für Mastercam ein wichtiger Geschäftsbereich. Das spiegelt sich besonders in den über 119.000 Installationen allein im Ausbildungssektor wider.\n\nIm Jahr 2016 stellte das Unternehmen mit \"Mastercam 2017\" die aktuelle Version der CAD/CAM-Software vor.\nDiese ist, wie seine Vorgänger auch, eine modular aufgebaute Software, die somit den unterschiedlichen Bedürfnissen der jeweiligen Anwender angepasst werden kann.\nDie verschiedenen Produkte sind – je nach Anwendungsgebiet und Anforderungen – nochmals in diverse Produktlevel unterteilt.\nFolgende Mastercam-Produkte gibt es:\n\n\nDarüber hinaus sind Zusatzprodukte und Add-ons für Mastercam erhältlich.\n\n"}
{"id": "6004753", "url": "https://de.wikipedia.org/wiki?curid=6004753", "title": "Jurix", "text": "Jurix\n\njurix war eine frühe, hauptsächlich auf Disketten aufgebaute Linux-Distribution, die heute nicht mehr weiterentwickelt wird. Sie wurde von Florian La Roche vom Rechts-Fachbereich der Universität von Saarbrücken ins Leben gerufen und betreut und ist mit einem Copyright-Hinweis für mindestens die Spanne von 1994 bis 1996 versehen. Am Ende dieser Zeit wurden die Viert-Level-Domains \"jurix\" und \"susix\" in der Hierarchie \"jura.uni-sb.de\" für die Kommunikation und die Erstveröffentlichung der gepackten Ergebnisse benutzt.\n\nDer Ursprung des Namens jurix geht nicht auf La Roche, sondern auf Alexander Sigel, einen Mitarbeiter derselben Universität, zurück. Dieser benannte im Jahr 1994 den ersten Internet-Server der Abteilung zu \"jurix\" – dieser lief bereits unter Linux. Es gibt keine Hinweise, ob diese Entscheidung irgendwie mit der nicht allzu fern gelegenen holländischen Bildungs-Institution für Recht und Informationstechnik mit Namen JURIX in Verbindung zu bringen ist oder es sich um eine simple Zusammenfügung der Begriffe \"Jura\" und \"Unix\"/\"Linux\" handelt. Letztlich belegt ist, dass La Roche selbst im Jahr 1995 die offizielle Aufgabe übertragen bekommen hat, diese Web-Plattform administrativ zu betreuen.\n\nEine Diskussion über die Geschichte von Linux enthielt die Worte:\nDie letzte bekannte sowie archivierte Version der Distribution bestand im Kern aus diesen Anwendungen:\n\nDie Distribution hatte einige weitere Merkmale, wozu insbesondere ein Installationsprogramm gehörte, das auch fähig war, skriptgesteuerte Installationen vorzunehmen und so ein bestimmtes Software-Set auf relativ gleichen Maschinen reproduzierbar machte. Standards wie BOOTP oder NFS wurden unterstützt. Als das zentrale Dateisystem für den Einsatz war ext2 standardmäßig in die Distribution integriert.\n\nDieses Gesamtpaket formte später den Ausgangspunkt für die Initialversion der eigentlichen Distribution SuSE Linux und ihrer Nachfolger. Im weiteren Verlauf der Entwicklung trat der Betreuer von jurix der Firma SuSE ebenfalls bei und war dort für z. B. den Installer und das von ihm geschriebene Konfigurations-Werkzeug YaST zuständig.\n\n"}
{"id": "6005638", "url": "https://de.wikipedia.org/wiki?curid=6005638", "title": "Cash Trapping", "text": "Cash Trapping\n\nCash Trapping (dt. \"Geldfalle\") ist eine Diebstahlsvariante. Der Geldausgabeschacht von Geldautomaten wird so präpariert, dass das abgehobene Geld im Ausgabeschacht hängen bleibt. Der Bankkunde bemerkt davon nichts, sondern geht davon aus, dass der Automat defekt ist. Der Geldautomat schaltet nach der Meldung eines Defekts ab. Nachdem sich der Kunde entfernt hat, holt der Täter das ausgegebene Geld aus dem Schacht. \n\nIm Ausgabeschacht des Geldautomaten wird eine auf die Breite des Schachts zugeschnittene Teppichleiste angebracht. An der Unterseite ist ein doppelseitiges Klebeband aufgeklebt. Die Anbringung erfolgt so, dass die Geldscheine an dem Klebeband hängen bleiben. \n\nDer Täter begeht einen Diebstahl, da er sich rechtswidrig eine fremde Sache aneignet. Die Haftungsfrage ist derzeit umstritten, da sich die Bank auf den Standpunkt stellen kann, dass das Geld ausgezahlt worden ist.\n\nDie Täter arbeiten meist zu zweit oder zu dritt. Bei den Eingriffen am Automaten und der Abholung des Geldes werden Kapuzen oder ähnliches getragen, um durch die Aufnahmen der an Automaten üblichen Kameras nicht identifiziert werden zu können. Ein Mittäter passt in der Nähe des Tatorts auf; er steht dabei über Kommunikationsmittel mit den anderen Tätern in Verbindung. Nach der Tat wird die Teppichleiste wieder entfernt; zurück bleiben oft nur Klebereste.\n\nBeim Skimming werden illegal Kartendaten, insbesondere an Bankautomaten erlangt, indem Daten von Magnetstreifen ausgelesen und auf gefälschte Karten kopiert werden. Skimming wird als Betrug bestraft.\n\n"}
{"id": "6008052", "url": "https://de.wikipedia.org/wiki?curid=6008052", "title": "Bunny (Film)", "text": "Bunny (Film)\n\nBunny ist ein US-amerikanischer computeranimierter Kurzfilm von Chris Wedge aus dem Jahr 1998.\n\nEine alte, verwitwete Hasenfrau bereitet einen Möhrenkuchen vor. Der Herd ist vorgeheizt und sie siebt gerade das Mehl, als eine beständig gegen die Glühlampe fliegende Motte ihre Arbeit stört. Die Motte stößt auch gegen das Hochzeitsfoto der Häsin mit ihrem Gatten und wird schließlich von der Hasenfrau aus dem Haus befördert.\n\nDie Hasenfrau rückt das Hochzeitsfoto gerade und wird beim Anblick des Bildes melancholisch. Draußen ist die Motte zu hören, die solange gegen das Fliegengitter am Fenster fliegt, bis die Hasenfrau das Fenster zuschlägt. Die Häsin hoppelt an ihrer Gehhilfe mühsam zum Tisch zurück und beginnt die Möhren zu raspeln. Plötzlich stößt die Motte ein Flügelfenster auf und flattert in der Wohnung umher. Die Häsin macht Jagd auf das Tier, ein Glas geht zu Bruch – nach einem gezielten Schlag landet die Motte im Kuchenteig, den die Häsin eilig in den Ofen schiebt. Hektisch zieht sie den Kurzzeitwecker auf, setzt sich schließlich erschöpft nieder und schläft ein.\n\nAus dem Ofen dringt plötzlich blaues Licht und der Ofen beginnt zu vibrieren, bis schließlich die Ofentür aufklappt. Im Inneren schwebt die Motte und die Häsin kriecht in den Ofen und folgt dem Tier. Die Ofentür schlägt zu. Die Häsin schwebt im Himmel, nun ebenfalls mit Flügeln versehen, einem gleißenden Licht zu. Zahlreiche Motten folgen ihr. Das Hochzeitsfoto in der Wohnung der Hasenfrau wird lebendig: Sie schaut ihn liebevoll an und schmiegt sich an ihn. Zwei halbdurchsichtige Motten verschmelzen mit dem Foto und geben Hasenmann und Hasenfrau Flügel.\n\nDer Titel \"Bend Down the Branches\", der zu den Filmcredits läuft, wurde von Tom Waits geschrieben und gesungen.\n\n\"Bunny\" gewann 1999 den Oscar in der Kategorie „Bester animierter Kurzfilm“. Es war der erste Oscar, den Chris Wedge erhielt.\n\nAuf dem Drama Short Film Festival gewann Chris Wedge für \"Bunny\" 1999 den Spezialpreis im Bereich Animation.\n\n"}
{"id": "6009139", "url": "https://de.wikipedia.org/wiki?curid=6009139", "title": "Selbstwechselwirkungskorrektur", "text": "Selbstwechselwirkungskorrektur\n\nDie Selbstwechselwirkungskorrektur (oft kurz SIC: \"self-interaction correction\") ist eine Methode im Rahmen der Dichtefunktionaltheorie. Sie korrigiert den im Rahmen der Lokalen Dichtenäherung (LDA) auftretenden Selbstwechselwirkungsfehler teilweise.\n\nDie von John Perdew und Alex Zunger vorgeschlagene Methode kann insbesondere auf den Festkörper angewandt werden. Für viele Materialien hat die Selbstwechselwirkungskorrektur Ergebnisse geliefert, die in deutlich besserer Übereinstimmung mit dem Experiment sind, als die innerhalb der LDA erzielten.\n"}
{"id": "6017258", "url": "https://de.wikipedia.org/wiki?curid=6017258", "title": "Adobe PDF Print Engine", "text": "Adobe PDF Print Engine\n\nDie Adobe PDF Print Engine, auch \"APPE\" genannt ist eine Druckplattform-Technologie von Adobe. Aktuell liegt sie in Version 3 vor und hat den Adobe CPSI-Interpreter abgelöst. Sie stellt die technische Intelligenz in Druckereien dar, aus PDF-Dokumenten belichtungsfähige Rasterdaten zu erzeugen. Da Adobe den Funktionsumfang seines Portable Document Formats ständig erweitert, wird auch die \"Adobe PDF Print Engine\" stetig weiterentwickelt. Sie gilt als Nachfolger des eingestellten PostScript-Formates.\n\nDieses Software-Paket ist für den Endkunden nicht erhältlich. Stattdessen erhalten OEM-Kunden wie Heidelberger Druckmaschinen AG (Prinect), Agfa (Apogee), Fujifilm (XMF) oder Screen die entsprechenden Pakete im Rahmen eines Lizenzabkommens. Adobe stellt ein Software-Paket, das unter anderem wichtige Rendering-Funktionen, wie die der RIPs, enthält. RIP ist die Abkürzung für „Raster Image Processor“. Seine Aufgabe besteht darin, logische Informationen aus einer Postscript- oder PDF-Datei so in Pixel zu konvertieren, dass sie auf dem gewünschten Gerät ausgegeben werden können – also beispielsweise einem Monitor, Laserdrucker oder CtP-Recorder. Das können einfache RGB-Pixel sein, die auf einem Monitor gezeigt werden. Oder aber Millionen schwarzer Punkte im stochastischen Offsetdruckraster einer Druckplatte, die dazu dienen, Druckfarbe über ein Gummituch auf Papier zu bringen.\n\nDie \"Adobe Print Engine\" erwartet stets PDF-Dokumente. PostScript-Dokumente müssen vorher in das Portable Document Format gewandelt werden.\n\nMit Version 3 wurde die Mercury RIP Architecture eingeführt. Diese besonders auf hohe Skalierbarkeit ausgelegte Architektur besitzt ein integriertes Load-Balancing und ermöglicht es, vorhandene Ressourcen auf einem einzelnen System oder in einem Netzwerk (RIP-Farm) effektiv zu nutzen. Außerdem wird das Erzeugen von variablen Druckdaten (Variable Data Printing) durch Mercury stark beschleunigt.\n\nLaut Adobe ist die PDF Print Engine 3 die schnellste auf dem Markt verfügbare Rendering-Technologie.\n"}
{"id": "6017823", "url": "https://de.wikipedia.org/wiki?curid=6017823", "title": "BricsCAD", "text": "BricsCAD\n\nBricsCAD ist eine Softwareanwendung für Computer Aided Design (CAD), die es seit 2002 gibt. BricsCAD in seinen Editionen kann für zweidimensionale Konstruktionszeichnungen, dreidimensionale Konstruktionsmodelle, das parametergestützte Modellieren, Tiefzieh-Modellierung und für Bauwerksdatenmodellierung (BIM) eingesetzt werden. Alle BricsCAD-Editionen basieren auf der \"Teigha\"-Plattform der Open Design Alliance, und können daher das von AutoCAD stammende .dwg-Format nativ schreiben und lesen. Darauf beruht auch der Erfolg der Programmfamilie, BricsCAD zählte 2003 zusammen mit AutoCAD LT und DraftSight zu den weitverbreiteten AutoCAD-Klonen im Niedrigpreis-Segment.\n\nBricsCAD wird von Bricsys NV mit Hauptsitz in Gent, Belgien, entwickelt. Das Unternehmen wurde 2002 von Erik de Keyser gegründet. Im Jahr 2011 erwarb Bricsys die Rechte am geistigen Eigentum von Ledas für Constraints-basierte parametrische Design-Tools, die die Entwicklung von Anwendungen in den Bereichen der direkten Modellierung und des Assembly-Designs ermöglichen. Bricsys betreibt Entwicklungszentren in Nischni Nowgorod und Novosibirsk, Bukarest und Singapur. Bricsys ist Gründungsmitglied der Open Design Alliance.\n\nDie BricsCAD-Software, die für die Betriebssysteme Windows, Linux und macOS erhältlich ist, ist in drei Editionen verfügbar:\n\nZwei weitere Editionen von BricsCAD wurden Ende 2018 veröffentlicht. Vor V19 wurde das BricsCAD BIM-Produkt als Modul namens \"BIM für BricsCAD\" ausgeliefert, das über eine Lizenz von BricsCAD Platinum installiert wurde. BricsCAD Mechanical ist ein neues Produkt für V19. Es enthält erweiterte Funktionen aus dem Modul \"Sheet Metal für BricsCAD\" vor der V19 und zusätzliche Werkzeuge zur Modellierung von Baugruppen, kinematische Animationen, Stücklisten und Explosionszeichnungen.\n\nAlle BricsCAD-Editionen verwenden die Open Design Alliance Drawing API-Softwareentwicklungsplattform, die BricsCAD das Lesen und Schreiben im .dwg Format ermöglicht, welches von Autodesk's AutoCAD bekannt gemacht wurde. populär gemacht wurde. BricsCAD V19 liest und schreibt nativ im 2018er .dwg-Dateiformat, bei Bedarf auch bis hinunter zu AutoCAD Release 12. Die Software ist in der Lage, fast alle modernen AutoCAD-Funktionen auszuführen. BricsCAD ist derzeit in 18 Sprachversionen erhältlich.\n\nCommunicator für BricsCAD importiert und exportiert 3D-CAD-Daten, um den Datenaustausch mit den meisten mechanischen CAD-Programmen (e.g. CATIA, Creo Elements/Direct Modeling, Solid Edge, NX (Siemens), SolidWorks und Autodesk Inventor) und verschiedenen neutralen Dateiformaten zu ermöglichen. BricsCAD Communicator ist ein separater Software-Download aus dem BricsCAD-Kernprodukt und wird durch den Erwerb eines Lizenzaktivierungsschlüssels aktiviert.\n\nIm Januar 2018 veröffentlichte Bricsys ein kostenloses Entwurfs- und Modellierungswerkzeug namens BricsCAD Shape , das von BricsCAD Platinum abgeleitet ist und Architekten und Designern eine Modellierungsumgebung für die konzeptionelle Gestaltung von Gebäuden und Strukturen bietet. Die Arbeitsweise von Shape wurde entwickelt, um CAD-genaue, eindeutige Volumenmodelle zu erstellen, ohne dass der Benutzer Gebäudeelemente klassifizieren muss.\nDie Geometrie-Domäne von BricsCAD Shape entspricht der von BricsCAD BIM, und das native Dateiformat beider Produkte ist 2018.dwg. In BricsCAD Shape erstellte 3D-Konzeptmodelle können mit BricsCAD BIM geöffnet und weiterverwendet werden - zur automatischen Klassifizierung von Gebäude-Elementen und deren räumlicher Lage. BricsCAD Shape verfügt über eine vereinfachte Benutzeroberfläche, die die Befehlsoptionen auf ein Minimum reduziert, um eine effektive Volumenkörpermodellierung zu unterstützen BricsCAD Shape enthält auch eine Bibliothek von parametrischen Fenstern und Türen, Materialbibliotheken und eine Auswahl von 3D-Möbeln und -Objekten. \n\nBricsys bietet des Weiteren ein Cloud-Zusammenarbeitstool als SaaS (Software als Service) an, das Bricsys 24/7 genannt wird.\n\nBricsCAD implementiert viele AutoCAD Application Programming Interfaces (APIs). Im Allgemeinen bietet BricsCAD eine nahezu identische Untermenge von AutoCAD-äquivalenten Funktionsnamen. Im Fall von nicht kompilierten AutoCAD-Anwendungen (z. B. LISP, Diesel und DCL) können diese Programme direkt in BricsCAD geladen und ausgeführt werden. Speziell in Bezug auf LISP-Routinen unterstützt BricsCAD AutoCAD Vl-, Vlr-, Vla- und Vlax-Funktionen. Bricsys unterstützt auch Entwickler, die die LISP-Verschlüsselung verwenden möchten, aber wie erwartet, kann BricsCAD AutoCAD FAS (kompilierte LISP) -Dateien nicht lesen.\n\nDie meisten kompilierten Anwendungsprogramme, die für AutoCADs Advanced Runtime eXtension (ObjectARX) entwickelt wurden, erfordern nur eine Neukompilierung mit den BricsCAD Runtime eXtension (BRX) -Bibliotheken. BRX ist zu 100 % mit AutoCAD ARX kompatibel. Bricsys unterstützt auch das veraltete Autodesk-Entwicklungssystem (ADS) über die (ebenfalls veraltete) SDS-Schnittstelle von BricsCAD.\n\nBricsys konzentriert sich auf die Entwicklung der zentralen CAD Softwareplattform und arbeitet mit Anwendungsentwicklungspartnern zusammen, um Lösungen für die Märkte AEC (Architektur, Ingenieurwesen und Bauwesen), GIS und mechanische CAD auf den Markt zu bringen.\n\nDas Unternehmen LEDAS ist ein Teil des BricsCAD-Ökosystems und ist an der Entwicklung spezieller Module für diese Software (einschließlich Geometrievergleichsfunktionen), dem Wiederverkauf der geometrischen Löser LGS 2D und 3D und der Befriedigung von benutzerdefinierten Funktionsanforderungen korporativer BricsCAD-Benutzer beteiligt. LGS 2D und 3D sind Komponenten innerhalb von BricsCAD, die parametrisches Zeichnen/Skizzieren in 2D, 3D-Skizzieren, Oberflächendesign, 3D-Direktmodellierung, 3D-Feature-Modellierung, 3D-Assembly-Design, 3D-Kinematikanalyse und Bewegungssimulation, wissensbasiertes Engineering und Produktoptimierung und vieles mehr ermöglichen. Jetzt bietet Bricsys die Lizenzierung und Einbettung von LGS 2D und LGS 3D in beliebige Endanwendersoftware an. Die Liste der Lizenznehmer umfasst unter anderem ASCON (CAD), Cimatron (CAD/CAM).\n\nSeit 2008 ist die Firma MERViSOFT der deutsche Repräsentant von Bricsys und betreut den gesamten Handel von Bricscad in Deutschland und in der Schweiz.\n\n\n"}
{"id": "6021875", "url": "https://de.wikipedia.org/wiki?curid=6021875", "title": "User Principal Name", "text": "User Principal Name\n\nUser Principal Names (UPN) (zu Deutsch Benutzerprinzipalnamen) können im Kerberos-Authentifizierungs-System, wie es etwa von Microsofts Active Directory benutzt wird, als Alias für den Realm-basierten Benutzernamen konfiguriert werden. Sie erlauben z. B. die bequemere Anmeldung an Windows Computern und Servern auch unter einem Benutzernamen, der eher einer E-Mail-Adresse gleicht, unabhängig von technischen Details wie dem exakten Namen der benutzten Active Directory Domäne. Der UPN ist mit dem Benutzerkonto verknüpft. Das Format des UPN ähnelt typischerweise einer RFC 822 E-Mail-Adresse.\n\nEin Kerberos-Prinzipalname besteht aus zwei Teilen, dem Anmeldenamen des Benutzers (z. B. \"michael\") und dem Benutzerprinzipalnamen-Suffix (User Principal Name Suffix, UPN-Suffix). Getrennt werden beide Teile beim Windows-Login durch ein \"@\"-Zeichen (also hier z. B. \"michael@beispielfirma.xy\"). Das Benutzerprinzipalnamen-Suffix ist ein Alias für längere Domänennamen, um übersichtlicher und kürzer zu sein (z. B. nur \"beispielfirma.xy\" anstatt von \"kundenbetreuung.koeln.deutschland.beispielfirma.xy\"), bzw. um bei mehreren Domänen nur einen, griffigen Namen zu vergeben, der für alle Domänen gilt. Sie werden in der Active-Directory-Verwaltung unter den Eigenschaften von \"Active-Directory-Domänen und -Vertrauensstellungen\" eingegeben.\n\n\n"}
{"id": "6025748", "url": "https://de.wikipedia.org/wiki?curid=6025748", "title": "Arthur und die Minimoys 3 – Die große Entscheidung", "text": "Arthur und die Minimoys 3 – Die große Entscheidung\n\nArthur und die Minimoys 3 – Die große Entscheidung (Originaltitel: \"Arthur et la Guerre des deux mondes\") ist ein französischer Spielfilm von Luc Besson aus dem Jahr 2010. Die Fortsetzung von \"Arthur und die Minimoys\" und \"Arthur und die Minimoys 2 – Die Rückkehr des bösen M.\" ist eine Mischung aus Realfilm und Computeranimation.\n\nNachdem der zweite Film damit endete, dass Maltazard – der böse M – aus der Welt der Minimoys in Arthurs Welt gelangt ist, beginnt der dritte Film mit den größenwahnsinnigen Plänen des nun in Menschengröße umherwandelnden bösen M. Er will mit Hilfe seiner neu aufgestellten Armee aus riesigen Insekten erst die Erde und dann das ganze Universum erobern.\n\nArthur weilt unterdessen noch in der Welt der Minimoys unter dem Haus und dem Garten seines Großvaters Archibald, zusammen mit seiner großen Liebe Prinzessin Selenia und ihrem Bruder Beta. Da das Fernrohr, Arthurs Weg aus der Welt der Minimoys, zerstört ist, muss er nun einen anderen Weg zurück in seine Welt finden. Dieser Weg findet sich in einem geheimnisvollen Elixier seiner Großmutter, das irgendwo im Haus versteckt ist. Arthur macht sich mit Hilfe der Prinzessin Selenia und Beta auf eine lange Suche.\n\nWie bereits in den beiden vorhergehenden Filmen spielt die Handlung zum Teil im US-amerikanischen Connecticut der 1960er Jahre sowie in der unterirdischen Welt der Minimoys. Nach der Premiere am 13. Oktober 2010 in Paris erschien der Film in Deutschland am 15. April 2011 direkt auf DVD.\n\nDas \"Lexikon des internationalen Films\" befand, dass der dritte Teil „[z]war wirkungsvoller als der zweite Teil“ sei, jedoch „die Mischung aus Real- und Zeichentrickfilm dennoch nur belanglose Unterhaltung mit Spezialeffekten“ biete.\n\n"}
{"id": "6031247", "url": "https://de.wikipedia.org/wiki?curid=6031247", "title": "Rango (Film)", "text": "Rango (Film)\n\nRango ist ein computeranimierter Kinofilm von Gore Verbinski aus dem Jahr 2011. Der offizielle Kinostart in Deutschland und Österreich war am 3. März 2011, in den USA am 4. März 2011. Die Produktion wurde 2012 mit dem Oscar der Kategorie bester animierter Spielfilm ausgezeichnet.\n\nEin Chamäleon lebt als Haustier in einem Terrarium, sein Umfeld besteht aus einer Plastikpalme, einem Plastikfisch und dem Torso einer Barbiepuppe, mit denen er ein Theaterstück inszeniert. Als sein Terrarium mit dem Auto transportiert wird, fällt er bei einem Ausweichmanöver heraus. Auf der Straße trifft er das Gürteltier \"Roadkill\", Auslöser des Manövers. Zusammen fliehen sie vor weiteren Autos neben die Straße, wo ihm Roadkill vom \"Geist des Westens\" erzählt, der auf der anderen Straßenseite anzutreffen sei, und ihm den Weg zur nächsten Stadt weist, in der es Wasser geben soll.\n\nDas Chamäleon macht sich auf den Weg, wird unterwegs von einem Habicht angegriffen und übernachtet in einem Rohr, aus dem es nach einigen wirren Träumen herausgespült wird. Es trifft auf die Wüstenleguanin \"Bohne\", die ihn mit einem Gewehr bedroht. Jemand lässt in der Wüste Wasser versickern, um an das Land ihrer Familie zu kommen. Schließlich nimmt sie das Chamäleon mit in die Stadt „Dreck“ (im Original „Dirt“). Hier verkaufen und verlassen die Einwohner ihr Land, da es kein Wasser mehr gibt. Als Fremdling wird es von den Gästen des Saloons misstrauisch beäugt. Nun kann er ein Held sein, wie er es sich schon lange gewünscht hat. Es gibt sich den Namen „Rango“, gibt sich als furchtloser Revolverheld aus und legt sich gleich mit einem Einwohner der Stadt an. Beim Duell taucht plötzlich der Habicht auf und stürzt sich auf Rango. Nach einer wilden Verfolgungsjagd löst sich ein Schuss aus der Waffe Rangos und lässt einen Wasserturm auf den Vogel stürzen. Rango gilt von nun als Held, da er den Raubvogel mit nur einem Schuss erledigt hat, und wird vom Bürgermeister zum Sheriff ernannt.\n\nAn seinem ersten Tag als Sheriff sieht Rango, wie die Bewohner der Stadt erfolglos Wasser aus dem Wasserhahn holen wollen. Im folgenden Tumult, in dem unter anderem Rango die Schuld an der Dürre gegeben wird, offenbart Bohne unbeabsichtigt den Dorfbewohnern, dass es in der Bank von Dreck, in dessen Tresorraum ihre Bewohner statt Geld ihre Wasservorräte lagern, kaum noch Wasser gibt. Bestürzt stürmt die Menge daraufhin zur Bank und verlangt ihr Wasser zurück, doch es gelingt Rango, die Situation zu beruhigen. Am Abend tauchen aus einem Tunnel mitten unter der Hauptstraße Balthazar, ein Nacktmull, und seine Präriehunde auf. Diese wollten sich eigentlich bis unter die Bank graben, um diese auszurauben. Rango aber überhört das, schafft ihnen Ausrüstung herbei und stellt ihnen auch noch eine Bergbaugenehmigung aus.\n\nAm nächsten Morgen ist die Bank leergeräumt. Rango versammelt die Bürger, stellt einen Suchtrupp zusammen und begibt sich in die Tunnel auf die Spur der Verbrecher. Wieder an der Oberfläche finden sie den Bankdirektor, der mitten in der Wüste ertränkt wurde. Sie verfolgen die Spuren weiter und finden schließlich Balthazars Bande, die die geraubte Wasserflasche auf einem Planwagen in ihr Versteck bringen wollen. Rango und seine Leute verkleiden sich als Zirkus und führen sein Theaterstück vor den drei Bankräubern auf, um sie dann zu verhaften. Doch in diesem Moment tauchen hunderte Präriehunde auf und drohen, die Bürger zu überwältigen. Verfolgt von unzähligen auf Fledermäusen reitenden Präriehunden liefern sie sich eine Verfolgungsjagd, ehe der Wagen mit der Wasserflasche umkippt und einen Hügel hinab rollt. Dabei zeigt sich, dass eine leere Wasserflasche gestohlen wurde.\n\nZurück in Dreck werden die erfolglosen Helden von den enttäuschten Einwohnern erwartet, die versuchen die verhafteten Präriehunde zu lynchen. Rango stellt sich ihnen entgegen, weil er vermutet, dass der Bürgermeister hinter dem Wassermangel steckt. Sobald alles Land dem Bürgermeister gehört, will dieser eine neue Stadt bauen, wie sie bereits auf der anderen Seite der Schnellstraße existiert. Als Rango ihm droht, diese Pläne zu durchkreuzen, lässt der Bürgermeister \"Klapperschlangen-Jake\" holen, um den immer lästiger werdenden Sheriff endlich loszuwerden. Klapperschlangen-Jake stellt Rango erst einmal vor der versammelten Stadt bloß, die erfährt, dass er gar kein Revolverheld ist und auch nicht so mutig, wie er sich gibt.\n\nRango verlässt die Stadt, kehrt zur Straße zurück und überquert sie unbeschadet, bevor er in Ohnmacht fällt. Als er wieder zu sich kommt, steht vor ihm ein Golfwagen mit mehreren goldenen Figuren darin, davor ein Mensch im Poncho, der „Geist des Westens“, der Rango den Mut gibt, seine Mission zu Ende zu bringen. Mithilfe wandernder Kakteen findet Rango heraus, dass das Wasser der Wüste nach Las Vegas fließt, und die Leute des Bürgermeisters die Leitung abgedreht haben, die einst auch die Stadt Dreck mit Wasser versorgte. Rango kehrt zurück nach Dreck und bittet die Präriehunde um Hilfe, weil sie nur mit ihm gemeinsam ihren Vater vor dem Galgen retten können. Die Präriehunde graben das Rohr aus und brechen es an einer Stelle. In der Zwischenzeit versucht der Bürgermeister, auch Bohne zum Verkauf ihres Lands zu zwingen. Als sie sich weigert, wird sie von Jake beinahe erwürgt, doch als Rango ihn zum Duell fordert, lässt er von ihr ab.\n\nGemeinsam mit den Präriehunden, Roadkill und den wandernden Kakteen kann Rango die Schlange überlisten und das Wasser wieder in die Stadt leiten. Einen kurzen Moment lang wirkt es, als wäre Jake von Rango besiegt worden.\n\nDoch der Bürgermeister hat noch immer Bohne in seiner Gewalt. Gemeinsam mit Bohne wird Rango in den Tresorraum der Bank eingesperrt, der sich langsam mit Wasser füllt. Hier wird Rango von Bohne geküsst, wobei sie seine letzte Pistolenkugel verschluckt, die er im Mund hielt, und daraufhin einen ihrer Anfälle bekommt, bei dem die Echse als Schutzreflex erstarrt.\n\nIm gleichen Moment spitzt sich der Konflikt außerhalb der Flasche zu, als der Bürgermeister nun auch Klapperschlangen-Jake aus dem Weg räumen will.\nKurz bevor dies geschieht und Rango sowie Bohne schon fast zu ertrinken drohen, gelingt Rango das Heimlich-Manöver, und die von Bohne wieder ausgespuckte Kugel trifft die Glasscheibe des Tresors, die das Glas unter dem Druck des Wassers zum Bersten bringt. Der Bürgermeister, seine Schergen sowie Jake werden weggespült.\n\nDer Bürgermeister versucht ein letztes Mal Rango auf seine Seite zu ziehen, doch dieser überlässt ihn der Klapperschlange. Jake erweist Rango seinen Respekt und verlässt mit dem Bürgermeister im Schlepptau die Stadt, um mit diesem abzurechnen. Rango hat die Stadt gerettet und Bohnes Herz erobert.\n\nDer Film wurde von \"Nickelodeon Movies\", \"Blind Wink\" und \"GK Films\" produziert. Die CGI-Animationen wurden von \"Industrial Light & Magic\" (ILM) erstellt – einer Firma, die eigentlich auf Spezialeffekte spezialisiert ist. Gore Verbinski hatte zuvor das Angebot, bei einem weiteren „Pirates of the Caribbean“-Film Regie zu führen, abgelehnt und dem Animationsprojekt den Vorzug gegeben.\n\nDamit sich die Sprecher in ihre Rollen und den Film hineinfühlen konnten, wurden für sie Kostüme und Sets angefertigt. Da Johnny Depp nur zwanzig Tage Zeit hatte, wurden fast alle Sprachaufnahmen innerhalb eines Monats abgeschlossen.\n\nDer Film feierte seine Premiere am 14. Februar 2011 in Westwood. Am 20. Februar 2011 wurde der Film in Berlin gezeigt. Der offizielle Kinostart erfolgte in Deutschland und Österreich am 3. März 2011, einen Tag später lief er in den US-amerikanischen Kinos an. In der Schweiz war der Film ab dem 6. April 2011 zu sehen.\n\nBei einem Budget von 135 Millionen US-Dollar spielte der Film weltweit umgerechnet 222,5 Millionen US-Dollar ein, davon über 123 Millionen US-Dollar in den USA.\n\nDie deutsche Synchronbearbeitung entstand bei der Berliner Synchron AG in Berlin. Das Dialogbuch verfasste Alexander Löwe, Synchronregie führte Frank Schaff.\n\nIn \"Rango\" werden Einflüsse des Kriminalfilms \"Chinatown\" von 1974 auch im Bereich einer Hommage gesehen. Mit Anleihen bei diversen Sergio-Leone-Filme sei es Verbinski gelungen, einen „hinreißend komischen Animationswestern“ zu drehen. Von Filmkritikern wurde der Film des häufigeren als computeranimierte Fortsetzung von \"Fear and Loathing in Las Vegas\" bezeichnet. Der Film enthält weitere Anlehnungen an Italo-Western wie \"Für eine Handvoll Dollar\". Zudem sei der Charakter des Jake nach Meinung von James Berardinelli dem Schauspieler Lee Van Cleef nachempfunden.\n\n\nParallel zum Film wurde im Februar 2011 von \"Electronic Arts\" ein Videospiel zum Film veröffentlicht. \"Rango – das Videospiel\" ist für PlayStation 3, Xbox 360, Wii und Nintendo DS erhältlich.\n\n"}
{"id": "6033466", "url": "https://de.wikipedia.org/wiki?curid=6033466", "title": "Rubberhose", "text": "Rubberhose\n\nRubberhose ist ein kryptografisches Archivsystem, das zum Zweck der glaubhaften Abstreitbarkeit entwickelt wurde. Es kann mehrere separat verschlüsselte Dateisysteme (sogenannte „aspects“) enthalten, wobei deren Existenz nur nachgewiesen werden kann, wenn man den korrekten kryptografischen Schlüssel besitzt.\n\nDer Name „Rubberhose“ (deutsch: „Gummischlauch“) bezieht sich auf den euphemistischen Begriff der „Gummischlauch-Kryptoanalyse“, der die Erlangung kryptographischer Schlüssel mittels Folter bezeichnet.\n\nDie Software wurde ursprünglich für Menschenrechtsgruppen in Diktaturen der Dritten Welt entwickelt, wurde aber auch oft für die Benutzung in anderen Ländern wie zum Beispiel dem Vereinigten Königreich empfohlen, weil man dort nach dem britischen Telekommunikationsüberwachungsgesetz unter Androhung von Gefängnisstrafe gezwungen werden kann, seine Passwörter beziehungsweise kryptografischen Schlüssel preiszugeben.\n\nEs wurde im Quelltext veröffentlicht und zur kostenlosen Nutzung für nicht kommerzielle, für akademische oder auch humanitäre Zwecke freigegeben.\n\nDas Projekt wurde 1997 von Julian Assange gestartet und ab 1999 zusammen mit Suelette Dreyfus und Ralf Weinmann entwickelt.\nRubberhose wird nicht mehr weiterentwickelt, ist aber für Linux-Kernel 2.2, NetBSD und FreeBSD verfügbar. Die im Oktober 2000 erschienene letzte verfügbare Version 0.8.3 hat immer noch den Alpha-Status.\nSeit Mitte 2004 ist auch die ursprüngliche Projekt-Website unter rubberhose.org nicht mehr verfügbar.\nDas Konzept wurde bei TrueCrypt aufgegriffen, das mit seinen sogenannten „versteckten Volumes“ und „versteckten Betriebssystemen“ Ähnliches und Weitergehendes bietet.\n"}
{"id": "6035420", "url": "https://de.wikipedia.org/wiki?curid=6035420", "title": "La dama y la muerte", "text": "La dama y la muerte\n\nLa dama y la muerte ( \"Die Frau und der Tod\") ist ein spanischer animierter 3D-Kurzfilm von Javier Recio Gracia aus dem Jahr 2009.\n\nEine alte Frau betrachtet das Bild ihres verstorbenen Ehemanns und legt sich mit dem Bild im Arm schlafen. Sie stirbt und ihr Geist wird bereits vom Tod aus dem Zimmer geführt, als die Frau plötzlich von einem Arzt wieder ins Leben zurückgeholt wird. Der Tod schaut verdutzt und geht zum Angriff über: Abwechselnd versuchen Arzt und Tod, die Frau für sich zu gewinnen, die eigentlich sterben möchte. Am Ende des bizarren Kampfs gibt der Tod auf und der Arzt und die Krankenschwestern sind erschöpft. Die alte Frau jedoch lässt beide Streitparteien frustriert allein, schiebt einen Defibrillator ins Zimmer neben dem Behandlungsraum, lässt Wasser in eine Wanne ein und bringt sich anschließend mit einem Elektrischen Schlag um.\n\nIm Abspann ist der Tod zu sehen, der gerade nach Hause kommt, und auf seinem Pager die Nachricht von der „Ankunft“ der alten Frau erhält. Wütend wirft er das Gerät fort.\n\nDer computeranimierte 3D-Kurzfilm \"La dama y la muerte\" entstand zwischen 2007 und 2009. Der Film erlebte am 31. Oktober 2009 auf dem Festival Internacional de Jóvenes Realizadores de Granada seine Premiere. In Spanien lief der \"La dama y la muerte\" unter anderem als Vorfilm zu \"Alice im Wunderland\" und \"Toy Story 3\".\n\nIm Film ist mehrfach der Titel \"We’ll Meet Again\" zu hören: Er wird sowohl von Vera Lynn als auch von The Turtles interpretiert.\n\n\"La dama y la muerte\" wurde 2010 für einen Oscar in der Kategorie „Bester animierter Kurzfilm“ nominiert, konnte sich jedoch nicht gegen \"Logorama\" durchsetzen. Es war die erste Oscarnominierung für einen spanischen Trickfilm in der Geschichte der Oscars.\n\nIm Februar 2010 gewann der Film den Goya in der Kategorie „Bester animierter Kurzfilm“ („Mejor Cortometraje de Animación“).\n\n"}
{"id": "6041117", "url": "https://de.wikipedia.org/wiki?curid=6041117", "title": "Schnelltaste", "text": "Schnelltaste\n\nSchnelltasten sind Tasten auf einer Tastatur oder anderen Eingabegeräten für Computer oder Geräte, die mit vordefinierten, häufig benötigten Funktionen belegt sind. Die Zuordnung ist unabhängig von laufenden Applikationen, so dass z. B. bei geöffneter Textverarbeitung die im Hintergrund laufende Audiowiedergabe gesteuert werden kann.\n\nBeispiele aus dem PC-Bereich sind:\n\nÄhnliche Funktionen erfüllen auch Funktionstasten (beim PC in der Regel F1 bis F12). Diese werden jedoch vom jeweiligen Programm individuell mit Funktionen belegt.\n"}
{"id": "6043089", "url": "https://de.wikipedia.org/wiki?curid=6043089", "title": "Gnomeo und Julia", "text": "Gnomeo und Julia\n\nGnomeo und Julia ist ein US-amerikanisch-britischer Computeranimationsfilm aus dem Jahr 2011, der lose auf der Tragödie Romeo und Julia von William Shakespeare aufbaut.\n\nDie miteinander verfeindeten Mrs. Montague und Mr. Capulet bewohnen je einen Teil eines älteren Herrschaftshauses, dessen eine Hälfte in Rot und die andere Hälfte in Blau gehalten ist. Wenn sie ihre Häuserhälften verlassen, erwachen die beiden Gärten und deren jeweilige, natürlich auch verfeindeten roten und blauen Gartenzwerge und anderen Figuren zum Leben.\n\nBei einem Rasenmäherrennen kämpfen der blaue Gartenzwerg Gnomeo gegen den roten Zwerg Tybalt. Obwohl es während des Rennens so aussieht, als würde Gnomeo gewinnen, gewinnt Tybalt, indem er Gnomeos Rasenmäher zerstört. Als sich Gnomeo später gemeinsam mit seinem besten Freund Benny an den Roten rächen will, indem sie Tybalts Rasenmäher mit Farbe besprühen, löst Benny eine Sicherheitsvorkehrung aus, die dazu führt, dass alle roten Zwerge alarmiert werden und die beiden angreifen. Sie können fliehen und Gnomeo landet in einem fremden Garten. Dort lernt er Graf Zinnoberrots Tochter Julia kennen. Beide versuchen an eine Orchidee zu gelangen, um den Garten zu verschönern. Dabei verlieben sie sich ineinander und während sie jeweils vom anderen die Orchidee nehmen wollen, entdecken sie, dass sie aus verfeindeten Clans stammen.\n\nAls beide jeweils in ihrem Garten sind, erzählt Julia ihrer besten Freundin Nanette von ihrer überraschenden Begegnung. Dann haben Gnomeo und Julia ein geheimes Treffen in einem anderen Garten, wo sie den Gartenflamingo Featherstone kennenlernen, der sie unterstützt und ihre Liebe fördert. Als Gnomeo nach diesem Treffen wieder in seinen Garten kommt, sieht er seine verzweifelte Mutter, die die zerstörte Pflanze seines verstorbenen Vaters betrauert. Während Gnomeo weg war, drangen Rote in den Garten ein und verwüsteten diesen.\n\nDaraufhin wollen die Blauen Rache und Gnomeo erkennt, dass er nicht ablehnen kann, solange er sein Geheimnis nicht offenbart. Durch einen Tunnel erreicht er den roten Garten und will gerade die preisgekrönte Blumen der Roten besprühen, als er von seiner Julia entdeckt wird. Er flüchtet und erzählt Benny, dass er sein Attentat wegen einer defekten Sprühflasche nicht durchführen konnte. Als sich Gnomeo und Julia danach treffen, fangen sie einen Streit an, der nur von Featherstone mit den Worten unterbrochen wird, dass anderer Leute Hass ihre Liebe zerstöre. Sie entschuldigen sich beieinander und wollen sich gerade küssen. Allerdings werden sie von Benny abgelenkt, der sie dabei beobachtet und daraufhin flüchtet. Er läuft in eine Gasse und wird von Tybalt mit dessen Rasenmäher überrascht, der ihn damit auch gleich überfährt und dessen Zipfelmütze abschlägt. Gnomeo kommt zu Hilfe geeilt und kämpft mit Tybalt auf dessen Rasenmäher, bis dieser in eine Mauer kracht, wobei Tybalt zersplittert. Fawn zielt darauf mit einigen Steinen auf Gnomeo, während überraschenderweise Julia Gnomeo zur Hilfe eilt und ihn mit den Worten, dass sie ihn liebe, vor ihrer Familie beschützen will. Plötzlich kommt eine Joggerin vorbei und alle Gartenzwerge erstarren zu leblosen Objekten, während Gnomeo auf die angrenzende Straße gerät und zwischen den fahrenden Autos umherschleudert.\n\nNachdem die Joggerin weitergelaufen ist, glauben alle angesichts eines Scherbenhaufens auf der Straße, dass Gnomeo von einem Auto überfahren wurde. Julias Vater sieht den Schmerz seiner Tochter und klebt sie deswegen an einen Brunnen, weil er sie nicht genauso verlieren will wie ihre Mutter. Doch Gnomeo konnte überleben, indem er auf einen Truck kletterte. Die Fahrt endet in einem Park und Gnomeo klettert auf die Statue von William Shakespeare, dem er seine ganze Geschichte erzählt. Dieser antwortet ihm, dass es sich fast genauso anhöre wie seine eigene Geschichte Romeo und Julia und dass Gnomeo wohl auch ein trauriges Ende erleben werde.\n\nUnterdessen kauft Benny online einen noch größeren Rasenmäher, um sich an den roten Gartenzwergen zu rächen. Doch dies geht im Endeffekt daneben, da er das meiste der beiden Gärten zerstört. Währenddessen hat es Gnomeo geschafft zurückzukehren und versucht, Julia vom Brunnen zu befreien, doch er scheitert. Sie fordert ihn auf zu gehen, doch er weigert sich und küsst sie. In diesem Moment kracht Bennys Rasenmäher in den Brunnen, zerstört ihn und befreit Julia. Alle glauben, dass Gnomeo und Julia nicht überlebt haben. Graf Zinnoberrot und Gräfin Blaublut realisieren, dass ihre Fehde für diese Katastrophe verantwortlich ist und beschließen einen Waffenstillstand. Da steigen beide unverletzt aus den Trümmern.\n\nDer Film endet mit der Heirat von Gnomeo und Julia.\n\nNachdem der Film bereits am 23. Januar 2010 seine Weltpremiere feierte, war sein offizieller US-amerikanischer Kinostart am 11. Februar 2011. Seitdem konnte er weltweit 189 Mio. US-Dollar, davon 99,96 Mio. US-Dollar in den USA einspielen. In Deutschland startete er am 24. März 2011 und wurde von 399.839 Kinobesuchern gesehen. Die DVD-Veröffentlichung war anschließend am 4. August 2011.\n\n\nIm Film gibt es zusätzlich zu Romeo und Julia, auf dem der Film basiert, einige Anspielungen auf Shakespeares Stücke. So befindet sich auf der Pinnwand im alten Gartenschuppen eine Eintrittskarte zur Komödie Was ihr wollt. Die Umzugsfirma wird von Rosenkranz und Güldenstern betrieben, zwei Figuren aus Hamlet. Julia wird mit speziellem Kleber auf ihrem Sockel festgeklebt. Der Kleber wird Kleber der Zähmung genannt, eine Anspielung auf Der Widerspenstigen Zähmung. Die Hausnummern der verfeindeten Nachbarn sind \"2B\" und \"Not 2B\" - eine Anspielung auf \"\"To be or not to be\"\". Auch kommt Shakespeare selbst zu Wort, seine Statue erzählt Gnomeo das tragische Ende von Romeo und Julia. Außerdem spielt der Film in Stratford-upon-Avon, wo Shakespeare geboren wurde, lebte und auch starb.\n\nDer pinke Gartenflamingo heißt Featherstone - eine Anspielung auf Donald Featherstone, den Erfinder der Gartenflamingos, die in vielen Gegenden der USA ein beliebter Vorgartenschmuck sind.\n\n2018 erschien die Fortsetzung \"Sherlock Gnomes\", die inhaltlich und stilistisch jedoch nur wenig mit dem ersten Film gemeinsam hat und deutlich negativere Kritiken bekam.\n\n"}
{"id": "6044408", "url": "https://de.wikipedia.org/wiki?curid=6044408", "title": "Barbie in Schwanensee", "text": "Barbie in Schwanensee\n\nBarbie in Schwanensee (Originaltitel \"Barbie of Swan Lake\") ist ein US-amerikanischer Animationsfilm aus dem Jahr 2003. Es handelt sich um eine Direct-to-Video-Produktion von Mainframe Entertainment in Kooperation mit Mattel Entertainment, Regie führte Owen Hurley.\n\nOdette, Tochter eines Bäckers, folgt einem Einhorn in einen Zauberwald, in der sich die Feenkönigin und ihr Cousin, der böse Zauberer Rothbart, um die Herrschaft streiten. Rothbart verwandelt Odette bei ihrer ersten Begegnung in einen Schwan. Die Feenkönigin mildert den Fluch, sodass Odette in der Nacht ihre menschliche Gestalt zurückerhält. Die ebenfalls verzauberten Bewohner des Waldes glauben, dass Odette diejenige ist, der es gemäß einer Prophezeiung mit Hilfe eines magischen Kristalls gelingen wird, ihre Welt von dem bösen Zauber zu befreien. Gemeinsam mit dem Einhorn Lila und dem Troll Erasmus lüftet Odette das Geheimnis des Kristalls. Als sich Daniel, der Prinz ihres Heimatlandes, in den magischen Wald verirrt, verliebt er sich in Odette. Der Zauber Rothbarts kann nur gebrochen werden, wenn der Prinz der Trägerin des Kristalls seine ewige Liebe schwört. Mit einer List gelingt es Rothbart, dass Prinz Daniel seiner Tochter Odile diesen Schwur leistet, weil er sie für Odette hält. Durch den falschen Schwur löst sich auch der Zauber über Odette, die ihre menschliche Gestalt zurückerhält und mit der Feenkönigin und ihrem Gefolge in den Zauberwald flüchtet. Dort kommt es zu einem Kampf zwischen Rothbart, Odette und dem zu Hilfe eilenden Prinz Daniel, bei dem der Zauberer durch die Kraft des Kristalls besiegt werden kann.\n\nDer Film ist der dritte Teil einer Reihe von Filmen mit der Barbie-Puppe als animierte Figur. Die Musik stammt aus dem Ballett \"Schwanensee\" von Pjotr Iljitsch Tschaikowski, gespielt vom London Symphony Orchestra. Die animierten Tanzszenen beruhen auf Bewegungen von Tänzern des New York City Ballet.So sind der Schwarze Schwan Pas de Deux (Adagio), Spanischer Tanz, Ungarischer Tanz, Neapolitanischer Tanz und der Tanz der vier kleinen Schwäne zu sehen. Es gibt auch Tanzsequenzen zu der Musik der Walzer aus dem 1. und 2. Akt.\n\nDie Synchronisation des Films wurde bei der Deutsche Synchron nach einem Dialogbuch und unter der Dialogregie von Beate Gerlach erstellt.\n"}
{"id": "6045532", "url": "https://de.wikipedia.org/wiki?curid=6045532", "title": "MEDINA (Software)", "text": "MEDINA (Software)\n\nMEDINA (kurz für \"Model EDitor Interactive for Numerical Simulation Analysis\") ist ein universeller Pre-/Postprozessor für FEM-Simulationsrechnungen.\n\nDie Entwicklung von MEDINA begann Anfang der 1990er Jahre bei der Daimler-Benz AG, wurde dann beim debis Systemhaus fortgesetzt und erfolgt seit 2001 durch T-Systems International GmbH.\nDer aktuelle Releasestand ist MEDINA 8.2.\n\nMEDINA wurde als universeller Pre-/Postprozessor konzipiert und entwickelt, der Funktionalitäten für die verschiedensten Aufgabengebiete der FEM-Simulation bietet und die meisten der gängigen CAD-Formate, Solver und Betriebssysteme unterstützt.\n\nDie unterstützten 3D-Datenformate sind derzeit (MEDINA Rel. 8.2): CATIA, IGES, JT, SAT (ACIS), STEP, STL und VDA-FS.\n\nMit der 3D-Datenkonvertierungslösung COM/FOX der T-Systems können weitere Formate eingebunden werden.\n\nZu den unterstützten Solvern zählen derzeit (MEDINA Rel. 8.2) vor allem: ABAQUS, LS-DYNA, NASTRAN, PAMCRASH, PERMAS.\n\nMEDINA kann derzeit auf den folgenden Betriebssystemen und Hardwarearchitekturen betrieben werden: Linux, Microsoft Windows, IBM / AIX, Hewlett Packard / HP-UX, Silicon Graphics / IRIX, SUN / SunOS.\n\nTypischerweise wird MEDINA für die folgenden FEM-Aufgaben eingesetzt: Crashsimulationen, Betriebsfestigkeitsuntersuchungen (thermische und mechanische Belastungen), Schwingungs- und Geräuschuntersuchungen NVH (Noise Vibration Harshness), Untersuchungen zum Fußgänger- und Insassenschutz.\n\nMEDINA besteht aus zwei Modulen: dem FEM-Preprozessor (MEDINA.Pre) und dem FEM-Postprozessor (MEDINA.Post).\nIm Preprozessor werden alle notwendigen Schritte vorgenommen, um eine FEM-Rechnung starten zu können.\nHierzu gehören Funktionalitäten, wie:\n\n\nIm Postprozessor erfolgen alle Schritte zur Aufbereitung der vom Solver berechneten Daten (auch oftmals Primärdaten genannt).\nHierzu gehören Funktionalitäten, wie:\n\n\nMEDINA wurde in besonderen Maßen darauf ausgelegt, komplexe Simulationsrechnungen und die Bearbeitung großer FEM-Modelle, wie sie beispielsweise in der Automobilindustrie und der Luft- und Raumfahrt üblich sind, bedarfsgerecht und performant zu unterstützen.\n\nEine wesentliche Bedeutung kommt hierbei den sogenannten Partsstrukturen und Konnektorelementen zu.\nPartsstrukturen ermöglichen es, die im CAD-/PDM-System verwendeten Produktstrukturen exakt im FEM-Modell abzubilden.\nDie Konnektorelemente dienen zur generischen Modellierung sowie solver- und kundenspezifische Ausgestaltung der meisten gebräuchlichen Verbindungstechniken (wie Verschweißungen, Verschraubungen, Verklebungen).\nIm Prozessschritt der sogenannten Assemblierung werden die FEM-Komponenten (Partsstrukturen und Verbindungselemente) zu einem komplexen FEM-Gesamtmodell zusammengesetzt.\nAnhand dieses FEM-Gesamtmodells lässt sich das physikalische Verhalten komplexer Produkte, wie bspw. Automobile oder Flugzeuge, untersuchen.\n\nMit Hilfe von Protokollen und Skripten lassen sich einzelne Prozessschritte und ganze Prozessketten des Pre- und Postprocessings automatisieren. Über sogenannte dynamische Kommandos ist es möglich, die Standardfunktionalitäten um kundenspezifische Erweiterungen\nauszubauen.\n\nAufgrund der Entwicklungshistorie von MEDINA sowie der vorhandenen Funktionalitäten zur Bearbeitung sehr großer Modelle ist MEDINA vor allem in der Automobilindustrie weit verbreitet. Zu den weiteren Nutzergruppen zählen die Bereiche Luft- und Raumfahrt, die Fertigungsindustrie, Ingenieurbüros und Universitäten.\n\n"}
{"id": "6045644", "url": "https://de.wikipedia.org/wiki?curid=6045644", "title": "Barbie – Modezauber in Paris", "text": "Barbie – Modezauber in Paris\n\nBarbie – Modezauber in Paris (Originaltitel \"Barbie: A Fashion Fairy Tale\") ist ein US-amerikanischer Animationsfilm aus dem Jahr 2010. Es handelt sich um eine Direct-to-DVD-Produktion von Rainmaker Entertainment in Kooperation mit Mattel Entertainment, Regie führte William Lau. Vertrieben wird der Film von Universal Pictures.\n\nBarbie ist eine erfolgreiche Schauspielerin. Während eines Filmdrehs kommt es zum Streit mit dem Regisseur, der Barbie daraufhin feuert. Als sie einen Anruf von ihrem Freund Ken erhält, erzählt dieser ihr, dass er die Beziehung beenden will. Daraufhin packt Barbie ihre Koffer und reist nach Paris, um ihre Tante Millicent zu besuchen, die dort ein Modehaus betreibt. Dort angekommen, muss jedoch Barbie feststellen, dass es von der Schließung bedroht ist und ihre Tante es daher bereits verkauft hat. \n\nWährenddessen stellt sich heraus, dass der Anruf nicht von Ken stammte, sondern von ihrer Gegenspielerin Raquelle gefälscht wurde. Ken beschließt, Barbie nach Paris hinterherzureisen, um die Sache aufzuklären. Mit Hilfe der drei Glitzerfeen Shyne, Shimmer und Glimmer entwirft Barbie gemeinsam mit der schüchternen Designerin Alice und ihrer Tante eine neue Kollektion und stellt sie mit Erfolg bei einer Modenschau vor. Ihre Tante erhält den Auftrag, 10.000 Kleider anzufertigen, und kann von den Einnahmen das Modehaus zurückkaufen. Auch Ken trifft in der Zwischenzeit in Paris ein und kann das Missverständnis aufklären.\n\nDer Film ist der bislang 18. Teil einer Reihe von Filmen mit der Barbie-Puppe als animierte Figur. Er erschien im deutschsprachigen Raum am 16. September 2010 ausschließlich auf DVD, die deutsche Erstausstrahlung war am 9. Oktober 2010 beim Fernsehsender Super RTL.\n\nDie deutsche Synchronbearbeitung fertigte das Synchronstudio SDI Media an. Das Dialogbuch stammt von Nana Spier, welche auch für die Synchronregie zuständig war.\n\n"}
{"id": "6052646", "url": "https://de.wikipedia.org/wiki?curid=6052646", "title": "Apple A5", "text": "Apple A5\n\nApple A5 ist der Markenname vier verschiedener System-on-a-Chips, die von Apple in mehreren iOS-Geräten verwendet werden. Sie werden alle von Samsung hergestellt. Die A5-Chips kombinieren einen ARM-Hauptprozessor des Typs Cortex A9 mit einem PowerVR-Grafikprozessor und übernehmen zudem die Funktionen eines herkömmlichen PC-Chipsatzes. Oftmals wird die Bezeichnung Apple A5 bzw. A5X alleine für den ARM-Prozessor verwendet, dies ist aber nicht richtig. Der A5 gehört zu den S5L SoCs.\n\nDer erste A5-Chip wurde im März 2011 als Teil des iPad 2 vorgestellt. Diese Variante kommt neben dem iPad 2 nur im iPhone 4s vor. Weitere Revisionen wurden in nachfolgenden Apple-Geräten verbaut.\n\nVorgänger des A5 ist der Apple A4, Nachfolger ist der Apple A6.\n\nEs gibt insgesamt vier verschiedene Revisionen des A5-Chips. Jede Revision hat 32 KiB Daten- und 32 KiB Instruktionscache, hinzu kommen noch 1024 KiB Level-2-Cache. Alle A5-Chips beherrschen den ARMv7-Befehlssatz.\n\nDer Apple A5 kommt in insgesamt drei verschiedenen Versionen vor, die zwischen März 2011 und Anfang 2013 vorgestellt wurden. Er wird in folgenden Produkten eingesetzt:\n\nDer erste A5-Chip S5L8940 wurde am 2. März 2011 als Teil des iPad 2 vorgestellt. Er verfügt über 512 MB SDRAM-Speicher und zwei ARM-Cortex A9-Prozessorkerne. Die Taktfrequenz ist variabel und wird durch iOS den Anforderungen an das Gerät angeglichen. Der Kerntakt des ARM Cortex A9 beträgt normalerweise 1,2 GHz, wurde jedoch von Apple herabgesetzt. So beläuft sich der Standardtakt beider Kerne im iPad 2 auf 1 GHz, beim iPhone 4s auf 800 MHz. Benchmarks zeigen eine Leistungssteigerung von mindestens 56 % gegenüber dem ebenfalls mit 1 GHz getaktetem A4-SoC im iPad der ersten Generation. Der erste A5 wird im 45-nm-Verfahren hergestellt. Bedingt durch den zweiten Kern ist er mit 12,1 × 10,1 mm größer als der A4 (7,3 × 7,3 mm). Als Grafikprozessor kommt ein \"PowerVR SGX 543MP2\" mit zwei Prozessorkernen von Imagination Technologies zum Einsatz. Diese haben einen Kerntakt von 200 MHz. \n\nDer \"A5 Revision A\" S5L8942 wurde mit dem Apple TV der 3. Generation am 7. März 2012 vorgestellt. Er unterscheidet sich nur kaum vom ersten A5, mit der Ausnahme, dass der A5 Rev A im 32-nm-Verfahren hergestellt wird. Dadurch verkleinert sich die Grundfläche um ca. 40 % auf 69 mm und der Stromverbrauch wird reduziert. Beim Apple TV der 3. Generation wurde im A5 Rev A ein Cortex-A9-Prozessorkern deaktiviert. Neben dem Apple TV der 3. Generation verwenden auch das iPad mini, der iPod touch der 5. Generation und das im April 2012 eingeführte iPad 2,4 den A5 Rev A. In Tests der Seite Anandtech führte der S5L8942 im iPad 2,4 zu 15–30 % längeren Akkulaufzeiten.\n\nDer \"A5 Revision B\" mit der Bezeichnung \"S5L8947\" wurde Anfang 2013 mit dem Apple TV 3G Revision A (AppleTV3,2) eingeführt und auch nur dort verwendet. Der A5 Rev B verfügt als einziger A5-Chip nur über einen Prozessorkern und eine externe Speicheranbindung. Als Grafikprozessor kam ein PowerVR SGX 543MP1 zum Einsatz. Grund für die Einführung der Revision B war ein günstigerer Herstellungsprozess, da der bis dahin verwendete Revision-A-Chip über zwei Prozessorkerne verfügte, von welchem im ATV 3G jedoch ein Kern nicht benötigt und somit deaktiviert wurde. Die Herstellung erfolgte ebenfalls im 32-nm-Verfahren, der Chip hatte die Kennung \"APL7498\" und die Größe des Dies betrug 37,8 mm².\n\nDer A5X-S5L8945-Chip kommt nur im iPad der 3. Generation vor. Er wurde zusammen mit diesem im Frühjahr 2012 vorgestellt. Der A5X wird wie der erste A5 im 45-nm-Verfahren hergestellt. Er verwendet jedoch 1024 MB SDRAM-Speicher und als GPU kommt hier der Grafikchip PowerVR SGX 543MP4 zum Einsatz, der über vier ebenfalls mit 200 MHz getaktete Prozessorkerne verfügt. Nach Angaben von Apple bietet dieser gegenüber dem im A5 eingesetzten 543MP2 die doppelte Grafikleistung. Aufgrund der gestiegenen Wärmeentwicklung musste das Gehäuse des Prozessors für eine bessere Wärmeabstrahlung aus Metall gefertigt werden. Die Abmessungen des Chips betragen 12,82 mm × 12,71 mm, was eine Grundfläche von 162,94 mm ergibt.\n"}
{"id": "6053190", "url": "https://de.wikipedia.org/wiki?curid=6053190", "title": "Langzahlarithmetik", "text": "Langzahlarithmetik\n\nDie Langzahlarithmetik beschäftigt sich mit dem Rechnen mit Zahlen, bei denen eine sehr hohe Anzahl an Stellen zu verarbeiten ist.\n\nEin Computer hat eingebaute Befehle, um mit kleinen Zahlen extrem schnell zu rechnen. Der Zahlenbereich dieser „kleinen“ Zahlen umfasst üblicherweise ±2 Milliarden (bei 32-Bit-Computern) oder ±9 Trillionen (bei 64-Bit-Computern). Alles, was darüber hinausgeht, kann der Computer nicht mehr von sich aus berechnen, sondern braucht speziell zu diesem Zweck geschriebene Programme, die die Rechenregeln für große Zahlen definieren.\n\nDie meisten Computer können nicht nur mit ganzen Zahlen rechnen, sondern haben auch eingebaute Befehle für Gleitkommazahlen. Das sind Zahlen, die aus einer festen Anzahl an Ziffern bestehen, bei denen das Komma jedoch verschoben werden kann. Üblicherweise haben Gleitkommazahlen 16 Stellen Genauigkeit. Auch hier gibt es Anwendungen, die exakter rechnen müssen, so dass die eingebauten Rechenbefehle nicht ausreichen.\n\nAnwendungen der Langzahlarithmetik sind z. B.:\n\nUm mit langen Zahlen zu rechnen, benutzen Computer die gleichen Verfahren wie bei der schriftlichen Addition und der schriftlichen Subtraktion. Sie zerlegen große Zahlen in ihre Ziffern, rechnen dann die Teilergebnisse aus und setzen die Teilergebnisse dann zum Endergebnis zusammen. Der einzige Unterschied ist, dass Menschen üblicherweise mit den 10 Ziffern von 0 bis 9 rechnen, Computer jedoch mit größeren „Ziffern“ von 0 bis 2 Milliarden, 9 Trillionen oder gar 170 Quintilliarden, da sie für diese Zifferngrößen bereits eingebaute Befehle haben.\n\nIn der Langzahlarithmetik setzt nun nicht die Prozessorarchitektur, sondern die Größe des verfügbaren Arbeitsspeichers den Spielraum, innerhalb dessen beliebig lange Zahlen verarbeitet werden können. Bei einigen modernen Programmiersprachen ist Langzahlarithmetik standardmäßig eingebaut, bei anderen stehen dafür Bibliotheken zur Verfügung. Computeralgebrasysteme unterstützen (neben der symbolischen Mathematik, mit der sie nicht zu verwechseln ist) seit jeher auch Langzahlarithmetik.\n\nBei der Implementierung stehen möglichst effiziente mathematische Algorithmen im Vordergrund, um die Berechnungszeiten zu minimieren.\n\nBei Addition und Subtraktion von langen Zahlen werden die einzelnen binären Ziffernblöcke getrennt addiert bzw. subtrahiert und ein Übertragsbit übergeben.\n\nBei der Multiplikation gibt es bereits verschiedenste Ansätze für Algorithmen, wie zum Beispiel den Karazuba-Algorithmus oder den Schönhage-Strassen-Algorithmus. Es gibt die Vermutung, dass die Schranke formula_1 bei der Komplexität nicht unterboten werden kann.\n\nProgrammiersprachen, die Langzahlenarithmetik unterstützen, entweder als eingebaute Funktionalität oder im Rahmen der Standardbibliothek:\n\n\n"}
{"id": "6053309", "url": "https://de.wikipedia.org/wiki?curid=6053309", "title": "IPad 2", "text": "IPad 2\n\nDas iPad 2 ist ein Tabletcomputer der iPadreihe von Apple. Es wurde am 2. März 2011 vom mittlerweile verstorbenen Apple CEO Steve Jobs auf seiner letzten Keynote der Öffentlichkeit vorgestellt und war ab dem 11. März 2011 erhältlich. Der Verkauf wurde bis zum 18. März 2014 fortgeführt. Das iPad 2 ist das am meisten verbreitete iPad-Modell, bis zur Vorstellung des iPad Air im September 2013 betrug der Gesamtanteil an allen iPad-Modellen annähernd 40 %. Auf dem iPad 2 läuft das mobile Betriebssystem Apple iOS bis zur Version 9.3.5. Es ist das letzte iPad ohne Retina Display.\n\nDas iPad 2 hat eine Rückseite aus Aluminium und wahlweise einen weißen oder schwarzen Rand der vorderen Glasscheibe um den zentralen Bildschirm herum. Am mittigen unteren Rand ist eine Home-Taste angebracht, an der rechten Gehäuseseite befindet sich neben den Lautstärkewippen auch ein Orientierungssperrschalter. Unterhalb des An-Ausschalters auf der Gehäuseoberseite verfügt das iPad 2 über eine Kamera, auf der Frontseite ist mittig am oberen Bildschirmrand eine weitere Kamera verbaut. Die Auflösung der Kameras beträgt 0,7 und 0,3 Megapixel. Weiters gibt es auf der Oberseite ein Monomikrofon und einen 3,5 mm-Klinkenanschluss. Auf der Unterseite ist ein Monolautsprecher neben dem klassischen 30-Pin-Dockanschluss verbaut. Bedient wird das iPad 2 primär über Berührungen des Touchbildschirms.\n\nApple bot das iPad 2 als 16-, 32- oder 64-GB-Variante ohne Modem an. Zusätzlich gibt es für den nordamerikanischen Markt ein iPad 2 mit CDMA-Modem sowie für den europäischen Markt eines mit UMTS-Modem. Die europäischen Geräte verwenden SIM-Karten des Formats \"micro-SIM\" oder Karten mit dem Formfaktor \"3FF\" (12 mm × 15 mm). Apple gibt bis zu 10 Stunden Akkulaufzeit beim Surfen im Internet über WLAN und bis zu 9 Stunden bei der Nutzung eines 3G-Datennetzes an. Der Akku des iPad 2 ist ein 25-Wh-Lithiumpolymerakkumulator. Zusätzlich zum Mobilfunkmodem verbaute Apple ein A-GPS-Modul. Den digitalen Kompass besitzen auch die Geräte ohne Modem.\n\nAls System-on-a-Chip dient dem iPad 2 der Apple A5, der einen Dualcoreprozessor des Typs ARM Cortex A9 mit 1 GHz Taktfrequenz verwendet. Das iPad 2 verfügt in jeder Ausführung über einen SGX-543-Grafikprozessor mit zwei Kernen. Gegen Ende März 2012 kam eine überarbeitete Variante des iPad 2 auf den Markt, welches intern \"iPad 2,4\" heißt. Das iPad 2,4 hat im Vergleich zum „Ur-iPad 2“ ein überarbeitetes Apple-A5-SoC und dadurch eine verbesserte Akkulaufzeit. Äußerlich unterscheidet sich das iPad 2,4 nicht vom normalen iPad 2. Das iPad 2,4 ist nur als WiFi-Variante mit 16 GB produziert worden. Das iPad mini teilt sich mit dem iPad 2 die Versionsnummern.\n"}
{"id": "6056030", "url": "https://de.wikipedia.org/wiki?curid=6056030", "title": "Turtle F2F", "text": "Turtle F2F\n\nTurtle ist eine freie P2P-Software, die an der Vrije Universiteit in Amsterdam u. a. von Andrew Tanenbaum entwickelt wurde. Wie andere anonyme P2P-Software erlaubt es Benutzern, Dateien zu teilen und auf andere Art und Weise zu kommunizieren, ohne gleichzeitig Angst vor gesetzlichen Konsequenzen oder Zensur haben zu müssen. Turtles Ansprüche an Anonymität werden durch zwei Forschungsarbeiten bekräftigt, die bei den Weblinks zur Verfügung stehen.\n\nTechnisch gesehen ist Turtle ein friend-to-friend-(F2F)-Netzwerk, ein spezieller Typ des Peer-to-peer-Netzwerks, bei dem jegliche Kommunikation nur über \"Freunde\", deren \"Freunde\" und so weiter zum Ziel geroutet wird.\n\nDie Grundidee hinter Turtle ist, ein P2P-Overlay auf schon vorher existierenden Vertrauens-Beziehungen zwischen Turtle-Nutzern zu bauen. Jeder Nutzer wirkt als Knoten im Overlay, auf dem eine Instanz der Turtle-Software läuft. Anders als andere P2P-Netzwerke erlaubt Turtle nicht, dass beliebige Knoten Verbindungen aufbauen und Daten austauschen können. Stattdessen öffnet jeder Nutzer sichere und authentizierte Kanäle mit einer begrenzten Anzahl an Knoten, die durch Nutzer, denen er vertraut, kontrolliert werden können. Im Turtle-Overlay bewegen sich sowohl Anfragen als auch Antworten \"hop-by-hop\"; dadurch werden Informationen nur zwischen sich vertrauenden Nutzer ausgetauscht und immer verschlüsselt. Mit diesem Konzept bietet ein Turtle-Netzwerk viele nützliche und sichere Eigenschaften, wie z. B. Schadensbegrenzung im Falle eines kompromittierten Knotens oder Resistenz gegenüber Denial-of-Service-Angriffen.\n\n\n"}
{"id": "6058055", "url": "https://de.wikipedia.org/wiki?curid=6058055", "title": "Windows Embedded Automotive", "text": "Windows Embedded Automotive\n\nWindows Embedded Automotive (früher auch \"Windows Automotive\" oder \"Microsoft Auto\") ist ein Betriebssystem der Windows-Embedded-Produktfamilie. Es ist der Nachfolger der Betriebssysteme Microsoft Auto 4.1 und Windows Automotive 5.5. Zur Verwendung des Betriebssystems wird das Windows Embedded Automotive Development Kit (WE-ADK) benötigt. Im Kit sind neben der Hardware auch Evaluierungsversionen von Windows Embedded Automotive, sowie ein Windows Embedded Platform Development Kit.\n\nIn manchen neuen Fahrzeugen sind die Hardware sowie Windows Embedded Automotive 7 bereits enthalten. Weitere Automobile mit dieser Ausrüstung sind angekündigt.\n\nDer Preis, dem das Fahrzeug durch das System aufgeschlagen wird, hängt unter anderem davon ab, in welchem Umfang das Betriebssystem im Auto eingesetzt wird.\n\nDas Betriebssystem basiert auf Windows CE. Die erste Version wurde 1998 unter dem Namen AutoPC als Betriebssystem des gleichnamigen AutoPC veröffentlicht. Im Jahr 2000 wurde es in \"Windows CE for Automotive\" umbenannt. Im Jahr 2002 wurde abermals der Name abgeändert und es hieß nun \"Windows Automotive\". 2007 wurde es schließlich im Zuge der Veröffentlichung von Ford Sync in \"Microsoft Auto\" umbenannt.\n\n\nDie ersten Fahrzeuge, welche diese Version einsetzen, wurden im Jahr 2006 fertiggestellt. Neben der speziellen Eignung für Navigationssysteme und Kommunikationswerkzeuge zeichnet es sich durch die Unterstützung gerade der Schnittstellen aus, die im Automobilbau von besonderer Bedeutung sind. Fiat brachte das System unter dem Namen „Blue&Me“ in die Modellpalette im Frühjahr 2006. Damit lassen sich die Handy-Freisprechfunktionen über Bluetooth, TtS (Text to Speech, also SMS vorlesen), Spracherkennung, und eine USB-Schnittstelle steuern.\n\nDer Unterhaltungselektronikhersteller Clarion stellt seit 2007 Navigationssysteme mit Multimediafunktionen für die Nachrüstung her.\n\n"}
{"id": "6062993", "url": "https://de.wikipedia.org/wiki?curid=6062993", "title": "Xtranormal", "text": "Xtranormal\n\nXtranormal war eine Website, die mit einer künstlichen Stimme versehen, Computer animierte Videoclips präsentierte. Die Videoclips konnten von jedem Nutzer erstellt und mit einem frei herunterladbaren Programm bearbeitet und hochgeladen werden.\n\nIm Juni 2013 gab das Unternehmen bekannt, dass die Online-Dienste ab 31. Juli 2013 heruntergefahren werden. Ab August 2013 wurde der Inhalt ihrer Website durch eine einfache Seite ersetzt.\n\nSeit 16. Mai 2014 ist die Website wieder verfügbar, dieses Mal durch eine andere Firma betrieben. Nach diesem Datum war kein Erstellen oder Abrufen von Videos möglich.\n\nZwischen Ende Juli 2015 und Beginn September 2015 wurde das neue Angebot (ähnliche Inhalte wie das ursprüngliche Xtranormal) auf einer anderen Domain aktiviert. Seitdem befindet sich auf der Webseite nur ein Hinweis auf die neue Domain.\n\nVideoclips konnten entweder mit einer herunterladbaren Testversion (beschränkt auf die Erstellung einfacher Clips) erstellt werden oder der Clip wurde direkt online auf der Webseite erstellt und gespeichert. \n\nWährend YouTube nur die Möglichkeit bietet, bereits fertige Videos hochzuladen, hatte man bei Xtranormal die Möglichkeit, aus einer Art „Baukasten“ verschiedene Figuren, Umgebungen und Hintergründe mit künstlichen Stimmen zu einem selbst produzierten, animierten Video in 3D zusammenzustellen. Dafür waren keine speziellen Kenntnisse oder besonders leistungsfähige Computer nötig. \n\nDie auf mehreren Sprachen verfügbare Website bekam etwa 65 Prozent ihrer Zugriffe aus den Vereinigten Staaten. \n\n\n"}
{"id": "6070149", "url": "https://de.wikipedia.org/wiki?curid=6070149", "title": "Libzypp", "text": "Libzypp\n\nZYpp oder libzypp ist ein Paketverwaltungssystem, das vor allem in openSUSE eingesetzt wird. Es ist die SUSE-spezifische Implementation von PackageKit. libzypp verfügt über einen nach eigenen Angaben herausragenden Abhängigkeitsauflöser, um Paketabhängigkeiten zu berechnen, den SAT-Solver (siehe SAT-Problem und Constraint-Satisfaction-Problem). Die libzypp ist Open Source und wird mit Unterstützung von Novell entwickelt.\n\nZur libzypp gehört das Kommandozeilen-Interface zypper, das auch über eine eigene Eingabeaufforderung verfügt. Zypper unterstützt YaST2 und RPM MetaData als Repository-Format. Die installierten Repositories in zypper sind synchron mit denen in YaST2, da YaST selbst auch auf die libzypp als Paketverwaltungsengine setzt. Zypper unterstützt alle gängigen Paketverwaltungs-Funktionen, wie das Auflösen von Abhängigkeiten, das Installieren und Entfernen von Paketen und die Aktualisierungsverwaltung, also das Suchen nach Patches und Updates. Als grafische Oberfläche für Zypper kann YaST betrachtet werden, da sowohl YaST als auch Zypper auf die libzypp-Engine zurückgreifen.\n\nZypper erschien das erste Mal mit openSuse 10.2, ist aber auch für openSuse 10.1 verfügbar. 2003 entschied Novell in der Folge der Übernahme von Ximian und der SUSE GmbH, beide Paketsysteme (Yast und RedCarpet) zu vereinigen. 2005 erfüllte keiner der beiden Paketmanager mehr die Anforderungen, die andere Open-Source-Paketmanagement-Systeme erfüllt hätten. Novell übernahm Eigenheiten beider Paketsysteme und entwickelte libzypp.\n"}
{"id": "6092636", "url": "https://de.wikipedia.org/wiki?curid=6092636", "title": "SoftPC", "text": "SoftPC\n\nSoftPC und SoftWindows sind Emulatoren der x86-Hardware.\n\nDiese Emulatoren wurden von der Firma Insignia Solutions entwickelt. Ursprünglich waren sie für UNIX-Workstations gedacht, um MS-DOS-Programme auszuführen. \n\nSpäter wurde die Software nach Mac OS portiert und bot auch die Möglichkeit Windows zu nutzen. Die Version für den Atari ST/Falcon wurde niemals veröffentlicht.\n\nDas Paket bestehend aus SoftPC und Windows (3.x, 95, 98) wurde SoftWindows genannt, obwohl es auch möglich war Windows in eine SoftPC-Umgebung mit zusätzlichen Aufwand zu installieren.\n\nAnfang 1996 war Insignia Marktführer in diesem Produktbereich, doch der Wettbewerb wurde durch Connectix mit Virtual PC stärker. Insignia verkaufte diese Produktlinie an FWB Software im Oktober 1999, um sich in Zukunft auf Java-Implementierungen für Mobilgeräte zu konzentrieren. \n\nFWB verkaufte SoftWindows weiterhin bis zum März 2001. Das gleiche Unternehmen bot auch die ähnliche Software RealPC bis 2003 an.\n\nNeben Apple Mac OS wurden folgende Plattformen unterstützt:\n\n\n\n\n\n\n\n"}
{"id": "6096745", "url": "https://de.wikipedia.org/wiki?curid=6096745", "title": "Ich muß immer das letzte Wort haben", "text": "Ich muß immer das letzte Wort haben\n\nIch muß immer das letzte Wort haben ist eine Installation des deutschen Künstlers und heutigen Unternehmers Werner Vollert aus den 1980er-Jahren. Es handelt sich dabei um eine Maschine, „die selbsttätig fünf Feuerwerksraketen in die Luft schießt, sobald in einer Entfernung zwischen zwanzig und dreißig Kilometern eine Atombombe detoniert“. Das interaktive Kunstwerk wurde auf zahlreichen Kunstausstellungen in Europa gezeigt, wie unter anderem auf der Ars Electronica 1991 in Linz.\n\nDer im Jahr 1985 geschaffene Automat „Ich muß immer das letzte Wort haben“ gehört zu einem Zyklus von sechs Maschinen, die zwischen 1984 und 1990 von Werner Vollert konzipiert und erbaut wurden und die die Symbiose aus Mensch und Maschine thematisieren. Wie die formal ähnlichen und aus dem gleichen Zyklus stammenden Automaten „Sind Sie Profiraucher?“ und „Testen Sie Ihre Reaktion!“ handelt es sich um eine gebrauchsfertige Maschine, die nach Geldeinwurf funktioniert. \n\nVon dem Automaten „Ich muß immer das letzte Wort haben“ werden ständig verschiedene Parameter der Außenwelt gemessen, wie unter anderem Radioaktivität, Temperatur und Luftfeuchtigkeit, um bei einer Atombombenexplosion in der Nähe des Automaten – in einem Umkreis von etwa zwanzig bis dreißig Kilometern – fünf Feuerwerksraketen zu starten. Nach Einwurf von einer Mark wird auf einem LED-Anzeigeelement der „Ernstfall“ mit der Anzeige von „Exact Overkill Time“ (englisch \"\", „Genaue Totalvernichtungs-Zeit“) und Countdown-Zeitangaben bis zum Start der Feuerwerksraketen simuliert.\n\nDie Installation „Ich muß immer das letzte Wort haben“ wurde unter anderem zusammen mit weiteren Automaten von Vollert auf der \"Ars Electronica 1991\" gezeigt, die vom 10. bis 13. September 1991 im oberösterreichischen Linz stattfand und die unter dem Motto „Out of Control“ (englisch \"\", „Außer Kontrolle“) stand. \n\nMit den von Werner Vollert bei der Linzer \"Ars Electronica 1991\" gezeigten Automaten setzt sich der damalige Ausstellungsmacher und heutige Lehrbeauftragte für Veranstaltungsmanagement (Beuth Hochschule für Technik Berlin) Thomas Sakschewski in seinem Beitrag mit dem Titel \"Dem Homunculus zum Trotz\" zu dem 1991 erschienenen Ausstellungskatalog \"(„Out of Control“. Ars Electronica 1991)\" auseinander. Er sieht Vollerts Automaten „in einem Konnotationsraum aus Interaktionspessimismus, Technoästhetik und Misanthropie“, wobei weder der Sachwert der Automaten noch der Bedienungsprozess im Vordergrund stünden. Nach Sakschewski sei es „naiv, positivistisch und maschinenutopisch zu behaupten, dass in medialer oder interaktiver Kunst a priori ein Evolutionsschub, ein Avantgardeschock stecke“, denn wie solle „der ‚aktive Betrachter zum echten Teilnehmer‘ (P. Weibel) erwachsen, wenn durch das Programm des Interaktiven Kunstwerks jede Teilnahme zur Pseudopartizipation mutiert; wenn Alles so festgelegt ist, wie der digitale Wecker den digitalisierten Arbeiter zur ‚Exact Overkill Time‘ (erscheint als LED-Anzeige zum Zeitpunkt des Programmstarts, also auch zum Zeitpunkt eines Atomwaffenangriffs, bei dem Automat ‚Ich muß immer das letzte Wort haben‘) weckt“.\n\nSakschewski sieht nicht Vollerts Automaten selbst als ästhetische Zeichenträger, sondern die Interaktion zwischen Mensch und Maschine und die Metakommunikation über diese Beziehung. Ohne Demontage des Automaten bleibe es unprüfbar, ob der Automat wirklich regelmäßig die genannten Parameter misst, ob die Feuerwerksraketen wirklich in einer „Exact Overkill Time“ starten würden. Die Unvorstellbarkeit des Machbaren führe durch die Handlichkeit des Automaten, die Griffnähe der Spielzeugraketen und die Eindringlichkeit des LED-Countdowns zu einem Schaudern, konstatiert Sakschewski; die „Metapher der Kontrolle“ bei diesem Automaten werde zu einem „Spielverlauf fast tragödischen Ausmaßes“. Der Automat, der erkennen soll, ob ein Out-Of-Control-Zustand beginnt, könne nicht kontrolliert werden; das „Dilemma der Wirklichkeitserfassung durch Beobachtung“ werde so „auf eindrucksvolle Weise erfahrbar“.\n\nDurch die Mehrdeutigkeit der benutzten Zeichen und das unauflösbare Zusammenspiel von Maschinensturm und Technoästhetik und der sich überlappenden Interaktionsverhältnisse machten Vollerts Automaten deutlich, resümiert Sakschewski, dass das Out Of Control nicht Zustandsbeschreibung eines einzelnen Automaten sei, sondern Stigma unserer Zeit. Mit der exponentiell wachsenden globalen Informationsmenge werde jedes Erklärungsmodell so multifaktoriell, dass eine Soll-Ist-Zustandskontrolle nicht mehr möglich sei; so wenig einfach wie die Installation „Ich muß immer das letzte Wort haben“ als Jahrmarktsattraktion abgetan werden könne.\n\n"}
{"id": "6096811", "url": "https://de.wikipedia.org/wiki?curid=6096811", "title": "HP TouchPad", "text": "HP TouchPad\n\nDas HP TouchPad ist ein Tablet-Computer des amerikanischen Herstellers Hewlett-Packard, der sich durch seinen berührungsempfindlichen Bildschirm (Multi-Touch) steuern lässt. Es war der erste Tablet-Computer mit dem Betriebssystem HP webOS 3.0. Das HP TouchPad wurde am 9. Februar 2011 auf einer Pressekonferenz angekündigt und war in den USA seit 1. Juli und in Deutschland seit 15. Juli 2011 erhältlich. Im August 2011 verkündete der Konzern die Einstellung der Tablets.\n\nDas Gerät verfügt über einen 9,7-Zoll-Touchscreen und wird von einem Dual-Core-Prozessor vom Typ Snapdragon mit 1 Gigabyte Arbeitsspeicher betrieben. Geplant war, das TouchPad in zwei Varianten auf den Markt zu bringen, mit Wi-Fi und dem Mobilfunkstandard 3G. Aufgrund der Einstellung des HP Touchpads seitens HP ist nur die Wi-Fi version auf den Markt gekommen.\nDie letzte Touchpad-Version hatte 64 GB Speicher und eine weiße Rückseite, die Doppelkern-CPU wurde mit 1,5 GHz getaktet. Die 16- und 32-GB-Versionen liefen noch mit 1,2 GHz.\n\nEine geplante 7-Zoll-Version mit 1,5 GHz Dual-Core-CPU und 3G Modem wurde nur 2 Tage vor Produktionsstart von HP am 19. August 2011 eingestellt.\n\nDas Gerät kann serienmäßig über eine spezielle Dockingstation, den sogenannten \"Touchstone\", drahtlos via Induktion geladen werden. Als weiteres Originalzubehör wurden eine Bluetooth-Tastatur und faltbare Schutztasche angeboten.\n\nAls Betriebssystem wird das für Tablet-Computer optimierte HP webOS 3.0 verwendet. Ursprünglich wurde das HP Touchpad für ein Android Betriebssystem entwickelt (Android 2.3x) aber von HP quasi in letzter Minute auf WebOS umgestellt.\n\nDas CyanogenMod-Team hat das Google Open Source-Betriebssystem Android in den Versionen 2.3.7 „Gingerbread“, 4.0 „Ice Cream Sandwich“ sowie 4.4.2 \"Kitkat\" auf das TouchPad gebracht. HP unterstützt das CyanogenMod-Team durch die Bereitstellung von Kernel-Quellcodes.\n"}
{"id": "6101223", "url": "https://de.wikipedia.org/wiki?curid=6101223", "title": "Hard-core-Prozess", "text": "Hard-core-Prozess\n\nEin Hard-core-Prozess ist ein stochastischer Punktprozess, bei dem aufeinanderfolgende Ereignisse einen festgelegten Mindestabstand zueinander einhalten. Aus Sicht der stochastischen Geometrie bestehen formula_1-dimensionale Punktfelder, die durch Hard-core-Prozesse erzeugt wurden, aus den Mittelpunkten formula_1-dimensionaler, sich nicht gegenseitig durchdringender Kugeln mit vorgegebenem Durchmesser.\n\nJe nach der Art und Weise, wie die Punkte erzeugt werden, lassen sich verschiedene Hard-core-Prozesse mit unterschiedlichen Eigenschaften beschreiben. Hard-core-Prozesse werden hauptsächlich in der theoretischen Ökologie und Physik der kondensierten Materie zur Modellierung verschiedener Phänomene angewandt. Weitere Anwendungen finden Hard-core-Prozesse in der Computergrafik, wo sie auch als Poisson-disk- oder Blue-noise-Abtastung bezeichnet werden.\n\nEin einfaches Beispiel eines Hard-core-Prozesses ist das „Random car parking problem“ („Problem des zufälligen Einparkens“), das 1958 von Alfréd Rényi beschrieben wurde. Auf der Strecke formula_3 (der Straße) werden nacheinander zufällig Positionen gewählt. Um jede dieser Positionen wird ein Intervall der Länge formula_4 (ein Auto) platziert, sofern es keines der bisher platzierten Intervalle überlappt. Dabei handelt es sich um einen eindimensionalen Hard-core-Prozess, da die Mittelpunkte der Intervalle einen Mindestabstand von formula_4 einhalten.\n\nDie rein zufällige Wahl von Positionen, ohne Einhaltung eines Mindestabstands, wird durch den Poisson-Prozess modelliert. Ein Beispiel für einen Poisson-Prozess ist das Auftreffen von Regentropfen auf dem Boden. Der Poisson-Prozess kann demnach als Hard-core-Prozess mit formula_6 aufgefasst werden.\n\nMeist sind nur \"vollständige\" Hard-core-Punktfelder von praktischem Interesse, also Punktfelder, bei denen der zur Generierung verwendete Hard-core-Prozess beendet ist und kein weiterer Punkt mehr in die vorgegebene Fläche hinzugefügt werden kann. Je nach Mindestabstand und je nachdem, wie eng ein Prozess die Punkte platziert, enthält ein vollständiges Hard-core-Punktfeld mehr oder weniger Punkte. Rényi interessierte sich für den Erwartungswert der Anzahl von Intervallen, die durch zufälliges Einparken platziert werden können.\n\nDas im vorherigen Abschnitt beschriebene Prozess beim Einparkproblem lässt sich auf zwei und höhere Dimensionen verallgemeinern; er wird in der Statistik im Allgemeinen als \"Simple sequential inhibition\" (SSI), in der Physik und Chemie als \"Random sequential adsorption\" (RSA), in der Sequenzplanung als \"On-line packing\" und in der Computergrafik als \"Dart throwing\" bezeichnet. Hierbei werden nach und nach Punkte von einem Poisson-Prozess erzeugt, aber nur jene berücksichtigt, die den Mindestabstand zu allen bisher beibehaltenen Punkten einhalten.\n\nAlgorithmisch lässt sich die Erzeugung von SSI-Punktfeldern mit folgendem Pseudocode beschreiben. ξ steht hierbei für eine zufällig generierte reelle Zahl zwischen 0 und 1 (oder, bei mehrdimensionalen Punktfeldern, für Tupel solcher Zufallszahlen).\n\nBertil Matérn beschrieb drei Arten von Hard-core-Prozessen, die durch Ausdünnung eines Poisson-Prozesses entstehen, d. h. durch das nachträgliche Löschen bestimmter Punkte, die von einem Poisson-Prozesses erzeugt wurden. Anders als beim im vorherigen Abschnitt beschriebenen SSI-Prozess werden Punkte erst gelöscht, nachdem das vollständige Poisson-Punktfeld erzeugt wurde. Beim ersten matérnschen Prozess werden alle Punkte gelöscht, deren nächstgelegener Nachbarpunkt näher liegt als der Mindestabstand. Falls mehrere Punkte zu nahe beieinander liegen, so werden sie \"alle\" gelöscht.\n\nDer Algorithmus zur Erzeugung von Punktfeldern nach dem ersten matérnschen Prozess ist wie folgt:\n\nBeim zweiten matérnschen Prozess werden die vom Poisson-Prozess erzeugten Punkte mit einer aufsteigenden „Markierung“ versehen. Anschließend werden alle Punkte beibehalten, die innerhalb des Mindestabstands keine vorher erzeugten Nachbarpunkte (mit einer niedrigeren Markierung) haben.\n\nDer Algorithmus für den zweiten matérnschen Prozess lautet folgendermaßen:\n\nMatérn erwähnte kurz einen dritten Prozess, der wie der zweite beginnt. Anschließend wird der gleiche Prozess mit den Punkten des Poisson-Prozesses, die keine Nachbarpunkte der bisher ausgewählten Punkte sind, so lange wiederholt, bis keine neuen Punkte mehr ausgewählt werden können. Der Algorithmus lautet wie folgt:\n\nEs wurde ein effizienterer Algorithmus zur Simulation von Matérn-III-Punktfeldern beschrieben.\n\nEin weiterer Hard-core-Prozess ist das Dead leaves model („Modell der abgestorbenen Blätter“), auch Non-overlapping germ-grain model („Modell der nicht-überdeckenden Samenkörner“) genannt. Bei diesem Prozess werden Kreise mit Durchmesser δ zufällig in der Ebene platziert, wobei sie vorhandene Kreise überdecken können. Das Hard-core-Punktfeld besteht aus den Mittelpunkten der nicht überdeckten Kreise (der oberen Schicht), nachdem unendlich viele Kreise hinzugefügt wurden. In endlicher Zeit simulieren lässt sich der Prozess, indem neue Kreise nicht über, sondern unter die vorhandenen Kreise platziert werden und der Vorgang abgebrochen wird, sobald die gesamte Fläche abgedeckt ist. Der Prozess lässt sich auf andere Dimensionen übertragen.\n\nIn der Festkörperphysik wurden besondere Hard-core-Prozesse entwickelt, um dichte zufällige Kugelpackungen zu simulieren und zu untersuchen. Üblicherweise werden zur Simulation dieser Punktprozesse horizontal periodische Randbedingungen gewählt.\n\nJodrey und Torys Sedimentationsalgorithmus simuliert Kugelpackungen durch das sukzessive Fallenlassen von Kugeln in einen Container. Ausgangspunkt ist eine initiale Kugelschicht („Startkombination“) am Boden des Containers. Es werden dann nach und nach Kugeln hinzugefügt, die aufgrund der Gravitation nach unten fallen und dann, ohne abzuprallen, an den existierenden Kugeln entlangrollen, bis sie an einer stabilen Position zum Liegen kommen. Als stabil gilt eine Position, wenn die Kugel mindestens drei Nachbarn (oder den Boden und zwei Nachbarn) berührt. Falls nach einer festgelegten Zeit keine stabile Position für eine Kugel gefunden werden kann, wird der Versuch mit einer neuen Kugel wiederholt. Der Prozess wiederholt sich so lange, bis der Container gefüllt ist.\n\nDie mit dem Sedimentationsalgorithmus erreichbare Dichte ist geringer als bei natürlichen Kugelpackungen; die maximale Packungsdichte des Algorithmus beträgt ungefähr 0,58. Das liegt daran, dass nicht die optimale Position für die Kugeln bestimmt wird, sondern jeweils die erste akzeptiert wird. Es ist außerdem eine Unregelmäßigkeit in der Dichteverteilung entlang der vertikalen Achse feststellbar. Wegen dieser unerwünschten Eigenschaften wird der Sedimentationsalgorithmus meist nicht mehr zur Simulation dichter Kugelpackungen verwendet.\n\nBei der Gruppe der Collective-rearrangement-Algorithmen bleibt die vorgegebene Anzahl der Kugeln konstant. Im Laufe der Simulation werden viele der Kugeln verschoben. Ein bekannter Algorithmus aus dieser Gruppe ist der Force-biased-Algorithmus, der auf einer Idee von Jodrey und Torey basiert. Als Ausgangspunkt wird eine Menge von zufällig verteilten, eventuell überlappenden Kugeln im Container gewählt. Nur diese Ausgangskonfiguration ist zufällig, der restliche Algorithmus arbeitet deterministisch. Die Kugeln werden voneinander weg verschoben, so als ob ein abstoßendes Kraftfeld zwischen ihnen wirken würde. Gleichzeitig wird der Radius der Kugeln mit einem Faktor kleiner als 1 multipliziert. Dieser Vorgang wiederholt sich so lange, bis die Kugeln einander nicht mehr überlappen.\n\nEin weiteres Beispiel für einen Collective-rearrangement-Algorithmus ist der Stillinger-Lubachevsky-Algorithmus, bei dem die Kugeln vergrößert werden und häufiger bewegt werden als beim Force-biased-Algorithmus. Weiterhin gibt es sogenannte Molecular-dynamics-Methoden, bei denen sich die Größe der Kugeln nicht verändert. Stattdessen bewegen sie sich gemäß Newtons Bewegungsgesetzen, wobei sie elastisch von anderen Kugeln abprallen. Ein Beispiel für einen solchen Algorithmus ist der SPACE-Algorithmus.\n\nCollective-rearrangement-Algorithmen sind in der Lage, sehr dichte Kugelpackungen zu erzeugen.\n\nFür die Computergrafik wurden eigene Methoden zur Erzeugung von Hard-core-Punktfeldern entwickelt, da hier die Ausführungsgeschwindigkeit eine große Rolle spielt.\n\nBridson beschrieb einen Algorithmus mit linearer Zeitkomplexität in Abhängigkeit von der Anzahl der Punkte. Im Gegensatz zu vielen anderen in der Computergrafik üblichen Algorithmen eignet sich Bridsons Algorithmus für Hard-core-Punktfelder in beliebigen Dimensionen.\n\nDer Algorithmus beginnt mit einem zufällig gewählten Ausgangspunkt, der zu einer Liste „aktiver“ Punkte hinzugefügt wird. Es wird dann ein zufälliger Referenzpunkt aus der aktiven Liste gewählt. Anschließend werden eine maximale Anzahl von Kandidatenpunkten (typischerweise bis zu formula_7) innerhalb des Kreisringes zwischen δ und 2δ zufällig platziert. Falls ein Kandidatenpunkt den Mindestabstand zu allen bisher beibehaltenen Punkten einhält, wird er zum Punktfeld hinzugefügt und zur aktiven Liste hinzugefügt. Falls nach formula_8 Versuchen kein Kandidatenpunkt den Mindestabstand einhält, wird der Referenzpunkt aus der aktiven Liste entfernt. Dieser Vorgang wiederholt sich, bis die aktive Liste leer ist.\n\nDie lineare Zeitkomplexität wird erreicht, indem die Fläche oder der Raum in ein regelmäßiges Gitter eingeteilt wird. Die Seitenlänge der Zellen wird hierbei nicht größer als formula_9 gewählt, wobei formula_1 die Anzahl der Dimensionen ist. Dadurch enthält jede Zelle maximal einen Punkt, sodass bei der Prüfung auf Einhaltung des Mindestabstands nur Nachbarzellen durchsucht werden müssen. Durch ein solches Aufteilungsschema lassen sich auch viele der vorher beschriebenen Algorithmen beschleunigen.\n\nDer Pseudocode des Algorithmus (hier ohne Aufteilungsschema) lautet wie folgt:\n\nDunbars und Humphreys’ Algorithmus weist ebenfalls eine lineare Zeitkomplexität auf. Wie auch bei Bridsons Methode werden neue Punkte in der Umgebung der bestehenden Punkte hinzugefügt. Der für neue Punkte verfügbare Bereich wird jedoch präziser mittels einer speziellen Datenstruktur, dem „ausgekehlten Kreissektor“, repräsentiert. Dadurch kann das Hard-core-Punktfeld sehr effizient erzeugt werden.\n\nAnstatt ein Hard-core-Punktfeld für die gesamte Fläche zu generieren, können mehrere kleine Kacheln mit individuellen Punktfeldern erzeugt und anschließend zusammengesetzt werden. Es wurden mehrere solcher Methoden entwickelt, die entweder quadratische Kacheln oder Wang-Kacheln verwenden. Um den Mindestabstand auch an den Rändern der Kacheln so gut wie möglich einzuhalten, können die Kacheln periodische Randbedingungen aufweisen oder bestimmte Punkte je nach Zusammensetzung der Kacheln verschoben werden.\n\nDer Lloyd-Algorithmus kann dazu verwendet werden, um den Mindestabstand eines bestehenden (Hard-core-)Punktfeldes zu erhöhen. Der Lloyd-Algorithmus geht vom Voronoi-Diagramm des Punktfeldes aus und verschiebt die Punkte in Richtung des Flächenschwerpunktes ihrer Voronoi-Zelle. Dieser Prozess wird schrittweise wiederholt. Für zweidimensionale Punktfelder konvergiert der Lloyd-Algorithmus zu 75 bis 85 % der maximalen Packungsdichte.\n\nDie untenstehenden Bilder zeigen ein Punktfeld nach 1, 2, 3 und 15 Schritten des Lloyd-Algorithmus. Die Kreuze markieren die Schwerpunkte der Voronoi-Zellen.\n\n"}
{"id": "6102327", "url": "https://de.wikipedia.org/wiki?curid=6102327", "title": "OpenNMS", "text": "OpenNMS\n\nOpenNMS ist ein freies Netzwerkmanagement-System zur Überwachung von IT-Netzwerken. Der gesamte Code steht unter der GNU General Public License (GPL). Verwaltet wird das Projekt von Tarus Balog, der OpenNMS Group und „The Order of the Green Polo“.\nOpenNMS ist in Java geschrieben und lässt sich über eine Weboberfläche benutzen. Es gilt als sehr skalierbar. Installationen zur Überwachung von 70.000 Systemen mit einer Instanz sind in der Praxis im Einsatz.\n\n\nOpenNMS unterstützt die Betriebssysteme Linux, Solaris, Mac OS X, FreeBSD und Microsoft Windows.\n\nOpenNMS besteht aus mehreren Diensten, die jeweils über einen gemeinsamen Eventbus miteinander kommunizieren.\nDer Discovery-Daemon durchsucht in regelmäßigen konfigurierbaren Abständen IP-Adressbereiche nach neuen Knoten. Wird ein neuer Knoten erkannt, wird ein NewSuspect-Ereignis erzeugt. Nach dem Auftreten eines solchen Ereignisses beginnt der Dienst Capsd die auf dem Gerät verfügbaren Dienste zu erkennen und in OpenNMS aufzunehmen. Der Pollerd übernimmt anschließend das Abfragen der einzelnen erkannten Dienste während der Collectd in regelmäßigen Abständen Leistungsdaten wie zum Beispiel die CPU-Auslastung unter anderem per SNMP erhebt. Mit den Diensten Trapd und Syslogd können SNMP-Traps sowie Syslog-Nachrichten empfangen werden und dem jeweiligen überwachten Knoten zugeordnet werden.\nSämtliche Daten mit Ausnahme von Leistungsdaten werden in einer PostgreSQL-Datenbank gespeichert. Leistungsdaten werden in RRD-Dateien abgelegt. Mit einem Applikationsserver werden die gesammelten Informationen dem Benutzer über eine Weboberfläche zur Verfügung gestellt.\n\nOpenNMS verfügt über eine große, internationale Community. Einmal jährlich finden Konferenzen für Benutzer und Anwender statt. Der Inhalt und die Konferenzprogramme sind frei zugänglich im dokumentiert.\n\n"}
{"id": "6113466", "url": "https://de.wikipedia.org/wiki?curid=6113466", "title": "Memotech MTX", "text": "Memotech MTX\n\nMemotech MTX waren drei Anfang der 1980er Jahre angebotenen Computer des Unternehmens Memotech mit den Bezeichnungen MTX500, MTX512 und RS128. Als Prozessor wurde eine Variante des Prozessors Zilog Z80 eingesetzt.\n\nDie Computer hatten Gehäuse aus gebürstetem und dunkel eloxierten Aluminium und dadurch ein recht hohes Gewicht von etwa 2,6 kg. Die Tastatur war sehr umfangreich, hatte aber einen hakeligen Anschlag. Es gab sie auch mit einem deutschen Layout.\n\nSie ähnelten technisch den MSX-Computern, waren aber nicht zu ihnen kompatibel. Beide Systeme benutzten zum Beispiel den Videoprozessor TMS9918A von Texas Instruments. Intern konnten die Modelle MTX500 und MTX512 um zwei RS232-Schnittstellen erweitert werden. Das Modell RS128 hatte diese bereits eingebaut.\n\nSehr ungewöhnlich war, dass drei Programmiersprachen integriert wurden. Zum einen war das ein damals üblicher BASIC-Interpreter. Darüber hinaus waren auch ein Assembler und eine Programmiersprache namens Noddy, mit welcher sich Bildschirmseiten (beispielsweise Adress-Karteikarten) verwalten ließen, eingebaut. Auf diese Bildschirmseiten konnte dann auch von BASIC aus zugegriffen werden. Auch die Grafik, die 32 Sprites und der Sound ließen sich komfortabel vom BASIC aus ansprechen.\n\nDie Computer ließen sich mit den Erweiterungsboxen FDX oder HDX erweitern. In der FDX waren zwei 5,25\" Diskettenlaufwerke mit einer Kapazität von jeweils 500 kB eingebaut. In der HDX hingegen wurde ein Diskettenlaufwerk und eine Festplatte eingebaut. Außerdem gab es in der FDX und HDX Steckplätze für Erweiterungskarten, wie zum Beispiel 80-Zeichen-Karten. Die Datenübertragung zum Computer erfolgte über die RS232-Schnittstelle, so dass die Geschwindigkeit mit 1200 Bytes/s doch recht gering ausfiel. Darüber hinaus gab es noch das 3,5\" Diskettenlaufwerk SDX mit einer Kapazität von 1 MB, das über den Systembus an der linken Seite angeschlossen wurde. Hier konnte zusätzlich noch eine Speichererweiterung eingebaut werden. Wurden die Computer mit einem Diskettenlaufwerk erweitert, so war auch ein Betrieb über CP/M möglich.\n\n\n"}
{"id": "6113754", "url": "https://de.wikipedia.org/wiki?curid=6113754", "title": "Philips P2000", "text": "Philips P2000\n\nDie P2000-Desktop-Serie war nach dem Videopac G7000 der erste Versuch von Philips, auf dem Heimcomputer-Markt Fuß zu fassen. Im März 1980 wurden die beiden Versionen P2000M und P2000T veröffentlicht.\n\nDer Hauptunterschied zwischen den beiden Versionen lag im Video-Interface. Die T-Version, welche für den Heim- und Ausbildungsbereich vorgesehen war, konnte an einen Fernseher oder an einen RGB-Monitor angeschlossen werden. Der Videochip dieser Version war ein Chip für Teletext, was wohl relativ günstig war, aber die Grafikfähigkeiten doch sehr einschränkte. Die professionellere M-Version hatte eine zusätzliche 80-Zeichen-Karte, wodurch man sie an einen monochromen Monitor anschließen konnte. Diese Version wurde zusammen mit einem Monitor vertrieben, in dessen Gehäuse auch zwei 5,25\"-Diskettenlaufwerke Platz fanden. Hiermit konnte auch CP/M als Betriebssystem gefahren werden. Es gab keine eingebaute Programmiersprache, da das ROM von 4 kB nur ein Grundsystem und einige Ein- & Ausgaberoutinen beinhaltete. Zwei Plätze für Steckmodule erlaubten es, den Computer um ROM-Module (Steckplatz 1) oder Schnittstellen-Karten (Steckplatz 2), wie Modem oder eine Druckerschnittstelle, zu erweitern. Auch ein BASIC konnte über solch ein Steckmodul nachgerüstet werden. Durch die unterschiedlichen Videointerfaces waren die T- und die M-Version nicht 100 % zueinander kompatibel.\n\nProgramme und Daten konnten auf einem eingebauten Mini-Kassettenlaufwerk mit einer Kapazität von 42 kB gespeichert werden. Dieses Laufwerk wurde vom Benutzer aus wie ein Diskettenlaufwerk mit automatischer Suche nach einem Programm (CLOAD-Befehl) und Ermittlung des zur Verfügung stehenden freien Speichers (CSAVE-Befehl) gesehen. Ein Befehl erlaubte es, das Inhaltsverzeichnis einer Kassette anzeigen zu lassen.\n\nDie P2000 hatten in Europa keinen großen Erfolg. Die Fertigung der Computer fand in Österreich statt. Eine gewisse Verbreitung fanden die Computer in niederländischen und deutschen Schulen.\n\n\n"}
{"id": "6114126", "url": "https://de.wikipedia.org/wiki?curid=6114126", "title": "Thomson TO7-70", "text": "Thomson TO7-70\n\nDer Thomson TO7-70 war ein Heimcomputer aus Frankreich, der in Deutschland nur gering verbreitet war. Er war der Nachfolger des Thomson TO7.\n\nAls Besonderheit hatte er unter einer Klappe oberhalb der Tastatur einen Lichtgriffel untergebracht. Dieser wurde sogar vom Betriebssystem von Anfang an unterstützt. So konnte man mit ihm gleich nach dem Anschalten, je nach eingelegten Modulen und angeschlossenen Peripheriegeräten, zwischen verschiedenen Menüpunkten (z. B. Lichtgriffel kalibrieren, BASIC oder Kassette) auswählen. Links neben der Tastatur war ein Schacht für Steckmodule, welcher durch eine Klappe geschützt war. Diese wurde durch einen Drucktaster geöffnet und ließ sich gegen unbeabsichtigtes Öffnen durch einen Schiebeschalter verriegeln. Eine Programmiersprache war nicht eingebaut, jedoch war ein BASIC-Modul im Lieferumfang enthalten.\n\n\n"}
{"id": "6114814", "url": "https://de.wikipedia.org/wiki?curid=6114814", "title": "Microsoft KIN", "text": "Microsoft KIN\n\nKin (auch oft als KIN geschrieben) ist eine Mobiltelefonfamilie von Microsoft, die bei Verizon Wireless erhältlich war. Nach langer Entwicklungszeit und hohen Kosten erschien es im Mai 2010 und wurde als „naher Verwandter“ (engl. \"kin\" = verwandt) zu Windows Phone 7 bezeichnet. Eigentlich sollte das Kin auch in Europa verkauft werden, jedoch wurden diese Pläne nach schlechten Absatzzahlen in den USA verworfen. Seitdem wurde das Kin-Team in das Windows-Phone-7-Entwicklungsteam integriert und die Werbung für das Kin gestoppt. Das Kin wurde von Microsoft entwickelt und von Sharp hergestellt. Es wurde als besonders geeignet für soziale Netzwerke beworben und für eine Zielgruppe zwischen 15 und 30 Jahren geplant.\n\nDas Kin war das Ergebnis einer zweijährigen Entwicklungsarbeit bei Microsoft, die mit dem Aufkauf von Danger Inc begann, das schon das \"Danger Hiptop/T-Mobile Sidekick\" entworfen hatte. Kin OS basiert auf Windows CE.\n\nZunächst war das Kin-Projekt unter dem Codenamen \"Project Pink\" bekannt und wurde unter der Führung des Microsoft-Managers J Allard begonnen. 2008 wurde Danger Inc. für etwa 500 Millionen US-Dollar von Microsoft aufgekauft.\n\nDas Kin selbst wurde in Microsofts \"Premium Mobile Experiences\"-(PMX)-Abteilung entwickelt, und zwar durch eine Arbeitsgruppe, die auch Angestellte von Danger Inc. beinhaltete. Hardwarehersteller waren zunächst angeblich begeistert von Kin, und konkurrierten um eine Mitgliedschaft im Kin-Projekt.\n\nDie „Enthüllung“ des Kin begann mit dem Einladen ausgewählter Journalisten für ein geheimes Treffen in San Francisco am 12. April 2010. Auf den Einladungen für das Event, von dem wenig später bestätigt wurde, dass es um das \"Project Pink\" ging, stand \"It’s time to share\" (\"Es ist Zeit, zu teilen\"). Die Veranstaltung selbst fand schließlich im Nachtclub \"Mighty\" statt und beinhaltete einen Auftritt von Robbie Bach, dem Chef von Microsofts Entertainment- und Mobilfunksparte.\n\nDas Kin litt sehr unter nur schwachen Verkaufszahlen, sodass Microsoft-Manager der New York Times davon berichteten, dass sie von der fehlenden Werbung durch Verizon-Mitarbeiter sehr erschreckt worden seien. Schon nach 48 Tagen auf dem Markt stellte Microsoft die Kin-Serie am 30. Juni 2010 ein. Die Pläne für eine Europa-Einführung bei Vodafone wurde verworfen.\n\nDas Kin ONE und TWO sind inzwischen wieder als sogenannte „Feature Phones“ auf dem Markt – Telefone, die von den Funktionen her zwischen normalem Handy und echtem Smartphone einzuordnen sind. Diese neuen Kins bekommt man ohne Vertrag und jetzt als „Kin ONEm“ bzw. „Kin TWOm“. Verizon bestätigte am 18. November 2010 die Wiederaufnahme der Kin-Verkäufe, wobei die Geräte bis Dezember 2010 nicht in den Geschäften verfügbar waren.\n\nMicrosoft bezeichnet die Kin-Serie als \"Social Phones\". Das Kin legt Schwerpunkte auf Social Networking und das sog. Teilen von Inhalten (z. B. Bilder, Videos etc.) im Internet, besitzt jedoch keine Möglichkeit, \"Apps\" zu installieren.\n\nDer Startbildschirm des Kin heißt \"Loop\" und zeigt eine Zusammenstellung der Neuigkeiten aus Quellen wie RSS-Webfeeds, Twitter, Facebook, MySpace etc. an.\n\nIn Kritiken wurde oft als negativ erwähnt, dass das Kin nur alle 15 Minuten die Zusammenstellung aktualisiert, ohne dass der Nutzer dieses Intervall ändern könnte. Der Nutzer kann jedoch einen „Aktualisieren“-Knopf auf dem Display drücken, um die Informationen zu aktualisieren. Microsoft begründet dieses Verhalten mit einer Verkürzung der Batterielaufzeit und unausgegorenen APIs der Netzwerkbetreiber. Außerdem wird spekuliert, dass Microsoft erst durch diese „Funktion“ Verizon überzeugen konnte, niedrigpreisige Tarife für das Kin anzubieten, um die Teenager-Zielgruppe erreichen zu können.\n\nDas Kin unterstützt das Hochladen von Fotos auf Twitpic, Facebook, etc. nicht; genauso wenig das \"Retweeten\", Ansehen der Updates einer einzelnen Person oder das direkte Öffnen von Links aus Twitter-Nachrichten. Auch dies könnte sich durch die Ermöglichung billiger Datentarife erklären lassen.\n"}
{"id": "6117993", "url": "https://de.wikipedia.org/wiki?curid=6117993", "title": "GeoNetwork opensource", "text": "GeoNetwork opensource\n\nGeoNetwork opensource ist eine Metadaten-Informationssystem-Software für Geodaten. Sie zeichnet sich aus durch Konformität zu Standards ISO/TC211 sowie des Open Geospatial Consortiums (OGC) und implementiert den Web Catalogue Service (CSW) 2.0.2. Als Projekt der Open Source Geospatial Foundation ist das Programm freie Software.\n\nBei der Entwicklung von GeoNetwork wird viel Wert auf die Einhaltung offener Standards gelegt, um die Interoperabilität mit anderen Anwendungen zu ermöglichen. Die Server-Software ist in Java programmiert.\n\nDie Software findet Verwendung als Suchdienst bei der Ernährungs- und Landwirtschaftsorganisation der Vereinten Nationen sowie seit 2009 in der Nationalen Geodateninfrastruktur der Schweiz (GDI-CH).\n\n"}
{"id": "6118647", "url": "https://de.wikipedia.org/wiki?curid=6118647", "title": "HiCAD", "text": "HiCAD\n\nHiCAD ist ein durchgängiges 2D-/3D-CAD-System des Herstellers ISD Software und Systeme GmbH. HiCAD basiert auf dem Software-Kern ESM (European Solid Modeller), einer Eigenentwicklung des Unternehmens.\n\nDie Software ist modular aufgebaut. So sind unter anderem verschiedene Branchenlösungen verfügbar: Maschinenbau, Stahlbau, Metall-/Glas-/Fassadenbau, Anlagenbau und Blechbearbeitung. Alle Branchenfunktionen sind in die Oberfläche integriert und müssen nicht als Zusatzapplikationen gestartet werden. Da alle HiCAD-Module mit den gleichen Datenstrukturen arbeiten, lassen sich mit dieser Hybrid-Technologie komplexe, branchenübergreifende Projekte realisieren.\n\nHiCAD ist ein durchgängiges System, das sowohl die 2D-Konstruktion als auch die 3D-Modellierung unterstützt. Die Konstruktionsmethode kann außerdem frei gewählt werden zwischen der parametrischen und der freien bzw. direkten Konstruktion.\n\nDie aktuelle Version ist HiCAD 2019. Zu den Neuerungen zählen deutlich verbesserte Skizzenfunktionalität – unverzichtbar bei der Erzeugung und Modellierung von 3D-Modellen, der Einbau von Vernietungen, die Erweiterungen bei der Simulation, Schweißsymbole nach DIN EN ISO 2553, Prüfung der Spiegelsymmetrie beim Wiederholen von 3D-Modellen, das neue Ankanten von Skizzen in der Blechbearbeitung, der neue Treppenkonfigurator auf Basis von Designvarianten im Stahlbau, der Prüfstatus für die Stahlbau Verwaltung + BIM (Zeichnungsverwaltung), der automatische Einbau von Flanschverschraubungen im Anlagenbau und vieles mehr.\n\n\n\nSTEP, IGES, CATIA, Parasolid, Acis, DWG, DXF, ISF, DSTV, SDNF und andere.\n\nDas Unternehmen wurde 1977 gegründet. Der Hauptsitz und Entwicklungsstandort befinden sich im Dortmunder Stadtteil Barop. Darüber hinaus unterhält die ISD Tochtergesellschaften unter anderem in der Schweiz, den Niederlanden und in Österreich.\n\nWeiteres Produkt: HELiOS (PDM)\n\n\n\nAnwenderforen:\n\nUserclubs\n\n"}
{"id": "6125817", "url": "https://de.wikipedia.org/wiki?curid=6125817", "title": "Sublime Text", "text": "Sublime Text\n\nSublime Text ist ein proprietärer Texteditor für Microsoft Windows, Linux und macOS.\n\nSublime Text wurde in C++ und Python geschrieben.\n\nDie erste Version von Sublime Text wurde im November 2007 präsentiert und war nur unter Windows lauffähig.\n\nEine Besonderheit von Sublime Text ist die Bedienoberfläche, die mit verschiedenen Farbschemata gestaltet werden kann. Fast sämtliche GUI-Elemente sind ausblendbar und es gibt einen Vollbildmodus, so dass Sublime Text zum ablenkungsfreien Editieren (engl. \"distraction-free editing\") verwendet werden kann.\n\nEs ist möglich, mehrere Dateien gleichzeitig anzuzeigen; hierfür kann das Editorfenster in mehrere Zeilen und Spalten aufgeteilt werden, wobei jedes „Feld“ wiederum mehrere Tabs haben kann. Dem Benutzer steht zudem eine „Minimap“, eine visuelle Übersicht über die gerade aktive Datei, zur Verfügung, so dass die Navigation in langen Quellcodes oder Texten erleichtert wird.\n\nAufgrund der Python-Integration ist Sublime Text nahezu beliebig erweiterbar. Das Programm eignet sich sowohl für Reintext als auch für Programmcode, es unterstützt Syntaxhervorhebung ebenso wie die Verwendung von Makros. Auch Codevervollständigung und die Integration eines Compilers sind möglich.\n\nAm 17. September 2010, vier Tage nach der Veröffentlichung von Sublime Text 1.4, wurde bekannt, dass der Entwickler beabsichtigte, die kommende Version unter dem Codenamen „Sublime Text X“ von Grund auf neu zu entwickeln. Am 28. Januar 2011 wurde die erste öffentliche Alphaversion des Programms, das nun „Sublime Text 2“ hieß, freigegeben. Die erste Betaversion trägt die Buildnummer 2111 und wurde am 31. August 2011 veröffentlicht. Die finale Version 2.0 erschien am 26. Juni 2012.\n\nIn Version 2 ist Sublime Text erstmals auch unter Linux und Mac OS X lauffähig. Eine wesentliche Neuerung ist „Goto Anything“ (\"Gehe zu irgendetwas\"), ein via Tastenkürzel erreichbarer Dialog, der einen Sprung in eine andere Datei oder innerhalb des gerade geöffneten Dokuments zu einer bestimmten Funktion, einer bestimmten Zeile oder einem bestimmten Symbol erlaubt. Außerdem wurde das Format von Projektdateien geändert, und es wurden einige kleinere Änderungen vorgenommen.\n\nAm 3. August 2011 wurde zusammen mit der Betaversion 2.0 build 2096 das Plugin \"vintage.py\" veröffentlicht, das die Bedienung des Texteditors vi weitgehend emuliert; so ist auch das modale Editieren (Befehlsmodus, Eingabemodus, visueller Modus) möglich. Dieses Plugin ist standardmäßig deaktiviert.\n\nAm 29. Januar 2013 veröffentlichte Jon Skinner die erste Betaversion von Sublime Text 3. Die finale Version wurde am 13. September 2017 veröffentlicht.\n\nMit Sublime Text 3 wurde ein neues API, basierend auf Python 3, eingeführt, wodurch bestehende Plugins teilweise oder komplett neu geschrieben werden mussten. Ein weiterer Fokus bei der Entwicklung lag auf Geschwindigkeit; so ist Sublime Text 3 in der Lage, alle Dateien eines Projekts mittels Symbolindizierung zu durchsuchen, um schnelleren Zugriff auf bestimmte Funktionen zu ermöglichen. Ab der Entwicklerversion 3127 unterstützt Sublime Text auch unter Windowssystemen Toucheingabe sowie eine hohe Punktdichte.\n\n\n"}
{"id": "6126703", "url": "https://de.wikipedia.org/wiki?curid=6126703", "title": "Rio (Film)", "text": "Rio (Film)\n\nRio ist ein US-amerikanischer Animationsfamilienfilm in 3D der Blue Sky Studios und wurde in Co-Produktion mit 20th Century Fox produziert. In die deutschen Kinos kam der Film am 7. April 2011.\n\nDie letzten beiden Spix-Aras sollen den Fortbestand ihrer Art sichern. Der männliche Blu wuchs in Gefangenschaft auf und ist flugunfähig, die weibliche Jewel konnte vor Schmugglern gerettet werden. Beim ersten Treffen der beiden werden sie erneut von Schmugglern gefangen genommen. Sie können fliehen, müssen sich aber aneinandergekettet durch Rio de Janeiro schlagen.\n\nDer Hauptcharakter Blu ist das letzte Männchen seiner Gattung der Spix-Ara, der als Jungtier von Schmugglern aus seiner Heimat Rio de Janeiro gebracht wurde und mittlerweile bei der Buchhändlerin Linda in Minnesota lebt. Eines Tages kommt der Ornithologe Tulio in die Kleinstadt Moose Lake und erklärt Linda, dass Blu benötigt würde, um seine Art zu retten. Diese willigt ein und fliegt mit Blu nach Rio de Janeiro.\n\nDort angekommen, kommt Blu in eine Voliere mit seiner letzten Artgenossin, der freiheitsliebenden, rebellischen Jewel, deren Gedanken nichts mit der Rettung ihrer Art, sondern einzig und allein mit Flucht zu tun haben. Nachts werden die beiden Aras mithilfe des Gelbhaubenkakadus Nigel von dem Straßenjungen Fernando gestohlen und zu Vogelschmugglern gebracht. Von dort aus können sie fliehen, wobei Blu Jewel gestehen muss, nie fliegen gelernt zu haben. Mithilfe des Riesentukans Rafael, den sie im Urwald treffen, machen sie sich auf den Weg zu Luiz, einer Bulldogge, die dabei helfen soll, die Ketten, mit denen Jewel und Blu aneinander gekettet sind, loszuwerden, damit sich ihre Wege wieder trennen können.\n\nUnterwegs treffen sie auf den Graukardinal Pedro und seinen Kumpel, den Gelbbauchgirlitz Nico, von denen sie fortan begleitet werden. Rafael, Pedro und Nico versuchen immer wieder, das ungleiche Paar zusammenzuführen. Das Oberhaupt der Schmugglerbande will die Tiere unter keinen Umständen einfach ziehen lassen, da sie reich werden wollen. Also schickt er Nigel los, um sie wieder einzufangen.\n\nWährend des Filmes muss sich Blu einem inneren Konflikt (ob Minnesota seine wahre Heimat sein kann), einer Bande diebischer Marmosettenaffen und seiner Flugangst stellen. Nachdem er Luiz erreicht hat und die Ketten gelöst sind, fliegt Jewel hoch in die Luft und wirbelt dort oben mit den anderen umher, während Blu sie nur vom Boden aus beobachten kann. Daraufhin stürmt er frustriert davon, wobei Jewel ihn aufhalten will. Es kommt zu einem Streit. Sie ziehen in entgegengesetzte Richtungen. Jewel, die weit weg fliegen möchte, um ihren Schmerz zu verdrängen, wird in der Luft von Nigel aufgegriffen und sogleich zu den Vogelschmugglern gebracht. Die Augenzeugen Nico und Pedro, welche sofort zu Blu fliegen, der in Begleitung von Rafael seine Besitzerin Linda sucht, erzählen ihm von der Entführung. Blu eilt mit Pedro, Nico, Rafael und Luiz sofort zur Rettung seiner Freundin, die im Trubel des Karnevals in einem Paradewagen festgehalten wird. Dort laufen sie Linda und Tulio, verkleidet als Spix-Aras, über den Weg, die Blu und Jewel hier vermuteten. Blu entschließt sich jedoch dazu, zunächst Jewel zu befreien.\n\nBlu und seine gefiederten Freunde werden jedoch ebenfalls gefangen genommen und werden, gesperrt in Käfige, am Flugplatz in ein kleines Flugzeug verladen. Linda, die einen Paradewagen gestohlen hat und mit Tulio zu dem Flugplatz eilt, kommt um Sekunden zu spät und das Flugzeug hebt ab. Auf dem Weg kann Blu seinen und die Käfige der anderen gefangenen Tiere aufbrechen, da er keine Schwierigkeiten mit dem Öffnen von Sperrvorrichtungen hat. Die Vögel können alle fliehen, während Blu und Jewel noch von Nigel aufgehalten werden. Während des letzten Kampfes, bei dem Blu Nigel endgültig besiegt, wird Jewels Flügel gebrochen. Die nun flugunfähige Jewel stürzt aus dem Flugzeug, Blu springt ihr aus Liebe hinterher und schafft es auf den letzten Metern vor dem Aufprall, die Flügel auszubreiten und sich und Jewel zu retten, indem er endlich fliegt.\n\nMit Jewel in den Klauen fliegt er zurück zum Flugplatz, wo Linda noch schluchzend in den Armen Tulios liegt; sie hatte bereits jegliche Hoffnung verloren. Am Ende bleibt Linda bei Tulio in Rio, sie nehmen Fernando auf und arbeiten miteinander als Tierschützer. Blu und Jewel haben mittlerweile eine Familie gegründet.\n\n\"Rio\" hat bei Produktionskosten von 90 Millionen US-Dollar weltweit rund 483,9 Millionen US-Dollar eingespielt und ist damit einer der erfolgreichsten Filme 2011.\nIn Deutschland wurden bundesweit 1.752.119 Besucher an den Kinokassen gezählt; der Film belegt damit den 21. Platz der meistbesuchten Kinofilme 2011.\n\nDer Film erhielt größtenteils positive Kritiken. Bei Rotten Tomatoes fielen 72 % von 145 Kritiken positiv aus. Bei IMDb erreichte er (mit 7,0/10) eine gute Bewertung. Bei Metacritic bekam er eine Durchschnittswertung von 63 % basierend auf 29 Kritiken.\n\nDer Film wurde von der Deutschen Film- und Medienbewertung (FBW) mit dem Prädikat \"wertvoll\" ausgezeichnet.\n\nDie deutsche Synchronisation entstand nach einem Dialogbuch von Klaus Bickert unter der Dialogregie von Frank Schaff im Auftrag der Berliner Synchron.\n\nDie Fortsetzung Rio 2 wurde im Januar 2012 von Sérgio Mendes erstmals erwähnt und erschien im Frühjahr 2014.\n\n"}
{"id": "6132521", "url": "https://de.wikipedia.org/wiki?curid=6132521", "title": "Scrat’s Continental Crack-Up", "text": "Scrat’s Continental Crack-Up\n\nScrat’s Continental Crack-Up ist ein computeranimierter Kurzfilm der Blue Sky Studios und wurde von 20th Century Fox vertrieben. Der Film ist ein Ableger von Ice Age und handelt von Scrat und wurde als Vorfilm zu Gullivers Reisen – Da kommt was Großes auf uns zu sowohl in 2D, als auch in 3D in den Kinovorstellungen gezeigt. Da Gullivers Reisen erst 2011 in den deutschen Kinos erschien, kam auch \"Scrat’s Continental Crack-Up\" 2011 in die Kinos.\n\nDas Hörnchen Scrat lebt in der Eiszeit. Der Film beginnt damit, dass Scrat an der Eisplatte eines Berges entlang schnüffelt, um einen Ort zu finden, an dem er seine Eichel sicher verstecken kann. Als er sie ins Eis stecken will, öffnet sich eine Spalte. Daher nimmt Scrat die Eichel wieder heraus und verriegelt das Eis mit Schnee, um Schlimmeres zu vermeiden.\n\nBei seinem zweiten Versuch scheitert er abermals – obwohl er es vorsichtiger macht. Diesmal bricht allerdings das Eis und der Berg teilt sich. Scrat fällt nach unten, am Dinosaurier Rudy und seinem Reiter Buck, im Dschungel unter der Erde vorbei. Er versucht sich zwar an der Felswand festzuhalten, doch durch die Reibung fangen seine Pfoten an zu glühen. Als er versucht sie auszupusten, gerät er in einen Feuerball. Über die Erdkruste fliegt Scrat, durch den Erdmantel nach unten bis zum Erdkern, der sich als ein fester Metallkern entpuppt.\n\nDaraufhin sieht man die Erde vom Weltraum aus, wie sie vor einer langen Zeit aussah. Scrat versucht, an seine Eichel heranzukommen, jedoch rollt sie ihm davon. Um sie zu fassen, rennt Scrat los, doch rollt auch die Eichel weiter. Dabei entstehen die Kontinente in der heutigen Form: erst Australien, dann Afrika.\n\nAls sich dieser Kontinent trennt, fressen die Giraffen von den sich trennenden Kontinenten die Baumblätter. Dabei müssen sie aber ihre Hälse immer weiter strecken, sodass es zu Mutationen kommt. Als Europa entsteht, spielt der Stiefel Italien eine ballförmige Insel zwischen Europa und Afrika vorbei – daraufhin ertönt ein Torruf.\n\nScrat verliert das Gleichgewicht und gerät ins Schleudern, sodass er immer wieder zwischen einem ebenfalls festen Erdmantel und dem Erdkern stößt. Als Folge entstehen Bauwerke wie die Große Sphinx von Gizeh. Wieder im Gleichgewicht fängt er die Eichel auf.\n\nSein Körper verhakt sich dabei im Kern und sein Kopf schleudert diesen mit den Armen und der Nuss gegen den felsigen Erdmantel. Schließlich hört sich der Kern auf zu drehen, doch durch Scrats elastischen Körper dreht sich dieser anschließend wieder in die andere Richtung. Er fliegt dadurch aus dem Erdinneren hinaus in den Himmel, wobei die Kontinente noch am entstehen sind.\n\nBei der Landung fällt er kopfüber auf eine einsame Eisscholle im Meer. Durch den Aufprall trennt sich diese – auf der einen Seite die Eichel, auf der anderen Scrat. In der abschließenden Szene versucht Scrat verzweifelt, seine Eichel zu bekommen.\n\nDer Film war sowohl Marketing für \"Gullivers Reisen – Da kommt was großes auf uns zu\" als auch zu \"Ice Age 4: Voll verschoben\", der 2012 in die Kinos kam. Ebenso als Vorschau für den letztgenannten Film ist die Fortsetzung \"\", die beide in den vollendeten Film eingebaut wurden.\n"}
{"id": "6138691", "url": "https://de.wikipedia.org/wiki?curid=6138691", "title": "Knick Knack", "text": "Knick Knack\n\nKnick Knack (engl. für \"Nippes, Schnickschnack\") ist ein knapp vierminütiger, animierter Kurzfilm, der 1989 von Pixar produziert wurde. Es war Pixars erste Produktion in 3D. Die Handlung wird von einem Scat-Stück begleitet, das vom Jazz-Vokalisten Bobby McFerrin komponiert und interpretiert wurde.\n\nAuf einem Regal stehen einige Souvenirs aus sonnigen Urlaubsländern und bewegen sich leicht zum Klang der karibisch anmutenden Hintergrundmusik. Etwas abseits steht eine Schneekugel aus dem kalten Nome, Alaska. Der einsame Schneemann in der Kugel wird auf die Feiernden aufmerksam, als ihn ein Mitbringsel aus dem ‚Sonnigen Miami‘, eine attraktive Frau im Bikini, zu sich herüberwinkt. Allerdings muss er feststellen, dass er in der Schneekugel gefangen ist. Er unternimmt nun verschiedene Ausbruchsversuche: der Iglu aus der Kugel scheitert als Rammbock, seine Karottennase verbiegt sich, als er sie als Meißel benutzt. Der Einsatz eines Presslufthammers bringt ihn seinem Ziel auch nicht näher, sorgt aber dafür, dass die Kohlestückchen, die seine Gesichtszüge bilden, herunterfallen. Ein gezündeter Schneidbrenner wirbelt ihn nur mehrfach durch sein Gefängnis. Die zuletzt eingesetzte Sprengladung beschädigt zwar auch nicht das Glas, rückt die Schneekugel aber gefährlich nahe an den Rand des Regals. Als der Schneemann sich etwas vorbeugt, um nach unten zu blicken, stürzt die Kugel ab. Im freien Fall bemerkt er einen Notausgang im Boden der Kugel und entkommt durch diesen seinem Kerker, nur um in einem Goldfischglas zu landen. Kurzfristig frustriert von der Situation, erblickt er ein Urlaubssouvenir aus dem ‚Sonnigen Atlantis‘, eine Meerjungfrau, sehr ähnlich der Dame aus Miami. Doch bevor er zu ihr gelangen kann, sinkt die Schneekugel auf den Boden des Glases und nimmt ihn wieder gefangen.\n\nNach dem technisch aufwendigen Tin Toy wollte Regisseur John Lasseter einen cartoonartigen Film im Stil von Chuck Jones oder Tex Avery machen. Daher wirkt \"Knick Knack\" durch die einfachen geometrischen Formen und glatten Oberflächen im Vergleich eher simpel animiert.\n\nEs existieren zwei Versionen von \"Knick Knack\", die beide jeweils in 2D und 3D veröffentlicht wurden. Die ursprüngliche Fassung wurde zuerst auf der SIGGRAPH 1988 in 3D gezeigt, sowie in 2D auf der Tiny-Toy-Stories-VHS-Kassette. Als Vorfilm von Findet Nemo wurde 2003 eine digital überarbeitete Version veröffentlicht, bei der die Brüste der weiblichen Hauptpersonen deutlich verkleinert wurden und die Meerjungfrau ein Bikinioberteil aus Muscheln anstatt der ursprünglichen Seestern-Pasties trägt. John Lasseter begründete dies mit seiner Verantwortung als Vater. Eine 3D-Ausgabe der neuen Version findet sich auf der Disney-Digital-3D-Veröffentlichung von \"The Nightmare Before Christmas\" aus dem Jahr 2006.\n\nAuszeichnung in der Kategorie \"Best Short Film\" beim \"Seattle International Film Festival 1990\". Im Jahr 2001 wählte Terry Gilliam \"Knick Knack\" zu einem der zehn besten Trickfilme aller Zeiten.\n"}
{"id": "6140909", "url": "https://de.wikipedia.org/wiki?curid=6140909", "title": "Anonymous (Kollektiv)", "text": "Anonymous (Kollektiv)\n\nAnonymous (amerikanisch-englische Aussprache [], vom griechischen ανώνυμος \"anonymos\" für „namenlos“) ist ein Internetphänomen, das weltweit von verschiedenen Gruppen und Einzelpersonen innerhalb der Netzkultur verwendet wird, um – mit oder ohne Abstimmung mit anderen – unter diesem Namen Hacktivismus und öffentliche Demonstrationen zu betreiben und über verschiedene Internetplattformen zu veröffentlichen.\n\nAnfangs als Spaßbewegung aus dem Imageboard \"4chan\" hervorgegangen, trat Anonymous seit 2008 zunehmend politisch mit Protestaktionen für die Redefreiheit, die Unabhängigkeit des Internets und gegen das Urheberrecht, Schriftsteller und verschiedene Organisationen, darunter \"Scientology\", staatliche Behörden, global agierende Konzerne, Urheberrechtsgesellschaften und auch in internationalen sozialen Problemfällen in Erscheinung. Die Teilnehmer agierten anfangs nur im Internet, mittlerweile betreiben sie ihre Aktivitäten auch außerhalb des Internets. Aktionsmittel von Anonymous sind unter anderem Demonstrationen und Hackerangriffe. Bei öffentlichen Kundgebungen treten die Aktivisten zu einem erheblichen Teil mit Gesichtsmasken auf, die zu einer Art Markenzeichen der Bewegung geworden sind. Diese stellen den britischen, katholischen Attentäter Guy Fawkes dar und sind dem dystopischen Polit-Comic \"V wie Vendetta\" entlehnt, in dem die so maskierte Hauptfigur ein unterdrückerisches Regime bekämpft.\n\nDie Wurzeln von \"Anonymous\" liegen vornehmlich in sogenannten Imageboards, auf denen alle unzensiert und unmoderiert Bilder und Botschaften hinterlassen können, wobei auch ein Name angegeben werden kann. Allerdings tut das kaum jemand, weswegen die meisten Beiträge mit dem Namen „Anonymous“ gekennzeichnet sind. So stammt der Name des Kollektivs wahrscheinlich daher, dass – je nach technischer Voreinstellung – bei unangemeldeter Benutzung sämtliche Einträge in den Imageboards mit „Anonymous“ gekennzeichnet werden. Mit der Zeit erlangte diese Art der Veröffentlichung den Status eines Internetphänomens. Die teilnehmenden Nutzer werden abgekürzt als „Anon“ bezeichnet.\n\nTypisch für \"Anonymous\" sind die der Graphic Novel \"V wie Vendetta\" von Alan Moore und David Lloyd entnommenen Masken, die ursprünglich das Gesicht des britischen Freiheitskämpfers Guy Fawkes darstellen sollen. Diese dienen sowohl als Erkennungszeichen als auch zur Anonymisierung und im Zuge der Protestaktionen auch zum Schutz vor Verfolgung durch \"Scientology\" im Rahmen ihrer sogenannten \"Fair Game Policy\". David Lloyd, der Illustrator des Comics, begrüßt, dass die Menschen „seine“ Maske für diesen Protest nutzen. Sie sei zu einem Sinnbild des Protestes gegen die Tyrannei geworden. Im Internet werden zur Verbreitung von Informationen an die Öffentlichkeit häufig Videos auf \"YouTube\" eingestellt.\n\nAm Ende von Botschaften von \"Anonymous\" und auf der Website des Kollektivs findet sich meist folgendes Motto:\n\nDieses Motto wird auch abgewandelt oder erweitert, so können zusätzlich Menschenrechtsverletzungen oder Informationsfreiheit angesprochen sein, etwa mit dem Satz „Knowledge is free.“\n\n\"Anonymous\" bestand im Anfangsstadium größtenteils aus Benutzern von diversen Imageboards und Internetforen. Zusätzlich wurden zur Organisation verschiedene Wikis und Internetchats aufgestellt, um noch mehr Raum im Internet auszunutzen. Über diese Plattformen werden Proteste wie \"Projekt Chanology\" organisiert.\n\nInsgesamt ist \"Anonymous\" eine lose Verbindung von Internetnutzern, die im virtuellen Raum vor allem auf Webseiten wie \"711chan\", \"420chan\", \"4chan\", \"Something Awful\", \"Fark\" oder \"Encyclopedia Dramatica\" anzutreffen sind.\nSoziale Netzwerke wie \"Facebook\" spielen eher eine Nebenrolle, werden aber zur Bildung sogenannter Zellen benutzt, die sich dann zu realen Protesten mobilisieren lassen.\n\"Anonymous\" hat keine Anführer oder kontrollierenden Instanzen und basiert auf der kollektiven Kraft seiner individuellen Teilnehmer und dem Vorteil, dass Informationen über das Internet schnell verbreitet werden können. Manche Websites bestimmen zwar, dass nur Erwachsene ab 18 Jahren die Inhalte betrachten sollten, da es aber keine sichere Möglichkeit gibt, jüngere Besucher zu blockieren, sind auch manche „“ minderjährig.\n\nEs existieren weder eine Führung noch eine Mitgliedschaft im administrativen Sinne, und das Mitwirken ist dadurch völlig unverbindlich. Es gibt keine zentrale organisatorische Struktur oder Hierarchie, die für alle Mitglieder des Kollektivs in irgendeiner Form bindend wären. Es handelt sich also bei \"Anonymous\" nicht um eine Organisation im herkömmlichen Sinn, sondern eher um eine Bewegung. Jeder Aktivist kann also frei nach Belieben entscheiden, was er tun möchte. Dies könnte auch von Kriminellen ausgenutzt werden.\n\nAnfangs beschränkte sich \"Anonymous\" in seinen Forderungen hauptsächlich auf das Verbot der \"Church of Scientology\" und deren Praktiken und Institutionen. Der Glaube der Scientologen oder anderer Organisationen sollte dabei nicht angegriffen werden.\n\nIn letzter Zeit richtet sich \"Anonymous\" immer mehr gegen Internetzensur sowie vom Staat ausgehende Zensur.\nDies kann man vor allem an den Ereignissen in Australien erkennen, bei denen Mitglieder von \"Anonymous\" Websites der australischen Regierung angegriffen haben, nachdem diese einem Gesetz zur Implementierung von Internetfiltern zugestimmt hatte.\n\"Anonymous\" fiel auch durch \"DDoS\"-Attacken gegen Finanzunternehmen wie \"PayPal\" sowie die Kreditkartenunternehmen \"Visa\" und \"Mastercard\", die zuvor dem Whistleblowerportal \"WikiLeaks\" den Zugang zu seinen Konten verwehrt, beziehungsweise diese gesperrt hatten, auf. Diese Attacken wurden danach auf Tunesien und Simbabwe ausgeweitet, da diese Länder drohten, „jeden zu verklagen, der \"WikiLeaks\"[-Dokumente] veröffentlicht“. Bei den Massenprotesten gegen die Gesetzesvorhaben ACTA und SOPA war Anonymous maßgeblich mitbeteiligt. Der 2013 aufgekommene Widerstand gegen bi- und multilaterale Freihandelsabkommen wie TTIP oder CETA wird ebenfalls von Anonymous unterstützt.\n\nGrundsätzlich erklärt \"Anonymous\" in diversen Videobotschaften stets, alle Menschenrechtsverletzer, Zensoren und Diktatoren als Ziele anzuvisieren. Jedoch herrscht hierzu kein Konsens, da es schlichtweg unmöglich scheint, alle sich dem Kollektiv zugehörig fühlenden Menschen darüber abstimmen zu lassen bzw. sie zu involvieren.\n\nDas Kollektiv Anonymous kommuniziert seine Ziele und Aktivitäten primär über soziale Netzwerke. Insbesondere der Nachrichtendienst Twitter wird verwendet, da sich dessen Betreiber durchgehend liberal gegenüber Anonymous verhalten haben und durch die Nutzung mehrerer Konten ohnehin auch keine dauerhafte Blockade von Anonymous praktikabel wäre. Einzig im Dezember 2012 kam es zu einer kurzen Sperre eines Anonymous-Profils, da über dieses private Daten verbreitet wurden.\n\nDie Gruppe erhielt weltweite Aufmerksamkeit in der Presse durch das \"Projekt Chanology\", das den internationalen Protest gegen \"Scientology\" unter einem Namen zusammenfasste.\n\nAm 14. Januar 2008 gelangte ein ursprünglich scientologyinternes Video, in dem Tom Cruise unkritisch über sich und Scientology redet, ins Internet und wurde auf YouTube hochgeladen. Scientology unterstellte YouTube daraufhin eine angebliche Verletzung des Urheberrechts und forderte die Beseitigung des Videos. Als Antwort darauf formulierte Anonymous das „Projekt Chanology“. Mitglieder des „Projekts Chanology“, die die Aktion von Scientology als Internetzensur bezeichneten, organisierten eine Reihe von „Denial-of-Service“-Angriffe gegen Scientology-Websites, woraufhin Scientology sich vom Sicherheitsdienstleister Prolexic schützen ließ. Anonymous ging danach zu anderen Protestformen wie Demonstrationen, Streichanrufen und Scherzpost via Fax zu verschiedenen Scientologyzentren über.\n\nAm 21. Januar 2008 erklärten einige Anonymous-Anhänger ihre Ziele und Absichten in dem auf YouTube hochgeladenen Video \"Message to Scientology\" und gaben eine Pressemitteilung heraus, in der sie „Scientology den Krieg erklärten“: gegen die Scientology-Kirche und das Religious Technology Center.\n\nIn der Pressemitteilung gibt die Gruppe an, dass die Attacken gegen Scientology weitergehen würden, um so die Redefreiheit zu schützen und die finanzielle Ausbeutung der eigenen Mitglieder durch Scientology zu beenden. Ein neues Video mit dem Namen \"Call to Action\" tauchte am 28. Januar 2008 auf YouTube auf, das zu Protesten vor Scientology-Zentren am 10. Februar 2008 aufrief. Am 2. Februar 2008 versammelten sich 150 Demonstranten vor einem Scientology-Gebäude in Orlando, Florida und riefen gegen deren Praktiken auf. Kleine Proteste wurden in Santa Barbara und Manchester abgehalten. Am 10. Februar 2008 demonstrierten zwischen 6000 und 8300 Menschen in 14 Ländern gegen Scientology. Viele Demonstranten vermummten sich, um Vergeltungsmaßnahmen durch Scientology zu unterbinden.\n\nAnonymous führte die zweite Protestwelle am 15. März 2008 in Städten überall auf der Welt, darunter Boston, Dallas, Chicago, Los Angeles, London, Paris, Vancouver, Toronto, Berlin und Dublin, durch. Die weltweite Anzahl der Teilnehmer wurde wiederum auf 7000 bis 8000 geschätzt. Die dritte Welle fand am 12. April 2008 statt. Die sogenannte „Operation Reconnect“ beabsichtigte es, die Aufmerksamkeit auf die scientologische Disconnection-Policy-Praxis zu steigern.\n\nAm 17. Oktober 2008 sagte ein 18-jähriger Anhänger von Anonymous aus, er bekenne sich als schuldig an der Beteiligung bei den Internetattacken auf Scientology vom Januar 2008.\n\nDie Proteste dauerten an und nutzten Veranstaltungen wie die Premiere des Tom-Cruise-Films \"Walküre\". Deren Ort wurde in Reaktion auf vorherige Proteste so gewählt, dass den Demonstranten möglichst wenig Bildfläche gegeben wurde.\n\nScientology reagierte auf den neuen „kopflosen“ Gegner ohne Führung, indem es kurz nach den Denial-of-Service-Attacken ein Video veröffentlichte. In diesem wurde behauptet, man hätte tausende von Morddrohungen, Bombendrohungen und belästigende Telefonanrufe erhalten.\nAngeblich sollten Anonymous-Mitglieder innerhalb von weniger als drei Wochen 8931 belästigende Anrufe getätigt, über 3,6 Millionen bösartige E-Mails verschickt und mehr als 114 Millionen Mal auf die Website zugegriffen haben.\n\nAuf das Video antwortete Anonymous mit Witzbotschaften, die das Video \"Anonymous Exposed\" aufgrund seiner angeblich maßlosen Übertriebenheit parodierten.\n\nUrsula Caberta, ehemalige Leiterin der \"Obersten Landesjugendbehörde\" und von 1992 bis 2010 Leiterin der Hamburger \"Arbeitsgruppe Scientology\", befürwortete in einem auf YouTube erschienenen Interview die Proteste und forderte zum Fortfahren mit friedlichen Protestaktionen gegen Scientology auf, die sie selbst für sehr wirksam hält. Aus ihrer Sicht seien die um einiges verstärkten Aussteigerzahlen in den USA auf die dort höhere Aktivität von Anonymous zurückzuführen. Von der Bewegung habe sie das erste Mal durch positive Resonanzen von Ex-Scientologen erfahren. Jedoch könne sie bei Anonymous aufgrund von Zeitmangel nicht mitwirken.\n\nDiese Aussage bezog sich nur auf die friedlichen Proteste gegen Scientology, nicht auf Aktionen wie die DDoS-Angriffe gegen Zahlungsdienstleister wie Visa und Mastercard, mit denen das Kollektiv erst später begann.\n\nAb September 2010 führten Mitglieder des Kollektivs im Rahmen der sogenannten „Operation Payback“ Distributed-Denial-of-Service-Angriffe auf die Websites von Rechteinhaberverbänden wie RIAA oder IFPI durch.\n\nIm Dezember 2010 wurde ein neues Ziel für die Angriffe ausgemacht: Zuerst wurden Geldinstitute wie Visa und Mastercard, die Konten der Whistleblowing-Plattform WikiLeaks gesperrt hatten, angegriffen. Später richteten sich die Angriffe auch gegen die niederländische Staatsanwaltschaft und Polizei, die zwei Teilnehmer der Aktion festnahmen.\n\nIm Januar 2011 wurden Regierungsseiten von Simbabwe und Tunesien attackiert, da juristische Schritte gegen den sogenannten „Indiskretions-Dienst WikiLeaks“ in beiden Ländern stattfänden. In einem Statement von Anonymous hieß es: „Wir greifen [Simbabwes Präsident] Mugabe und sein Regime der [Partei] Zanu-PF an, weil sie die freie Presse für vogelfrei erklärten und drohen, jeden zu verklagen, der WikiLeaks[-Dokumente] veröffentlicht.“\nEbenso drohte Anonymous, die Regierungsseiten Ägyptens zu attackieren, falls Kommunikationskanäle wie Twitter zensiert würden. Seit der Revolution in Tunesien wird sozialen Netzwerken eine wichtige Rolle bei der Organisation politisch motivierter Protestgruppen zugeschrieben. In dem Aufruf hieß es:\nIm Zuge der im Januar 2011 eingereichten Klagen von Sony gegen die Hacker George Hotz und Alexander Egorenkov, denen vorgeworfen wurde, Informationen zum Kopierschutzsystem der PlayStation 3 öffentlich gemacht zu haben, griff Anonymous ein.\n\nAnfang April 2011 kam es zu Angriffen auf die Websites des Konzerns und seines PlayStation Network, die jedoch wieder gestoppt wurden, da sie deren Kunden beeinträchtigten. Sie wurden unter dem Titel \"OPSony\" bekannt, teilweise jedoch auch der \"Operation Payback\" zugeordnet. Als zum Ende des Monats bekannt wurde, dass 77 Millionen Nutzerdaten des PlayStation-Networks bei einem Hackerangriff gestohlen wurden, erklärten allerdings Teile des Anonymous-Netzwerkes, nichts mit dem Angriff zu tun zu haben.\n\nAm 10. Juni 2011 nahm die spanische Polizei in Gijón drei mutmaßliche Aktivisten des Kollektivs fest. Sie sollen mit den Angriffen auf Sony und die Webpräsenzen verschiedener Regierungen in Verbindung stehen und die Führungsriege des spanischen Teils von Anonymous stellen. Zwei Tage später reagierte Anonymous mit einer DDoS-Attacke auf die Homepage der spanischen Polizei.\n\nAm 16. Juni 2011 gab das Kollektiv bekannt, die Angriffe gegen Sony einzustellen. Sie begründeten dies mit der Störung der Sony-Kunden, für die und für deren Rechte man sich einsetzen wolle.\n\nAnonymous-Aktivisten sammelten Informationen über das mexikanische Drogenkartell Zetas. Daraufhin entführte das Kartell offenbar einen Mitstreiter der Gruppe und drohte ihn zu töten, wenn die Namen veröffentlicht würden. Bis zum 5. November 2011 sollte das Anonymous-„Mitglied“ freigelassen werden, anderenfalls werde die Gruppe Namen und Adressen von Leuten im Netz veröffentlichen, die mit den Zetas zusammenarbeiten. Nach Angaben von Anonymous kam daraufhin das „Mitglied“ frei. Angeblich hatten die Zetas den Internet-Aktivisten damit gedroht, für jeden veröffentlichten Namen zehn Menschen umzubringen.\n\nNach der Freilassung will Anonymous nun auf die Veröffentlichung verzichten, schrieben Blogs, die der Gruppe zugeschrieben werden. Barret Brown, der als ehemaliger „Sprecher“ von Anonymous gilt, sagte, die mexikanischen Anonymous-„Mitglieder“, die die Aktion starteten, würden sehr vorsichtig vorgehen, um sich selbst zu schützen.\n\nSeit 2013 sammeln Anonymous-Aktivisten jedes Jahr für die kalte Jahreszeit Kleidung, Decken, Schlafsäcke und Lebensmittel, um diese direkt an bedürftige Obdachlose zu verteilen. Mittlerweile haben Anonymous-Aktivisten über eine sogenannte \"Anonymous WorldMap\" die jährlich stattfindende Charity dokumentiert. Neben Städten wie Stuttgart, Berlin oder München, beteiligen sich auch Orte in den USA, im Vereinigten Königreich und in anderen Ländern.\n\nIm September 2014 gab das Kollektiv auf Twitter bekannt, dass es unter dem Namen \"Operation Ice ISIS\" eine Cyberwar-Kampagne gegen die Terrororganisation Islamischer Staat (IS) betreibt. Ziel der Kampagne ist es, den Einfluss des IS auf soziale Medien zu verringern. Im Zuge dieser Aktion wurde eine größere Zahl an Accounts bei Twitter und Facebook aufgedeckt, übernommen oder unbrauchbar gemacht.\n\nAm 16. November 2015 – drei Tage nach Terroranschlägen in Paris mit über 130 Toten – kündigte Anonymous an, dass der IS, der sich zu den Anschlägen bekannt hatte, nicht ungestraft davonkommen dürfe, und erklärte ihm erneut den Krieg. Unter dem Namen \"Operation Paris\" unternimmt es das Kollektiv, die Internetauftritte der Terrororganisation unter anderem bei Twitter zu hacken.\n\n\n\"Anonymous.Kollektiv\" wurde ursprünglich als deutsche Facebook-Seite des Hacker-Netzwerks eingerichtet, aber seit 2012 nicht mehr von Anonymous betrieben. Nach Presseberichten hatte das Erfurter AfD-Mitglied Mario Rönsch die übrigen Seitenbetreiber damals verdrängt. Die Seite verbreitete fortan Rechtspopulismus, Verschwörungstheorien und Hetze gegen Migranten, Flüchtlinge und Muslime. Anonymous-Aktivisten distanzierten sich davon und klärten ihre Anhänger über die Hintergründe der Fälschung auf. Nachdem die „Likes“ für die gefälschte Seite seit November 2015 enorm zunahmen, berichteten auch viele Medien über die Fälschung.\n\nNach Strafanzeigen gegen den mutmaßlichen Betreiber entfernte dieser selbst oder die Facebook-Administration die Seite. Anfang Juni erschien eine Nachfolgeseite gleichen Namens auf dem russischen Netzwerk Vk.com, die auf die Sperrung der Vorgängerseite verweist und die Hetze gegen Zuwanderer fortsetzt. Gegen Rönsch laufen Ermittlungen wegen des Verdachts auf Volksverhetzung und eine Fahndung.\n\nIm Juli 2011 wurde bei 35 Razzien in den USA, 14 in den Niederlanden und vier in Großbritannien ein mutmaßlicher Anonymous-Aktivist festgesetzt. 35 zusätzliche Haftbefehle wurden vom FBI ausgestellt.\n\nAls Reaktion auf die Festnahmen haben die Hacker einen Server mit mehr als 70 Websites von US-Strafverfolgungsbehörden gehackt und 10 Gigabyte an Daten kopiert.\n\nDokumente der Globalen Überwachungs- und Spionageaffäre belegen, dass der britische Geheimdienst GCHQ gezielt gegen Anonymous vorging.\n\nAm 25. Juni 2011 wurde der Twitter-Account „AnonAustria“ erstellt. Er dient dem österreichischen Kollektiv von AnonAustria (den Usern des IRC-Channels von AnonAustria) als mediales Sprachrohr.\n\nNeben AnonAustria, die vor allem durch hacktivistische Aktionen für Aufsehen gesorgt haben, gibt es auch Anonymous Wien, die sich auf Demonstrationen und sogenannten Paperstorms (das Verteilen von Flyern) beschränken. Neben einem Wordpress-Blog und einem Forum dienen ihnen eine Facebook-Seite und der Twitter Account Anonymous Wien als Sprachrohr.\nSo protestieren sie seit 15. März 2008 öffentlich gegen Scientology.\nSie organisierten ebenfalls einige Paperstorms gegen Vorratsdatenspeicherung und ACTA. Ebenfalls mitorganisiert haben sie den Protestmarsch gegen Vorratsdatenspeicherung am 31. März 2012.\n\nAnonAustria gewannen 2011 den Wolfgang Lorenz Gedenkpreis für internetfreie Minuten. Die Jury argumentierte, dass AnonAustria mehrmals private Daten auf fremden Servern aufgespürt und veröffentlicht habe, darunter die Privatadressen von Polizisten. Damit sei wiederholt die achte Regel der Hackerethik verletzt worden: „Öffentliche Daten nützen, private Daten schützen.“\n\nEbenfalls gibt es noch AnonNewsAUT.\n\n2012 im Vorfeld der Einführung von Vorratsdatenspeicherung (VDS) in Österreich im Rahmen der EU-Regulierung machten Meldungen die Runde, dass lokale Vertreter des losen Netzwerks Anonymous E-Mail-Verkehr von allen größeren Parteien des Landes (SPÖ, ÖVP, FPÖ und weitere) in mehr als 10.000 Exemplaren abgegriffen hätten und damit Belege für Seilschaften und Verbrechen im Polit-Bereich gesammelt hätten, speziell ein gerade laufender Korruptionsausschuss solle davon tangiert werden, aber auch noch viel weitere Machenschaften sollten aufgedeckt werden. Die Aktivität wurde mehrfach mit dem Bedarf für „Gegenüberwachung“ tituliert. Die Ankündigung der Veröffentlichung ging durch zahlreiche Medien und war für den Einführungstermin der VDS zum Sonntag den 1. April 2012 um 0 Uhr bekannt gemacht. Dem Termin gingen tatsächliche Demonstrationen in mehreren österreichischen Städten am Samstag, den 31. März 2012 voraus. Die Aktion trug den Namen „pitdog“, vom englischen „pit“ für Loch/Grube und „dog“ für Hund, also Grubenhund und somit relativ gleich bedeutend zur Zeitungs-„Ente“. Zwar war der 1. April gelegentlich ein Anlass, zumindest die Möglichkeit eines Aprilscherzes zu erwägen, wurde jedoch durch die Vorgabe des Datums durch andere Umstände im Vorfeld als zufällig abgetan, die offenbar vorsätzlich gewählte Bezeichnung „pitdog“ wurde insgesamt erst nach dem Termin greifbar. Veröffentlichungen am selben Tag geben die Anonymous-Worte „frei erfunden“ wieder. Die Meinungen, ob diese Aktion nun dem Ansehen der AnonAustria Gruppe evtl. geschadet hat, gehen auseinander.\n\nAm 2. Juni 2012 kam es während einer Demonstration von Anonymous Wien gegen Scientology zu Anzeigen wegen Vermummung, da einige Teilnehmer ihre Gesichtszüge mit einer Guy-Fawkes-Maske verhüllt hatten. Daraufhin wurde die Strafverfügung eines Anon-Aktivisten ins Internet gestellt und via Twitter verbreitet (u. a. auch von AnonAustria). Die Strafe belief sich auf 50 € bzw. eine Ersatzfreiheitsstrafe von 25 Stunden. Ob die angezeigten Anon-Aktivisten die Strafe bezahlt oder Einspruch gegen die Strafverfügung erhoben haben, ist unklar. Kurz nach den Anzeigen veröffentlichte AnonAustria die Mails von Scientology. Wilfried Handl nutzte einige dieser geleakten Mails in seinem Blog, worauf Scientology gegen ihn klagte. Dies blieb allerdings erfolglos.\n\nIn Deutschland wird in mehreren Städten seit 10. Februar 2008 regelmäßig gegen Scientology protestiert, und seit 2011 werden Protestaktionen gegen Überwachung und Zensur durchgeführt.\n\nAm 6. April 2013 hackte Anonymous aus Protest gegen die Bestandsdatenauskunft das FDP-Portal meine-freiheit.de und veröffentlichte einige Zugangsdaten im Internet. Auch sind sie auf ihrem deutschen Youtube-Kanal aktiv, der eine abgeänderte Form des offiziellen englischsprachigen Kanals darstellt.\n\nSeit April 2016 setzen sich sowohl deutsche, als auch globale Aktivisten dafür ein, mittels friedlichen Demonstrationen darauf aufmerksam zu machen, was wirklich „hinter den Kulissen“ der Schlachthäuser und Massentierhaltungsindustrien passiert. Bei den Demonstrationen, formen die Aktivisten den so genannten „Cube of Truth“ und zeigen mittels Videomaterial, was wirklich mit den Tieren, vor der Schlachtung und wie sie behandelt werden, passiert und möchten so auf das Leid der Tiere aufmerksam machen, um ein Umdenken bei den Menschen zu ermöglichen. Dabei werden nicht nur Schlachthäuser gezeigt, sondern auch andere Bereiche: Ausrupfen von Federn, Labortests mit Ratten, Mäusen usw., Abzug des Fells, lebendiges Kochen von Schweinen und viele weitere Bereiche. Bei den Demonstrationen haben Passanten die Möglichkeit, mit den \"Anons\" zu reden und Informationen einzuholen. Dabei wird erklärt, dass eine vegane Lebensweise dabei helfen kann, den Tieren weitere Qualen zu ersparen, wobei ein Aufzwingen dieser Lebensart nicht das Ziel ist. Bei den Demonstrationen und im Allgemeinen gilt „Jeder Mensch ist verantwortlich, für das Massentiersterben und nur wir Menschen haben die Möglichkeit, uns zu entscheiden, ob wir es weiter unterstützen, oder den Tieren ein friedliches Leben ermöglichen wollen.“\n\nIm Rahmen der \"Operation GEMA\" griff Anonymous im Juni 2011 die Webpräsenz der GEMA mit DDoS-Attacken an und legte sie kurzzeitig lahm. In einem Video erläuterte die Gruppierung die Beweggründe: Die GEMA trage die Schuld daran, dass auf der Internetplattform YouTube in Deutschland ein Großteil der Musikvideos nicht mehr abgerufen werden kann, da sich YouTube mit der GEMA seit 2009 nicht mehr auf einen neuen Lizenzvertrag einigen konnte. (Tatsächlich sind die entsprechenden Videos von YouTube willkürlich ausgewählt worden; die GEMA führt einen Musterprozess mit YouTube um korrekte Lizenzierung, der nur wenige Videos betrifft.) Aus Sicht von Anonymous verlangt die GEMA zu hohe Gebühren für den Abruf von Videos. Im Video wurden „weitere Maßnahmen“ angekündigt, sollte sich das Verhalten der GEMA nicht ändern. Nachdem dies nicht geschehen war, erfolgte am 22. August ein weiterer Angriff auf die Website, bei der die Seite kurzzeitig auf eine Grafik umgeleitet wurde, deren Text auf die Sperrmeldungen von YouTube anspielte. Ferner gelang es, Benutzernamen und Passwörter auszulesen, die daraufhin bei Twitter veröffentlicht wurden. Als Reaktion auf die DDoS-Angriffe kam es zu mehreren Hausdurchsuchungen bei Verdächtigen. Zu Weihnachten startete Anonymous unter dem Namen LulzXmas weitere Aktionen gegen die GEMA und gegen andere Seiten der \"Initiative Urheberrecht\". Dabei kam es zu einem „Deface“ der Seite \"Initiative Urheberrecht\" und zur Veröffentlichung von personenbezogener Daten der Initiative. Wie sich später herausstellte, wurde die Kommunikation in den IRC-Channels vor den DDoS-Angriffen 2011 von den Behörden aufgezeichnet.\n\n\n\n"}
{"id": "6152396", "url": "https://de.wikipedia.org/wiki?curid=6152396", "title": "Hack-Tic", "text": "Hack-Tic\n\nHack-Tic war ein niederländisches Hackermagazin, das nach dem Vorbild der deutschen Datenschleuder des Chaos Computer Clubs von 1989 bis 1994 in Amsterdam erschien. Zu den Gründern gehörte Rop Gonggrijp, der Internetanbieter XS4ALL ging aus Hack-Tic hervor.\n\nDie „Zeitschrift für Techno-Anarchisten“, wie sie untertitelt war, veröffentlichte Hackertricks fraglicher Legalität, etwa zum Phreaking oder zur Manipulation von Magnetstreifenkarten, und wandte sich der entstehenden Technologie des Internet zu.\n\nSie veranstaltete zwei Hackerkonferenzen, 1989 die \"Galactic Hacker Party\" und 1993 \"Hacking at the End of the Universe\" in Form eines Camps unter freiem Himmel. Auch nach der Einstellung von Hack-Tic verselbständigte sich diese Idee und führte 1997 zu \"Hacking In Progress\", 2001 zu \"Hackers At Large\", 2005 zu \"What the Hack\", 2009 zu \"Hacking at Random\", 2013 zu \"Observe. Hack. Make.\" und 2017 zu \"Still Hacking Anyway\".\n\n\n\n"}
{"id": "6156082", "url": "https://de.wikipedia.org/wiki?curid=6156082", "title": "ERDAS Imagine", "text": "ERDAS Imagine\n\nERDAS IMAGINE ist eine Software zur Auswertung von Fernerkundungs-Daten, speziell von Grafiken und Photos. Das Programm analysiert Rastergrafiken und wurde von dem US-amerikanischen Unternehmen ERDAS Inc. für geostatistische und geoanalytische Anwendungen entwickelt. Das Programm erlaubt die Aufbereitung von digitalen Fernerkundungsdaten für GIS oder CAD.\n\nDie Software analysiert Rastergrafiken und wurde speziell für geostatistische und geoanalytische Anwendungen entwickelt. 2010 erschien die Version 10.1. ERDAS IMAGINE erlaubt die Aufbereitung von digitalen Fernerkundungsdaten und digitalisierten Luftbildern u. ä. für GIS oder CAD.\n\nGrafiken und Photos können mittels ERDAS IMAGINE mit einer Geocodierung versehen werden, das heißt, sie werden entzerrt und damit geographischen Koordinaten zugeordnet (Georeferenziert). Das Programm verfügt über Filter zur Kontraststreckungen, kann Farbkodierungen und Klassifizierungen vornehmen. Darüber hinaus können über Rechenoperationen aus den Bilddaten unterschiedlichste Ergebnisse generiert werden, vor allem bei multitemporalen Betrachtung von Gebieten ist dies notwendig (Monitoring).\n\nNeben der Analyse von Fernerkundungsdaten kann diese Software auch Daten in räumliche Modelle umsetzen. Mittels des „Map Composition-Modul“ können die Ergebnisse der Analysen in 2D, 3D, sowie in Filme und hochwertige Karten umgesetzt werden.\n\nERDAS IMAGINE wird hauptsächlich im professionell-institutionalisierten Bereich eingesetzt. Das deutsche Luft und Raumfahrtzentrum DLR arbeitet beispielsweise mit der Software. Das Programm wird im zivilen Bereich unter anderem in der Makroökologie und in der Entwicklungsforschung eingesetzt.\n\nGrundsätzlich bietet sich das Programm für viele Anwendungsbereiche an. Beispiele für die vielfältigen Einsatzbereiche sind wissenschaftliche Fragestellungen wie nach der Landnutzungskartierung, Auswertung von klimatischen Beobachtungen der Weltmeere (Ozeanographie), der ökologischen Belastungen von aquatischen Ökosystemen (Limnologie) und bei großräumigen forstwirtschaftlichen Fragestellungen (Waldinventarisierung, Waldsterben). Zudem können morphologische und struktur-morphologische (geologische) Fragestellungen bearbeitet werden. Des Weiteren ermöglicht die Software ein großflächiges Regenwaldmonitoring und andere Anwendungen aus dem Bereich der Raumwissenschaft.\n\n"}
{"id": "6160142", "url": "https://de.wikipedia.org/wiki?curid=6160142", "title": "Fail2ban", "text": "Fail2ban\n\nFail2ban (sinngemäß „Fehlschlag führt zum Bann“) ist ein in Python geschriebenes \"Intrusion Prevention System\" (Framework zur Vorbeugung gegen Einbrüche), das auf allen POSIX-Betriebssystemen läuft, die ein manipulierbares Paketfiltersystem oder eine Firewall besitzen (z. B. iptables unter Linux).\n\nDer Hauptzweck von fail2ban ist das Bestimmen und Blockieren bestimmter IP-Adressen, die wahrscheinlich zu Angreifern gehören, die sich Zugang zum System verschaffen wollen. fail2ban ermittelt aus Log-Dateien (u. a. codice_1, codice_2 oder codice_3) IP-Adressen, die in einem vom Administrator angesetzten Zeitrahmen z. B. öfter versuchen, sich mit falschen Passwörtern anzumelden oder andere gefährliche oder sinnlose Aktionen ausführen. Normalerweise ist fail2ban so konfiguriert, dass es blockierte Adressen nach einer bestimmten Zeit wieder freigibt, um keine seriösen Verbindungsversuche zu blockieren (beispielsweise, wenn die Angreifer-IP dynamisch einem anderen Host zugeteilt wird). Als hilfreich gilt eine Blockierzeit von einigen Minuten, um das Fluten des Servers mit bösartigen Verbindungsversuchen (Brute Force) zu stoppen.\n\nFail2ban ist in der Lage, verschiedene Aktionen auszuführen, wenn eine wahrscheinlich bösartige IP entdeckt wurde, beispielsweise diese IP mit einer Regel in \"iptables\" oder der zu TCP-Wrappern gehörenden codice_4 zu blockieren, um nachfolgende Angriffe zurückzuweisen, E-Mail-Benachrichtigungen oder jede benutzerdefinierte Aktion, die mit Python ausgeführt werden kann.\n\nDie Standardkonfiguration enthält Filter für Apache, Lighttpd, sshd, vsftpd, qmail, Postfix und den Courier Mail Server. Filter werden durch reguläre Ausdrücke definiert, die vom Administrator gut angepasst werden können. Die Kombination aus Filter und Aktion wird als \"jail\" (Gefängnis) bezeichnet und ist in der Lage, bösartige Hosts zu blockieren. Ein \"jail\" kann für jede Software erstellt werden, die Logdateien erstellt welche sich mit Regulären Ausdrücken auswerten lassen. Beispielsweise existiert für das WordPress-Plugin \"Antispam Bee\" ein \"jail\", welches Spam-Attacken bereits auf der Server-Ebene abwehrt und somit die Auslastung des Webservers und der Datenbank reduziert.\n\n"}
{"id": "6160228", "url": "https://de.wikipedia.org/wiki?curid=6160228", "title": "DenyHosts", "text": "DenyHosts\n\nDenyHosts ist ein in Python geschriebenes, log-basiertes Intrusion Prevention System für SSH-Server. Es wurde mit der Absicht geschrieben, Brute force-Attacken auf SSH-Server durch das Loggen und Aufspüren ungültiger Logins zu verhindern und die Quell-IP-Adressen zu blockieren. DenyHosts wird von Phil Schwartz entwickelt.\n\nDenyHosts überprüft das Authentikationslog auf neue, fehlgeschlagene Login-Versuche. DenyHosts filtert aus den Log-Einträgen die Quell-IP-Adresse und überprüft, wie oft eine IP versucht hat, sich einzuloggen. Wird eine benutzerdefinierte Zahl überschritten, so nimmt DenyHosts eine Wörterbuchattacke an und blockiert die IP-Adresse, um einen eventuellen Erfolg zu verhindern, indem es die IP in die codice_1 einträgt. Im Internet lassen sich blockierte IPs einsehen.\n\nDenyHosts kann manuell, als Daemon und als cron-Job betrieben werden.\n\nIm Juli 2007 berichtete The Register, dass von Mai bis Juli 2007 \"kompromittierte Computer\" bei Oracle UK unter den 10 größten Brute-Force-Quell-IPs gelistet waren. Nach einer eingeleiteten Untersuchung wies Oracle jegliche Infektion derer Computer zurück. Daniel B. Cid schrieb einen Aufsatz, in dem er zeigte, dass DenyHosts, ähnlich wie BlockHosts und Fail2ban, verwundbar gegenüber \"Remote Log Injection\" waren, einem Angriff ähnlich wie SQL Injection, und bei der ein speziell dazu angelegter Benutzer dazu benutzt wird, eine Blockierung gegenüber beliebigen Seiten zu erreichen.\n\n\n"}
{"id": "6167185", "url": "https://de.wikipedia.org/wiki?curid=6167185", "title": "International Society for Computer Aided Surgery", "text": "International Society for Computer Aided Surgery\n\nInternational Society for Computer Aided Surgery (ISCAS) (Internationale Gesellschaft für Computerunterstützte Chirurgie) ist eine weltweit agierende gemeinnützige Gesellschaft zur Förderung des wissenschaftlichen und klinischen Fortschritts in der computerassistierten Chirurgie und der damit verbundenen medizinischen Maßnahmen.\n\n\nUm die oben genannten Ziele zu erreichen, werden regelmäßig Meetings mit Beiträgen von Spezialisten aus der Medizin, Ingenieuren, Physikern und Informatikern aus Universitäten, Kliniken, Forschungseinrichtungen und der Industrie organisiert, beispielsweise während des Computer Assisted Radiology and Surgery (CARS; Computerassistierte Radiologie und Chirurgie), ein jährlich stattfindender wissenschaftlicher Kongress, initiiert 1983 vom Berliner Senat.\n\nDie ISCAS ist inhaltlich beteiligt an\nDas Ziel der Akkreditierungsverfahren ist die Bewertung, Verbesserung und öffentliche Anerkennung von Programmen oder Förderinstitutionen für die Forschung und Ausbildung in Computerunterstützter Chirurgie(CAS), um die Qualität der Lehr-, Lern-, Forschungs- und fachlichen Praxis zu verbessern.\nZur Förderung junger Wissenschaftler und als Anerkennung herausragender wissenschaftlicher Arbeit vergibt die Gesellschaft folgende Preise und Stipendien:\nJede Person aus den Berufsfeldern Ingenieurwesen, Gesundheitswesen, aus wissenschaftlichen oder industriellen Bereichen im Zusammenhang mit computerassistierter Chirurgie und damit verbundenen medizinische Eingriffen kann aktives Mitglied werden.\nJede nationale oder internationale Vereinigung mit ähnlichen Zielen kann die assoziierte Mitgliedschaft beantragen und zu einem verbundenen Verein werden, so wie auch jede Bildungseinrichtung, Industrie, Firma oder Organisation, die auf dem Gebiet tätig ist.\nPersonen, die sich durch besondere Leistungen ausgezeichnet oder die wesentlich zur Entwicklung des Vereins beigetragen haben, können zu Ehrenmitgliedern ernannt werden (ohne jede Verpflichtung zur Zahlung von Mitgliedsbeiträgen).\n\n"}
{"id": "6172970", "url": "https://de.wikipedia.org/wiki?curid=6172970", "title": "Sociedad Gallega de Ortopedia y Traumatología", "text": "Sociedad Gallega de Ortopedia y Traumatología\n\nDie Sociedad Gallega de Ortopedia y Traumatología (Galicische Gesellschaft für Orthopädie und Traumatologie) ist eine 1980 gegründete gemeinnützige wissenschaftliche Gesellschaft, die der Verbesserung der persönlichen und beruflichen Kenntnisse der Unfallchirurgen sowie dem wissenschaftlich-technischen Fortschritt auf den Gebieten Orthopädie und Traumatologie dient.\n\nZiel der Gesellschaft ist die Verbesserung der persönlichen und fachlichen Kenntnisse unter Unfallchirurgen, die Verbreitung von Informationen über moderne wissenschaftliche Methoden und technische Verfahren, sowie von Informationen über neueste wissenschaftliche Erkenntnisse.\nDarüber hinaus zielt sie auf den Austausch von Erfahrungen zwischen Orthopäden, Traumatologen und verwandten Berufsgruppen ab und dient der Förderung der Forschung.\n\nDie Aktivitäten der SOGACOT haben sich kontinuierlich entwickelt und bestehen in der Realisierung von wissenschaftlichen Kongressen, Konferenzen und Meetings, Arbeitsgruppen sowie der Schaffung und Bereitstellung von Stipendien und Auszeichnungen\n\n\n"}
{"id": "6173504", "url": "https://de.wikipedia.org/wiki?curid=6173504", "title": "MixRadio", "text": "MixRadio\n\nMixRadio (früher \"Nokia Music Store\", \"OVI Music Store\") war ein Online-Musikdienst für Musik im MP3-Format von LINE. Der Zugriff erfolgte über einen Webbrowser oder über eine App für Windows Phone 8, Apple iOS sowie Android.\n\nMixradio wurde am 21. März 2016 eingestellt.\n\n2014 wurde MixRadio nach der Übernahme von Nokias Geräte-Sparte an Microsoft Mobile verkauft, wodurch MixRadio Microsofts Xbox Music konkurrierte. Im Juli 2014 gab Microsoft bekannt, MixRadio auszugliedern. Im März 2015 wurde MixRadio an das japanische Unternehmen LINE verkauft. Auch die Portierung der App auf Android und iOS durch LINE konnte den Streaming-Dienst nicht vor dem Aus retten, woraufhin LINE Mitte Februar 2016 ankündigte, Mix Radio in den folgenden Wochen einzustellen. Ende Februar 2016 wurde die App aus den App Stores entfernt.\n\nDie angebotene Musik im früheren Kaufshop war frei von DRM und konnte beliebig kopiert werden. Für das Herunterladen benötigte man ein Nokia-Konto. Der Kaufshop wurde im Rahmen der Umbenennung von Nokia Music in Nokia MixRadio geschlossen. Der Dienst war in 38 Ländern verfügbar und bot mit Stand Juli 2014 über 30 Millionen Songs an. Das Streaming selbsterstellter Playlists war kosten- und werbefrei. Die 2008 eingeführte Musik-Flatrate wurde 2011 eingestellt, war aber später unter dem Namen \"MixRadio+\" wieder erhältlich.\n\n"}
{"id": "6175978", "url": "https://de.wikipedia.org/wiki?curid=6175978", "title": "Computerassistierte Chirurgie", "text": "Computerassistierte Chirurgie\n\nComputerassistierte Chirurgie (, CAS), manchmal auch , repräsentiert ein chirurgisches Konzept, um chirurgische Eingriffe mit Computerunterstützung zu planen und ihre Ausführung zu steuern. Synonyme sind \"computergestützte Chirurgie\", \"computergestützte Intervention\", \"bildgeführte Chirurgie\" und \"chirurgische Navigation\". Bei einer CAS erhält der Operateur ständig Informationen, wo genau seine Instrumente im Körper des Patienten sich befinden, auch wenn er sie nicht direkt sehen kann. Die Anlagen übertragen dazu das Echtzeit-Tracking der Instrumente in ein vorher aus Schnittbildern vorbereitetes dreidimensionales Modell des Operationsgebietes. CAS wird vor allem für minimalinvasive Eingriffe verwendet, ist aber auch ein wichtiger Faktor bei der Entwicklung der Roboterchirurgie.\n\nWichtigster Bestandteil von CAS ist die Entwicklung eines präzisen Modells des Patienten. Dies kann durch bildgebende Verfahren wie Computertomographie, Magnetresonanztomographie, oder Ultraschall geschehen. Die Aufnahmen werden heute in der Regel schon digital erstellt und müssen nicht mehr eingescannt werden. Es ist sinnvoll, mehrere Modalitäten zu kombinieren. Beispielsweise sind MR-Bilder sehr kontrastreich, aber nicht geometrisch genau; CT-Daten sind dagegen strecken- und winkeltreu im Rahmen der Auflösung des verwendeten Scanners. Die Bilder können parallel nebeneinander präsentiert, werden oder optisch überlagert (Datenfusion). Die Fusion kann halb- oder vollautomatisch erfolgen. Ziel ist ein 3D-Datasets, der die exakte räumliche Lage der normalen und krankhaft veränderten Gewebe und Strukturen der Zielregion wiedergibt. Bildanalyse schließt die Bearbeitung des 3D-Modell des Patienten ein, um die relevanten Informationen zu extrahieren. Durch die unterschiedlichen Kontraststufen der verschiedenen Gewebe kann zum Beispiel ein Modell so geändert werden, dass nur feste Strukturen wie Knochen gezeigt werden, oder aber der Verlauf der Arterien und Venen durch das Gehirn sichtbar ist.\n\nEin Datensatz kann zum Beispiel Daten von 180 CT-Schichten enthalten, 1 mm dicke Schichten in 1 mm Abstand mit jeweils 512 × 512 Pixel. Die Details sowohl der weichen als auch der festen Gewebestrukturen können automatisch segmentiert und dann optisch getrennt dargestellt, z. B. farblich markiert oder dreidimensional freigestellt werden. Von Hand werden Orientierungspunkte (\"land marks\") gesetzt, um in der Lage zu sein, zu einem späteren Zeitpunkt den virtuellen Datensatz neu auszurichten und mit der Situation während der Operation abzugleichen (Bildregistrierung).\n\nProfessionelle medizinische Betrachtungssoftware (DICOM-Viewer, z. B. OsiriX) kann den segmentierten und markierten Datensatz des Patienten als virtuelles 3D-Modell wiedergeben. Dieses Modell kann rotiert, beschnitten und gefiltert werden, um dem Chirurgen Ansichten aus jedem möglichen Blickwinkel und jeder Tiefe zu liefern. So kann der Chirurg den Fall besser beurteilen und eine genauere Diagnose stellen. Dann wird die chirurgische Intervention geplant und virtuell simuliert, bevor die eigentliche Operation stattfindet. Steht ein Operationsroboter zur Verfügung, wird er nun programmiert, die geplanten Aktionen während des aktuellen chirurgischen Eingriffs durchzuführen.\n\nBeim Eingriff sieht der Chirurg in Echtzeit, wie sein Instrument ausgerichtet ist und wo es sich im dreidimensionalen Patientenmodell befindet. Meist hat er dazu einen Monitor; es gibt aber inzwischen auch innovative Systeme mit Datenbrillen (Augmented Reality). Die Instrumente werden beispielsweise optisch verfolgt, indem man daran angebrachte Markierungen im infraroten Licht aus mehreren Raumrichtungen verfolgt, oder über elektromagnetische Sender. Mechanische Tracking-Systeme (Achsen und Scharniere mit Sensoren) sind zu ungenau und nicht mehr gebräuchlich.\n\nAuf diese Weise soll der Operateur die chirurgischen Schwierigkeiten besser bewerten und sein Vorgehen besser festlegen können. Der Eingriff wird präziser, die Redundanz der Handgriffe des Chirurgen verringert. Man verspricht sich auch eine allgemein bessere Ergonomie im Operationssaal; das Risiko von Fehlern soll sich verringern, die Operationszeit verkürzen.\n\nChirurgische Roboter sind hochgenaue Industrieroboter, also mechanische Arme, die vom Computer gesteuert werden. Roboterunterstützung besteht immer aus dem Zusammenspiel des Chirurgen und des Roboters; selbsttätig operierende Roboter gibt es bisher nicht. Nach dem Grad der Interaktion unterscheidet man telechirurgische, \"shared-control-\", und beaufsichtigte (\"supervised-controlled\") Roboterchirurgie. Beaufsichtigte Eingriffe werden nach ausführlicher Vorbereitung vom Roboter ausgeführt, welcher vorprogrammierte Befehle umsetzt; der Chirurg beobachtet es und kann jederzeit unterbrechen. Bei \"shared control\" (\"gemeinsame Steuerung\") führt der Chirurg das Instrument, während der Roboter es aktiv stabilisiert (z. B. Zittern verhindert oder es von vordefinierten Positionen fernhält). Bei der Telechirurgie steuert der Chirurg die Roboterarme selbst. Seine Konsole kann dabei direkt neben dem Patienten stehen oder beliebig weit entfernt; seibst auf einem anderen Kontinent.\n\nWichtigstes Einsatzgebiet der CAS ist die Neurochirurgie am Gehirn. Remote Manipulatoren werden dafür schon seit den 1980er Jahren genutzt. In der Kieferchirurgie ist Knochensegmentnavigation ein modernes Konzept bei Operationen am Kiefergelenk oder bei der Gesichtsrekonstruktion. Die navigierte Implantologie ist ein prothetisch-chirurgisches Hilfsverfahren in der Mund-Kiefer- und Gesichtschirurgie und der Zahnmedizin, um Zahnimplantaten exakt in den Kieferknochen einzusetzen. HNO-Chirurgen kennen ebenfalls Gebiete mit eingeschränktem Zugang und der Notwendigkeit hochpräzisen Handelns wie zum Beispiel bei der Mittelohr-Chirurgie. Die Computerassistierte orthopädische Chirurgie (CAOS) ist in der Orthopädie weit verbreitet, vor allem im Hüft- und Kniegelenkersatz. Sie ist außerdem nützlich zur Operationsplanung und -führung in der Osteosynthese von verschobenen Knochenbrüchen. In der allgemeinen und gynäkologuischen Chirurgie sind Bauchspiegelungen Nutznießer dieses Fortschritts, etwa für die Hysterektomie (Gebärmutterentfernung). In der Herzchirurgie können Steuerungssysteme den Mitralklappenersatz oder die Ventrikularstimulation über kleine Thorakotomien durchführen. In der Urologie helfen chirurgische Roboter bei der Pyeloplastik (Nierenbeckenplastik), bei der Nephrektomie (operative Entfernung einer Niere), und bei Eingriffen an der Prostata.\n\nAuch Radiochirurgie (eine Form der Strahlentherapie) erfolgt heute oft unter Einbeziehung von Robotersystemen, etwa dem Cyberknife. Dabei ist ein Linearbeschleuniger auf einem Industrieroboter montiert und wird unter Nutzung der Skelettstrukturen als Bezugsrahmen auf den Tumor ausgerichtet (stereotaktisches Radiochirurgiesystem). Während des Verfahrens wird Röntgenstrahlung verwendet, um das Gerät vor Abgabe der Strahlenbündel akkurat zu positionieren.\n\n1989–2007 wurden mehr als 200 CAS-Systeme von verschiedenen Universitäten und Forschungsinstituten entwickelt, praktisch noch experimentelle Geräte. Gegenwärtige handelsübliche Systeme mit Zulassung für die klinische Anwendung sind hauptsächlich \"StealthStation\" (Medtronic, USA), EnLite (ein transportables System der Stryker Corporation) und \"NavSuite\" (Stryker Corporation), \"MATRIX POLAR\" (Scopis medical/ XION, Deutschland), \"VectorVision\" (Brainlab, Deutschland), \"DigiPointeur\" (Dr. Lombard / Ste COLLIN, Frankreich). Alle außer DigiPointeur und StealthStation nutzen ein optisches IR-Tracking-System. \"DigiPointeur\" ist ein elektromagnetisches Tracking-System, und StealthStation nutzt ein elektromagnetisches (PoleStar) oder optisches IR-Tracking-System. Die StealthStation stellt sowohl optische als auch elektromagnetische Tracking-Systeme.Der erste chirurgische Roboter hieß \"Äsop\" (Computer Motion, USA); Aesop 1000 erhielt 1993 in den USA die behördliche Zulassung der Food and Drug Administration (FDA). Es gab mehrfach Verbesserungen und Varianten, wie \"Zeus\" oder \"Hermes\".Das chirurgische System \"Da Vinci\" wurde von \"Intuitive Surgical\", einem Zweig des Stanford Forschungsinstituts (USA), entwickelt. \"Da Vinci\" ist ein telechirurgisches System, meist verwendet bei laparoskopischen Bauch-OPs. Im Jahr 1997 hatte es die Zulassung von der FDA erhalten und war 2000 der erste Remote Manipulator, der die FDA-Zulassung bekam, Stand-alone-Operation durchzuführen. Nach heftigen Auseinandersetzungen fusionierten schließlich die beiden Hersteller, noch unter der Marke von Intuitive Surgical.\n\"OrthoDoc\" und \"Robodoc\" sind Roboter, entwickelt von \"Integrated Surgical Systems\" für die Assistenz in der orthopädischen Chirurgie. Dieselbe Firma hat \"Neuronate\" produziert, nutzbar in Verbindung mit OrthoDoc / Robodoc in der Neurochirurgie.CyberKnife (Accuray Incorporated) ist ein Roboter mit integriertem Linearbeschleuniger, der seit 2001 in der Radiochirurgie verwendet wird.\n\nNeue technologische Verfahren und Geräte können zu neuen und unvorhergesehenen Risiken für den Patienten und/oder das OP-Team führen. Solange sie nicht im Regelbetrieb, sondern experimentell eingesetzt werden, müssen die zuständigen Ethikkommissionen dem Einsatz zustimmen. Die zu Beginn oft sehr teuren Verfahren können nicht überall angeboten werden, sodass sich ethisch die Frage nach gleichberechtigtem Zugang zu medizinischer Versorgung ergibt.\n\n"}
{"id": "6186490", "url": "https://de.wikipedia.org/wiki?curid=6186490", "title": "Das Dschungelbuch (3D-Animationsserie)", "text": "Das Dschungelbuch (3D-Animationsserie)\n\nDas Dschungelbuch (\"The Jungle Book\") ist der Titel einer 104-teiligen indisch-britischen Computeranimationsserie, die auf der Geschichtensammlung \"Das Dschungelbuch\" basiert.\n\nNachdem Akela der neue Anführer des Wolfsrudels ist, wird Mogli aus dem Rudel ausgeschlossen. Gemeinsam mit seinen Freunden Balu und Bagira erlebt er aufregende Abenteuer im Dschungel und hofft, eines Tages als richtiger Wolf im Rudel akzeptiert zu werden. Dabei trifft er neue Freunde, wie beispielsweise ein Stachelschwein, aber auch einige weniger freundlich gesinnte Zeitgenossen, wie den Tiger Shir Kahn, den Schakal Tabaqui und die Schlange Kaa. Zusammen helfen die drei Tieren in Not und vereiteln die üblen Machenschaften von Shir Kahn und Tabaqui.\n\nHauptfiguren:\n\nMogli: Mogli hat fast jeden Tag Unterricht bei seinem Lehrer Balu. Wenn er mal keinen Unterricht hat, spielt er mit seinen Freunden, den anderen Tieren, im Dschungel.\n\nBalu: Balu ist ein Lippenbär und der gutmütige Lehrer Moglis. Zu seiner Lieblingsnahrung gehören Honig und Wassermelonen. Er ist zwar gegen viele Sachen, die Mogli anstellt, kann seinem kleinen Freund jedoch nicht lange böse sein.\n\nBaghira: Baghira ist ein Panther und einer der besten Freunde Moglis. Er ist fast immer bei dessen Unterrichtsstunden dabei und tollt mit dem Menschenjungen, wie Mogli von vielen Tieren genannt wird, gern durch den Dschungel. Wenn Shir Khan Mogli angreift, steht der Panther seinem Freund stets zur Seite.\n\nShir Khan: Der Königstiger ist Moglis größter Feind. Er findet, dass der Menschenjunge nicht in den Dschungel gehört, daher versucht er mit allen Mitteln, Mogli zu töten.\n\nTabaqui: Tabaqui ist ein hinterhältiger und listiger Schakal. Er tut alles, was sein ständiger Wegbegleiter Shir Khan ihm befiehlt. Meistens versagt er sehr zum Leidwesen des Tigers.\n\nKaa: Der Python Kaa kann manchmal ganz schön launisch sein. Zwar ist er neutral und hat nichts für Shir Khans Attacken auf Mogli übrig, doch oft hilft er dem Menschenjungen.\n\nAkela: Akela kann sich stolz den Anführer des Wolfsrudels im Dschungel nennen. Er mag Mogli, aber sein Stiefsohn Phaona hat nichts für den Jungen übrig und versucht Mogli immer wieder vor Shir Khan lächerlich zu machen.\n\nDaruka: Daruka ist ein Indischer Wolf und Moglis Vater. Oft besucht der Adoptivsohn ihn und seine Familie. Seine Nase ist eine der besten im ganzen Dschungel.\n\nRakscha: Sie hat Mogli einst aufgezogen und freut sich immer wenn er bei ihr vorbeikommt. Die Wölfin gibt Mogli oft gute Ratschläge und schlichtet die Streite zwischen Mogli und seinen Wolfsgeschwistern Bala und Lali.\n\nBala & Lali: Die Wolfsgeschwister halten ihre Eltern Rakscha und Daruka ganz schön auf Trab. Lali ist ein bisschen eitel, während ihr Bruder Bala oft gerne angibt. Am liebsten spielen sie mit Mogli und trotz mancher Streitigkeiten tollen die drei zusammen durch den Dschungel.\n\nPhaona: Er ist auch ein Indischer Wolf und Moglis größter Widersacher im Wolfsrudel. Er war von Anfang dagegen, dass Mogli ins Rudel aufgenommen wurde und versucht den Menschenjungen mit allen Tricks bei seinem Onkel Akela unbeliebt zu machen und schreckt auch nicht davor zurück, Shir Khan zu Hilfe zu rufen.\n\nHathi: Der Asiatische Elefant ist ein guter Freund von Balu, Baghira und Mogli. Er ist sehr gutmütig und klug und hilft Mogli nicht selten aus der Klemme. Seine einzige Schwäche ist sein Elefantengedächtnis, das ihn manchmal im Stich lässt.\n\nGayini: Gayini ist die Frau von Hathi und sehr willensstark, doch die Elefantendame hat ein gutes Herz, vor allem, wenn es um ihre gemeinsamen Kinder Hita und Appu geht.\n\nAppu & Hita: Die beiden Elefantenkinder sind der ganze Stolz ihrer Eltern Gayini und Hathi. Zwar streiten sich die beiden öfters, doch schon bald sind sie wieder bester Laune und spielen zusammen mit Mogli. Hita ist ein Mädchen, während Appu ein Elefantenjunge ist.\n\nChil: Der Brahminenweih wird vom ganzen Dschungel bewundert. Chil ist stark und kräftig und ein Freund von Mogli.\n\nDarsi: Mit ihrem Kurzzeitgedächtnis kann Darsi ihre Freunde ganz schön nerven. Aber in Wirklichkeit ist der kleine Nektarvogel nett und hilfsbereit und immer zur Stelle, wenn man sie braucht.\n\nAffenbande: Diese Affen haben nichts als Unsinn im Kopf und machen nur, was ihnen gefällt oder Spaß macht. Sie sperren Mogli in einen Raum in ihrer verlassenen Tempelanlage ein, reiten auf den Elefantenkindern Appu und Hita und streiten sich mit Tabaqui.\n\nMasha: Sie ist die Anführerin der Affenbande und sehr eitel. Trotz ihres Affenverstands ist sie nicht dumm und falls sich die Äffin etwas in den Kopf gesetzt hat, setzt sie es durch. Dennoch gehorchen ihre Kumpanen ihr nicht immer und ziehen sich lieber zurück, wenn sie einen Fehler macht.\n\nUuh & Buh: Die beiden Schildkröten sind ruhige Gesellen und mögen keine Aufregung. Uuh kann ein bisschen kratzbürstig sein, während seine Frau Buh meistens nett ist.\n\nJakala: Das große Sumpfkrokodil nimmt was es kriegen kann. Doch als Vater von fünf Söhnen hat auch er ein gutes Herz. Jakala legt sich, wenn es sein muss, sogar mit Shir Khan an und gewinnt meistens.\n\nIkki: Ikki, das Indische Stachelschwein, ist schüchtern und zurückhaltend. Mit Mogli ist sie sehr gut befreundet und befreit ihn manchmal mit ihren Stacheln aus so mancher brenzliger Situation.\n\nRikki Tikki Tavi: Ebenfalls ein Freund von Mogli ist Rikki Tikki Tavi, der meist nur mit Rikk angesprochen wird. Als Indischer Mungo kämpft er oft mit Kobras, macht jedoch keine unüberlegte Sachen.\n\nPonya: Ponya ist ein Roter Panda. Sie ist sehr ängstlich und begibt sich oft unabsichtlich in große Gefahren. Doch Mogli, Balu und Baghira helfen ihr ohne zu Schimpfen gerne.\n\nAutorin der Serie ist Rachel Murrell. Für die Produktion von 2009 bis 2011 in Indien waren die Firmen DQ Entertainment International Production und Moonscoop verantwortlich. Regie führten Tapaas Chakravavarti und Siddharth Vasudeva. Das Titellied zur Serie, geschrieben von Guy Michelmore, sang Lisa Abbott. Die Serie wird in High Definition Television, im Format und Dolby Digital 5.1 ausgestrahlt.\n\nDie Erstausstrahlung der Serie erfolgte ab dem 18. Oktober 2010 auf TF1 in Frankreich. Es folgten Ausstrahlungen in Australien bei ABC, in Großbritannien bei BBC und in Kanada bei TVO. In Deutschland wurden ab 23. April 2011 im ZDF, jeweils am Samstag und im KiKA werktags ab dem 26. April 2011 drei Staffeln mit jeweils 26 Folgen ausgestrahlt. Zur Serie sind im Jahre 2011 3 DVDs (Länge: 55 Minuten) erschienen. Die ersten 26 Folgen sind auch als Hörspiel erschienen.\n\nZur Serie ist auch ein Film von 60 Minuten Länge erschienen.\n\n"}
{"id": "6189778", "url": "https://de.wikipedia.org/wiki?curid=6189778", "title": "Sigil", "text": "Sigil\n\nSigil ist ein Open-Source-Editor, der von 2009 bis Juli 2011 von Strahinja Markovic und von Juli 2011 bis Juni 2015 von John Schember entwickelt wurde. Seit Juni 2015 wird die Entwicklung von Kevin Hendricks and Doug Massay geleitet. Am 1. August 2009 erschien die erste Version (v0.1.0). Ziel des Projekts ist, einen benutzerfreundlichen Editor für EPUB-Dokumente zu erschaffen. Sigil unterstützt sowohl WYSIWYG als auch direktes Editieren des HTML-Quellcodes.\n\n\nDie Anwendung ist großteils in der Programmiersprache C++, basierend auf dem Qt-Framework geschrieben. Sigil wird unter den Bedingungen von Version 3 der GNU General Public License (GPL) als freie Software auch im Quelltext veröffentlicht.\n\n"}
{"id": "6192864", "url": "https://de.wikipedia.org/wiki?curid=6192864", "title": "Raspberry Pi", "text": "Raspberry Pi\n\nDer Raspberry Pi (engl. Aussprache: ˈɹɑːzbɹi 'paɪ) ist ein Einplatinencomputer, der von der britischen Raspberry Pi Foundation entwickelt wurde. Der Rechner enthält ein Ein-Chip-System von Broadcom mit einem ARM-Mikroprozessor, die Grundfläche der Platine entspricht etwa den Abmessungen einer Kreditkarte. Der Raspberry Pi kam Anfang 2012 auf den Markt; sein großer Markterfolg wird teils als Revival des bis dahin weitgehend bedeutungslos gewordenen Heimcomputers zum Programmieren und Experimentieren angesehen. Der im Vergleich zu üblichen Personal Computern sehr einfach aufgebaute Rechner wurde von der Stiftung mit dem Ziel entwickelt, jungen Menschen den Erwerb von Programmier- und Hardware­kenntnissen zu erleichtern. Entsprechend niedrig wurde der Verkaufspreis angesetzt, der je nach Modell etwa 5 bis 35 USD beträgt.\n\nBis Ende 2017 wurden mehr als 17 Millionen Geräte verkauft. Die Entwicklung des Raspberry Pi wurde mit mehreren Auszeichnungen bzw. Ehrungen bedacht. Es existiert ein großes Zubehör- und Softwareangebot für zahlreiche Anwendungsbereiche. Verbreitet ist beispielsweise die Verwendung als Mediacenter, da der Rechner Videodaten mit voller HD-Auflösung (1080p) dekodieren und über die HDMI-Schnittstelle ausgeben kann. Als Betriebssystem kommen vor allem angepasste Linux-Distributionen mit grafischer Benutzeroberfläche zum Einsatz; für das neueste Modell existiert auch Windows 10 in einer speziellen Internet-of-Things-Version ohne grafische Benutzeroberfläche. Der Startvorgang erfolgt gewöhnlich von einer wechselbaren SD-Speicherkarte als internes Boot-Medium. Bei der neueren Generation mit dem BCM2837 ist der Start auch von einem USB-Massenspeicher oder Netzwerk möglich. Eine native Schnittstelle für Festplattenlaufwerke ist nicht vorhanden, zusätzlicher Massenspeicher kann per USB-Schnittstelle angeschlossen werden, beispielsweise externe Festplatten bzw. SSDs oder USB-Speichersticks.\n\nDas Motiv hinter der Entwicklung eines preisgünstigen Rechners war die sinkende Anzahl an Informatikstudenten an der Universität Cambridge sowie die jedes Jahr geringeren Programmierkenntnisse der Studienanfänger. Für einen der Gründe hielt man, dass Computer heute in der Regel teuer und komplex sind und Eltern ihren Kindern deswegen häufig verbieten, mit dem Familien-PC zu experimentieren. Man wollte daher Jugendlichen einen günstigen Computer zum Experimentieren und Erlernen des Programmierens an die Hand geben. Dabei hoffte man, dass sie wie in der Anfangszeit der Heimcomputer (z. B. IMSAI 8080, Apple I, Sinclair ZX80) die Computergrundlagen und -programmierung spielerisch erlernen würden.\n\nDer Name wird wie \"\" ausgesprochen, das englische Wort für Himbeerkuchen. Die „Himbeere“ knüpft an die Tradition an, Computer nach Früchten zu benennen, wie etwa Apple oder Acorn. Das „Pi“ steht für „Python interpreter“, ursprünglich sollte der Rechner mit fest eingebautem Interpreter für die Programmiersprache Python geliefert werden, ähnlich wie bei den Heimcomputern der 1980er Jahre fast durchweg ein BASIC-Interpreter eingebaut war.\n\nDas Logo des Projekts wurde im Rahmen eines öffentlich ausgeschriebenen Wettbewerbs ausgewählt. Es zeigt eine stilisierte Himbeere.\n\nHinter dem Raspberry Pi stehen zwei Organisationen: Die Raspberry Pi Foundation ist eine Stiftung und in Großbritannien als Wohltätigkeitsorganisation eingetragen. Die Herstellung und der Vertrieb der Hardware geschieht durch die Raspberry Pi Trading, die der \"Raspberry Pi Foundation\" gehört und alle Gewinne an diese ableitet.\n\nDie \"Raspberry Pi Foundation\" hat sich zum Ziel gesetzt, das Studium der Informatik und verwandter Themen zu fördern, besonders an Schulen. Sie wurde am 5. Mai 2009 in Caldecote, South Cambridgeshire, Großbritannien gegründet. Die Treuhänder der Stiftung sind:\n\n\nEin Prototyp mit einem Atmel-ATmega644-Mikrocontroller wurde im Jahr 2006 produziert. Die Schaltpläne der Platine wurden veröffentlicht.\nDie Leistungen des Gerätes überzeugten die Entwickler nicht. Wegen des damals beginnenden Booms von Smartphones kamen jedoch geeignete ARM-Prozessoren auf den Markt. Man fand mit dem BCM2835 einen günstigen Prozessor mit verhältnismäßig hoher Leistung und entwarf für diese CPU eine neue Mehrlagenplatine. Für den Atmel war man noch mit einer Lochrasterplatine ausgekommen.\n\n50 Alpha-Boards wurden im August 2011 geliefert. Diese Platinen waren funktional gleich mit dem späteren Modell B des Raspberry Pi, aber größer, weil sie Messpunkte zur Fehlersuche aufwiesen. Die Verkaufsversion hat die Grundfläche einer Kreditkarte. Auf diesen Versuchsplatinen wurde bereits gezeigt, dass die Desktop-Umgebung LXDE unter Debian sowie Quake III Arena und H.264-Videos mit einer Auflösung von 1080p via HDMI funktionieren. Seit Herbst 2012 wird eine leicht veränderte Revision 2 verkauft. Sie hat zwei Befestigungslöcher, es wurden kleinere Fehler behoben und einige Pins sind anders belegt.\n\nEtwa gleichzeitig konnte wegen der unerwartet großen Verkaufszahlen auch die Produktion von China nach Wales, in eine Fabrik des Unternehmens Sony verlegt werden und der Arbeitsspeicher des Modells B auf 512 MB verdoppelt werden.\n\nAm 14. Mai 2013 kam ein Kameramodul für den Raspberry Pi in den Handel. Eine Variante ohne Infrarotfilter ist unter der Bezeichnung Pi NoIR erhältlich (November 2013).\nAm 7. April 2014 angekündigt und seit dem 9. Juni 2014 lieferbar ist das Raspberry Pi Compute Module, ein Raspberry Pi in der Größe und mit dem Aussehen eines DDR2-SODIMM-Speichermoduls. Das Modell entspricht etwa den technischen Spezifikationen des Modells A, verfügt jedoch zusätzlich über 4 GB eMMC-Flashspeicher. Da dem Modul die üblichen I/O-Anschlüsse fehlen, lassen sich diese bei Bedarf über ein optionales I/O-Board nachrüsten.\n\nAm 14. Juli 2014 wurde das Modell B+ vorgestellt. Bei diesem wurde die Anzahl der GPIO- und der USB-Ports erhöht, die Leistungsaufnahme verringert und die Audioausgabe verbessert. Der SD-Karten-Steckplatz wurde durch einen kompakteren für Micro-SD-Karten ersetzt. Das Modell B+ ersetzt das gleich viel kostende Modell B. Modell B wird auch weiterhin angeboten und ist für Kunden gedacht, deren Anwendungen auf die Form der Platine und Pinbelegung hin konstruiert sind. Erstmals mit dem Modell B+ wurde eine offizielle Spezifikation für Erweiterungsplatinen, sogenannte HATs (HAT: Hardware attached on top), vorgestellt.\n\nAm 10. November 2014 wurde das Modell A+ vorgestellt. Während das Modell A als eine teilbestückte Version des Modells B angesehen werden kann, handelt es sich bei Modell A+ um eine Neuentwicklung, die günstiger und kompakter ist. Es verfügt wie das Modell B+ über einen 40-poligen Anschluss für Erweiterungsplatinen (HATs) und einen Micro-SD-Karten-Steckplatz, ist aber etwa ein Viertel kürzer als Modell A, B und B+.\nAm 2. Februar 2015 wurde der Raspberry Pi 2 Model B vorgestellt, obwohl Eben Upton noch im Juli 2014 bekannt gegeben hatte, dieses würde nicht vor 2017 erscheinen. Dessen Ausstattung ist dem Modell B+ sehr ähnlich, besitzt nun jedoch 1 GB Arbeitsspeicher und einen Vierkernprozessor vom Typ Broadcom BCM2836 auf ARM-Cortex-A7-Basis mit einer Taktfrequenz von bis zu 900 MHz. Das neue Modell soll bei Multithreading-Anwendungen bis zu sechsmal schneller als seine Vorgänger sein und sowohl Ubuntu Core Snappy als auch Microsoft Windows 10 unterstützen.\nAuf der Entwicklerkonferenz „Build 2015“ von Microsoft wurde Windows 10 IoT (Spezielle Version von Windows 10 für „Internet of Things“-Geräte) offiziell angekündigt.\n\nAm 26. November 2015 wurde der Raspberry Pi Zero vorgestellt. Die Ausstattung ähnelt der des Model A+, jedoch taktet der Prozessor nicht mehr mit 700 MHz, sondern mit 1 GHz und die Platinenbreite wurde von 56 mm auf 35 mm verringert. Der HDMI-Steckverbinder wurde durch den kleineren Mini-HDMI ersetzt und die USB-A-Buchse durch die kleinere Micro-USB-Buchse (B). Die 40-polige Stiftleiste für die GPIO-Pins ist ebenso wie der FBAS-Videoausgang nicht bestückt.\nAm 29. Februar 2016 wurde der Raspberry Pi 3 Model B vorgestellt. Er erweitert das Vorgängermodell um integriertes WLAN und Bluetooth Low Energy und hat eine schnellere CPU mit 64-bit-ARMv8-Architektur.\n\nEnde 2016 wurde die Version 1.2 des Raspberry-Pi-2-Modell B mit der neuen CPU des Modell 3 vorgestellt. Abgesehen von dieser ist die Ausstattung identisch mit der des ursprünglichen Modell 2; auch die CPU ist weiterhin nur mit 900 MHz getaktet, anstatt der 1200 MHz des Modell 3.\n\nAm 16. Januar 2017 wurde das Compute Module 3 (CM3) vorgestellt. Es hat den SoC des Raspberry Pi 3 und 1 GB RAM (vorher: 512 MB). Die CPU-Leistung soll sich im Vergleich zum CM1 etwa verzehnfacht haben. Das CM3 ist in zwei Varianten verfügbar: eine Standardvariante und eine Lite (CM3L), wobei letztere nicht über den aufgelöteten 4-GB-Flashspeicher verfügt. Das CM3 ist mit dem CM1 kompatibel, einziger sichtbarer Unterschied ist die um 1 mm gewachsene Breite.\n\nAm 28. Februar 2017 wurde der Raspberry Pi Zero W vorgestellt. Die Ausstattung des Modells ist nahezu identisch zum Raspberry Pi Zero, wurde jedoch durch den schon beim Raspberry-Pi-3-Modell B eingesetzten zusätzlichen Chip um die Funktionalität von integriertem WLAN und Bluetooth Low Energy erweitert. Seit dem 12. Januar 2018 ist der Raspberry Pi Zero WH erhältlich, der technisch dem Raspberry Pi Zero W entspricht, aber dessen 40-poliger Anschluss bereits werkseitig mit entsprechenden Pfostensteckern versehen ist.\n\nAm 14. März 2018 (Pi-Tag) wurde das Raspberry-Pi-3-Modell B+ vorgestellt. Der Prozessortakt wurde um 200 MHz auf 1400 MHz erhöht und ein neues Funkmodul kommt zum Einsatz. Dieses beherrscht nun auch 5-GHz-WLAN nach dem IEEE-802.11ac-Standard und Bluetooth 4.2. Außerdem verfügt es jetzt auch über Gigabit-Ethernet, das jedoch weiterhin über den einzigen USB-Port angebunden ist und damit die maximale Übertragungsrate auf ca. 300 MBit/s limitiert. Das neue Modell ist vorbereitet für Power over Ethernet.\n\nIm Januar 2019 erschien die auf dem basierenden Compute Module 3+ (CM3+). Es verwendet wie dieses den Processor BCM2837B0 taktet diesen jedoch nur mit 1200 MHz und ist im Unterschied zu den Vorgänger Versionen des Compute Module neben der \"Lite-Version\" ohne eMMC-Speicher auch mit 8 GB, 16 GB oder 32 GB Speicher verfügbar. Bisher war Compute Module nur mit max. 4 GB eMMC verfügbar.\n\nDie unterschiedlichen Produkte unter dem Namen Raspberry Pi besitzen folgende Eigenschaften:\n\nDer Prozessor der ersten Generation nutzt den ARMv6-Instruktionssatz mit den Erweiterungen Thumb und Java-Bytecode (Jazelle). Der Speicher ist über einen 64 Bit breiten Bus angebunden und wird direkt als Package-on-Package auf den Prozessor gelötet.\n\nDa die Raspberry Pi Foundation eine Verringerung der Lebensdauer bei Übertaktung befürchtete, wurde der Prozessor zunächst mit einem „Sticky (engl. wörtlich „klebenden“, das bedeutet: nicht rücksetzbaren) Bit“ ausgestattet, das unwiderruflich gesetzt wird, sobald der Prozessor übertaktet wird, und somit ein Erlöschen der Garantie signalisiert. Nachdem ausführliche Tests gezeigt hatten, dass sich ein Übertakten auf bis zu 1 GHz kaum auf die Lebensdauer auswirkt, wurde am 19. September 2012 mit einem neuen Treiber die Möglichkeit geschaffen, sowohl Prozessor als auch GPU und Speicher ohne Garantieverlust zu übertakten. Die Frequenz und Spannung werden dabei im Betrieb nur dann erhöht, wenn die Leistung benötigt wird und die Temperatur des Chips nicht über 85 °C liegt.\nDas Sticky-Bit wird nur noch gesetzt, wenn stärker als empfohlen übertaktet wird.\n\nEin deutliches Untertakten auf bis zu 50 MHz und Verringern der Spannung ist ebenfalls möglich, was vor allem beim Modell A zu einer deutlich reduzierten Leistungsaufnahme führt.\n\nIn der zweiten Generation kommt ein SoC mit der Bezeichnung BCM2836 ebenfalls vom Hersteller Broadcom zum Einsatz. Der dort in einer Quadcore-Konfiguration eingesetzte ARM Cortex-A7 mit 900 MHz Taktfrequenz nutzt den ARMv7-Befehlssatz und erreicht eine Gesamtrechenleistung von 6.840 DMIPS. Dazu ist der Prozessor um Faktor 3 energieeffizienter als sein Vorgänger.\n\nIn der dritten Generation wird ein BCM2837 von Broadcom eingesetzt. Der verwendete ARM Cortex-A53 mit 1,2 GHz Taktfrequenz hat 50–60 % mehr Leistung als die zweite Generation bzw. fast die zehnfache Leistung gegenüber der ersten Generation. Mit dem Raspberry Pi 3 Model B+ wurde der BCM2837B0, eine überarbeitete Version der dritten Generation, eingeführt. Diese Version hat Verbesserungen bei der Takt- und Spannungsregelung und einen Heatspreader aus Metall. Damit sollen höhere Taktraten und ein längerer Betrieb unter hoher Last ohne Drosselung der CPU-Leistung möglich sein.\n\nDer ARM11-Prozessor ist mit Broadcoms „VideoCore“-Grafikkoprozessor kombiniert. OpenGL ES 2.0 wird unterstützt, und Filme in Full-HD-Auflösung (1080p30 H.264 high-profile) können dekodiert und über die HDMI-Buchse und FBAS-Cinchbuchse ausgegeben werden.\n\nAm 24. August 2012 wurde bekanntgegeben, dass Lizenzen für das hardwarebeschleunigte Dekodieren von VC1- und MPEG-2-kodierten Videos zusätzlich erworben werden können. Die Lizenz beschränkt sich dabei auf den bei der Bestellung mit der Seriennummer spezifizierten Raspberry Pi, so dass für jeden dieser Mikrorechner eine eigene Lizenz erforderlich ist. Die vorhandene Lizenz zum Dekodieren von H.264-kodierten Videos erlaubt nach Angaben der Raspberry Pi Foundation auch das Kodieren solcher Videos.\n\nIm März 2014 legte Broadcom Dokumentation und Treibercode für den SoC BCM21553 unter einer BSD-Lizenz offen, mit dem auch ein freier Grafiktreiber für den verwendeten BCM2835 erstellt werden kann.\n\nEin entsprechender Treiber wurde nach einem von der Raspberry Pi Foundation ausgerufenen und mit 10.000 USD dotierten Programmierwettbewerb im März 2014 von einem einzelnen Programmierer veröffentlicht.\n\nDas Audiosignal erzeugt das System-on-Chip (SoC) BCM 2835 von Broadcom durch eine einfache Pulsweitenmodulation (PWM) und gibt es über den Audioausgang der 3,5-mm-Klinkenbuchse aus. Auf einen echten Digital-Analog-Umsetzer (DAC) wurde aus Kostengründen verzichtet. Diese Lösung gilt jedoch als schwach, weil DAC und Tiefpassfilter fehlen, da ohne diese störende Nebengeräusche, die als Vielfaches der Modulationsfrequenz entstehen, nicht beseitigt werden. Elektrisch ist dieser Ausgang besser zum Anschluss von Aktivboxen oder am Verstärker einer herkömmlichen Stereoanlage geeignet als für verstärkerlose Kopfhörer. Des Weiteren wird ein Audiosignal in digitaler Form über den HDMI-Ausgang ausgegeben.\n\nSeit Raspbian Stretch wird ein neuer Audio-Treiber verwendet, dessen Analog-Signal-Rausch-Verhältnis CD-Qualität erreichen soll.\nDabei wird die Technik der Delta-Sigma-Wandlung verwendet.\n\nVerschiedene Dritthersteller bieten außerdem dedizierte Audiolösungen in Form von USB-Audio-Karten oder als Aufsteckkarten an, die eine simulierte I²S-Schnittstelle nutzen. Ferner existieren Lösungen, die das Audiosignal aus der HDMI-Schnittstelle extrahieren.\n\nDer Raspberry Pi enthält keine Echtzeituhr (RTC). Das Gerät kennt daher nach dem Anschalten weder Datum noch Uhrzeit. Sofern es mit dem Netzwerk verbunden ist und es nicht selbst kritische Teile der Netzwerkinfrastruktur (etwa den Namensdienst) anbietet, kann die Zeit meist via NTP beschafft werden. Ansonsten muss eine separate Echtzeituhr angeschlossen werden, wenn eine verwendete Software die korrekte Uhrzeit benötigt.\n\nDer Raspberry Pi stellt eine frei programmierbare Schnittstelle für Ein- und Ausgaben bereit. Diese Allzweckeingabe/-ausgabe wird auch als „GPIO“ („General Purpose Input/Output“) bezeichnet. Über diese Schnittstelle können LEDs, Sensoren, Displays und andere Geräte angesteuert werden.\nEs gibt fünf GPIO-Anschlüsse, wobei im Allgemeinen nur der Anschluss P1 gebraucht wird. Die GPIO-Schnittstelle P1 besteht bei Modell A und Modell B aus 26 Pins und bei Modell A+ und Modell B+ aus 40 Pins, jeweils ausgeführt als doppelreihige Stiftleiste, wovon\nMit dem Modell B+ wurde eine offizielle Spezifikation für Erweiterungsplatinen, sogenannte Hardware attached on top (HAT), vorgestellt. Jeder HAT muss über einen EEPROM-Chip verfügen; Darin finden sich Herstellerinformationen, die Zuordnung der GPIO-Pins sowie eine Beschreibung der angeschlossenen Hardware in Form eines „device tree“-Abschnitts. Dadurch können die nötigen Treiber für den HAT automatisch geladen werden. Auch die genaue Größe und Geometrie des HAT sowie die Position der Steckverbinder werden dadurch festgelegt. Modell A+ und Raspberry Pi 2 Modell B sind mit diesen ebenfalls kompatibel.\n\nDie in der Revision 2 hinzugekommene GPIO-Schnittstelle P6 erlaubt es, den Raspberry Pi zurückzusetzen bzw. zu starten, nachdem er heruntergefahren wurde.\n\nZur Steuerung der GPIOs existieren Bibliotheken für zahlreiche Programmiersprachen. Auch eine Steuerung durch ein Terminal oder Webinterfaces ist möglich.\n\nZur direkten Anbindung einer Kamera ist ein CSI (Camera Serial Interface) vorhanden.\n\nDie seit Mai 2013 erhältliche Kamera mit fünf Megapixeln wird per CSI angesteuert.\nDer Fokus ist nicht veränderbar und das Kameramodul verfügt über kein Mikrofon. Die Kamera nimmt Fotos mit einer maximalen Auflösung von Pixeln auf, Videos können unter anderem mit , und Pixeln aufgenommen werden. Die Bildfrequenz beträgt je nach Auflösung und Einstellung 1 bis 90 Bilder pro Sekunde, der Sensor stammt von Omnivision (OV 5647). Bei schlechtem Licht entsteht schnell Bildrauschen.\n\nSeit Oktober 2013 ist auch die Variante „PI NoIR“ ohne eingebauten Infrarotfilter verfügbar, die unter Zuhilfenahme eines Infrarotscheinwerfers Nachtsichtaufnahmen ermöglicht.\n\nEnde April 2016 wurde ein neues Kameramodul vorgestellt. Es verfügt über einen acht Megapixel auflösenden Bildsensor vom Typ IMX219 von Sony. Er nimmt Fotos mit einer maximalen Auflösung von Pixeln auf.\n\nZur direkten Anbindung von Bildschirmen ist ein DSI (Display Serial Interface) vorhanden.\n\nSeit September 2015 ist offiziell ein Bildschirm erhältlich, der direkt über die DSI-Schnittstelle angeschlossen werden kann. Seine Bildschirmdiagonale misst 7 Zoll (178 mm) und es besitzt eine Auflösung von Pixeln. Die Bildschirmfläche misst (\"screen size\"); aufgrund des breiten Bildschirmrands misst das gesamte Anzeigegerät jedoch (\"display size\"), ist 20 mm dick und wiegt 277 g. Es verfügt außerdem über einen kapazitiven Multi-Touchscreen (bis zu zehn Finger) mit integriertem Controller und Befestigungsbolzen für den Raspberry Pi (außer Modell A und B). Dieser wird über I²C angeschlossen. Die Leistungsaufnahme des Displays beträgt 2,25 W.\n\nFür den Raspberry Pi sind mehrere Open-Source-Betriebssysteme verfügbar. Installiert werden sie entweder durch das Schreiben eines Speicherabbilds auf die SD-Karte oder seit dem 3. Juni 2013 auch mit der einfacher zu verwendenden Eigenentwicklung NOOBS-Installer (engl. Abk. für \"new out of box software\"), deren Dateien nur auf die SD-Karte kopiert werden müssen. Mit BerryBoot gibt es einen ebenso einfach zu installierenden Bootloader, der es ermöglicht, mehrere Betriebssysteme auf einer Karte parallel zu installieren und wahlweise zu verwenden. Seit Version 1.3 ist dies auch mit NOOBS möglich.\n\nDie empfohlene Linux-Distribution ist das auf Debian basierende Raspbian. Dieses Betriebssystem basiert auf einem Debian-9-System (Debian Stretch) der ARM-hard-float-Architektur (armhf) mit Anpassungen an den Befehlssatz für den ARMv6-Prozessor. Als grafische Oberfläche wird LXDE vorkonfiguriert. Das etwa 3 GB große Image kann auf SD-Karten mit 4 GB oder mehr übertragen werden. Nach dem Bootvorgang kann die Größe der Raspbian-Partition auf die gesamte SD-Karte erweitert werden. Die Raspberry Pi Foundation erstellt auf Basis der Raspbian-Distribution ein eigenes Raspbian-Image mit passender Firmware für die Raspberry-Pi-Modelle, es wird daher empfohlen, die Distribution immer von der Raspberry Pi Foundation zu beziehen.\n\nNeben Raspbian wird auch eine für ARM-Prozessoren kompilierte Version von Arch Linux, CentOS sowie einige Versionen (Remixe) von Fedora – u. a. unter den Namen Pidora und FedBerry – angeboten.\nGentoo Linux und Manjaro Linux können auf dem Raspberry Pi installiert und betrieben werden. Ebenso gibt es Kali Linux, die Neuauflage der Security-Distribution BackTrack und Bodhi Linux für den Raspberry Pi. OpenSUSE bietet ebenfalls lauffähige Images und mit dem openSUSE Build Service zudem die Möglichkeit, eigene Programmpakete zu erstellen und damit eigene openSUSE-basierte Distributionen zu erstellen. Zudem gibt es den Slackware-Ableger Slackarm, der auf allen Modellen lauffähig ist.\n\nUbuntu kann auf dem Raspberry Pi 2 und Raspberry Pi 3 betrieben werden. Auf dem Raspberry Pi der ersten Generation ist die Installation von Ubuntu nicht möglich, da diese Linuxdistribution keine ARMv6-Architektur (ARM11-Familie) unterstützt.\n\n\"SolydX\" bietet ebenfalls ein Image zum Herunterladen an. SolydX RPI basiert auf Debian und bringt Xfce als Desktop mit.\n\nMit den entsprechenden Distributionen (OpenELEC, LibreELEC, OSMC oder XBian) lässt sich der Raspberry Pi als Mediacenter nutzen. Kodi lässt sich auch mit der Fernbedienung des Fernsehers nutzen, wenn dieser per HDMI angeschlossen wird und CEC unterstützt. Kodi ist auch in Recalbox enthalten und kann bei RetroPie optional ausgewählt werden. Beide stellen aber eigentlich einen Emulator für alte Spielekonsolen dar.\n\nAußerdem wird das Android-System auf den Raspberry Pi portiert. Eine Variante eines Android-basierenden Betriebssystems ist emteria.OS, das für Raspberry Pi 3 B und 3 B+ erhältlich ist.\n\nAb der Modellreihe Pi 3 B kann die webOS Open Source Edition von LG eingesetzt werden.\n\nDes Weiteren sind die BSD-Varianten FreeBSD und NetBSD, aber auch Plan 9 und das damit verwandte Inferno auf dem Raspberry Pi einsatzbereit.\n\nOpenBSD bietet mit der arm64-Plattform sogar 64-Bit-Unterstützung für den Raspberry Pi 3 an.\n\nEine Entwicklerversion von steht ebenfalls zu Verfügung.\n\nObwohl Windows RT auf ARM-Prozessoren lauffähig ist, erschien es zunächst nicht möglich, dieses Betriebssystem auf den Raspberry Pi zu übertragen, da Windows 8 mindestens 1 GB Arbeitsspeicher benötigt, den der Raspberry Pi nicht hatte. Mit dem Erscheinen des Raspberry Pi 2 im Februar 2015 gab Microsoft jedoch bekannt, dass Windows 10 auf diesem lauffähig und für Teilnehmer des Windows-Entwicklerprogramms für das Internet der Dinge kostenlos sein werde. Dabei ist zu beachten, dass diese Version von Windows 10 als Small-Devices-Variante bezeichnet wird, nicht mit klassischen Desktop-Anwendungen kompatibel ist und für den Betrieb mindestens 256 MB RAM und 2 GB Speicher benötigt.\n\nEinige Programme wurden für den Raspberry Pi angepasst, um von der hardwarebeschleunigten Grafik durch die GPU zu profitieren. Dazu zählt insbesondere die Mediacenter-Software Kodi. Im Rahmen der Anpassung von Kodi an den Raspberry Pi wurde auch ein eigenständiger Videoplayer mit GPU-Unterstützung unter dem Namen OMXPlayer entwickelt.\nAuch das Spiel Minecraft gibt es in einer speziellen kostenfreien Version mit integrierter Programmierschnittstelle. Die Bibliotheken Qt und NGL wurden auf den Raspberry Pi unter dem Namen „QtonPi“ portiert.\n\nSeit November 2013 erhält jeder private Benutzer des Raspberry Pi ein kostenloses Exemplar der Software Mathematica.\n\nMit QEMU lässt sich ein Raspberry Pi 2 mit Einschränkungen emulieren, also Originalsoftware für Raspberry Pi 2 auf einem normalen PC ausprobieren.\n\nWegen des günstigen Preises und der geringen Leistungsaufnahme eignet sich der Raspberry Pi abseits der vorgesehenen Nutzung als Schulrechner insbesondere als Steuereinheit für Robotik- und Embedded-Projekte, Media Center, Thin Client oder Server.\n\nSeit dem Verkauf des Raspberry Pi berichten vor allem technisch ausgerichtete Medien regelmäßig über neue Projekte mit dem Raspberry Pi. Raspberry Pi wurde als Innovation des Jahres beim T3 Gadget Awards 2012 ausgezeichnet. Eben Upton, einer der Entwickler des Raspberry Pi, wurde 2013 mit der Silbermedaille der Royal Academy of Engineering ausgezeichnet.\n\nDer Raspberry Pi taucht in zahlreichen Filmen und TV-Serien auf, darunter in Point Break und Marvel’s Agents of S.H.I.E.L.D., in den Serien Revolution und Mr. Robot spielt der Raspberry Pi sogar eine zentrale Rolle in der Handlung.\n\nIm Mai 2012 wurde die erste Ausgabe der kostenlosen Community-Zeitschrift MagPi online veröffentlicht. Das Magazin greift alle Themen rund um den Raspberry Pi auf. Seit dem Erscheinen der Ausgabe 36 im Juli 2015 erscheint MagPi auch gedruckt.\nSeit Juni 2013 gibt es eine englische und seit August 2013 die deutschsprachige Zeitschrift „Raspberry Pi Geek“ vom Medialinx Verlag.\n\nNach dem großen Erfolg des Raspberry Pi kamen eine Reihe ähnlicher Einplatinencomputer auf den Markt. Zu nennen sind hier insbesondere das Cubieboard, das BeagleBone Black, das Banana Pi oder das HummingBoard. Einige davon ahmen das Raspberry Pi in Aussehen, Größe und Lage der Steckverbinder nach und versuchen dadurch eine weitgehende Kompatibilität zum Raspberry Pi zu erreichen. Für die alternativen Systeme gibt es derzeit keine vergleichbar großen Kern-Communitys wie im Fall des Raspberry Pi.\n\nIm Februar 2015 wurde bekannt, dass der Raspberry Pi 2 Model B abstürzt, wenn er mit einem Xenon-Blitz fotografiert wird. Die Raspberry Pi Foundation bestätigte dieses Verhalten. Verursacht wird es durch ein Bauteil („U16“), das für die interne Spannungsversorgung zuständig ist. Dieses erzeugt aus den 5 V des Micro-USB-Anschlusses die intern benötigten Spannungen. Dazu wurde ein Chip ohne Gehäuse gewählt und direkt auf die Platine gelötet. Wird der Chip angeblitzt, bringt der im freiliegenden Silizium auftretende photoelektrische Effekt die Spannungsregelung aus dem Takt. Die Folge ist eine Spannungsschwankung, die zum Absturz des Raspberry führt. Problematisch ist dabei die durch einen Xenon-Blitz oder auch einen Laserpointer hervorgerufene rapide Helligkeitsänderung und der enorme Lichtstrom. Andere helle Lichtquellen bereiten keine Probleme. Es werden verschiedene Lösungen diskutiert, wie künftige Revisionen unempfindlich gegenüber derartigen Lichtquellen gemacht werden können. Als einfache Lösung empfiehlt der Hersteller, das Bauteil mit einem Tropfen elektrisch nicht leitenden und lichtundurchlässigen Klebers abzudecken.\n\n\n\n"}
{"id": "6197623", "url": "https://de.wikipedia.org/wiki?curid=6197623", "title": "Mac OS X Lion", "text": "Mac OS X Lion\n\nLion (), vollständig Mac OS X Lion 10.7, auch kommuniziert als OS X Lion (ohne „Mac“), ist die achte Hauptversion von macOS, dem Desktop-Betriebssystems von Apple, das seinerzeit unter dem Namen Mac OS X eingeführt wurde. Es folgte auf Mac OS X Snow Leopard und wurde am 20. Juli 2011 veröffentlicht. Es wurde bei einer Produktpräsentation mit dem Titel „“ am 20. Oktober 2010 erstmals der Öffentlichkeit vorgestellt. Die erste Entwicklerversion war ab dem 24. Februar 2011 für Mitglieder des Apple Developer Programs verfügbar.\n\nZu den wichtigsten Neuerungen gehören die Einführung von Bedienelementen aus dem firmeneigenen Betriebssystem Apple iOS für sogenannte „Post-PC-Geräte“ und die Integration der ESD-Plattform Mac App Store. Das Betriebssystem wurde primär als Download über den Mac App Store vertrieben, dieser setzt als Betriebssystem mindestens Mac OS X Snow Leopard ab Version 10.6.6 voraus. Seit dem 16. August 2011 wurde das System außerdem zu einem höheren Preis auf einem USB-Speichermedium vertrieben.\n\nDer Funktionsumfang der bisherigen Server-Variante des Betriebssystems, bis Snow Leopard (10.6, 2009) noch als separates Betriebssystem Mac OS X Server veröffentlicht, ist für Mac OS X Lion (10.7) nun ein kostenpflichtiges Upgrade (als „OS X Server 1.0“ im Mac App Store vertrieben) und macht das Betriebssystem zum „Lion Server“. Eine separate Server-Version 10.7 entfällt.\n\nInnerhalb der ersten 24 Stunden nach Veröffentlichung wurde das Betriebssystem mehr als eine Million Mal heruntergeladen. Bis Anfang Oktober 2011 wurden sechs Millionen Kopien der Software verkauft, bis Juli 2012 26 Millionen Kopien. 30 % aller Mac-OS-X-Installationen liefen im Februar 2012 mit Mac OS X Lion (10.7), das hinter Mac OS X Snow Leopard (10.6, 2009) den zweitgrößten Anteil der Versionen innehatte.\n\nDie letzte Version von Mac OS X Lion ist 10.7.5 vom 19. September 2012. Der Nachfolger heißt OS X Mountain Lion und wurde am 25. Juli 2012 veröffentlicht.\n\n\nVerschiedene Betriebssystembestandteile, darunter die Mediencenter-Oberfläche Front Row, eine vorinstallierte Java-Laufzeitumgebung und die Emulationssoftware Rosetta, die das Ausführen von Programmen für PowerPC-Prozessoren ermöglichte, werden nicht mehr unterstützt. Auch iSync ist kein Bestandteil von Mac OS X mehr, lässt sich aber über Umwege nachträglich installieren. In der Server-Variante wurde MySQL durch PostgreSQL ersetzt.\nTomcat und der \"QuickTime Streaming Server (QTSS)\" werden ebenfalls nicht mehr unterstützt.\n\n\n"}
{"id": "6200697", "url": "https://de.wikipedia.org/wiki?curid=6200697", "title": "Chromebook", "text": "Chromebook\n\nAls Chromebooks werden mobile Computer bezeichnet, die als Betriebssystem die Linux-Distribution Google Chrome OS benutzen.\n\nChromebooks zeichnen sich dadurch aus, dass anders als bei einem klassischen Notebook Anwendungsprogramme zum überwiegenden Teil als Applikation im Chrome-Browser laufen. Daten und Einstellungen werden in der Regel nicht lokal, sondern in der Google-Cloud gespeichert und online zur Verfügung gestellt. Dadurch sind die Geräte schnell austauschbar: Mit der Anmeldung über ein persönliches Google-Konto auf einem anderen Gerät werden alle Daten und Einstellungen synchronisiert. Um ihren vollen Funktionsumfang auszuschöpfen, sind Chromebooks auf die Anbindung an die Google-Server über einen Internetzugang angewiesen. Weiteres wesentliches Merkmal von Chromebooks ist das schnelle Hochfahren, da Chrome OS im weitesten Sinn nur ein Browser ist.\n\nDie ersten Chromebooks wurden ab Juni 2011 in den USA, Großbritannien, Frankreich, Spanien, Italien und Deutschland angeboten.\n\nDie ersten Modelle der Chromebooks wurden von den asiatischen Unternehmen Samsung und Acer produziert und optional mit UMTS-Unterstützung angeboten. Das Chromebook von Samsung wurde mit einem 12,1\"-Monitor und einer Auflösung von 1280 × 800 Bildpunkten ausgeliefert, das Acer-Chromebook mit einem 11,6\"-Monitor. Beide Geräte verfügten über eine HD-fähige Webcam, sodass auch Videokonferenz-Dienste des US-amerikanischen Unternehmens Google genutzt werden konnten.\n\nHeutige Modelle (Stand 2018) sind bis auf wenige High-End-Modelle mit eher leistungsschwächeren Bauteilen wie CPUs und Arbeitsspeicher ausgestattet, die Akkus häufig fest verbaut. Die lokalen Massenspeicher, häufig SSDs, sind weitaus kleiner ausgelegt als bei Notebooks ähnlicher Größe, weil größere Datenmengen zentral auf Servern gespeichert werden.\n\nFür schnelles Booten wird Coreboot anstatt BIOS/UEFI verwendet.\n\nNeben den Notebooks werden seit 2012 auch Chrome OS-Geräte in Form von Desktop-Computern angeboten, die \"Chromebox\" genannt werden.\n\nJedes Chromebook hat sowohl ein \"Trusted Platform Module\" als auch einen passenden Firmware-Chip. Dieser Chip wird verwendet, um beim Bootvorgang zu überprüfen, ob die Read-Write-Firmware vom Unternehmen Google signiert wurde.\n\nDamit auf einem Chromebook auch ohne permanente Internetverbindung gearbeitet werden kann, hat Google für diese Art von Notebooks besondere „Offline“-Versionen seiner Software (z. B. Google Mail) entwickelt.\n\nFür den professionellen Einsatz sowie für Behörden und Bildungseinrichtungen werden Chromebooks als kombinierte Hardware und Software as a Service direkt von Google vertrieben.\n\nChromebooks versprachen bei ihrer Einführung eine Bootzeit von unter acht Sekunden einschließlich der Verbindung zum Internet. Die Akkus sollten eine Laufzeit von einem Tag bieten. In der Praxis booten Geräte des Jahres 2018 in rund zehn Sekunden, die Akkulaufzeit liegt zwischen zehn und vierzehn Stunden.\n\nDer größte Unterschied besteht im Betriebssystem Chrome OS, das als System auf den Webbrowser Chrome reduziert ist. Anwendungen laufen als Webanwendung in Chrome, deswegen muss keine Software installiert werden. Updates für Betriebssystem und Browser werden automatisch über das Internet verteilt, Web-Apps anderer Anbieter als Google erfolgen auf deren Servern.\nDeshalb ist auch das Aktualisieren auf eine neue Version oder das Installieren von Sicherheitskorrekturen durch den Benutzer unnötig.\nDa auf den Chromebooks nur Webanwendungen zum Einsatz kommen, können trotz beschränkter Hardware auch aufwendige und rechenintensive Anwendungen wie das Schneiden von Videos durchgeführt werden, sofern ein geeigneter Webdienst das anbietet. Dafür müssen allerdings die Benutzerdaten, also zum Beispiel das Video, hochgeladen werden.\n\nDatenschützer bemängeln, dass Chromebook-Nutzer nicht nur die Kontrolle über ihre Daten, sondern auch über die Programme verlieren. Bei einem Rückzug einer App und einem Sicherheitsleck seien sofort alle Nutzer betroffen. Außerdem werden in hohem Maße Nutzerdaten an Google übertragen. Dies ist auch bei von Google im Rahmen eines Service-Vertrages vertriebenen Geräten für Bildungseinrichtungen der Fall .\nEbenso können andere Betriebssysteme nicht ohne weiteres aufgespielt werden, da der Bootvorgang der Geräte nicht modifiziert werden kann . Eine Modifikation des Betriebssystems, um Linux auf dem Chromebook zu installieren, funktioniert über die Entwicklereinstellungen des Betriebssystems. Dabei hilft die Tatsache, dass es sich bei Google Chrome OS um ein Gentoo-Linux-Derivat handelt.\n\nBis Ende 2012 sah die Situation für Google und die Hersteller enttäuschend aus. Samsung und Acer verkauften weltweit deutlich weniger als 200.000 Chromebooks. Acer überlegte die Produktion von Chromebooks zu beenden, zuvorige Interessenten wie Asus und HTC wollten vorerst komplett auf das Betriebssystem verzichten.\n\n2013 konnte das Geschäft mit Chromebooks in den USA deutlich zulegen. Insbesondere konnten Chromebooks bei den Firmenkäufen einen Anteil am Gesamtmarkt von 10 % erreichen. Im dritten Quartal 2014 überstiegen die Verkaufszahlen von Chromebooks an US-Bildungseinrichtungen mit 715.000 Stück erstmals diejenigen von iPads. Im Januar 2015 kündigte Acer erstmals ein Chromebook mit einem 15,6 Zoll großen Full-HD-Display an.\n\nAuf der Google I/O 2016 wurde verkündet, dass Android Apps in Zukunft auf Chrome OS, und somit auch auf Chromebooks ausgeführt werden können. Die ersten Chromebooks werden dabei ab Juni 2016 die Möglichkeit bekommen, Apps aus dem Play Store herunterladen zu können. Andere Geräte sollen bis Dezember 2016 folgen, dazu hat Google eine Liste mit unterstützten Geräten veröffentlicht.\n\n"}
{"id": "6202710", "url": "https://de.wikipedia.org/wiki?curid=6202710", "title": "Bodhi Linux", "text": "Bodhi Linux\n\nBodhi Linux ist eine Linux-Distribution, die auf Ubuntu basiert und die Desktop-Umgebung Moksha benutzt.\n\nLaut Entwickler startet Bodhi Linux mit minimalen Hardwareanforderungen von 128 MB RAM, 2,5 GB Festplattenspeicher, und einem 300 MHz Hauptprozessor. Bodhi setzt zwar Desktopeffekte ein, schont dabei aber die Hardwareressourcen. Ein unabhängiger Test zeigte, dass GIMP innerhalb von 4,7 Sekunden unter Bodhi Linux startete, unter Ubuntu benötigte es dazu 11,1 Sekunden.\n\nDie speziell für Bodhi geschriebenen Werkzeuge wurden in der Programmiersprache C geschrieben. Mittlerweile wird aber auf die Desktop-Umgebung Moksha gesetzt.\n\nDas Versionierungsschema: Die erste Zahl steht für ein Major Release, die zweite Zahl für ein Quartals- oder Kernel-Update und die dritte Zahl nur für ein Software Update. Die Major-Release-Zyklen orientieren sich an dem Ubuntu-LTS-Zyklus (2 Jahre).\n\nBodhi Linux für ARM-Architektur basiert auf Debians ArmHardFloatPort (ARMHF) Port. Derzeit wird an einem installierbaren Image für das Genesi Smartbook gearbeitet.\nFür den Einplatinencomputer Raspberry Pi wird ein Image zum Download bereitgestellt.\n\nBodhi Linux zählte Mitte/Ende 2012 laut Distrowatch zu den 20 meistinteressierenden Linux-Distributionen – zudem mit zunehmendem Interesse. Mitte September 2012 listete Distrowatch in seinem Ranking für die zurückliegenden sechs Monate Bodhi Linux auf Platz 16, somit noch vor so namhaften Distributionen wie Knoppix und Mandriva.\n\nSourceForge meldete Mitte September 2012 etwa 20.000 Downloads von Bodhi Linux pro Woche.\nZwei Jahre später waren es etwa 10.000 Downloads pro Woche.\n\nIm September 2014 wurde bekannt, dass Jeff Hodgeland aus Zeitgründen die weitere Entwicklung in andere Hände abgeben will. Er dementierte damit Gerüchte, dass Bodhi eingestellt werden soll.\n\n\n\nSoftwarebesprechungen\n"}
{"id": "6218931", "url": "https://de.wikipedia.org/wiki?curid=6218931", "title": "Windows Workflow Foundation", "text": "Windows Workflow Foundation\n\nWindows Workflow Foundation (\"WF\", früher auch WWF und WinWF) ist eine Programmbibliothek innerhalb der .NET-Programmierumgebung von Microsoft. Sie dient der einfacheren Entwicklung von programmgesteuerten, komplexen Arbeitsabläufen (engl. \"Workflows\"). Diese Art von Software wird auch als \"Workflow-Anwendungssoftware\" bezeichnet.\n\nDie Windows Workflow Foundation ermöglicht eine deklarative Programmierung. Hierbei wird eine grafische Beschreibung des Ablaufes erstellt, anstatt ihn in Form von Programmcode zu modellieren. Die WF schafft damit höhere Abstraktionsebenen, die den Entwickler weg von der Codierung und näher zu den fachlichen Geschäftsprozessen rückt.\n\nDabei unterstützt sie den Entwickler einerseits durch vorgefertigte Klassen und Konstrukte, die typische Knoten und Aktivitäten eines Ablaufdiagramms repräsentieren, und andererseits durch einen grafischen Editor in Microsoft Visual Studio, in dem die Abläufe gestaltet werden können.\n\nDie Windows Workflow Foundation trennt zwischen der Logik des Prozesses und den technisch notwendigen Programmierungen für die einzelnen Arbeitsschritte innerhalb dieser Logik. Eine Aktivität (Terminus: \"Activity\") kann dabei von profanen Anweisungen (\"z. B. „Drucke Text auf Bildschirm“\") bis hin zu komplexen Programmen (\"z. B. „Berechne kürzesten Weg von A nach B“\") reichen. Zudem kann eine Aktivität in sich selbst wieder aus einem Arbeitsablauf mit anderen Aktivitäten bestehen.\n\nEine laufende Aktivität kann jederzeit unterbrochen und gesichert werden, um zu einem späteren Zeitpunkt wieder aufgenommen zu werden.\n\nDie Windows Workflow Foundation ist ein Teil von .NET ab der Version 3.0. In der Version 4.0 von .NET wurden alle für die Windows Workflow Foundation relevanten Aspekte deutlich überarbeitet und verbessert.\n\nDie Windows Workflow Foundation ist ein zentraler Baustein von Microsoft, um seine Software für Geschäftskunden mit einer Schnittstelle für die individuelle Anpassung (Customizing) zu versehen. Folgende Produkte bieten in unterschiedlicher Form eine Unterstützung für die Windows Workflow Foundation an, sei es durch eingebaute Editoren oder eine API zur Integration in andere Workflow-Systeme:\n\n\nusing System;\nusing System.Activities;\nusing System.Activities.Statements;\n\nnamespace HelloWorldWorkflow\n\nMit der Windows Workflow Foundation kann das gleiche Programm mit verschiedenen Darstellungsmöglichkeiten implementiert werden.\n\n\nDie Windows Workflow Foundation wurde von Entwicklern und Fachpresse zunächst als eine inhomogene, komplexe und im Vergleich zu anderen Teilen des .NET Frameworks schwer zugängliche Bibliothek angesehen. Ein Hauptgrund hierfür ist, dass ihr Einsatz neben einem guten Verständnis für die theoretische Seite der Prozesssteuerung auch fundierter praktischer Kenntnisse von .NET im Allgemeinen und der Konzepte der Windows Workflow Foundation im Speziellen bedarf. In Version 3.0 hatten Entwickler zudem mit vielen Programmfehlern zu kämpfen. Die Implementation ist bis heute noch nicht fehlerfrei.\n\nNeben der hohen Lernschwelle, bedingt durch die Komplexität, war ein großer Kritikpunkt in der Version 3.0 auch die langsame Verarbeitungsgeschwindigkeit, die Microsoft mit der Version 4.0 aber deutlich erhöhen konnte. Diese Version hat zudem gegenüber ihren Vorgängern deutlich an Qualität und Konsistenz gewonnen.\n\nTrotzdem wird die Windows Workflow Foundation gerade bei Anwendungen in Unternehmen als gutes Werkzeug angesehen, um die Komplexität der Software zu mindern. Sie erreicht dies durch die oben genannte Trennung zwischen dem Ablauf des Geschäftsprozesses und der Codierung der einzelnen Schritte. Dies gilt besonders für Prozesse, die sich durch äußere Umstände oftmals ändern.\n\n\n\n"}
{"id": "6229694", "url": "https://de.wikipedia.org/wiki?curid=6229694", "title": "AcetoneISO", "text": "AcetoneISO\n\nAcetoneISO ist eine freie Software zur Erstellung und Bearbeitung von ISO-9660-Speicherabbilddateien. Neben der ursprünglichen KDE-Version existiert mit xAcetoneISO2 auch eine GNOME-Version.\n\nMit AcetoneISO kann auf die Inhalte von Abbilddateien in verschiedenen Formaten zugegriffen, der Inhalt ins Dateisystem eingebunden, können die Abbilder auf optische Medien geschrieben und auch Abbilder erstellt werden. Neben dem namensgebenden ISO-9660-Format können auch Neros NRG, BIN, MDF, IMG und andere einschlägige Formate verarbeitet werden. Die Abbilder können mittels FUSE ohne Administratorrechte eingebunden werden.\n\nEs wird für Unix-ähnliche Betriebssysteme als freie Software auch im Quelltext unter den Bedingungen von Version 3 der GNU General Public License (GPL) verbreitet.\nIn vielen populären Linux-Distributionen kann es direkt aus den Standard-Paketquellen installiert werden.\n\nEs wird unter der Leitung von Marco di Antonio in C++ entwickelt und hat eine auf Qt 4 basierende graphische Benutzeroberfläche.\n\nSeine Entwicklung begann als Shell-Skript zum Einbinden und Aushängen eines ISO-Abbildes in das Dateisystem. Version 0.1 wurde am 29. August 2006 veröffentlicht. Für die einen Tag später erschienene Version 1.0 wurden die Skripts neugeschrieben und mit einer graphischen Benutzeroberfläche versehen und Unterstützung für weitere Formate hinzugefügt. Am 7. Juni 2007 erschien die Version 1 der AcetoneISO2-Reihe, zunächst unter einer Creative-Commons-Lizenz. Mit Version 1.0.2 vom 21. August 2007 wurde zu Version 3 der GPL gewechselt. Für Version 2.0.0 (24. Januar 2008) wurde die Anwendung auf C++ und Qt 4 portiert.\n\n"}
{"id": "6232964", "url": "https://de.wikipedia.org/wiki?curid=6232964", "title": "Gerrit (Software)", "text": "Gerrit (Software)\n\nGerrit ist ein kollaboratives Review-System für Git. Mit Gerrit lassen sich Änderungen an einer Software diskutieren und schließlich in diese integrieren.\n\nDas Open-Source-Projekt \"Gerrit\" eröffnet die Möglichkeit, alle Änderungen von einem oder mehreren Benutzern bestätigen zu lassen, bevor sie in den offiziellen Quellcode integriert werden. Dabei kann auch ein automatischer Build-Prozess, wie ihn etwa Jenkins/Hudson zur Verfügung stellt, als Unterstützung verwendet werden. \n\nDie Entwicklung von Gerrit begann, als ein System zur Quellcodeverwaltung für die Entwicklung des Betriebssystems Android gesucht wurde. Da an der Entwicklung von Android zahlreiche Google-Entwickler beteiligt waren, sollte dieses System einen ähnlichen Umfang wie das zuvor von Google verwendete Review-System \"Mondrian\" haben. Dazu wurde zunächst die Software \"Rietveld\" eingesetzt. Als sich zeigte, dass die Entwicklung dieser Software nicht schnell genug voranging, wurde Rietveld geforkt; es entstand Gerrit 1.0. Der Name \"Gerrit\" soll an den niederländischen Architekten Gerrit Rietveld erinnern.\n\nFür Gerrit 2.0 wurde der gesamte Code des Forks neu geschrieben. Während Gerrit ursprünglich in Python programmiert war, ist es ab Version 2 in Java EE (Java Platform, Enterprise Edition, Java Servlet mit SQL) verfasst.\n\nDas Review-System Gerrit wird zusammen mit einem Git-Repository verwendet.\n\nDas Git-Repository enthält den Quellcode einer Software. Änderungen, die an diesem Quellcode vorgenommen werden sollen, könnten durch Benutzer mit den entsprechenden Rechten grundsätzlich mit dem Git-Befehl codice_1 direkt in das Repository geschrieben werden.\n\nStattdessen kann jedoch auch eine Gerrit-Installation in der Form vorgeschaltet werden, dass die gewünschten Änderungen nicht direkt an das Repository gesendet werden können, sondern stattdessen an die Gerrit-Installation geschickt werden müssen. Gerrit bietet eine Webschnittstelle, in der die Änderungen diskutiert und verbesserte Versionen der Änderungen hochgeladen werden können. Es ist möglich, Änderungen als Diff-Ansicht zu vergleichen. Reviewer können ihre Kommentare an spezifische Zeilen anfügen und so auf einfache Weise den direkten Bezug zu einer bestimmten Codezeile herstellen. Über jeden Änderungssatz (Patch-Set genannt) kann abgestimmt werden. Nachdem ein Patch-Set die benötigten Stimmen erhalten hat, können Benutzer, die über die notwendigen Rechte verfügen, die Änderungen über die Webschnittstelle in das Repository schreiben.\n\nDie folgende Liste enthält beispielhaft einige bekannte Unternehmen und Projekte, die Gerrit verwenden:\n\n\n"}
{"id": "6235224", "url": "https://de.wikipedia.org/wiki?curid=6235224", "title": "Elementary OS", "text": "Elementary OS\n\nElementary ist ein im Jahr 2007 entstandenes freies Software-Projekt, das ursprünglich eine Sammlung von Programmen und Designs für Ubuntu zusammenstellte, welche sich stark am „Look and Feel“ von macOS orientierten. Seit März 2011 gibt es eine eigene Ubuntu-basierende Linux-Distribution unter dem Namen elementary OS.\n\nElementary OS ist eine auf Ubuntu 18.04 basierende Linux-Distribution, die das Ziel verfolgt, einfach zu handhabende Standardprogramme zur Verfügung zu stellen, auf dass der Benutzer weniger häufig darauf angewiesen ist, das Terminal zu benutzen.\n\nEin einzigartiger Aspekt von elementary OS ist das Engagement zu nativen GTK+-Programmen. Im Gegensatz zu anderen Linux-Distributionen (Ubuntu, Mint und andere), die Crossplattform-Anwendungen wie Mozilla Firefox oder LibreOffice enthalten, hat das elementary-Team entschieden, dass alle Programme aus Gründen der Konsistenz, Buildgröße und der Geschwindigkeit über dasselbe Widget-Toolkit verfügen sollen. Die konsequente Einführung von weniger bekannten Programmen wie der Textverarbeitung AbiWord und der Tabellenkalkulation Gnumeric führte zu Konflikten zwischen einigen Entwicklern.\n\nDie erste stabile Version, Codename „Jupiter“, wurde am 31. März 2011 veröffentlicht. Sie enthält nur vier Programme des elementary-Projekts, die zur Zeit der Veröffentlichung stabil waren: Postler, Dexter, Nautilus-elementary und Lingo. Zudem enthält es zwei Programme, die vom elementary-Projekt beeinflusst sind: Midori und Docky. Alle unwichtigen Daemons und Dienste wurden entfernt, weswegen es sehr viel schneller als Ubuntu arbeitet, auf dem es basiert.\n\nDas elementary-Projekt besteht aus einer Anzahl von Unterprojekten. Manche von ihnen sind „Was-wäre-wenn-Experimente“, während andere ausgereift und weit verbreitet sind. Dessen Entwickler bevorzugen überwiegend die Programmiersprache Vala und das GUI-Toolkit GTK+ 3. Heutzutage werden alle Softwareprojekte des Projektes (einschließlich der Skripte, die für das Zusammenstellen von elementary OS verwendet werden) auf Canonicals Dienst Launchpad gehostet.\n\n\n\n2012 haben sich einige Software-Projekte vom elementary-Team wegen Meinungsverschiedenheiten zwischen den Hauptautoren der Software und dem elementary-Team abgespalten. Die Hauptautoren der Software, die sich mit ihrer Software vom Team abspalten wollen, nennen meistens einen Zwang seitens der elementary-Programmrichtlinien als Grund. Diese Richtlinien, \"Human Interface Guidelines\" (HIG) genannt, schreiben unter anderem vor, wie sich ein Programm zu verhalten hat, und beschreiben ausführlich die Oberfläche eines idealen elementary-Programmes.\n\nDas erste Projekt war dabei BeatBox, aus dem der Fork Noise wurde. Später wurde aus der Software Marlin vom Autor ammonkey, von dem auch Nautilus elementary stammt, dann der Fork (Pantheon) Files.\n\n\nVerschiedene andere Projekte wurden stark von elementary beeinflusst oder in Zusammenarbeit mit dem elementary-Team entwickelt:\n\nDas elementary-Symbol-Theme ist unter Gnome-Benutzern sehr beliebt. Es ist das am zweithäufigsten heruntergeladene auf OpenDesktop.org, der größten Sammlung von Icon-Themes für Gnome. Das am häufigsten heruntergeladene Symbol-Theme GNOME-colors wurde vom elementary-Symbol-Theme inspiriert.\n\nDas elementary-Symbol-Theme hat großen Einfluss auf das Design freier Software: Das Standard-Symbol-Theme von Ubuntu ab Version 9.10, Humanity, ist ein Derivat von elementary; es gibt verschiedene vorgeschlagene Symbol-Themes für LibreOffice, die auf elementary basieren oder davon beeinflusst worden sind. Viele andere Benutzeroberflächen-Themes übernahmen Teile des Elementary-Projekts oder wurden davon inspiriert.\n\nDas elementary-Projekt wird oft als sich rasch entwickelnde Desktop-Umgebung bezeichnet und auf eine Stufe mit etablierten Projekten wie Gnome und KDE gestellt.\n\nSeit \"elementary OS Loki\" blockiert das Betriebssystem standardmäßig die eigenständige Installation von fremden Paketen via grafischer Oberfläche oder Terminal. Diese Blockade schränke die Freiheit und die Auswahl an Programmen der Nutzer ein. Andererseits soll dabei die Sicherheit des Systems verbessert werden.\n\n"}
{"id": "6235519", "url": "https://de.wikipedia.org/wiki?curid=6235519", "title": "PC System Design Guide", "text": "PC System Design Guide\n\nEin PC System Design Guide ist ein Leitfaden für die Auslegung von Personal Computern. \n\nDie Unternehmen Compaq, Dell, Hewlett-Packard, Intel und Microsoft verfassten im Verlauf des Jahres 1997 gemeinsam sogenannte \"Network PC System Design Guidelines\". Daraus entwickelte sich eine Reihe solcher Veröffentlichungen unter wechselnder Beteiligung. Sie sind nicht als Initiative der Unternehmen zu verstehen, sondern als ihre Sicht auf die Gegebenheiten des Marktes. \n\nDie Veröffentlichungen dokumentieren die schrittweise Ablösung IBM-PC-kompatibler Computer als technische Referenz und wurden mit dem \"PC 2001 System Design Guide\" abgeschlossen. \n\n"}
{"id": "6237677", "url": "https://de.wikipedia.org/wiki?curid=6237677", "title": "Pedion", "text": "Pedion\n\nDer Name Pedion bezeichnet ein im Jahre 1998 von Mitsubishi und Hewlett-Packard veröffentlichtes Notebook mit einer Bildschirmdiagonale von 12,1 Zoll (30,7 Zentimeter). Es war zum Zeitpunkt der Veröffentlichung mit nur 18,4 Millimetern das dünnste Notebook der Welt, im Oktober 2009 nahm das Sony Vaio X mit nur 14 Millimetern diese Stellung ein. Zum Verkaufsstart kostete das Notebook 6000 US-Dollar (damals 10.535 DM), eine Version mit einem leistungsschwächeren Prozessor war für 4200 US-Dollar (7374 DM) erhältlich. Der erste Prototyp des Pedion wurde am 8. September 1998 vorgestellt, kurz darauf folgte der Verkaufsstart in Japan. In den USA war das Notebook ab dem ersten Quartal 1999 erhältlich. Aufgrund technischer Probleme wurde das Notebook einige Jahre später durch Mitsubishi wieder vom Markt genommen.\n\nIm vorwiegend von Mitsubishi entwickelten Pedion waren vorwiegend Komponenten von Hewlett-Packard verbaut, unter anderem 64 Megabyte-RAM und eine 1,0 Gigabyte große Festplatte. Der Hauptprozessor stammte aus dem Hause Intel, verbaut waren (je nach Version) ein mit 233 bzw. 200 MHz getakteter Prozessor. Im Rahmen der Peripherie verfügte das Notebook über einen 4-MBit/s-schnellen Infrarotport, einen USB-Anschluss, zwei PC Card Typ II-Ports sowie einem Videoausgang. Die Akkulaufzeit gab der Hersteller mit 2 Stunden, diese Laufzeit konnte durch einen zusätzlich erhältlichen zweiten Akku auf bis zu 6,5 Stunden erhöht werden. Ein integriertes CD-Laufwerk war nicht vorhanden, war aber ebenso separat erhältlich.\n\nDas Pedion wurde vor allem wegen seiner bahnbrechenden Maße gelobt, da es weltweit das erste nur 18,4 Millimeter dünne Notebook war. Auch die Leistung überzeugte, die Presse war von den verbauten Komponenten begeistert. Lediglich der Preis wurde ein wenig kritisiert, wobei sich Mitsubishi hier auf die Kosten der Komponenten berief, der verbaute Prozessor habe demnach den größten Anteil am Preis gehabt.\n\n"}
{"id": "6244154", "url": "https://de.wikipedia.org/wiki?curid=6244154", "title": "ACOS Plus 1", "text": "ACOS Plus 1\n\nACOS Plus 1 ist eine Projektmanagementsoftware zum Planen, Steuern und Überwachen von Projekten, sie wurde in den 1980er Jahren entwickelt und wird bis heute weiter angepasst und verbessert. Die aktuelle Version ist die Version 9.\n\nDie Software ist ein branchenneutrales, auf der Netzplantechnik basierendes Projektmanagement- bzw. Multiprojektmanagement-System nach DIN 69901 und wird vor allem in professionellen Bereichen genutzt, beispielsweise im Bauwesen, Schiffs-, Kraftwerks- und Anlagenbau. Es stellt dem Projektleiter und allen an der Planung beteiligten Instanzen die nötigen Informationen zur Verfügung, um alle planungsrelevanten Parameter aufeinander abzustimmen. Dabei sind alle Beteiligten stets über den Gesamtstand des Projektes informiert und können ihre Termin-, Kosten- und Kapazitätenplanung optimieren. Das Programm ist derzeit in den Sprachen Englisch, Deutsch und Portugiesisch verfügbar.\n\nDer Projektmanagement-Client ermöglicht\n\nACOS Plus 1 benutzt die gewohnte graphische Windowsoberfläche um die Projekte abzubilden. In vielen Projektansichten vom Strukturplan bis zum Netzplan kann gearbeitet werden. Es bietet dem Anwender auch wenig bekannte Funktionen wie zum Beispiel Diagramme zur Meilenstein- und Kostentrendanalyse oder komprimierte Balkenpläne, in denen mehrere Balken in einer Zeile liegen.\n\nDie Verwendung von ACOS Plus 1 wurde bei einzelnen Projektausschreibungen gefordert (etwa beim Ausbau des Flughafens München).\n\nDas Programm wird in einzelnen Berufsschulen und auch an wenigen allgemeinbildenden Schulen ab Klasse 9 unterrichtet und mittels didaktischer Unterrichtsmaterialien zur Verfügung gestellt. Die Firma Tampier-Software stellt aber auch eine kostenlose Demoversion zur Verfügung, die mit 50 möglichen Vorgängen mehr als einfache Übungsbeispiele ermöglicht.\n\nDie Software wird beispielsweise von folgenden Unternehmen verwendet (Auswahl):\nAlexandria Shipyard, Bilfinger&Berger, BMW, British Aerospace, CPTM (Companhia Paulista de Trens Metropolitanos), DB ProjektBau, Deutsche Bahn, EADS, E.ON, Flensburger Schiffbau-Gesellschaft, Hochtief, Hofmann Modellbau, KPMG, Miele, Royal Australian Air Force, Strabag, Volkswerft Stralsund, Wittfeld. Das Hochbauamt der Stadt Frankfurt am Main verwendet ACOS für seine Termin- und Ablaufplanung.\n\n\n\n"}
{"id": "6253835", "url": "https://de.wikipedia.org/wiki?curid=6253835", "title": "Digital World", "text": "Digital World\n\nDigital World war ein Magazin rund um „Consumer Electronics“ und „Digital Living“ aus dem Münchner Verlag der International Data Group (IDG). Es wurde 2003 von Stephan Scherzer (Verlagsleitung) und Jürgen Bruckmeier (Chefredaktion) entwickelt. Das Magazin erschien erstmals zur Internationalen Funkausstellung (IFA) 2003 und Mitte 2007 zum letzten Mal. Von „Digital World“ gab es zahlreiche Ableger in vielen Ländern der Welt: 2004 in den USA, 2005 in Japan, dann in Frankreich, in der Schweiz und in Osteuropa. Auch diese Ausgaben wurden eingestellt. Digital World wurde anfangs als Website bei IDG Deutschland weiter geführt, später als Digital-Lifestyle-Rubrik in die Website der PC-Welt eingegliedert.\n\n"}
{"id": "6255496", "url": "https://de.wikipedia.org/wiki?curid=6255496", "title": "LulzSec", "text": "LulzSec\n\nLulzSec (oder lang Lulz Security) war der Name einer losen Gruppierung von Hackern, die im Jahr 2011 mehrere öffentlichkeitswirksame Aktionen im Bereich der Informationssicherheit verantwortete. \"LulzSec\" betrat teilweise kriminellen Boden, indem die Gruppe Passwörter Dritter ausspähte; andererseits wies sie auf Schwächen der Informationssicherheit der gehackten Systeme hin.\n\nDer Name \"LulzSec\" setzt sich aus den Worten „Lulz“ (Bedeutung etwa: „Schadenfreude“), einem abgewandelten Plural des Akronyms „LOL“ (Laughing Out Loud) im Netzjargon, und der umgangssprachlichen Kurzform von „Security“ (Sicherheit) zusammen.\nDie Gruppe \"LulzSec\" trat das erste Mal im Mai 2011 mit einem Angriff gegen Fox.com in die Öffentlichkeit.\n50 Tage nach ihrer Gründung gab die Gruppe im Juni 2011 ihre Auflösung bekannt.\n\n\"LulzSec\" wurde niemals mit finanziellen Motiven in Verbindung gebracht.\nDie Gruppe behauptete, aus Motiven der Unterhaltung heraus oder der Freude über Chaos und Verwüstung wegen zu handeln. Auf Grund dieser Äußerungen wurde von der Presse eine Parallele zur Spaßguerilla gezogen.\nFür einzelne Aktionen wurden politische Motive in Anspruch genommen, etwa Korruption oder Rassismus in Behörden anzuprangern, oder die Position gegen den War on Drugs zu stärken.\nEin gesellschaftspolitischer Hintergrund lässt sich rückwirkend bei allen Aktionen feststellen. Die Gruppe veröffentlichte zudem ein Manifest, in dem Anliegen ausformuliert wurden.\nDie Natur der losen Organisation lässt zu, dass einzelne Individuen den Namen der Gruppe für sich ohne Absprache oder Integration in den eigentlichen Kreis in Anspruch nehmen (\"siehe auch: Anonymous\", Absatz \"Struktur\").\nDer Gruppe werden im Kern sechs Mitglieder zugerechnet, welche dies zum Teil selbst verkündeten oder bestätigten, insbesondere nachdem Hacks anderer Gruppierungen persönliche Informationen zu Tage förderten. Abgegriffene IRC-Logdateien aus einem solchen Angriff wurden vom britischen The Guardian veröffentlicht und enthielten ebenfalls persönliche Details.\n\nIm Einzelnen werden folgende Personen mit \"LulzSec\" in Verbindung gebracht:\n\n\"LulzSec\" verwendete neben einfachen Distributed-Denial-of-Service-Techniken, wie beim Angriff auf die Webseite des CIA, auch SQL-Injections, zum Beispiel beim Sony-Hack. Welche Gesinnung der Gruppe zugesprochen werden sollte, ist strittig, allerdings lassen die teils deutlich subversiven Hacks kaum den Schluss zu, dass von \"LulzSec\" als „White-Hats“ gesprochen werden kann.\nBei den Unternehmungen der Gruppe lassen sich solche gegen Wirtschaftsvertreter und gegen Regierungsinstitutionen oder nahe Partner unterscheiden:\n\nEbenfalls im Juni 2011 konnte \"LulzSec\" die Webseite von InfraGard kompromittieren, einer Non-Profit-Organisation, die sich in Zusammenarbeit mit dem FBI auf die Überwachung von illegalen Botnetzen spezialisiert hat.\n\nIm Rahmen dieser Aktion erhielt \"LulzSec\" auch Zugriff auf vertrauliche E-Mails vom Chef der US-Sicherheitsfirma Unveillance, Karim Hijazi. Diese E-Mails beweisen, dass die Firma den US-Behörden verschiedene Dienstleistungen im Rahmen der digitalen Kriegsführung angeboten hat, wie zum Beispiel einen Angriff auf die digitale Infrastruktur der Ölfelder in Libyen.\n\nLaut eigener Aussage war die Aktion eine Antwort auf Barack Obamas Statement, dass Aktionen von Hackern auch als Angriff gegen die Vereinigten Staaten von Amerika gewertet werden könnten.\n\nWenig später erfolgte die Veröffentlichung einer Konfigurationsdatei der Website des Senats der Vereinigten Staaten von Amerika. Der Angriff wurde durch eine Sprecherin des Senats offiziell bestätigt.\n\nAm 15. Juni 2011 bekannte sich \"LulzSec\" zu einem Angriff auf die Website des amerikanischen Auslandsgeheimdienstes CIA, der dazu führte, dass deren Internetpräsenz kurzzeitig nicht erreichbar war.\n\nIm Mai 2011 hackten Mitglieder von \"LulzSec\" die Webseite des Public Broadcasting Service, kopierten Benutzerdaten und setzten eine Hoax-Nachricht in den Newsticker, welche besagte, dass der 1996 verstorbene Rapper Tupac Shakur noch am Leben sei und in Neuseeland lebe.\n\n\"LulzSec\" nannte als Motivation für den Hack die Verteidigung von Wikileaks und die Bekundung von Solidarität mit Bradley Manning.\n\nIm Juni 2011 erklärte sich \"LulzSec\" verantwortlich für einen Angriff gegen die Webseite von Sony Pictures, bei dem die Gruppe höchstwahrscheinlich illegalen Zugriff auf persönliche Daten (wie Name, Passwort, Adresse sowie Geburtsdatum) von über einer Million Nutzern hatte.\n\nDie Gruppe versuchte, Sony insbesondere dadurch bloßzustellen, dass sie darauf hinwies, wie schlecht die Seite gesichert gewesen sei und dass eine primitive SQL-Injection, eine allgemein bekannte Sicherheitslücke, ihnen den Zugriff ermöglicht hätte. Dieses war von besonderer Brisanz, da Sony bereits kurz zuvor einen illegalen Zugriff auf das PlayStation Network zugeben musste, bei dem vermutlich ebenfalls mehrere Millionen Nutzerdaten zusammen mit Kreditkarteninformationen gestohlen wurden.\n\nAls Motiv für den Angriff gab die Gruppe Rache für die juristischen Schritte von Sony gegen den Playstation-3-Hacker George Hotz an.\n\nObwohl \"LulzSec\" bereits am 26. Juni 2011 ihre Auflösung bekannt gab, stellten sie sich bereits kurze Zeit darauf wieder ins Rampenlicht. Das britische Boulevardmagazin The Sun war als Teil des Konzerns um Medienmogul Rupert Murdoch aufgrund des Abhörskandals um dessen News International bereits kritischer Aufmerksamkeit ausgesetzt. In der Nacht vom 18. auf den 19. Juli 2011 erschien auf der Internetseite von The Sun eine Falschmeldung über den angeblichen Tod Murdochs. Besucher der Seite wurden schließlich auf die Twitter-Seite von LulzSec weitergeleitet, wo sich die Hacker mit einer schnippischen Bemerkung zu der Tat bekannten.\n\nAm 19. Juni 2011 gaben LulzSec und Anonymous über Twitter ihre zukünftige Zusammenarbeit bekannt und riefen die Operation AntiSec ins Leben. Die beiden Gruppen, welche sich zuvor mehrfach angefeindet hatten, wollten gemeinsam gegen „Sicherheits-Terroristen“ vorgehen. Im Rahmen dieser Aktion wurden bald darauf die Website der „Serious Organised Crime Agency“ (Behörde für die Bekämpfung des organisierten Verbrechens im Vereinigten Königreich, kurz SOCA) für kurze Zeit lahmgelegt und vertrauliche Unterlagen der Grenzpolizei von Arizona auf Pirate Bay veröffentlicht.\n\nAm 26. Juni 2011 gab die Gruppe ihre Auflösung bekannt. Der ehemalige Hacker Kevin Mitnick führte dies auf den entstandenen hohen Verfolgungsdruck zurück und rechnete mit weiteren Aktionen von Nachahmern oder durch Folgeorganisationen.\n\nIm Mai 2013 wurden die von Sabu enttarnten LulzSec-Mitglieder Kayla, Topiary und Tflow zu Haftstrafen verurteilt, die von The Guardian als hart gewertet wurden. Zuvor hatten die Angeklagten auf Grund der Beweislast durch den Kronzeugen bereits gestanden, an verschiedenen Angriffen beteiligt gewesen zu sein.\n"}
{"id": "6256787", "url": "https://de.wikipedia.org/wiki?curid=6256787", "title": "Microsoft Windows 8", "text": "Microsoft Windows 8\n\nMicrosoft Windows 8 ist ein Desktop-Betriebssystem des US-amerikanischen Unternehmens Microsoft.\n\nDas Betriebssystem enthält zwei Benutzeroberflächen: Einerseits \"Windows 8 Modern UI\", eine speziell für Touchscreens optimierte Bedienoberfläche in „Kachelform“, und andererseits eine Desktop-Umgebung mit einer Taskleiste. Die Bedienung erfolgt mittels Maus, Tastatur oder Touchscreen. Zusammen mit den anderen Betriebssystemen \"Windows Phone 8\" für Smartphones und \"Windows RT\" für Tabletcomputer bietet es eine einheitliche Benutzeroberfläche für alle derart betriebenen Geräte.\n\nDas System aus der Reihe \"Windows\" wurde am 26. Oktober 2012 als Nachfolger von \"Windows 7\" veröffentlicht und ist der Vorgänger von \"Windows 10\".\n\nBei der Entwicklung von Windows 8 verfolgte Microsoft u. a. folgende Ziele:\n\n\nMicrosoft veranstaltete vom 13. September bis zum 16. September 2011 die Konferenz „Build Windows“, auf der Windows 8 vorgestellt wurde. Zugleich war eine Entwicklerversion freigegeben worden, die einen ersten Eindruck der neuen Windows-Version bot. Am 29. Februar 2012 wurde für Desktop-PCs eine Beta-Version unter der Bezeichnung \"Windows 8 Consumer Preview\" veröffentlicht. Dieser Version folgte am 31. Mai eine weitere Vorab-Version, die „Release Preview“ (ehemals Release-Candidate), welche bereits alle Funktionen der finalen Version beinhaltete. Im Juli 2012 bestätigte Microsoft in seinem Blog, dass Windows 8 am 26. Oktober 2012 veröffentlicht werde. Seit Anfang August 2012 befand sich Windows 8 in Produktion und wurde schrittweise an Partner von Microsoft ausgeliefert. Seit 15. August 2012 stand \"Windows 8\" auch Abonnenten von MSDN-, Microsoft-TechNet- und seit 22. September 2012 auch DreamSpark-Premium-Kunden zum Download bereit. Seit 26. Oktober 2012 war Windows 8 im Handel erhältlich.\n\nIm Oktober 2014 wurde Windows 8 von Microsoft für den Verkauf im Handel eingestellt, OEM-Versionen waren jedoch weiterhin erhältlich. Windows 8.1 war von dieser Einstellung nicht betroffen.\n\nIn Windows 8 existieren statt der bisherigen zwei nun drei verschiedene Arten von Anwendungen: Erstens die traditionellen Windows-Anwendungen, die auf dem Desktop in einem Fenster laufen, zweitens die Konsolenanwendungen und drittens die neu eingeführten Windows-Apps, die innerhalb der neuen Modern User Interface (UI) ausgeführt werden. Die Windows-Apps unterscheiden sich sowohl in ihrer Laufzeitumgebung als auch – zumindest teilweise – in der verwendeten API.\n\nAuf der Build-Konferenz im September 2011 betonte Microsoft, Windows 8 solle die Möglichkeiten der Nutzung eines Computer mittels Touchscreen und Maus vereinigen. Die Verwendung einer realen oder einer virtuellen Tastatur auf dem Bildschirm ist weiterhin möglich. Das Betriebssystem enthält zwei Oberflächensysteme: einerseits \"Windows 8 Modern UI\" (früher „Metro“ genannt) eine speziell für Touchscreens optimierte Bedienoberfläche in „Kachelform“ und andererseits die klassische Desktop-Oberfläche mit der Taskleiste. Diese entspricht großteils dem aus Windows 7 bekannten Desktop und kann aus der neuen Oberfläche gestartet werden.\n\nDer Bootmanager, welcher beim Start zur Auswahl des Betriebssystems dient, wurde ebenfalls für die Touch-Eingabe optimiert, lässt sich jetzt aber auch erstmals mit der Maus bedienen. Er enthält zudem eine grafische Oberfläche, über die sich erweiterte Einstellungen aufrufen lassen.\n\nDie Zertifizierungsrichtlinien von Microsoft für Computer, auf denen Windows 8 vorinstalliert ist, sehen vor, dass diese Rechner anstatt eines konventionellen BIOS das UEFI verwenden. Diese Systeme müssen so konfiguriert sein, dass sie standardmäßig \"Secure Boot\" verwenden. Hierdurch soll der Start von Schadsoftware während des Boot-Vorgangs unterbunden werden. Die Zertifizierungsrichtlinien sehen des Weiteren vor, dass der Mainboard-Hersteller diese Option auf x86-Systemen optional, sprich abschaltbar machen kann. In der Open-Source-Gemeinde besteht die Sorge, dass auf Systemen mit ARM-Architektur das Booten freier Betriebssysteme erschwert oder unmöglich werden könnte.\n\nWährend Desktop- und Konsolen-Anwendungen weiterhin die volle bzw. durch Benutzerkontensteuerung (UAC) eingeschränkte Berechtigung des ausführenden Benutzers haben, existiert für Modern-UI-Apps ein Rechtesystem, das demjenigen von mobilen Endgeräten nahekommt.\n\nModern-UI-Apps müssen zudem digital signiert sein. Für die Softwareentwicklung werden Signaturen kostenlos durch Microsoft ausgestellt. Apps können durch den Windows Store oder in Windows 8 Enterprise auch durch Side-Loading bezogen werden. Auf Windows RT, der Version für ARM-Prozessoren, können ausschließlich Modern-UI-Apps ausgeführt werden, nicht aber althergebrachte Desktop-Anwendungen. Ausnahme dafür sind vorinstallierte Desktop-Anwendungen wie Internet Explorer in der Desktopvariante.\n\nDurch den Übergang im Layout der Benutzeroberfläche von den bisher verwendeten Icons für das Benutzen mit der Maus und dem Mauszeiger zu den neuen Kacheln für das Benutzen mit dem Finger auf dem Touchpanel wurde der spezifische Flächenbedarf für die einzelne Aktivierung einer Applikation erhöht. Um dennoch die gleiche Vielfalt an Applikationen zu erreichen, wurde eine neue Hierarchie der Anwahl von Applikationen über hinterlegte bänderförmige Strukturen (Ribbons) eingeführt.\n\nDamit ist die Verwendung des bisherigen kompakten Startmenüs und der bisherigen noch kompakteren Schnellstartleiste nicht mehr wie in früheren Windows-Versionen möglich. Allerdings kann eine dem früheren Layout ähnliche Oberfläche (\"Shell\") unterlegt werden.\n\nZusätzlich wird die Option der transparenten Überlagerung (\"Aero Overlay\") aus Windows 7 nicht mehr angeboten.\n\n\"Metro\" war Microsofts Codename der neuen Oberfläche, die in \"Windows 8\" bevorzugt verwendet wird. Aufgrund einer Klageandrohung der Metro AG wegen Verletzung des Markenrechts entschloss sich Microsoft, die Benutzeroberfläche in der endgültigen Version von Windows 8 umzubenennen. Der neue Name ist \"Modern UI\"; speziell dafür entwickelte Programme werden nicht mehr \"Metro Apps\", sondern \"Windows Store Apps\" genannt.\n\nIn Modern UI können sämtliche Menüs ins Bild „gestreift“ werden. Der Grundgedanke hierbei ist, die Menge der gleichzeitig sichtbaren Steuerelemente der Benutzerschnittstelle zu reduzieren und den Inhalt einer Anwendung in den Vordergrund zu rücken. Ebenso werden Ideen zur Anordnung von Text und Kontrollelementen aus Typografie, Bauhaus-Design, Swiss-Design und Motion-Design eingesetzt.\n\nBei der Bedienung mit Maus kann das oben erwähnte „Streifen“ im Falle der Systemleisten links und rechts mithilfe der sogenannten „Hot Corners“ erreicht werden. Dabei bewegt man die Maus in die jeweiligen Ecken und die Leisten werden eingeblendet. Durch einen Rechtsklick innerhalb einer Anwendung werden applikationsspezifische Menüs angezeigt.\n\nMithilfe der Tastenkombination  +  kann die Charmbar geöffnet werden. Sie enthält \"Charms\" genannte Shortcuts zu unterschiedlichen Funktionen. Ist keine App geöffnet, enthält die Charmbar eine Suchfunktion und eine „Teilen“-Funktion, mit der sich Informationen z. B. per E-Mail oder per Screenshot verbreiten lassen. Sie beinhaltet außerdem eine „Start“-Fläche, die Zugriff zu den Kacheln gewährt, die Option Drucker und Projektoren zu nutzen sowie „Einstellungen“, die einige Systemsteuerungseinstellungen zugänglich machen. Ist dagegen eine App geöffnet, enthält die Charmbar anwendungsspezifische Optionen zur Benutzung der jeweiligen App.\n\nWindows 8 nutzt sogenannte Kacheln (englisch \"\") statt Programmicons und übernimmt damit einige Neuerungen von Windows Phone 7. Nach der Kritik, das Modern-UI-Design sei nicht benutzerfreundlich genug, wurden diverse Detailverbesserungen vorgenommen. So wurde z. B. die Kachelgröße angepasst.\n\nViele Firmen haben ihre Programme bereits vor der Veröffentlichung von Windows 8 an Modern-UI angepasst (z. B. Mozilla seinen \"Firefox\"-Browser und Google Chrome).\n\nModern-Anwendungen (auch kurz „Modern-Apps“ genannt) haben die Möglichkeit, Inhalte direkt an andere Anwendungen weiterzugeben bzw. diese zu empfangen. So ist es unter anderem möglich, eine Textpassage im Browser zu markieren und anschließend über eine beliebige Social-Media-Anwendung mit Freunden oder Bekannten zu teilen. Außerdem ist das Verwenden von Inhalten wie Bildern aus Anwendungen, welche auf Cloud-Dienste wie Flickr zugreifen, möglich, ohne dass die Anwendung, die diese Inhalte anfordert, Zugriff auf die Login-Daten der Online-Bildergalerie haben muss.\n\nDie Startseite ist eine personalisierbare Auflistung der dem Benutzer wichtigen Apps und App-Inhalte in Form von Kacheln. Zur Organisation können Kacheln gruppiert werden.\n\nDie Startseite lässt sich über die Schaltfläche \"Start\" aufrufen. Im Gegensatz zu vorigen Windows-Versionen – welche über eine ständig sichtbare Startschaltfläche verfügen, sofern in den Taskleisten-Einstellungen nicht ausgeschaltet – erscheint die Startschaltfläche unter Windows 8 erst, wenn die Maus die untere linke Ecke erreicht. Die Startseite lässt sich ebenfalls mithilfe der Charms, der zuletzt verwendeten Apps oder der Windowstaste auf der Tastatur aufrufen.\n\nEine besondere Stellung nimmt der Desktop ein, der, nicht zuletzt aus Gründen der Abwärtskompatibilität, weiterhin vorhanden ist und, ähnlich einer App, zunächst gestartet werden muss. Der Desktop bietet unter Windows 8 nicht mehr das mit Windows 95 eingeführte Startmenü, da dessen Funktionalität von der Startseite übernommen wird.\n\nBei der Verwendung von mehreren Monitoren ist es jetzt möglich, für jeden Desktop eine eigene Taskleiste einzurichten.\n\nObwohl die herkömmliche Desktop-Software auf Windows RT (außer Internet Explorer und einigen anderen Programmen) nicht funktioniert, ist der Desktop dort trotzdem enthalten. Auf ihm läuft das in Windows RT vorinstallierte Microsoft Office.\n\nIm Windows-Explorer werden vom Benutzer die gespeicherten Dokumente und Ordner navigiert, angelegt und gesichtet. Es können auch in einem zentralen Bereich alle laufenden Kopier- und Löschvorgänge pausiert, fortgesetzt und abgebrochen werden. Diverse umschaltbare Ansichtsoptionen wie Miniaturansichten, Listen, Details, Vorschaufenster usw. stehen dem Benutzer zur Verfügung, um sich in der Vielzahl der Dateien und Ordner schnell und übersichtlich zurechtzufinden. Zudem erhält der Datei-Explorer eine neue Ribbon-Menüleiste, wie sie bereits bei Microsoft-Office-Produkten seit 2007 bekannt ist, wodurch er übersichtlicher gestaltet werden soll, da dort die am häufigsten genutzten Befehle direkt zur Auswahl stehen. Diese zusätzliche Leiste kann vom Benutzer ein- und ausgeblendet werden. Dies ähnelt der Bedienung von Microsoft Office ab der Version Office 2007.\nNeu im Datei-Explorer ist auch, dass sich ISO-Dateien direkt ohne zusätzliche, externe Software mounten lassen. Dem darin enthaltenen Dateisystem wird entsprechend ein Laufwerksbuchstabe zugewiesen. Eine Funktion zum Defragmentieren von Laufwerken gibt es auch weiterhin, jedoch wird diese jetzt als \"Optimieren\" bezeichnet.\n\nDer Anmeldebildschirm in Windows 8 wurde weitgehend von Windows Phone 7 übernommen. Auf ihm können Anwendungen die Anzahl neuer Ereignisse anzeigen wie beispielsweise neue E-Mails, Nachrichten aus sozialen Netzwerken oder anstehende Termine. Außerdem werden dort der Akkustand und Informationen über Netzwerkverbindungen angezeigt. Zur Authentifizierung stehen unter Windows 8 drei Methoden zur Verfügung: ein normales Passwort, eine PIN oder ein Bildpasswort. Auf einem Bildpasswort müssen vom Benutzer festgelegte Gesten ausgeführt werden. Das benutzerdefinierte Bild soll das Finden der Gesten erleichtern.\nDer Task-Manager wurde durch eine neue Anwendung ersetzt; in den Vorschauversionen war der „alte“ Task-Manager noch vorhanden. Unter anderem werden laufende Anwendungen in Kategorien eingeordnet (z. B. Systemprozesse, Modern-Anwendungen und Desktop-Anwendungen). Nicht-aktive Anwendungen werden zur Steigerung der Performance angehalten und im Taskmanager als „Suspended“ markiert.\n\nIn Windows 8 Professional und Enterprise ist die Virtualisierungsplattform Hyper-V enthalten, die auch in Windows Server 2008 integriert ist.\n\nDie Enterprise-Version von Windows 8 enthält „Windows to Go“, das es ermöglicht, Windows mitsamt allen Programmen, Einstellungen und Daten auf einen USB-Stick zu sichern. Wird dieser Stick an einen fremden Rechner angeschlossen, so kann Windows 8 auf diesem starten. Nach dem Herunterfahren kann der Stick abgezogen werden und es sollen keine Daten auf dem verwendeten Computer verbleiben. Entfernt man den Stick dagegen im laufenden Betrieb, so friert zwar das Betriebssystem ein, kann aber nach Wiedereinstecken ohne Absturz weiterarbeiten.\n\nZudem bietet das Betriebssystem auch eine Rücksetzfunktion. Mit Administratorenrechten kann der „erweiterte Reset“ durchgeführt werden, welcher den Rechner wieder in den Auslieferungszustand versetzt. Die außerdem verfügbare „Refresh“-Methode bewirkt, dass Windows 8 zuerst die Nutzerdaten und Modern-Apps sichert, dann das System zurücksetzt und letztendlich die Daten und Programme wiederherstellt. Dies soll den Rechner beschleunigen.\n\nWindows 8.1 unterstützt neben FAT, FAT32, exFAT und NTFS auch das neue Dateisystem ReFS. Dieses ist mit NTFS kompatibel, ermöglicht aber eine verbesserte Prüfung und gegebenenfalls automatische Korrektur von Daten. ReFS ist nicht bootfähig. Es kann auf einer durch Windows Server 2012 in ReFS formatierten Festplatte verwendet werden.\n\nModern-Apps können über den neuen \"Windows Store\" bezogen werden. Microsoft sieht In-App-Käufe (das Erweitern von installierten Programmen um weitere Funktionen direkt aus diesen heraus) vor und bietet eine Möglichkeit, die Anwendungen für eine begrenzte Zeit kostenlos zu testen. Modern-Apps können ausschließlich über den Store heruntergeladen bzw. gekauft werden. Die Detailseiten des Stores bieten eine App-Beschreibung, ein Bild, die Hardwareanforderungen und Bewertungen. Modern-Apps können auf maximal fünf Computern mit Windows 8 genutzt werden. Diese Apps sind ab 1,49 US-Dollar erhältlich.\n\nDie PC- und Videospielbranche kritisiert den möglichen Trend zu einer geschlosseneren Plattform. Derartige Kritik äußerten Gabe Newell, Geschäftsführer der Valve Corporation, Rob Pardo, der Vizepräsident von Blizzard Entertainment und der Minecraft-Erfinder Markus Persson. Letzterer betonte, dass vor allem kleinere Indie-Games darauf angewiesen seien, zur Entwicklung auf freie und offene Plattformen zugreifen zu können.\n\nWindows Defender durchsucht unter Windows 8 den Computer nicht nur nach Spy- und Malware, sondern auch nach Viren und ähnlichen Schadprogrammen sowie dem Anschluss zu Botnets. Die Bedienungsoberfläche ähnelt jener der Microsoft Security Essentials 4.1. Das neue Betriebssystem besitzt mit dem Windows Defender einen integrierten Virenscanner und bietet somit einen Basisschutz. Im Computer-Bild-Test konnte der Defender 70 % aller Angriffe abwenden, deutlich weniger als kostenpflichtige Virenscanner. Demnach kann der Defender eine professionelle Security-Suite nicht ersetzen.\n\nDas Logo von Windows 8 lehnt sich gestalterisch an die Bedienoberfläche an. In Kooperation mit dem Designstudio \"Pentagram\" wurde aus dem vorherigen Windows-Logo eine geometrische Form entwickelt, die gleichzeitig modern und klassisch wirken soll. Im Logo ist das für Windows typische Fenster mit einer Kachel aus der neu eingeführten Oberfläche verbunden. Wie beim Vorgänger ist die Wortmarke in Segoe UI gesetzt. Außerdem hat es sehr große Ähnlichkeit mit dem Logo von \"Windows 1.0\".\n\nDer „Product Key“ bei gekauften Systemen wie PCs oder Notebooks wird nicht mehr als Aufkleber auf dem Gerät mitgeliefert, sondern ist nun digital auf dem Mainboard gespeichert. Die Aktivierung geschieht automatisch bei einer bestehenden Onlineverbindung.\n\nEntsprechend der Bekanntgabe von Microsoft vom 16. April 2012 ist das Betriebssystem in vier verschiedenen Editionen erhältlich:\n\n\n\"Windows 8 (\"Core\")\" ist der Name der Standard-Edition. Sie enthält alle Funktionen, die auf den Markt für Heimanwender abzielen und stellt alle in Windows 8 neu hinzugekommenen Funktionen wie den Startbildschirm mit semantischem Zoom, den Windows Store, Internet Explorer 11, verbundenen Standby, Microsoft-Account-Integration, den Windows Desktop, DirectX 11 und vieles mehr zur Verfügung. Das Windows Media Center ist nicht enthalten, kann aber hinzugekauft werden.\n\nDie Standardversion wird sowohl für x86- als auch x64-Prozessoren angeboten.\n\n\"Windows 8 Pro\" ist der Nachfolger von Windows 7 Professional und Ultimate und richtet sich an Kleinunternehmer, die ihren PC privat und geschäftlich nutzen. Windows 8 Pro enthält alle Funktionen von Windows 8 und zusätzlich einen Remote-Desktop-Server, die Möglichkeit an einer Windows-Domäne teilzunehmen, Encrypting File System, Hyper-V und das Booten von einer Virtual Hard Disk, Gruppenrichtlinien, als auch BitLocker und BitLocker To Go. Das Windows Media Center ist nicht enthalten. Bis zum 31. Januar 2013 konnte das Media Center kostenlos nachinstalliert werden, seit dem 1. Februar 2013 werden für die nachträgliche Installation 9,99 € verlangt.\n\n\"Windows 8 Pro\" wird wie Windows 8 sowohl für x86-, als auch x64-Prozessoren angeboten. Ein Upgrade von einer bestehenden Installation ist für die Vorgängerversionen \"Windows 7 Professional\" oder \"Windows 7 Ultimate\", Windows XP, Windows Vista oder bei Neukauf eines PCs mit vorinstallierter Version für \"Windows 7 Starter\", \"Windows 7 Home Basic\" und \"Windows 7 Home Premium\" verfügbar.\n\n\"Windows 8 Pro mit Media Center\" enthält alle Features von Windows 8 Pro und zusätzlich das Media Center sowie nötige Codecs zum Wiedergeben von DVDs. Man erhält es, indem man Windows 8 (Standard-Edition) mit dem Pro-Pack upgradet oder sich das Media Center für Windows 8 Pro für einen Preis von 10 € (im Upgrade-Fenster) nachkauft.\n\nIm Frühjahr 2014 hat Microsoft eine besonders günstige Windows Version für Hersteller angekündigt. Hersteller von Tablet-PCs, Laptops oder Desktop-PCs können so ihre Produkte deutlich günstiger mit dem vorinstallierten Betriebssystem \"Windows 8.1 mit Bing\" vertreiben. Diese Version von Windows 8.1 unterscheidet sich nur sehr gering von der Standardversion. Der Hersteller ist lediglich dazu verpflichtet, die Suchmaschine Bing als Standardsuchmaschine im Internet Explorer eingestellt zu lassen. Diese Einstellung lässt sich jedoch problemlos vom Nutzer ändern. Außer in den Windows Einstellungen, in denen die Windows Version als \"\"Windows 8.1 mit Bing\"\" angegeben ist, unterscheidet sie sich nicht weiter von \"Windows 8.1\".\n\n\"Windows 8 Enterprise\" beinhaltet alle Funktionen von \"Windows 8 Pro\" und zusätzlich erweiterten Funktionsumfang in den Bereichen PC-Management, Deployment, Sicherheit und Virtualisierung. Zu den exklusiven Funktionen gehören außerdem \"Windows To Go\", mit dem eine Windows-8-Installation von einem USB-Stick aus gestartet werden kann, \"DirectAccess\", mit dem eine VPN-lose Remote-Verbindung zwischen Client-Rechnern und Firmennetzwerken aufgebaut werden kann, \"BranchCache\", mit dem Firmenserver erstellt werden können, \"AppLocker\", mit dem das Ausführen von Programmen und Skripten eingeschränkt werden kann, und die Möglichkeit zum Side-Loading, das es ermöglicht, Modern-Apps ohne den Windows Store installieren zu können.\n\nDiese Version wird für 32- und 64-Bit-Prozessoren angeboten und ausschließlich unter Volumenlizenz vertrieben.\n\nDas Windows Media Center kann in dieser Edition nicht installiert werden.\n\n\"Windows RT\" ist eine besondere Version von Windows 8 für Geräte mit ARM-Prozessoren. Sie ist die erste Windows-Version für ARM-Prozessoren und wird nur vorinstalliert vertrieben. Es werden ausschließlich Modern-Apps verwendet; das Installieren und Ausführen von herkömmlichen x86- oder x64-Anwendungen auf Basis der Win32-API ist nicht möglich. Gegenüber der Standardversion \"Windows 8\" sind der Windows Media Player und die Storage Spaces nicht enthalten. In \"Windows RT\" sind Microsoft Office mit Word, Excel, Powerpoint und Onenote vorinstalliert; in den anderen Editionen ist das Office-Paket nicht enthalten. Seit dem Update Windows 8.1 ist Outlook ebenfalls vorinstalliert.\n\nEin Upgrade auf Windows 8 konnte als Einführungsangebot bis 31. Januar 2013 vergünstigt erworben werden. Durch den deutlich niedrigeren Preis setzte Microsoft einen verstärkten Kaufanreiz. Laut Einschätzungen von Experten kann diese Entscheidung maßgeblich durch die Konkurrenz auf dem Mobile-Markt beeinflusst worden sein, in dem Google und Apple eine Vorrangstellung innehaben.\n\nWindows 8 hat etwas höhere Hardware-Anforderungen als Windows 7 und läuft Erfahrungsberichten zufolge mit etwa gleicher Geschwindigkeit wie Windows 7. Neben BIOS wird auch UEFI als Firmware bzw. Firmware-Schnittstelle unterstützt. USB 3.0 wird ohne Zusatzsoftware von Drittherstellern unterstützt.\n\nIm ersten Verkaufsmonat konnte Microsoft nach eigenen Angaben über 40 Millionen Lizenzen von Windows 8 absetzen, das sich damit besser verkaufte als Windows 7. Hardware-Hersteller beklagen jedoch einen schleppenden Verkauf der Geräte mit Windows 8. Die Marktanalysefirma Context berichtet, dass im ersten Verkaufsmonat 48 % der Windows-Verkäufe auf die Vorgängerversionen entfielen.\n\nAm 8. Januar 2013 gab Microsoft neue Verkaufszahlen bekannt, wonach bis dahin 60 Millionen Windows-8-Lizenzen verkauft wurden. Damit sei die Verkaufskurve vergleichbar zu Windows 7. Der Windows App Store verzeichnete über 100 Millionen Downloads. Trotzdem läge der Marktanteil beim Endkunden nur bei knapp zwei Prozent. Dies deutet darauf hin, dass zwar vom Handel und den PC-Herstellern viele Lizenzen gekauft wurden, diese jedoch nicht an Endkunden weiterverkauft werden konnten. Laut Marktforschungsinstitut Gartner ging der Verkauf von Windows-basierten PCs im vierten Quartal 2012 um 4,3 % zurück. Die NPD Group bilanzierte für das Weihnachtsgeschäft 2012 sogar einen Rückgang von 11 %.\n\nBis Mai 2013, einem guten halben Jahr nach Einführung, wurden über 100 Millionen Windows-8-Lizenzen verkauft. Damit liegt Windows 8 etwa gleichauf mit Windows 7 nach einem halben Jahr. Allerdings verlangsamte sich der Verkauf zuletzt.\n\nGemäß den Daten der Firma Net Applications, welche die Webbrowser-Aufrufe von 40.000 Websites analysiert, lag nach den ersten 7 Monaten der Verfügbarkeit im Einzelhandel der Marktanteil von Windows 8 bei 4,27 %. Im Vergleich lag der Marktanteil von Windows Vista nach den ersten 7 Monaten (30. Januar bis 31. August 2007) bei 6,26 % und jener von Windows 7 bei 12,67 %.\n\nWindows 8 und RT wurden bis zum 12. Januar 2016 unterstützt. Microsoft plant die Mainstream-Supportphase für Windows 8.1 und RT 8.1 bis 9. Januar 2018 und den erweiterten Support bis 10. Januar 2023 aufrechtzuerhalten.\n\n\"Microsoft Windows 8.1\" (Codename Windows Blue) ist ein kostenloses Update zu Windows 8. Die Veröffentlichung war weltweit am 18. Oktober 2013, in Mitteleuropa durch Zeitverschiebung schon am 17. Oktober 2013 um 13:00 Uhr (MESZ). Der RTM-Status (\"Release to Manufacturing\") wurde Ende August 2013 vergeben. Das Betriebssystem lag damit bereits in der finalen Version vor, aber viele vorinstallierte Modern-UI-Apps waren zu diesem Zeitpunkt noch nicht lokalisiert übersetzt verfügbar. Das Update wird anders als bisherige Service Packs nicht über Windows Update, sondern über den Windows Store ausgeliefert. Neben dieser Bezugsmethode ist auch seit November 2014 das direkte Beziehen eines ISO-Abbilds möglich, in welchem das Update bereits enthalten ist.\n\nWindows 8.1 soll die größten Kritikpunkte an Windows 8 auch für Desktopnutzer beheben. So ist es wieder möglich, direkt auf den Desktop zu starten. Die Start-Schaltfläche wurde wieder eingeführt; sie bietet jedoch kein Startmenü wie in Windows 7, sondern führt nur zur Startseite von Windows 8 zurück. Mit einem rechten Mausklick auf die Startfläche öffnet sich ein Kontextmenü, das dem Startmenü ähnelt. Auch kann der Zugriff auf die \"Charmbar\" in der oberen rechten Ecke des Bildschirms deaktiviert werden. Mit Windows 8.1 ist es auch möglich, bei gleichzeitiger Anzeige mehrerer Apps das Größenverhältnis der Fenster frei einzustellen.\n\nDie interne Versionsnummer von Windows 8.1 lautet \"Windows NT 6.3\" und ist somit ein systemveränderndes Upgrade, das zudem folgende Änderungen enthält: Der Datei-Explorer zeigt standardmäßig nicht mehr die aus Windows 7 und 8 bekannten „Bibliotheken“ an. Das Symbol „Computer“ heißt nun „Dieser PC“ und listet nicht mehr nur alle Festplatten, sondern auch die Benutzerordner wie „Dokumente“, „Musik“ oder „Bilder“ auf. Windows Store Apps lassen sich nun komplett schließen, indem man die App wie schon unter Windows 8 vom Oberen zum Unteren Bildschirmrand zieht, zudem aber noch kurz wartet bis die Kachel sich umdreht und das App-Logo zu sehen ist. Lässt man nun los, wird die App nach kurzer Zeit auch nicht mehr im Task-Manager ersichtlich sein. Sie ist komplett geschlossen.\n\nDarüber hinaus ist der Microsoft-OneDrive-Ordner stets in der Navigationsleiste links im Explorer sichtbar. Windows 8.1 bietet die Möglichkeit, alle neu erstellten Fotos und Videos bei bestehender Internetverbindung dorthin hochzuladen bzw. OneDrive anstelle der lokalen Benutzerordner als standardmäßigen Speicherort zu nutzen. OneDrive ist anders als noch in Windows 8 nun Bestandteil des Betriebssystems.\n\nDie Suchfunktion innerhalb von Modern UI („Kachel-Startseite“) umfasst nun standardmäßig personalisierte, standortbezogene Online-Suchergebnisse über Bing. Es werden lokale Dateien aufgelistet und optional auch dazu passende Webergebnisse wie Bilder, Links oder Store-Verknüpfungen angezeigt.\n\nDer Internet Explorer 11 bietet in seiner Modern-UI-Variante neue Funktionen. Da der VoIP-Client Skype nun systemweit verfügbar ist, kann der Internet Explorer auf Websites erkannte Telefonnummern bei Bedarf direkt via Skype anrufen, ohne den Internet Explorer verlassen zu müssen. Für eine eingeschränkte Erreichbarkeit nur zu bestimmten Uhrzeiten lassen sich in Windows 8.1 „Ruhezeiten“ einstellen. Unterstützte Websites können in einem gesonderten „Lesemodus“ betrachtet werden. Dabei wird der reine Textanteil eines Artikels neu formatiert und auf einem neutralen, in den Farben sepia, grau, weiß oder schwarz gehaltenen Hintergrund angezeigt. Die „Teilen“-Funktion umfasst nun mehr Optionen, etwa das Anfertigen von Screenshots, die per Mail oder Twitter weitergereicht werden können.\n\nIm Vergleich zu Windows 8 kommen nun erheblich mehr vorinstallierte Modern-UI-Apps zum Einsatz, darunter viele Ersatzanwendungen für typische Windows-Zubehörprogramme, wie etwa ein Soundrecorder, eine App mit Hilfen zur Bedienung oder eine Scan-Anwendung. Die bisherigen Apps „Fotos“, „Kamera“, „Musik“, „Videos“ wurden in ihrer Funktionalität erweitert. So bietet die „Fotos“-App beispielsweise grundlegende Bildbearbeitungsfunktionen mit der Möglichkeit, Belichtungskorrekturen und Farbtonanpassungen vorzunehmen.\n\nFolgende Apps sind im Vergleich zu Windows 8 hinzugekommen:\n\nIm April 2014 veröffentlichte Microsoft ein kumulatives Update für Windows 8.1, das neben Bugfixes auch zahlreiche Änderungen in der Benutzeroberfläche bringt. So wurde die bisher oft kritisierte Bedienung mit Maus und Tastatur optimiert: Apps haben nun eine Titelleiste, über die sie minimiert und geschlossen werden können und innerhalb von Apps lässt sich jetzt auch die Taskleiste anzeigen. Außerdem können nun auch Apps an die Taskleiste angepinnt werden. Wenn Windows 8.1 auf einem Gerät mit Maus und Tastatur ausgeführt wird, startet es nun automatisch auf die Desktop-Oberfläche. In der Kacheloberfläche wurden zusätzliche Optionen ergänzt, über die Apps schneller als bisher deinstalliert oder in der Größe verändert werden können. Auch enthält die Kachelansicht seit dem Update eine neue Schaltfläche, mit der sich die Optionen den PC neuzustarten oder auszuschalten leichter als bisher nutzen lassen. Für den Bezug nachfolgender Windows-8.1-Updates ist ein installiertes Windows 8.1 Update 1 Pflicht.\n\nWindows 8 wurde für die für Touch-Bedienung optimierte Modern-Oberfläche in Hinblick auf Bedienbarkeit mit Maus und Tastatur kritisiert. Kritik erhielt auch das neue Design des Logos für Windows 8. Die deutsche Computerzeitschrift c’t schrieb:\n\nDer Valve-Gründer und langjährige Microsoft-Entwickler Gabe Newell sagte:\nAndererseits kam Spiegel Online zu dem Fazit:\n\nBzgl. der Aktivierung wurde Microsoft kritisiert, da der Product Key durch den Endbenutzer-Lizenzvertrag fest an genau das Mainboard gebunden wird, auf dem er aktiviert wurde. Ob eine solche Bindung in Deutschland wirksam ist, ist umstritten. Sollte sie wirksam sein, ginge die Windows-Lizenz bei einem Defekt oder Austausch des Mainboards verloren.\n\n\n"}
{"id": "6260830", "url": "https://de.wikipedia.org/wiki?curid=6260830", "title": "SurfCAM", "text": "SurfCAM\n\nSurfCAM ist eine CAD/CAM-Lösung des US-amerikanischen Herstellers Surfware, Inc. mit Sitz in Camarillo. SurfCam wird in den Bereichen Produktentwicklung, der Fertigung und dem Datenaustausch eingesetzt und dient als PC-basierte CAM-Software zur Steuerung von CNC-Maschinen.\n\nDurch seine direkte Schnittstelle ist SurfCAM kompatibel zu jedem auf dem Markt verfügbaren CAD-System. Die Software wird in den Bereichen Drehen, Fräsen, Erodieren und der kombinierten Dreh-/Fräsbearbeitung eingesetzt. Die eigens für jede Maschine gefertigten Postprozessoren werden im Unternehmen gefertigt und weit über den Grenzen Europas hinaus eingesetzt. Folgende SurfCAM-Produkte gibt es.\n\n\nsowie die TrueMill Lösung im Bereich 2- und 3-Achsen.\n\n"}
{"id": "6261658", "url": "https://de.wikipedia.org/wiki?curid=6261658", "title": "Jagdfieber 2", "text": "Jagdfieber 2\n\nJagdfieber 2 (Originaltitel: \"Open Season 2\") ist eine computeranimierte Filmkomödie aus dem Jahr 2008 und die Fortsetzung von \"Jagdfieber\" aus dem Jahr 2006. 2010 erschien ein weiterer Film unter dem Titel \"Jagdfieber 3\", 2015 wurde \"Jagdfieber – Ungebetene Besucher\" veröffentlicht.\n\nDer Hirsch Elliot und seine Hirschdame Giselle stehen kurz vor ihrer Hochzeit. Am Tag der Zeremonie kommen Elliot Zweifel, ob er das Richtige tue. Zudem fällt ihm unglücklicherweise sein Geweih ab. In der Zwischenzeit legt das Frauchen des inzwischen in der Wildnis lebenden Dackels Hr. Wiener Spuren mit dessen Lieblings-Hundekuchen \"Hündfüd\" aus. Hr. Wiener kann dem nicht widerstehen und frisst sich der Spur entlang zu seinem Frauchen, das ihn sogleich zu sich in die Zivilisation zurückbringt. Elliot hat das Weglaufen von Hr. Wiener während der Hochzeitszeremonie beobachtet und diese deswegen kurz vor dem Jawort verlassen, um Hr. Wiener zu folgen. Eine Gruppe macht sich nun auf, Hr. Wiener von den Menschen zu befreien und zurückzuholen. Sie finden Hr. Wiener in einem Wohnmobil an einer Tankstelle. Die Befreiungsaktion scheitert jedoch wegen Elliots Tollpatschigkeit und das Wohnmobil fährt mitsamt dem Dackel wieder davon. Nach einem Streit verlässt Elliot die Gruppe und sucht getrennt von den anderen nach Hr. Wiener, irrt jedoch nur planlos im Kreis herum. Währenddessen versuchen andere Haustiere, angeführt vom Pudel Fifi, die Hr. Wiener nun für verwildert halten, ihn wieder zu kultivieren, indem sie mit ihm unter anderem das Stöckchenholen trainieren. Hr. Wiener gelingt es mit der Hilfe von Buddy zu fliehen. Die beiden treffen später auf Elliot. Boog, Giselle, McSquizzy sowie Serge und Deni, die nichts von der erfolgreichen Flucht von Hr. Wiener wissen, sind nun auf dem Weg ins Tierparadies (Pet Paradiso), wo sie das Wohnmobil mit Hr. Wiener vermuten. Giselle und McSquizzy tarnen sich als Hunde und gelangen so unerkannt ins Tierparadies. Inzwischen machen sich auch Elliot zusammen mit Hr. Wiener und Buddy auf den Weg zum Tierparadies, da Elliot glaubt, seine Hirschdame Giselle wäre in Gefahr und er müsste sie vor den Menschen retten. Vor dem Tierparadies treffen die drei auf Boog. Nun tarnen sich Boog als Hund und Elliot mit Buddy auf dem Kopf als Frau, um gemeinsam mit Hr. Wiener im Tierparadies nach den anderen zu sehen. Inzwischen wurden Giselle und McSquizzy von Fifi und seiner Bande gefangen genommen. Beim Versuch, sie zu befreien, werden auch Elliot und Buddy gefangen. Mit Hilfe von Boog und Hr. Wiener gelingt allen die Flucht. Hr. Wiener entscheidet sich schließlich, zurück zu seinem Frauchen zu gehen. Elliot und Giselle heiraten.\n\nDer Film wurde von der Berliner Synchron übersetzt und synchronisiert. Dialogbuch und -regie führte Michael Nowka.\n\n\n\n"}
{"id": "6263974", "url": "https://de.wikipedia.org/wiki?curid=6263974", "title": "Nokia Suite", "text": "Nokia Suite\n\nDie Nokia Suite (vormals Nokia Ovi Suite) ist eine Software des Unternehmens Microsoft Mobile für die Anbindung derer Mobilgeräte an den PC. Die Software synchronisiert Inhalte zwischen PC und Mobilgerät, dient der Datensicherung und kann via Tethering über das Mobilgerät für den PC eine Internetverbindung aufbauen. Der Vorgänger ist die Nokia PC Suite, die durch die Nokia Suite ersetzt wird.\n\nDie Verbindung zwischen Mobilgerät und PC kann über ein USB-Kabel oder Bluetooth hergestellt werden. Mit der Nokia Suite können Daten auf dem Mobilgerät und dem PC gleichzeitig verfügbar gemacht werden: zur Anzeige, Bearbeitung, Anlage oder Löschung. Es werden unterstützt:\n\n\nDie Software sorgt dafür, dass die Datenbestände auf beiden Geräten synchron gehalten werden. Die Nokia Suite kann eine vollständige Datensicherung des Mobilgeräts durchführen und diese wieder auf das Mobiltelefon zurückspielen. Mittels Tethering kann das Mobilgerät als Modem für den PC verwendet werden. Zudem kann man die Telefon-Software aktualisieren.\n\nFolgende Voraussetzungen müssen erfüllt sein:\n\n"}
{"id": "6264905", "url": "https://de.wikipedia.org/wiki?curid=6264905", "title": "ICloud", "text": "ICloud\n\niCloud ist ein Online-Dienst des Unternehmens Apple, mit dem Daten gespeichert und synchronisiert werden können. Der Dienst wurde am 6. Juni 2011 im Rahmen der Entwicklerkonferenz WWDC vorgestellt und am 12. Oktober 2011 gestartet. iCloud ersetzt Apples vorherigen Online-Dienst MobileMe, der am 1. Juli 2012 vollständig abgeschaltet wurde.\n\nMit iCloud ist es möglich, Daten auf maximal zehn Apple-Geräten und Microsoft-Windows-Rechnern synchron zu halten. Neben Mails, Kontakten und Kalendereinträgen, die bereits mit \"MobileMe\" synchronisiert werden konnten, können Fotos, Dokumente und Einstellungen automatisch in iCloud hochgeladen und zwischen allen Geräten des Besitzers synchronisiert werden. Für iOS-Geräte dient iCloud auch als Backup.\n\nIm iTunes Store gekaufte Multimedia-Inhalte können von allen Geräten des Nutzers heruntergeladen werden.\n\nDie Funktion „Mein iPhone suchen“ ermöglicht es, den Aufenthaltsort eines iOS-Gerätes zu bestimmen, etwa im Fall eines Verlusts. Mit der Funktion „Meine Freunde finden“ kann der aktuelle Standort auch anderen Personen bekanntgegeben werden.\n\nJedem Nutzer stehen in iCloud kostenlos 5 GB Speicherplatz zur Verfügung. Eigene Fotos in Photostream sowie bei Apple gekaufte Inhalte wie Musik, Apps oder Bücher werden nicht auf diesen Speicherplatz angerechnet. Zusätzlicher Speicherplatz kann kostenpflichtig erworben werden.\n\n\nAuf der WWDC 2012 wurden folgende Funktionen präsentiert, die mit OS X Mountain Lion und iOS 6 im Herbst 2012 eingeführt wurden:\n\n\nAuf der WWDC 2013 wurden weitere Funktionen vorgestellt, welche in iOS 7 und OS X Mavericks „Mavericks“ im Herbst 2013 eingeführt wurden:\n\n\nAuf der WWDC 2014 wurden weitere Funktionen gezeigt, welche in iOS 8 und OS X Yosemite „Yosemite“ im Herbst 2014 eingeführt wurden:\n\n\nMit Einführung von iCloud für iOS wurde es lediglich von iWork für iOS unterstützt, seit der Veröffentlichung von Mac OS X Lion ist die Verwendung auch unter iWork für Mac möglich. iCloud kann zudem in Software von Drittanbietern genutzt werden, die diese über den App Store anbieten.\n\nDer Dienst \"iTunes Match\" startete in den USA für zunächst jährlich 24,99 US-Dollar, in Deutschland (24,99 €) und der Schweiz (CHF 35) ist er seit dem 16. Dezember 2011 verfügbar. Die GEMA, die in Deutschland viele Musiker vertritt, hatte zunächst eine einjährige \"Experimentalvereinbarung\" mit Apple abgeschlossen.\n\niTunes Match erstellt für jeden Titel in der Musikbibliothek des Nutzers einen akustischen Fingerabdruck und gleicht die Bibliothek so mit dem im iTunes Store verfügbaren Angebot ab. Wenn ein Titel auch im iTunes Store verfügbar ist, wird er ab sofort behandelt, als wäre er im iTunes Store gekauft worden. Musikstücke geringer Tonqualität werden gegen bessere Kopien ausgetauscht und können auch behalten werden, wenn das iTunes-Match-Abo nicht verlängert wird. Nicht im iTunes Store erhältliche Titel werden hochgeladen; sie können während der Laufzeit des iTunes-Match-Abos zu allen Geräten eines Nutzers gestreamt oder heruntergeladen werden.\n\nApple bietet auf iCloud.com die Möglichkeit, alle iCloud-Dienste über ein Webinterface zu nutzen, welches im Quelltext als \"CloudOS\" bezeichnet wird. Dort können auf iCloud Drive gespeicherte Dateien heruntergeladen oder in browserbasierten Versionen von Pages, Numbers und Keynote bearbeitet werden. Zudem stehen Mail, Kontakte, Kalender, Notizen, Erinnerungen und die \"mein iPhone suchen\"-Funktion zur Verfügung.\n\nApple betreibt Rechenzentren in mehreren US-Bundesstaaten.\n\nIn iCloud hochgeladene Daten werden mit dem Algorithmus AES-128 verschlüsselt und bei Speicherdiensten wie Amazon S3 oder Windows Azure abgelegt, während die Schlüssel sowie Metadaten wie der Dateiname oder Zugriffsrechte in Apples Rechenzentren gespeichert werden.\n\nDa die Server in den USA stehen, unterliegen sie nicht dem deutschen, sondern dem wesentlich schwächeren US-amerikanischen Datenschutzrecht. Stiftung Warentest bewertete den Datenschutz bei allen US-amerikanischen Cloud-Anbietern daher nur als ausreichend.\n\nDer Stromverbrauch der Rechenzentren wurde stark debattiert.\nEin im April 2012 veröffentlichter Greenpeace-Bericht kritisierte, dass Apple sehr selektiv und intransparent sei, was die Veröffentlichung von Energiedaten betrifft. Der Bericht kritisiert außerdem die von Apple genutzten Energieträger. Greenpeace hatte den Energiebedarf eines Apple-Rechenzentrums im US-Bundesstaat North Carolina anhand der Investitionskosten in Höhe von 1 Mrd. US-Dollar auf 100 Megawatt geschätzt. Davon kämen nur 10 % aus umweltfreundlichen Quellen, der Rest stamme aus Kohle- und Atomkraftwerken. Die Branchenseite DataCenterKnowledge.com wies jedoch darauf hin, dass in den Investitionskosten auch Kosten für eine Solaranlage und Brennstoffzellen enthalten sind, die vor Ort einen Teil des benötigten Stroms erzeugen sollen. Die tatsächlichen Kosten des Rechenzentrums und damit der Energieverbrauch seien also deutlich geringer als von Greenpeace angenommen. Apple erklärte, das Rechenzentrum benötige bei voller Auslastung nur rund 20 Megawatt Leistung, davon würden 60 % vor Ort aus regenerativen Quellen erzeugt. Die restlichen 40 % seien zugekauft und ebenfalls aus erneuerbaren Energien.\n\nIn einem im April 2014 veröffentlichten Bericht erklärte Greenpeace, dass Apple das einzige untersuchte Unternehmen war, das alle Rechenzentren vollständig auf erneuerbare Energien umgestellt habe.\nZur Aktivierung des Dienstes ist mindestens ein iPhone, iPad oder iPod touch mit dem Apple-Betriebssystem \"iOS 5\" oder ein Mac mit Mac OS X Lion oder neuer beziehungsweise Windows Vista oder neuer mit zusätzlicher iCloud-Software erforderlich. Die Nutzung des Webservices über iCloud.com ist mittlerweile auch ohne ein iOS- oder MacOS- Gerät möglich.\n\nAnfang September 2014 wurde eine Sicherheitslücke in der Funktion „Find My iPhone“ bekannt. Über diese Funktion, die eigentlich Nutzern beim Auffinden eines iPhones oder iPads helfen soll, konnte über ein Tool namens iBrute ein zu einfach gewähltes Passwort eines bestimmten Nutzers mittels Brute-Force ermittelt werden, da Apple keine Begrenzung für die Anmeldeversuche eingebaut hatte. Kurz nach Bekanntwerden der Sicherheitslücke wurde diese von Apple geschlossen und es werden nur noch zehn Anmeldeversuche in „Find My iPhone“ gestattet.\n\n"}
{"id": "6265600", "url": "https://de.wikipedia.org/wiki?curid=6265600", "title": "GRiDPad", "text": "GRiDPad\n\nDas GRiDPad von GRiD Systems war einer der ersten Tabletcomputer, der mit einem Stift bedient wurde. Es wurde im Jahr 1989 von Samsung für die GRiD Systems Corporation hergestellt.\n\nAbgeleitet wurde das Tablet vom PenMaster von Samsung, der nicht über das Prototypenstadium hinauskam. Das Gerät in den Dimensionen 29,2 × 23,6 × 3,7 cm hatte einen 10 MHz schnellen 80C86-Prozessor mit DOS, ein CGA-Display (640 × 400 Pixel) und einen batteriegestützten RAM-Speicher von 256 bzw. 512 KByte. Der damalige Preis lag bei 2370 Dollar, ohne Software. Die Software war eine Eigenentwicklung von GRiD mit einer Texterkennung, die das Schreiben auf dem Bildschirm per Stift ermöglichte. Eine externe Tastatur konnte per Kabel angeschlossen werden. \n\nVerwendung sollte das Tablet bei Lagerverwaltung, Polizei, im Krankenhaus und anderen Datenerfassungstätigkeiten finden. \n\n"}
{"id": "6265653", "url": "https://de.wikipedia.org/wiki?curid=6265653", "title": "HTC 7 Pro", "text": "HTC 7 Pro\n\nDas HTC 7 Pro ist ein Smartphone des taiwanischen Herstellers HTC Corporation. Als Betriebssystem kommt Windows Phone 7 zum Einsatz.\n\nDas HTC 7 Pro gehört der ersten Serie von Smartphones an, die mit dem Microsoft-Betriebssystem Windows Phone 7 ausgestattet sind. Im Gegensatz zu den übrigen Windows-Phone-7-Smartphones des Herstellers HTC Corporation wurde das HTC 7 Pro erst Anfang 2011 eingeführt. Konzipiert ist das HTC 7 Pro als Business-Smartphone, da es über eine ausziehbare QWERTZ-Tastatur verfügt und mit einem stärkeren Akku (1500 mAh) ausgestattet ist. Insbesondere gegenüber dem HTC HD7 wurde ein Touchscreen mit gleicher Auflösung (WVGA), aber kleinerer Diagonale verbaut. Microsoft stellt an die Fabrikate, auf denen Windows Phone 7 laufen soll, strenge Anforderungen, die unter anderem der Qualitätssicherung dienen. Gleichzeitig führt dies aber zu weitreichenden Einschränkungen bezüglich der Offenheit für Anwendungsentwicklungen und individuelle Herstellerdesigns.\n\nDas HTC 7 Pro wurde in Deutschland erstmals im ersten Quartal 2011 ausgeliefert.\n\nHardware-Basis ist ein Snapdragon-Chipsatz des Typs QSD8250, welcher bereits im Vorgänger HTC HD2 verbaut war. Der mit 1 GHz getaktete Prozessorkern \"Scorpion\" ist vergleichbar mit dem \"ARM-Cortex-A8\"-Kern und wird von 576 MB Arbeitsspeicher unterstützt. Grafische Berechnungen übernimmt der fest auf der Platine verbaute Adreno 200-Chip von Qualcomm, welcher unter anderem den OpenGL ES 2.0- sowie Direct3D-Standard beherrscht.\nDas QSD8250-Chipset stellt die erste Generation der Snapdragon-Produktelinie dar und unterstützt mehrere Mobilfunkstandards, darunter GPRS, EDGE, UMTS und HSPA.\nZudem beinhalten alle Snapdragon-Chipsets Recheneinheiten zum Dekodieren von HDTV mit einer Auflösung von 720p sowie einen GPS-Empfänger.\n\nAnders als bei anderen Modellen, wie etwa dem Samsung Omnia 7, kommt im HTC 7 Pro kein festgelöteter NAND-Speicher zum Einsatz, sondern ein interner, nicht frei zugänglicher SD-Kartenslot; hier befindet sich eine 8 GB SDHC-Speicherkarte. Der interne ROM-Speicher mit einer Kapazität von 512 MB wird hierbei, gemeinsam mit der SD-Karte, in einem JBOD-Verbund zu einem Speicher zusammengefügt; innerhalb des Betriebssystems kann also nicht mehr zwischen ROM oder SD-Karte unterschieden werden.\n\nMittlerweile hat allerdings ein Tüftler der Online-Community PocketPC.ch anscheinend einen Weg gefunden, dennoch eine größere SD-Karte einzubauen. Solche Experimente waren auch beim HTC HD7 bereits erfolgreich und sollen dort laut einem Video, das bei YouTube eingestellt wurde, auch ohne Verlust der Garantieansprüche möglich sein.\n\nDie integrierte Kamera kann Fotos mit einer Auflösung von bis zu 5 Megapixeln (2.560 × 1.920 Pixel) machen. Zur Lichtmessung kommt ein aktiver Pixelsensor (auch bekannt als „CMOS-Sensor“) zum Zuge. Unterstützung erhält die Kamera dabei von einem Dual-LED-Blitzlicht. Die Kamera kann zudem Filme mit einer Auflösung bis zu 720p (1280 × 720 Pixel) aufnehmen. Weiterhin stehen dem Nutzer verschiedene Aufnahmeprogramme zur Verfügung, darunter \"Kerzenschein\", \"Landschaft\" und \"Porträt\".\n\nDrahtlos kommuniziert das HTC 7 Pro per WLAN-Standard 802.11 b/g/n, GPRS, EDGE, UMTS, HSPA und Bluetooth 2.1. Zudem ist eine A-GPS-Antenne eingebaut.Es werden die Bluetooth-Profile A2DP, AVRCP, HFP, HSP und PBAP unterstützt.\n\nDas HTC 7 Pro ist das einzige Gerät mit dem Betriebssystem Windows Phone 7 des Herstellers HTC Corporation mit einer physischen Tastatur. Die Tastatur fährt seitlich vom Bildschirm nach links aus. Insbesondere der Homescreen ist bei Windows Phone 7 aber auf eine vertikale Haltung des Bildschirms ausgelegt. Zur Nutzung der physischen Tastatur muss das HTC 7 Pro aber quer gehalten werden, was die Bedienung der dann falsch orientierten Menüs erschwert.\nDieses Manko wurde seitdem in mehreren redaktionellen Tests gerügt.\n"}
{"id": "6266854", "url": "https://de.wikipedia.org/wiki?curid=6266854", "title": "Newlib", "text": "Newlib\n\nNewlib ist eine C-Standard-Bibliothek, optimiert zur Erstellung von Projekten im Bereich Eingebettete Systeme. Newlib ist eine Zusammenstellung fundamentaler, geschwindigkeits- und größenoptimierter Teile der C-Standard-Bibliothek, ist unter freien Softwarelizenzen verfügbar und liegt als offener Quelltext vor. Ursprünglich von Cygnus Solutions entwickelt, wird Newlib nach der Übernahme durch Red Hat gepflegt.\n\nDa Newlib quelloffen ist, kann sie für eine Vielzahl von Prozessorfamilien compiliert werden und ist aufgrund dieser Flexibilität weit verbreitet bei mikrocontrollerbasierten Softwareprojekten. Dies reicht von Kleinstgeräten mit 8-Bit-Prozessoren (zum Beispiel Atmel AVR) bis hin zu aktuellen 32-Bit-Architekturen.\n\nDiverse kommerzielle GCC-Distributionen, beispielsweise von CodeSourcery, Atollic and Red Hat, nutzen Newlib als Basis im Bereich eingebetteter Systeme. Weiterhin erfährt die Weiterentwicklung von Newlib-Unterstützung durch Hersteller eingebetteter Prozessorarchitekturen wie beispielsweise ARM Limited und Renesas Electronics.\n\n"}
{"id": "6267486", "url": "https://de.wikipedia.org/wiki?curid=6267486", "title": "Druck-Taste", "text": "Druck-Taste\n\nDie Druck-Taste, in der Schweiz die Print-Screen-Taste, ist eine auf den meisten PC-Tastaturen vorhandene Taste. Bei deutschen und österreichischen Tastaturen lautet die Aufschrift „Druck“ bzw. „Drucken“, bei Schweizer und US-amerikanischen Tastaturen „Print Screen“, „Prt Sc“ oder ähnlich. Seit Einführung der MF2-Tastatur im Jahr 1987 handelt es sich (außer bei Notebooks) um eine eigenständige Taste, bei den ersten PCs wurde dieselbe Funktion über die Tastenkombination - bzw. - (Multiplikationszeichen des Ziffernblocks) erreicht.\n\nUnter MS-DOS diente die Taste ursprünglich dazu, unabhängig von der gerade laufenden Software eine einfache Hardcopy des gerade angezeigten Bildschirminhalts auf dem angeschlossenen Drucker zu erstellen. Somit konnten auch dann Informationen ausgedruckt werden, wenn das laufende Programm keine eigene Druckfunktion bot.\n\nUnter Microsoft Windows, wie auch diversen Linux-Oberflächen wie KDE und Gnome, wird durch Drücken der - bzw. -Taste ein Bildschirmfoto (Screenshot) im Bitmap-Format erstellt und in die Zwischenablage kopiert. Dieses Bildschirmfoto steht damit zur Speicherung oder Bearbeitung zur Verfügung.\n\nDas Erstellen eines Bildschirmfotos mittels der Druck-Taste funktioniert unter Windows jedoch nicht in folgenden Situationen:\n"}
{"id": "6268022", "url": "https://de.wikipedia.org/wiki?curid=6268022", "title": "Nero Video", "text": "Nero Video\n\nNero Video (bis 15. Oktober 2011 \"Nero Vision\") ist eine Videobearbeitungssoftware der Nero AG, die sowohl einfache Bearbeitung (Express-Modus) als auch erweiterte Videobearbeitung (erweiterter Modus) mit Mehrspur-Zeitleiste und Key-Framing unterstützt. Nero Video hat auch umfangreiche Funktionen zur Einbindung von Fotos und Musik in Videoprojekte sowie eine ganze Palette an Übergangs-, Video-, Audio-, und Titeleffekten. Daneben gibt es Vorlagen zur halbautomatischen Filmerstellung und Bild-in-Bild-Vorlagen. Nach der Videobearbeitung kann der fertige Film als Datei ausgegeben werden oder ins Web gestellt werden. Alternativ brennt das Programm DVDs und Blu-ray Discs, deren Menü und Kapitel man in einzelnen Schritten individuell gestalten kann. Die Video-Disc-Erstellung ist als eigenes Modul direkt vom Startbildschirm aus abrufbar. So können reine Discprojekte zügig umgesetzt werden. Einfache Trimm- und Arrangierwerkzeuge sind in diesem Authoring-Modul ebenfalls verfügbar.\n\nDas Programm weist eine starke technische Entwicklung in den verschiedenen Versionen auf:\n\nIn der ersten Version „Nero Vision 4“ konnte man bereits Videos in einer schmalen Schablone bearbeiten: Pro Film waren unveränderbar ein Videokanal, ein Effektekanal, ein Textkanal und zwei Audiokanäle vorhanden. Fotos lassen sich noch nicht in Videos integrieren. Die Menübearbeitung ist nur in einer automatischen Vorlage steuerbar.\n\nNun wurden auch HD-Videos möglich. In den Menüoberflächen waren mehr Vorlagen vorhanden, jedoch im Großen und Ganzen keine großen Neuerungen.\n\nIn der dritten Version der Software wurde die Menübearbeitung manualisiert. Jetzt konnten auch zusätzliche Untermenüs erstellt werden. Außerdem konnten nun Fotos in Videos eingefügt werden.\n\nMit dieser viel umfangreicheren Version wurde die Mehrspurbearbeitung möglich; auch visuell wurde die Software optimiert. Hier kamen viele Effekte zu denen der vorigen Versionen hinzu sowie optionale Keyframes (Punktmarkierungen) auf der Zeitleiste, um beispielsweise die Bildgröße oder Effekte über den Zeitverlauf zu variieren. An der Menübearbeitung wurde nichts Wesentliches geändert. Nun wurde jedoch auch das Brennen von Blu-ray Discs möglich.\n\nIn der ersten Version mit neuem Namen war die wichtigste Neuerung der Express-Modus, der eine einfache aber bereits komplette Bearbeitung von Videos in einer vereinfachten Zeitleiste ermöglicht. Hinzu kamen Expresseffekte als eine Reihe vordefinierter Effektvorlagen, die mittels Drag&Drop auf Clips angewendet werden können. Der Startbildschirm wurde komplett neu aufgebaut, auch der Import von AVCHD-Medien wurde vereinfacht. Alte Effekte wurden in einzelne Funktionen gesplittet und Soundeffekte kamen hinzu.\n\nHinzu kamen einige neue Effekte (Zeitlupe/-raffer, Bildstabilisierung, Retrodesign).\n\nBei dieser Version kamen Nero Tilt Shift-Effekte und Nero RhythmSnap hinzu. Der Startbildschirm erhielt eine Drag&Drop-Funktion zum schnellen Starten von Video- oder Discprojekten. Außerdem wurde die 4K-Video- und Diashowbearbeitung und -ausgabe eingeführt.\n\nDie Schriftarten und Schriftstile wurden verbessert. Außerdem kamen und neue, animierte Texteffektvorlagen, weitere Texteffekte sowie die Möglichkeit, eigene Texteffektvorlagen zu erstellen, hinzu.\n\nNeben Verbesserungen der Schriftarten, Text- und Videoeffekte wurden weitere neue Videovorlagen integriert. Zusätzlich bietet diese Version volle 4K-Unterstützung (Ultra-HD).\n\nDie plattformübergreifenden Wiedergabemöglichkeiten wurden verbessert. So können nun bei der Wiedergabe via Streaming Untertitel eingeblendet werden.\n\nNero Video ist Bestandteil von Nero 2017 Classic, Nero 2016 Platinum und Nero Video 2017. Außer in der Nero 2017 Classic Version, bei der die Effektpalette und die Vorlagen etwas abgespeckt sind, sind die Versionen von Nero Video in den anderen Produkten identisch. All Produkte beinhalten zusätzlich auch Nero MediaHome.\n\n\"Nero Media Home\" erlaubt die Verwaltung und das Abspielen von Bildern, Videos und Musikdateien. Neben dem Rippen von Audio-CDs und dem Erstellen von Playlisten und Slideshows sind wichtige Funktionen zum Organisieren wie das Vergeben von Tags, die Gesichtserkennung in Bildern und das Auslesen und manuelle Setzen von Ortsangaben (Geotagging) für Fotos und Videos vorhanden. Auch das Streaming zu TV-Geräten und Home-Media-Playern ist möglich. Ab Version 2015 kann man mit der \"Nero MediaHome Receiver App\" auf Mobilgeräte (iOS, Android, Amazon) streamen.\n\nDie Hauptfunktionen der aktuellen Version Nero Video 2017 sind Folgende:\n"}
{"id": "6272062", "url": "https://de.wikipedia.org/wiki?curid=6272062", "title": "Mascot (Software)", "text": "Mascot (Software)\n\nMascot ist eine Software zur Auswertung von Daten aus der Protein-Massenspektrometrie für die Betriebssysteme Windows und Linux.\n\nSie dient zur Identifizierung von Peptiden und Proteinen in der Proteomik indem eine Datenbanksuche durchgeführt wird.\n\nZahlreiche Einrichtungen verwenden Mascot, entweder als lizenzierte betriebsinterne Installation oder über den öffentlichen Webserver.\n\nMascot basiert auf MOWSE, entwickelt von Darryl Pappin and David Perkins am Imperial Cancer Research Fund und wurde von Cancer Research Technology lizenziert.\n\nDie Performance verschiedener Auswertungssoftware für die Proteomik kann in einer Studie der \"Proteome Informatics Research Group (iPRG)\" eingesehen werden.\n"}
{"id": "6273868", "url": "https://de.wikipedia.org/wiki?curid=6273868", "title": "Kung Fu Panda 2", "text": "Kung Fu Panda 2\n\nKung Fu Panda 2 ist eine US-amerikanische animierte Action-Komödie und die Fortsetzung des Films \"Kung Fu Panda\" aus dem Jahre 2008. Der Film wurde am 26. Mai 2011 in Digital 3D veröffentlicht. In Deutschland hatte er am 16. Juni 2011 Premiere. 2012 war der Film in der Kategorie \"Bester Animationsfilm\" für den Oscar nominiert. 2016 erschien Kung Fu Panda 3, der dritte Teil der Reihe.\n\nVor langer Zeit war der Sohn des Fürstentums von Gongmen City, Lord Shen (ein Pfau), seiner Faszination zum Feuerwerk verfallen – allerdings nicht um die anderen Wesen seines Reiches zu erfreuen, sondern um es als Waffe zu benutzen. Die alte Seherin des Hofes jedoch prophezeite ihm, dass er, wenn er seiner Eroberungssucht folge, am Ende von einem „Krieger in Schwarz und Weiß“ besiegt werden würde. Daraufhin ließ Shen, um der Prophezeiung entgegenzuwirken, sämtliche Pandas im Reich ausrotten; seine von dieser Bluttat entsetzten Eltern verstießen ihn daraufhin, was Shens Gelüste jedoch weiter anfachte.\n\nViele Jahre später hat Shen die Weiterentwicklung seines Projekts vorangetrieben und nahezu vollendet, doch für den letzten Schritt braucht er noch mehr Eisen. Zu diesem Zweck überfallen seine Männer die nahe gelegenen Dörfer und stehlen alles, was sie an eisernen Dingen finden können. Po und seine Freunde, die Furiosen Fünf, kommen den Dörflern zu Hilfe, doch bei dem Anblick ihres Hoheitssymbols überkommt Po ein Flashback von seiner Mutter, welcher ihn ablenkt, so dass die Übeltäter entkommen können. Später fragt Po Mr. Ping, den Mann, den er als seinen Vater kennt, nach seiner Herkunft, doch alles, was Ping ihm erzählen kann, ist dass er Po als Baby in einer Rettichkiste vor seinem Nudelrestaurant vorgefunden und ihn dann bei sich aufgenommen hat. Die Frage nach seiner Herkunft lässt Po unruhig werden, so dass er Probleme hat, seinen inneren Frieden zu finden.\n\nSpäter erhält Meister Shifu eine Nachricht von den fürstlichen Ratsherrn von Gongmen City, dass Shen die Macht in der Stadt mit Gewalt wieder an sich gerissen hat (seine Eltern sind bereits vor langer Zeit verstorben). Po und die Furiosen Fünf machen sich nach Gongmen City auf, um die beiden überlebenden Ratsherren Tosender Ochse und Kroko zu befreien, doch die beiden weigern sich standhaft, ihre Zellen zu verlassen: Shens neue Waffe – eine Kanone – hat ihren Meister Donnerndes Nashorn trotz dessen Meisterschaft im Kung Fu mit nur einem Schlag weggefegt, was sie den Mut hat verlieren lassen. Die sechs Gefährten werden daraufhin von Shen gefangen genommen; sie können sich zwar befreien und die Kanone in dessen Thronsaal zerstören, doch leider war dies nur ein Stück aus Shens Arsenal. Zudem erkennt Po Shens Symbol als das Zeichen wieder, das so eng mit seiner Vergangenheit zusammenhängt, weswegen Shen im letzten Moment fliehen konnte. Wegen dieses Fehlers verbietet Tigress Po, mit ihnen zu gehen, als sie versuchen, Shens Kanonengießerei zu sabotieren. Po jedoch folgt ihnen trotzdem, um Antworten von Shen zu bekommen; dabei erreicht er jedoch nur, dass seine Freunde erneut gefangen werden und er, nachdem Shen ihm eingeredet hat, dass seine Eltern ihn verlassen hätten, weil sie ihn nicht liebten, von der Kanone aus der Gießerei rausgeschossen wird. Er wird jedoch von der Seherin wiedergefunden und über seine und Shens Vergangenheit aufgeklärt, und mit dem Wissen, dass er dennoch mit Ping eine glückliche Kindheit hat durchleben können, findet Po endlich seinen inneren Frieden.\n\nAls Shen mit seinen Kanonen und seiner Kriegsflotte aufbrechen will, um China zu erobern, stellt sich ihm Po nun mit neuer Entschlossenheit entgegen, unterstützt von Meister Shifu, der Tosender Ochse und Kroko endlich neuen Mut einflößen konnte. Shen macht rücksichtslos von seinen Kanonen Gebrauch und schafft es zunächst, die Kung Fu-Meister zurückzuschlagen; doch dann kann Po dank seiner neuen inneren Ruhe und seinen bloßen Händen die auf ihn gerichteten Geschosse abfangen und sie zurück auf die Flotte schleudern, um sämtliche Schiffe und somit Shens Pläne zu versenken. Als Po Shen überreden will, seinen eigenen Frieden zu finden, weigert sich dieser und greift ihn an; dabei aber bringt er seine letzte Kanone dazu, auf ihn zu fallen und ihn unter sich zu zerquetschen. Zudem wird am Ende noch einmal (wie den gesamten Film hindurch) angedeutet, dass zwischen Po und Tigress eine besonders enge Bindung besteht.\n\nSiegreich kehrt Po wieder nach Hause zurück und akzeptiert Ping völlig als seinen Vater. In diesem Moment aber wird offenbart, dass Pos biologischer Vater in einem abgelegenen Pandadorf noch lebt und spürt, dass sein Sohn noch am Leben ist.\n\n\"Kung Fu Panda 2\" ist der Nachfolger des Films \"Kung Fu Panda\". Der erste Film wurde im Juni 2008 freigegeben, und im darauf folgenden Oktober gab das Studio DreamWorks Animation Pläne für einen zweiten Film bekannt. Jennifer Yuh Nelson, die Leiterin der Geschichte für den ersten Film, wurde engagiert, um die Fortsetzung zu lenken. Wie andere Filme mit Beginn der Produktion im Jahre 2009, wurde Kung Fu Panda 2 in stereoskopischer 3-D-Technik produziert. Das Studio plante, den Film in IMAX-Kinos weltweit zu veröffentlichen.\n\nVor der kommerziellen Veröffentlichung feierte \"Kung Fu Panda 2\" seine Premiere bei den Internationalen Filmfestspielen von Cannes Anfang Mai 2011. Der Film wurde in den Vereinigten Staaten am 26. Mai 2011 veröffentlicht. Im Vereinigten Königreich war es der 10. Juni 2011.\n\nBei 150 Millionen US-Dollar Produktionskosten spielte der Film an seinem Startwochenende in den USA knapp 48 Millionen US-Dollar, also mehr als 20 Prozent weniger als der erste Teil, ein. Die endgültigen amerikanischen Zahlen lagen bei 165 Millionen US-Dollar, was 50 Millionen weniger ist als bei seinem Vorgänger. International konnte er sich jedoch um mehr als 80 Millionen steigern und spielte 500 Millionen US-Dollar ein. Die Gesamteinnahmen lagen damit bei 665 Millionen US-Dollar. In Deutschland nahm der Film 15,8 Millionen Euro (umgerechnet 20,7 Mio. US-Dollar) ein. Damit war er auch hierzulande weniger erfolgreich als sein Vorgänger, der knapp 20 Millionen Euro bzw. 26 Mio. US-Dollar einnahm, und das trotz der Tatsache, dass 3D-Filme grundsätzlich höhere Ticketpreise haben.\n\n\"Kung Fu Panda 2\" erhielt positive Kritiken, viele Kritiker loben seine Animation, 3D-Effekte und Charakterentwicklung. Der Film erhielt einen „Certified Fresh“-Reward bei einem Rating von 81 % (6,9 von 10 Punkten im Durchschnitt) auf Rotten Tomatoes, basierend auf 134 Kritiken. \"Kung Fu Panda 2\" bietet Action, Komödie und visuellen Glanz. Er nahm auch einen gewichteten Durchschnittswert von 67 zu 100 bei Metacritic, basierend auf 31 Bewertungen von Mainstream-Kritikern.\n\nDas Magazin Variety nannte den Film eine würdige Fortsetzung, die einen zusätzlichen Kick bekam durch den Zusatz von dynamischen 3D-Kampf-Sequenzen, während The Hollywood Reporter ähnlich den Film gelobt habe. Roger Ebert gab dem Film 3,5 von 4 Sternen.\n\nFrank Lovece der Film Journal International beschreibt den Film als „wirklich schön anzusehen“ und er „funktioniert sowohl auf ästhetische(r) und emotionale(r) Ebene“. Betsy Sharkey von der Los Angeles Times schreibt, dass „Für Panda 2 ist nicht nur Wand-zu-Wand-Animation, es [ist] Artistik auch auf höchstem Niveau“.\n\nDas Jugendmagazin yaez.de würdigt den Film als „[soliden und unterhaltsamen] Familienfilm“, merkt aber an, dass \"Kung Fu Panda 2\" nicht an andere Animations-Blockbuster herankommt.\n\n\n"}
{"id": "6276616", "url": "https://de.wikipedia.org/wiki?curid=6276616", "title": "Teenage Mutant Ninja Turtles (Fernsehserie)", "text": "Teenage Mutant Ninja Turtles (Fernsehserie)\n\nTeenage Mutant Ninja Turtles, bzw. Tales of the Teenage Mutant Ninja Turtles in der fünften Staffel, ist eine US-amerikanische computeranimierte Fernsehserie, die auf den gleichnamigen Comics von Kevin Eastman und Peter Laird basiert. Ihre Erstausstrahlung erfolgte am 28. September 2012 bei Nickelodeon. Die deutschsprachige Erstausstrahlung erfolgte am 4. November 2012 beim deutschen Nickelodeon.\n\nAls Ninjutsu-Meister Hamato Yoshi (Splinter) mit vier gerade gekauften Babyschildkröten durch die Straßen New Yorks streift, stößt er auf ein paar seltsame Männer. Als er diese verfolgt, tritt er versehentlich auf eine Ratte, weshalb er entdeckt wird und gegen die Männer kämpfen muss. Beim Kampf zerbricht ein Behälter, den die Männer bei sich tragen, und bedeckt sowohl Hamato Yoshi als auch die 4 Schildkröten mit einer Chemikalie (Mutagen), durch die Splinter zu einer riesigen Ratte mutiert und die Schildkröten zu menschenähnlichen Mutanten.\n\nIn der ersten Staffel erlaubt Splinter an ihrem 15. Geburtstag den Schildkröten, die er Leonardo, Raphael, Donatello und Michelangelo genannt hat, zum ersten Mal, die Kanalisation zu verlassen. Dabei halten sie die Kraang davon ab, April O'Neil zu entführen, und freunden sich mit ihr an. Die vier Brüder machen es sich von diesem Moment an zur Aufgabe, die Bürger von New York zu beschützen, und treffen dabei auf gefährliche Feinde, allen voran der Shredder und seine Tochter Karai. Zudem versuchen sie die Pläne der Kraang aufzudecken und zu verhindern.\n\nAm Anfang der zweiten Staffel versuchten die Turtles eine Lieferung Mutagen der Kraang aufzuhalten, dabei werden die Mutagenbehälter über New York verstreut, nun ist es die Aufgabe der Turtles die Mutagenbehälter so schnell wie möglich wieder einzusammeln. Außerdem macht Donatello es sich zur Aufgabe ein \"Retro-Mutagen\" zu erschaffen, welches Mutanten wieder in Menschen verwandeln kann. Abgesehen davon versuchen die Turtles, Karai auf ihre Seite zu ziehen, da sich herausgestellt hat, dass sie Splinters Tochter ist. Nach einer Kraang-Invasion am Ende der zweiten Staffel müssen die Turtles ohne Splinter aus der Stadt fliehen.\n\nIn der dritten Staffel trainieren die Turtles auf dem Land. Dort begegnen ihnen neue Freunde und Feinde. Nach einigen Abenteuern in den Wäldern kehren die Turtles mit ihren Freunden nach New York zurück, um die Kraang zurückzuschlagen, \nwobei sie auf Slash und sein Team, die Mighthy Mutanimals treffen und sich wieder mit Splinter vereinigen. Nach einer \nharten Schlacht gelingt es den Turtles die Kraang aufzuhalten und die Menschen aus New York aus der Dimension X zu \nbefreien. Im Laufe der Staffel bekämpfen die Turtles weiter Shredder und seine Gehilfen und befreien Karai von der Gedankenkontrolle Shredders. Am Ende der Staffel starten die außerirdischen Triceratons eine Invasion,\num die Erde und damit die Kraang, ihre schlimmsten Feinde, zu zerstören. Dieser Plan gelingt auch und auch Splinter wird von Shredder von hinten erstochen. Die Turtles werden im letzten Moment jedoch von den Fugitoid, einen Roboter, gerettet.\n\nViele der Figuren basieren auf diversen Figuren vor allem aus den Mirage Comics und der 1987-iger Zeichentrickserie.\n\nDie Turtles & Verbündete\n\nMighty Mutanimals\nDie wichtigsten Feinde der Turtles\n\nAndere wichtige Charaktere\n\nNachdem Nickelodeon 2009 die weltweiten Rechte an der \"TMNT\"-Marke von der Mirage Group und 4kids Entertainment gekauft hatte, wurde angekündigt, dass man für 2012 eine neue Fernsehserie und für 2013 einen neuen Kinofilm produzieren werde.\n\nEin erster zur neuen Serie wurde unter dem Titel \"Mutation in Progress\" im März 2011 veröffentlicht, in dem klar zu erkennen ist, dass zwei der Turtles neue Waffen für die Serie bekommen haben. Donatello tauscht seinen Bō-Stab gegen ein Naginata ein und Michelangelo seine Nunchaku gegen Kusarigama.\n\nAuf der Licensing Expo in Amerika wurde ein erstes Werbebild zur neuen Serie mit dem klassischen Ausruf \"\"Turtle Power!\"\" ausgestellt. Auf dem Bild sind außerdem die vier Turtles zu sehen, wobei Donatello und Michelangelo wieder ihre ursprünglichen Waffen mit sich führen.\n\nAuf der San Diego Comic Con 2011 wurde von Nickelodeon ein weiteres abgehalten, wo die Produzenten zur Serie einige neue Information veröffentlicht haben: Die Serie soll viele Elemente der bisherigen Comics und Serien beinhalten, wodurch man ein neues Level mit den Ninja Turtles erreichen möchte. Man wird sich mehr mit dem Ninjutsu-Lebensstil, welcher sich nicht nur auf die Kampftechniken beschränkt, beschäftigen. Des Weiteren wurde die Persönlichkeiten der Turtles verfeinert, um die vier Schildkröten leichter unterscheiden zu können. Splinter wird wesentlich größer und jünger dargestellt werden als in den bisherigen Inkarnationen, damit er besser in einem Kampf gegen Shredder bestehen kann. April ist wie schon Splinter in dieser Version wesentlich jünger als zuvor, da die Nickelodeon-Autoren es unheimlich fanden, dass sich eine 30-jährige Frau mit vier Teenager-Schildkröten herumtreibt. Des Weiteren wird auch sie von Splinter unterrichtet, um eine Kunoichi, ein weiblicher Ninja, zu werden. Auch die Kraang wurden zum ersten Mal vorgestellt, und so handelt es sich bei dieser Alienrasse um eine böse Neuinterpretation der Utroms aus den Original-Comics.\n\nAm 21. Juni 2012 wurde der erste Trailer mit Szenen aus der Serie über die Webseite \"Insidetv.EW\" veröffentlicht, dabei wurde ein Erstausstrahlungsstart für Herbst 2012 angekündigt. Im Trailer kann man neben den ersten bewegten Szenen mit den vier Turtles auch den Shredder und seine Foot Ninjas sehen. Als Hintergrundmusik wird im Trailer eine Neuauflage des Titellieds der ersten Ninja-Turtles-Serie verwendet.\n\nKurz nach der Premiere der ersten Staffel wurde die Serie durch Nickelodeon Anfang Oktober 2012 um eine zweite Staffel, bestehend aus weiteren 26 Folgen, verlängert. Während der \"Nickelodeon Upfront\" Präsentation in New York wurde angekündigt, dass die Serie bereits um eine dritte Staffel verlängert wurde. Am 18. Juni 2014 wurde die Serie um eine vierte Staffel, bestehend aus 20 Folgen, verlängert und bekannt gegeben, dass Seth Green Jason Biggs als Sprecher von Leonardo ab der dritten Staffel ablösen wird.\n\nDie deutsche Synchronfassung wird bei der \"Deutschen Synchron Filmgesellschaft\" in Berlin produziert. Dialogregie an der Serie führt Andreas Böge, der auch das Buch dazu schreibt.\nAm 14. Juli 2012 wurde die erste Vorschau auf die Serie bei Nickelodeon Deutschland ausgestrahlt. Die Ausstrahlung der Serie begann offiziell am 4. November 2012.\n\nDie Episoden sind nach ihrer Produktionsreihenfolge auf DVD erhältlich. In der folgenden Liste sind die Episoden nach ihrer Produktionsnummer (siehe \"Prod. Code\" in \"Episodenliste\") aufgezählt:\n\n\n\nPlaymates Toys produziert eine Reihe von Actionfiguren zur Serie.\nMitte 2012 veröffentlichte Playmates Toys die erste Serie von Teenage Mutant Ninja Turtles Actionfiguren der 4 Schildkröten, Splinter und April O'Neil sowie Shredder, die Kraang und Foot-Soldaten. Anfang 2013 wurde die zweite Serie veröffentlicht, die Metalhead, Dogpound und Fishface beinhaltete. Im April 2013 erschien die dritte Serie mit Leatherhead, Snakefake und Baxter Stockman veröffentlicht. Serie vier beinhaltet Rattenkönig und Spy Roach sowie \"Stealth Tech\"-Versionen der Turtles und wurde im August 2013 veröffentlicht. Anfang Oktober 2013 erschien die fünfte Serie mit einem Pack mit sieben Mousers sowie vier Babyversionen der Turtles (Turtles im Training). Ende Oktober 2013 wurde Serie 6 veröffentlicht, die Spider Bytez und eine neue Figur von Shredder mit entfernbarem Helm und Umhang enthielt. Im Frühling 2014 sollen der Molchinator, Kirby Bat, der Squirrelannoid/das Eichhörnchenmonster und Mutagen Man erscheinen. Zudem werden wohl weitere Figuren veröffentlicht werden.\n\nEs existieren Lego-Sets zur Serie.\nJeden Monat kommt ein neues Magazin von den Teenage Mutant Ninja Turtles heraus, das erste im Juni 2014.\n\n2013 wurde von Nickelodeon \"Teenage Mutant Ninja Turtles: Rooftop Run\" als App für iOS veröffentlicht. \"Teenage Mutant Ninja Turtles: Out of the Shadows\" wurde am 28. August 2013 für Xbox 360 und Windows von Activision veröffentlicht, ein Jahr später auch für PlayStation 3. Es ist ein 3D Beat ’em up und beinhaltet einen Online Mehrspieler Modus und einen Co-Op Modus für bis zu 4 Personen.\n\nActivision veröffentlichte ein Spiel basierend auf der Serie für Wii, Xbox 360 und Nintendo 3DS am 22. Oktober 2013.\n\n\n"}
{"id": "6276823", "url": "https://de.wikipedia.org/wiki?curid=6276823", "title": "Coleco Adam", "text": "Coleco Adam\n\nDer Coleco Adam ist ein historischer, ausschließlich in den USA vermarkteter Heimcomputer mit Zilog Z80-Prozessor. Das US-amerikanische Unternehmen Coleco versuchte ab 1983, mit dem Adam an den Erfolg seiner Spielkonsolen (ColecoVision) anzuknüpfen. Den Adam plagten jedoch vor allem zu Beginn der Produktion verschiedene technische Probleme, und der Markterfolg blieb aus. Coleco stellte den Verkauf des Adam 1985 ein; das Unternehmen meldete 1988 Insolvenz an.\n\nDer Coleco Adam wurde als Komplettsystem mit umfangreicher Software und Peripherie verkauft, zu der auch ein Bandlaufwerk (später ein 5¼-Zoll-Diskettenlaufwerk) und ein Typenrad-Drucker gehörte. Wie damals bei Heimcomputern üblich, war es vorgesehen, einen Fernseher als Monitor zu nutzen.\n\nÜber einen Cartridge-Steckplatz konnten die Spiele des ColecoVision-Systems auf dem Adam genutzt werden. Umgekehrt konnte auch eine ColecoVision-Konsole durch Zukauf von Hardware zu einem Adam erweitert werden.\n\nDer Adam generiert beim Start ein starkes elektromagnetisches Feld, das Datenträger beeinträchtigen oder gar löschen kann, wenn sie im Gerät verbleiben.\n\nDer Drucker enthält die Stromversorgung für das gesamte System, das ohne diesen nicht lauffähig ist.\n\n\nIm Unterschied zu zeitgenössischen Konkurrenzprodukten war Colecos Variante des BASIC-Interpreters, Smartbasic, nicht im ROM gespeichert, sondern auf einem Datenträger beigelegt. Smartbasic war weitgehend kompatibel mit Applesoft BASIC, wodurch ein umfangreiches, bestehendes Angebot an Software erschlossen wurde.\n\nDas System bootet beim Start zunächst in einen Schreibmaschinen-Modus. Per Tastendruck lässt sich in eine Textverarbeitung (\"SmartWriter\") umschalten. Weitere Systemkomponenten sind das \"Elementary Operating System (EOS)\" und das ColecoVision Betriebssystem.\n\nDas Betriebssystem CP/M war als Option erhältlich.\n\nColeco stellte den Adam im Juni 1983 auf der Consumer Electronics Show (CES) vor. Als Verkaufsziel bis Weihnachten 1983 wurde eine halbe Million Einheiten angegeben. Von der Vorstellung des Systems bis zum Beginn der Auslieferung stieg der Verkaufspreis von 525 auf 725 US-Dollar. Vergleichbares Zubehör eingerechnet lag er damit etwa gleichauf mit dem Konkurrenzprodukt Commodore 64, und deutlich unter dem IBM PCjr.\n\nDer Adam wurde von der amerikanischen Fachpresse weitgehend positiv bewertet; Tastatur und Drucker waren von guter Qualität, Sound und Graphik entsprachen dem Standard der Zeit. Die Verkaufszahlen erreichten jedoch nicht die Erwartungen; darüber hinaus traten viele Kunden aufgrund der oben genannten technischen Probleme vom Kauf zurück. Im vierten Quartal 1984 brachte der Adam Coleco einen Verlust von 35 Millionen US-Dollar.\n\nAls Gegenmaßnahmen legte Coleco eine neue Betriebsanleitung für den Adam auf, reduzierte den Verkaufspreis, und vergab für jedes gekaufte Gerät die Option auf ein College-Stipendium in Höhe von 500 Dollar. Dennoch wurden insgesamt weniger als 100.000 Geräte verkauft, und der Adam wurde bereits 1985 wieder vom Markt genommen.\n\nDas Projekt Adam schwächte Coleco und verbrauchte einen großen Teil des Kapitals das die Firma mit dem Verkauf der Puppenfiguren-Reihe Cabbage Patch Kids angesammelt hatte; Coleco meldete 1988 Insolvenz an.\n\nBis mindestens 2012 gibt oder gab es in den USA eine jährliche Adam-Convention, \"AdamCon\".\n\n\n"}
{"id": "6278059", "url": "https://de.wikipedia.org/wiki?curid=6278059", "title": "Autodesk Animator", "text": "Autodesk Animator\n\nAutodesk Animator ist ein 2D-Animations- und Grafikprogramm, das 1989 von Autodesk für MS-DOS-PCs erschienen ist.\n\nDamit erzeugte Animationen im Dateiformat *.FLC und *.FLI waren bis Anfang der 1990er Jahre recht verbreitet. Auch Spielehersteller erstellten damit kurze Intro- oder Zwischensequenzen, erkennbar an der Dateiendung.\n\nDie Animationen bestehen aus verschiedenen Einzelbildern, vergleichbar mit Animated GIF. Abspielbar waren die Dateien mit einem (kostenlosen) Player für die DOS-Kommandozeile.\nEs folgte eine erweiterte Version namens \"Animator Pro\" und 1995 eine Version für Windows 3.1/95, welche auch Videos im AVI-Format ausgeben konnte. Autodesk stellte das Produkt ein. Später gab jedoch Jim Kent, einer der Autoren der Software, den Quellcode frei.\n"}
{"id": "6279340", "url": "https://de.wikipedia.org/wiki?curid=6279340", "title": "All-in-one-Computer", "text": "All-in-one-Computer\n\nUnter einem All-in-one-Computer versteht man einen stationären Computer, bei dem Hauptplatine und Monitorteil in einem gemeinsamen Gehäuse untergebracht sind. Außerdem wird der Begriff auf Desktop-Computer eingeschränkt, da er auf alle mobilen Geräte wie Notebooks, Tablet-Computer und Portables konzeptbedingt immer zutrifft.\n\nEin wichtiger Vorteil dieser Bauweise ist, dass die fehlerträchtige und oft unansehnliche Verkabelung weitgehend entfällt. Zusätzlich verringert sich der Stromverbrauch gegenüber Einzelkomponenten, wenn bei der Konstruktion auf Notebookkomponenten oder zumindest verbrauchsreduzierte Komponenten zurückgegriffen wird. Diese sind in der Regel allerdings etwas leistungsschwächer, produzieren aber auch weniger Abwärme, sodass auf störend laute Lüfter oft verzichtet werden kann.\n\nWenn ein optisches Laufwerk fehlt, muss bei Bedarf auf ein externes Laufwerk mit Anschluss per USB zurückgegriffen werden.\n\nBei den ersten Geräten dieser Bauart wurde der Begriff All-in-one noch nicht verwendet. Es waren beispielsweise Systeme von IBM (5100-Serie, 1975), die frühen Modelle von Commodore (PET 2001 von 1977, sowie nachfolgende CBM-Serie) und Tandy (TRS-80 Modelle 3 und 4, 1980 beziehungsweise 1983), bei denen sogar die Tastatur fest ins Gehäuse integriert war. IBM bezeichnete seine zwischen 20 und 48 Kilogramm schweren Geräte in Bezug auf schrankgroße Minicomputer als „portable“ Computer.\n\nIm Jahr 1984 stellte die Firma Apple nicht nur den ersten grafisch gesteuerten Computer für den Massenmarkt, sondern auch den wohl bekanntesten All-in-one-Computer aller Zeiten vor, den sehr kompakten Macintosh. Während diese würfelartige Gehäuseform – abgesehen von einem Modell der mäßig erfolgreichen IBM PS/2-Reihe – bei Konkurrenten keine Beachtung fand, bot Apple bis in die 1990er-Jahre immer wieder Rechner dieser Art an. Der Marktanteil Apples außerhalb der Kreativbranche war zu dieser Zeit jedoch gering und die Firma nahe am Bankrott.\n\nDies änderte sich, als Apple 1998 mit dem iMac ein Gerät in der All-in-one-Bauweise herausbrachte, das auf Anhieb erfolgreich war und heute als einer der Retter des Unternehmens gilt. Diese auf Kompaktheit und gefälliges Design ausgelegte Modellreihe wird bis heute fortgeführt. Mit der Zeit wandelte sich die Grundform des Gehäuses mit dem Aufkommen von Flachbildschirmen und höherer Miniaturisierung, weg vom Würfel und hin zum Monitor mit unscheinbarem, dahinterliegendem Flachrechner.\n\nDer in den 2000er-Jahren wieder zunehmende Erfolg Apples auf dem Verbrauchermarkt, nicht zuletzt populären Produkten wie dem iPod und iPhone geschuldet, verleitete auch andere Hersteller wie etwa Asus, Dell oder Sony ab etwa 2010 dazu, nun ebenfalls PCs in einer platzsparenden All-in-one-Konstruktion anzubieten. Anders als Apple integrieren viele dieser Hersteller zusätzlich einen Touchscreen in ihre Produkte.\n\n\n"}
{"id": "6286605", "url": "https://de.wikipedia.org/wiki?curid=6286605", "title": "K computer", "text": "K computer\n\nDer K computer (jap. , \"Kei\", [], dt. „10 Billiarden, 10 Peta-“) ist ein japanischer Supercomputer. Mit einer Rechenleistung von 10,51 Petaflops (gemessen nach LINPACK-Benchmark) galt er im November 2011 als das schnellste Rechnersystem der Welt.\n\nDie theoretische Maximalleistung liegt bei 10,51 Petaflops. Er wurde von Fujitsu gebaut und steht in Kōbe am \"RIKEN Advanced Institute for Computational Science\". Er kombiniert 88.128 SPARC64 VIIIfx CPUs (2,0 GHz) mit je 8 Prozessorkernen in 672 Schränken. Als Betriebssystem wird Linux verwendet. Der Ausbau des Systems soll im November 2012 mit 864 Schränken und einer Leistung von 11,28 Petaflops abgeschlossen sein.\n\nBereits im Juni 2011 löste der K computer in seiner ersten Ausbaustufe (8,16 PFLOPS) den chinesischen Tianhe-1A (2,56 PFLOPS) als bis dahin weltweit leistungsstärksten Supercomputer ab. Im Juni 2012 wurde dieser Rekord vom etwa doppelt so schnellen US-amerikanischen IBM Sequoia (16,3 PFLOPS) gebrochen.\n\nDer K-Computer ist ein ungeheuer großes System mit mehr als 80.000 CPUs. Das Netzwerk, das Daten wie z. B. Rechenergebnisse zwischen den CPUs austauscht spielt dabei eine sehr wichtige Rolle. Das K-Computer-Netzwerk, genannt Tofu, verwendet eine innovative Struktur mit dem Namen \"6-dimensionale Mesh / Torus\" Topologie. Diese bietet viele Kommunikationswege zwischen den benachbarten CPUs. Durch Ausführung der Datenkommunikation zwischen den CPUs auf dem kürzesten Weg und der kürzesten Zeit ist sichergestellt, dass das Netzwerk den CPUs die volle Rechenleistung ermöglicht.\n\nUm immer die höchste Leistung zu erreichen ist es weiterhin wichtig Ausfälle zu verhindern. Auch wenn ein teilweises Versagen von Komponenten auftritt, muss die Auswirkung minimiert werden. Dies wird erreicht durch eine Konfiguration von Ausweich-Routen im Netzwerk zwischen den CPUs. Ein Mechanismus, der fehlerhafte CPUs umgeht, sorgt dafür, dass der Datenaustausch fortgesetzt werden kann. Die rechnerische Verarbeitung wird nicht unterbrochen.\n\nAm 2. August 2013 gab das japanische Forschungsinstitut Riken bekannt, dass man in Zusammenarbeit mit dem deutschen Forschungszentrum Jülich die bis dato größte Simulation des Nervensystems des menschlichen Gehirns durchgeführt habe. Das zu simulierende virtuelle Neuronennetz bestand dabei aus rund 1,73 Milliarden Nervenzellen, die durch circa 10,4 Billionen Synapsen miteinander verbunden wurden. Das 82.944 CPU starke Rechencluster K benötigte dabei 40 Minuten Rechenzeit, um nur etwa 1 % der Gehirnaktivität für 1 Sekunde zu simulieren. Um ein exaktes mathematisches Modell zu erhalten, wurde jeder Synapse ein 24 Byte großer Speicher zugewiesen, was zu einem 1-Petabyte-Arbeitsspeicher-Verbrauch führte. Der Teamleiter Markus Diesmann zeigte sich bezüglich der Entwicklung, was die Simulation des Gehirn im Ganzen auf Neuronenebene angeht, sehr zuversichtlich: „Wenn Peta-scale-Computer wie K heute 1 % der Netzwerkstruktur repräsentieren können, dann […] wird mit Exa-Scale-Computern sicher innerhalb der nächsten Dekade das ganze Gehirn simulierbar.“ Als Simulationssoftware wurde das Open-Source-Projekt NEST verwendet.\n\n\n"}
{"id": "6287443", "url": "https://de.wikipedia.org/wiki?curid=6287443", "title": "Timeline 3D", "text": "Timeline 3D\n\nTimeLine 3D ist ein Präsentationsprogramm für das Betriebssystem Mac OS X und iOS. Es wurde von dem US-amerikanischen Unternehmen BEEDOCS entwickelt; der Vertrieb der deutschen Version läuft über die Webseite des Unternehmens.\n\nTimeLine 3D erzeugt Zeitleisten, die Texte, Grafiken, Hyperlinks und Anmerkungen enthalten können. Die Software hilft dabei mit vielen Werkzeugen, die Inhalte zu platzieren. Historische und chronologische Ereignisse lassen sich so grafisch ansprechend darstellen.\n\nAusgeben kann das Programm auf dem Drucker, als PDF, zu QuickTime oder Keynote. Der 3-D-Teil von TimeLine rückt die Ereignisse beim Abspielen optisch in den Vordergrund.\n\nDie etwas abgespeckte Version und preisgünstigere Variante Easy TimeLine ist über den App Store erhältlich, seit Dezember 2012 ist auch eine Version für iOS erhältlich.\n\n"}
{"id": "6287971", "url": "https://de.wikipedia.org/wiki?curid=6287971", "title": "Total Video Converter", "text": "Total Video Converter\n\nDer Total Video Converter ist ein Shareware-Programm von EffectMatrix zum Konvertieren von Video- und Audio-Dateien. Im Allgemeinen dient es dazu, die meisten der modernen Video-Formate so zu konvertieren, dass sie auf verschiedenen Video-Playern abgespielt oder als Foto-Diashow gezeigt werden können und das umgewandelte Video auf DVD gebrannt werden kann.\n\nEingeführt mit der Startversion 2.21 unterstützt der Total Video Converter beinahe alle Videoformate. Nicht unterstützt wird jedoch das SWF-Format. Die aktuelle Version (3.71) konvertiert und brennt Videos auf Blu-ray Disc und AVCHD, ein Format, das auf PlayStation 3 und Blu-ray-Playern abspielbar ist.\n\nGenau wie viele andere Video-Konverter kann auch der Total Video Converter zahlreiche Video- und Audio-Formate in eine Vielzahl anderer Formate konvertieren wie z. B. die von AVCHD, Mobiltelefonen, PDA usw. verwendeten Formate MP4 und AMR-Audio. Die aktuelle Version kann nicht nur Videos konvertieren, sondern beinhaltet auch ein Desktop Screen-Capture-Programm. Anwender haben damit die Möglichkeit, verschiedene Video- oder Audio-Dateien in einer Datei zu verbinden sowie den Ton aus verschiedenen Videos zu entschachteln, herauszunehmen und ihn in MP3, AAC etc. zu konvertieren. Das Programm enthält außerdem ein Feature zum Konvertieren von Videos in Standard-DVD-kompatibles MPEG-Format und zum Brennen der Datei auf DVD.\n\nEs gibt hauptsächlich zwei Modi im Total Video Converter: der Easy-Modus und der Erweiterte Modus:\n\nDer Easy-Modus bietet unerfahrenen Anwendern die Möglichkeit, einfach ein Video zu importieren, das gewünschte Format auszuwählen und es zu konvertieren.\n\nIm erweiterten Modus, vorzugsweise erfahreneren Anwendern zu empfehlen, können zahlreiche Komponenten des Videos wie zum Beispiel Größe, Bitrate und Audio-Codec vom Benutzer verändert werden.\n\nDer Total Video Converter läuft unter Windows 98/2000/XP/2003/Vista und Mac OS. In der auf 15 Tage limitierten Testversion erscheint auf der linken oberen Seite jedes konvertierten Videos ein Wasserzeichen.\n\nNeben dem Total Video Converter erhalten die Benutzer beim Herunterladen oder Kauf des Programms auch den Total Video Player. Mit diesem Programm können viele Video- und Audio-Formate wie zum Beispiel MP4 und VOB abgespielt werden.\n\nIm Jahr 2010 wurde der Total Video Converter für Mac herausgegeben. Im Vergleich zum Total Video Converter für Windows sind einige Funktionen wie das Brennen von Videos auf DVD noch in Bearbeitung.\n\nDie Entwickler von FFmpeg beschuldigen EffectMatrix, mit dem Total Video Converter ihre Urheberrechte zu verletzen, indem sie Software, die nur unter den Regeln der GPL vertrieben werden darf, ohne Quelltexte anbieten.\n\n\n"}
{"id": "6289346", "url": "https://de.wikipedia.org/wiki?curid=6289346", "title": "Marvel Super Heroes 4D", "text": "Marvel Super Heroes 4D\n\nMarvel Super Heroes 4D (dt. \"Marvel Superhelden 4D\") ist ein animierter Kurzfilm in 4D von der Produktionsfirma \"Threshold Animation Studios\" über Marvelfiguren der Rächer und ist im Londoner Madame Tussauds seit dem 31. Mai 2011 zu sehen. Der Kinosaal befindet sich im ehemaligen Planetarium, welches in der markanten grünen Kuppel von Madame Tussauds beheimatet war. Seit dem 26. April 2012 ist eine andere Version des Films mit einer anderen Handlung auch im New Yorker Madame Tussauds zu sehen.\n\nWeitere Versionen mit anderen Handlungen, die jeweils in den jeweiligen Orten spielen wurden auch in Madame Tussauds Las Vegas und in Bali im Jahr 2013 eröffnet.\n\nDie Superhelden Iron Man, Spider-Man, Hulk, Wolverine, Captain America und Ms. Marvel werden in den Buckingham Palace eingeladen, um eine Auszeichnung von der Queen für ihre Verdienste zu erhalten. Spider-Man und Captain America sind bereits da, finden aber einen Zettel am Eingangstor, dass die Verleihung abgesagt worden ist. Dann durchschlägt plötzlich ein roter Doppeldeckerbus die Uhr des Elizabeth Tower und fliegt auf die Helden zu, während Iron Man hinterher geflogen kommt und diesen stoppt. Daneben landet ein Mini, aus dem sich Wolverine befreit. Jetzt sieht man auch den Verursacher, einen gigantischen Roboter. Gemeinsam schaffen es die Helden schließlich, ihn zu besiegen.\n\nNun entpuppt sich der Wächter des Buckingham Palace als Doctor Doom persönlich und ein weiterer Kampfroboter taucht auf. Als dieser droht einen kleinen Hund zu zerquetschen, kommt Hulk, um ihn zu retten. Dieser hat aber anscheinend eine Hundeallergie, die einen gigantischen Nieser verursacht, der auch das Publikum trifft. Hulk gelingt es schließlich, den Roboter zu vernichten, und Iron Man fängt Dr. Doom. Doch dieser kann sich befreien und startet gigantische Roboterinsekten, die in das Kino fliegen und einen Stromausfall verursachen. Iron Man kommt den Zuschauern zu Hilfe und zieht die Insekten auf sich. Iron Man und Dr. Doom fliegen ins Weltall, während sich Iron Man von den Insekten lösen kann und diese mit Dr. Doom explodieren. Als Iron Man danach auf die Erde zu stürzen droht, wird er von Ms. Marvel gerettet.\n\n\n"}
{"id": "6293908", "url": "https://de.wikipedia.org/wiki?curid=6293908", "title": "Mageia", "text": "Mageia\n\nMageia ist eine Linux-Distribution, die im September 2010 als Abspaltung von Mandriva Linux ins Leben gerufen wurde. Der Name nach bedeutet „Magie“.\n\nIm Juni 2011 arbeiteten über 100 Personen, organisiert in mehr als 10 Teams, innerhalb der internationalen Mageia-Community an der Entwicklung. Träger des Projekts ist eine Non-Profit-Organisation, die von gewählten Mitgliedern geleitet wird.\n\nDie französische Firma Mandriva S.A., welche die Distribution Mandriva vertrieb, hatte in der Vergangenheit einige finanzielle Unsicherheiten, und auch die Zukunft von Mandriva selbst erschien ungewiss. Nach der Auflösung der zur Mandriva S.A. gehörenden Tochterfirma Edge-IT beschloss eine Gruppe ehemaliger Angestellter, zusammen mit einem Teil der Community einen Fork der Distribution zu erstellen, welcher nicht von einer Firma abhängig sein sollte. Man entschied sich für den Namen Mageia.\n\nAm 18. September 2010 wurde öffentlich die Gründung von Mageia als eigenständiger Fork aus Mandriva bekanntgegeben. Außerdem sollte die Non-Profit-Organisation Mageia.Org gegründet werden, welche die neue Distribution verwalten und koordinieren sollte. Die Leitung der Non-Profit-Organisation übernimmt eine gewählte Gruppe aus der Community, wobei die Leitung jährlich neu gewählt wird.\n\nNachdem es bereits im Vorfeld mehrere Vorschläge zum Logo für Mageia gegeben hatte, wurden die Grundsätze zum Aussehen des Logos veröffentlicht. Zwischen September und November 2010 wurden insgesamt 430 Vorschläge von 113 Künstlern eingereicht und nach mehreren Auswahlverfahren mit Einbezug der Community entschied man sich für das Logo von Olivier Faurax. Seit der Veröffentlichung von Mageia 3 wird das Logo in einer etwas überarbeiteten Form verwendet.\n\nDie erste Mageia-Version wurde am 1. Juni 2011 veröffentlicht.\n\nAm 20. Februar 2018 gaben die Entwickler bekannt, dass eine unberechtigte Person sich Zugriff auf den Server des Anmeldedienstes „Mageia Identity“ verschafft und persönliche Daten der Nutzer veröffentlicht hat. Bei einer Sichtung der Datensätze wurden zwar Ungereimtheiten bei den Hashes der Passwörter gefunden, Nutzernamen und E-Mail-Adressen waren jedoch authentisch. Die Administratoren reagierten mit einer Rücksetzung aller Passwörter und kündigten an, zusätzliche Regeln ins System einzupflegen.\n\nDie Distribution soll vor allem eine geringe Eintrittsschwelle bieten und legt hierfür Werkzeuge zur Systemkonfiguration vor, welche bereits auch in Mandriva in ähnlicher Weise zur Verfügung standen. So bietet das integrierte \"Mageia-Kontrollzentrum\" eine zentrale grafische Oberfläche an, mit der man die Hardware des Systems verwalten, sowie Software installieren, aktualisieren und deinstallieren kann.\n\nMageia bietet verschiedene Desktop-Umgebungen zur Auswahl. Als Vorauswahl der Desktop-Umgebung werden KDE Plasma 5 und Gnome angeboten, welche auch, neben Xfce, als Live ISOs zum Testen verfügbar sind. Die zusätzlich vorhandenen, reinen Installationsmedien, bieten, neben den bereits genannten, eine Auswahl an weiteren Desktop-Umgebungen. Zu diesen Desktop-Umgebungen gehören MATE, Cinnamon, LXDE, LXQt (welche Razor-qt seit Mageia 5 ersetzt), Enlightenment (E17), Openbox, WindowMaker, Fluxbox, Fvwm2 und IceWM.\n\nMageia nutzt zum Installieren von RPM-Paketen als Standard-Paketverwaltung urpm, welches Abhängigkeiten selbstständig auflöst und auch zum Aktualisieren des Systems dient.\nDie zur Verfügung stehende Auswahl an Software ist in folgende Repositorys unterteilt:\nAb Version 6 wird auch DNF (inkl. neuer grafischer Oberfläche dnfdragora) unterstützt. Auch Fedora COPR und den openSUSE Build Service werden unterstützt.\n\nEs ist geplant, alle neun Monate eine neue Version zu veröffentlichen. Diese soll dann 18 Monate lang unterstützt werden.\nEin Update von der jeweiligen Vorversion auf eine neuere Version (z. B. von 5 auf 6) wird über die Installationsmedien unterstützt.\n\nEine Portierung auf die ARM-Architektur, für Geräte wie den Raspberry Pi 2, ist in Arbeit.\n\n\nMageia war bei Distrowatch im Jahr 2012 auf Platz zwei, 2013 auf Platz vier und 2014 auf Platz sechs der aufgerufenen Distributionsseiten.\nAuf den Coverdiscs 148, 160 und 173 der englischen Zeitschrift Linux Format wurde sie mit ausgeliefert.\nIn der Ausgabe 03/2015 war Mageia 5 in der EasyLinux als DVD-Beilage erhältlich.\n\n\n"}
{"id": "6294225", "url": "https://de.wikipedia.org/wiki?curid=6294225", "title": "PC JX", "text": "PC JX\n\nDer IBM JX (oder JXPC) war ein Personal Computer, der im Jahr 1984 im asiatisch-pazifischen Raum auf den Markt kam. Er basierte auf dem wenig erfolgreichen IBM PCjr, wurde aber in Japan weiterentwickelt. Er trug die IBM-Bezeichnung 5511.\n\nDank seiner – im Gegensatz zum PCjr – professionellen Ansprüchen genügenden Tastatur, einer offiziell angebotenen optionalen Festplatte und einer auf Selbständige und das Bildungswesen ausgerichteten Vermarktung war der PC JX vor allem in Australien und Neuseeland wesentlich erfolgreicher als der PCjr in Nordamerika.\n\nDer IBM JX verfügte über die folgenden Ausstattungsmerkmale: \nIn Japan waren sowohl weiße als auch schwarze Geräte verfügbar, im sonstigen asiatisch-pazifischen Absatzmarkt waren alle IBM JX schwarz. In den 1980er Jahren war beige die dominierende Farbe für Computer- und Peripheriegehäuse, die Wahl der Farbe schwarz ist für diese Zeit sehr ungewöhnlich, zumal für eine vergleichsweise konservative Firma wie IBM.\n\nDie folgenden Schwächen erbte der IBM JX vom PCjr:\n\nWie der PCjr wurde der IBM JX mit IBM PC-DOS 2.11 ausgeliefert. Das Betriebssystem und das BIOS wurden ohne größere Anpassungen vom PCjr übernommen. Dies hatte zur Folge, dass auf den 3,5-Zoll-Disketten nur die Hälfte der Spuren genutzt werden konnte, da BIOS und Betriebssystem die 3,5-Zoll-Laufwerke wie 360 KB-5,25-Zoll ansprachen und adressierten.\n\nSpäter verkaufte IBM ein Upgrade-Set bestehend aus PC-DOS 3.21 und einem BIOS-Chip, das endlich die vollen Möglichkeiten, beziehungsweise die volle Kapazität der Diskettenlaufwerke nutzbar machte.\nBeliebte und häufige Zusatzausstattungen für den IBM JX waren eine externe 10-MB-Festplatte, welche in einem zum IBM JX passenden Gehäuse seitlich an diesen angedockt werden konnte, sowie der IBM JX-Joystick.\n\n"}
{"id": "6300805", "url": "https://de.wikipedia.org/wiki?curid=6300805", "title": "GeNiEnd2End", "text": "GeNiEnd2End\n\nGeNiEnd2End ist eine Software-Suite zum Überwachen und Verwalten der Leistung von IT-Systemen. Die GeNiEnd2End-Suite führt Performancetests an Ende-zu-Ende-Verbindungen durch und liefert Kennzahlen von Applikationsantwortzeiten aus der Benutzerperspektive.\n\nFür die IT-Administration spielt das punktuelle Monitoring von Netzwerkkomponenten (Router, Switche) eine große Rolle, wichtig ist die Aussagekraft über die IT-Qualität, also den Grad der Übereinstimmung der Ist-Leistung mit der Soll-Leistung eines IT-Systems. GeNiEnd2End überwacht die Strecke zwischen Endpunkten, also z. B. einem Server und einem Client. Administratoren können Schwellwerte für eine Dienstgüte definieren und sich bei Abweichungen benachrichtigen lassen. Über die permanente Überwachung der Leistungsfähigkeit von IT-Infrastruktur und Applikationen können Unternehmen beurteilen, ob. z. B. Latenz (Signallaufzeit) und Jitter (Schwankung der Signallaufzeit) im Netzwerk für einen VoIP-Betrieb „gut genug“ sind. Dies kann sowohl temporär vor der Einführung eines neuen Dienstes als auch permanent nach der Einführung als Qualitätssicherungsmaßnahme erfolgen. Mit Hilfe von GeNiEnd2End wird geklärt, ob es sich um ein Problem im Bereich von Netzwerk, Server oder Client handelt. Ist die Problemquelle lokalisiert, kann dort mit Hilfe von spezialisierten Analysetools das Problem behoben werden.\n\nHervorgegangen ist GeNiEnd2End aus den Produkten \"GeNiResponse\" und \"GeNiKPI\". Beides waren Erweiterungen zu bestehenden Produkten anderer Hersteller. Ursprung der Entwicklung waren Kundenanforderungen im Rahmen von Projekten, welche von bestehenden Systemen nicht erfüllt werden konnten. Aufgrund der sich einstellenden Akzeptanz am Markt fand eine Weiterentwicklung als Grundlage zu GeNiEnd2End statt. GeNiEnd2End-Installationen sind inzwischen im Mittelstand und Konzernen mit teilweise über 100.000 installierten Endpunkten zu finden.\n\nGeNiEnd2End besteht aus mehreren Komponenten. Abgesehen von GeNiEnd2End QoS, welches GeNiEnd2End Network benötigt, sind alle Module auch einzeln und unabhängig voneinander nutzbar. Gleichzeitig installierte Komponenten können aus einer zusammengefassten Oberfläche heraus benutzt werden.\n\nGeNiEnd2End Application überwacht proaktiv Ende-zu-Ende-Verbindungen mit Hilfe von Software-Agenten. Aus Anwendersicht misst GeNiEnd2End Application die Leistungsqualität geschäftskritischer Applikationen auf Client/Server-, Web- und Mainframe-Plattformen. Von der zentralen Konsole aus werden Performancetests erstellt und durchgeführt. Bei der Testdurchführung werden Datenpakete zwischen Software-Agenten, die auf Clients oder Servern installiert werden können, verschickt. Es handelt sich dabei nicht um reale Applikationsdaten, jedoch wird der Datenverkehr realer Applikationen, wie. z. B. SAP, simuliert. Als Ergebnis kann aus Anwendersicht bewertet werden, wie gut eine Applikation funktioniert. Über Verschlechterungen der Service-Qualität wird ein Administrator automatisch benachrichtigt. Die Applikationsantwortzeit wird dabei automatisch in Netzwerk- und Client/Server-Anteil unterteilt.\n\nGeNiEnd2End MultiTrace überwacht Multi-Tier Applikationen, wie sie z. B. bei Webapplikationen verbreitet sind (Web-Server, Datenbankserver, SAN). Die verteilte Paketaufzeichnung kann mittels Filtervorgaben ausschließlich die für den Netzwerkspezialisten interessanten Pakete aus dem Datenverkehr selektieren und ausgeben. Aufgezeichnete Paketmitschnitte können mit 3rd-Party Performance Analyse Tools, wie z. B. NetScout MultiSegment Analysis oder dem ClearSight Analyzer, analysiert werden. Diese unterstützen das Zusammenfügen der Datenaufzeichnungen, um eine Multi-Segment Analyse Session zu erstellen.\nEine Analyse mit Wireshark ist auch möglich, unterliegt jedoch Einschränkungen seitens Wireshark.\n\nGeNiEnd2End Network führt aktive Ende-zu-Ende Tests durch. Dabei ist sowohl eine 24/7-Überwachung als auch ein Performance-Selbsttest durch den Anwender in Zusammenarbeit mit einem HelpDesk-Mitarbeiter möglich. GeNiEnd2End Network setzt für seine Tests Endpunkte ein. Diese können auf Servern und Clients installiert werden. Zwischen den Endpunkten wird Datenverkehr erzeugt, um die Leistungsfähigkeit des Netzwerks zu messen. Anhand der Messdaten kann ein Administrator beurteilen, wie gut eine bestehende Infrastruktur für Applikationen und Dienste geeignet ist. Zu den erhobenen Parametern gehören Durchsatz, Delay, Lost Application Bytes, Paketverlust, Jitter, und der im VoIP-Umfeld verbreitete MOS-Wert.\n\nGeNiEnd2End QoS erzeugt Ende-zu-Ende Einsicht in die Quality of Service von Triple Play Netzwerken. Es ist eine Erweiterung für GeNiEnd2End Network mit dem Ziel einer automatischen Erkennung von QoS-Fehlkonfigurationen. Zu diesem Zweck werden Daten mit QoS-Parametern an einen anderen Endpunkt geschickt. Anhand der erhaltenen Daten kann GeNiEnd2End erkennen, ob die Infrastruktur einen korrekten QoS-Betrieb ermöglicht.\n\nGeNiJack ist ein integrierter Hardware Endpunkt für GeNiEnd2End, der als Messpunkt für 24/7 Ende-zu-Ende Überwachung dient. Hintergrund für die Verwendung einer dedizierten Hardware ist die Vereinfachung des administrativen Aufwandes zur Einrichtung eines Messpunktes. Es wird lediglich ein 230-V-Wechselstromanschluss und ein 10/100/GB-Ethernetkabel benötigt.\n\n"}
{"id": "6303703", "url": "https://de.wikipedia.org/wiki?curid=6303703", "title": "Blackberry Playbook", "text": "Blackberry Playbook\n\nDas Blackberry Playbook ist ein auf dem Blackberry Tablet OS (QNX) basierender Tablet-Computer der kanadischen Firma Blackberry (ehemals \"Research In Motion\"). Die Bedienung des PlayBook erfolgt über einen berührungsempfindlichen Touchscreen.\n\nDas Gerät wurde auf der RIM-Entwicklerkonferenz DevCon in San Francisco am 27. September 2010 als „erstes professionelles Tablet“ und als Antwort auf das Apple iPad vorgestellt.\nDas Playbook kam am 19. April 2011 in 20.000 Geschäften gleichzeitig auf den US-amerikanischen Markt. Mitte Juni 2011 wurde das Gerät auch in Deutschland verkauft.\n\nDas PlayBook 3G+ wurde ab August 2012 in Kanada und ab Ende September 2012 in Deutschland vertrieben. Das Gerät unterstützt neben dem PlayBook verfügbaren kabellosen Verbindungsmöglichkeiten WiFi und Bluetooth auch den Mobilfunkstandard UMTS/HSPA+.\n\nDas PlayBook sollte Kunden ansprechen, die das Gerät beruflich und auch privat nutzen möchten. Um die Sicherheit von Geschäftsdaten sicherzustellen, bietet Blackberry die Bridge-Funktion als App an, mit dem z. B. das firmeneigene Blackberry-Smartphone per Bluetooth mit dem PlayBook verbunden werden kann. Das PlayBook fungiert dann als ein separater Bildschirm und Eingabegerät in dem nur ausgewählte Anwendungen des Blackberry-Smartphones wie Kalender, Kontakte, Notizen, Nachrichten, Aufgaben und Blackberry Messenger bearbeitet, jedoch nicht lokal gespeichert werden können.\n\nDaneben unterstützt das Gerät wie die Konkurrenten von Apple (iOS) und Google (Android) die üblichen Tablet-Anwendungen wie Internetsurfen, Instant Messaging, Video- und Bildbetrachtung, E-Book-Reader, Spiele, Dokumentenbearbeitung, Navigation usw.\nMit dem im Februar 2012 kostenlos von RIM angebotenen Update vom OS 1.0 auf das OS 2.0 erhielt das PlayBook einen eigenständigen Mail-Client, so dass auch ohne Bridge-Funktion Kontakte, Kalender und Mails verwaltet werden können. Dieses Update beinhaltete außerdem eine stärkere Integration von sozialen Netzwerken sowie eine bessere Verbindung zwischen PlayBook und Blackberry-Smartphone.\nAm 3. Oktober 2012 folgte das Update auf OS 2.1.\n\nZum Lieferumfang gehörte neben dem Tablet-Computer und den Unterlagen standardmäßig ein Micro-USB-Ladegerät, ein Micro-USB-Übertragungskabel, eine schwarze Tasche und ein Putztuch.\n\nIm ersten Jahr nach Verkaufsstart konnte RIM rund 1,35 Mio. Einheiten absetzen, im zweiten Jahr waren es noch etwa 1 Mio. Einheiten.\n\nAlle PlayBook-Tablets besitzen einen hochauflösenden kapazitiven 7 Zoll WSVGA-Touchscreen. Eingesetzt sind bei allen Geräten ein 1 GB Arbeitsspeicher. Die Tablets werden je nach Ausführung mit einem 16, 32 und 64 GB großen Flash-Speicher angeboten, der nicht nachträglich erweitert werden kann.\n\nAlle Geräte unterstützen WLAN mit den Standards 802.11a/b/g/n und Bluetooth 2.1 + EDR (Enhanced Data Rate). Weiterhin sind ein GPS-Empfänger zur Navigation, ein Accelerometer zur 6-Achsen-Bewegungserkennung (Gyroskop) und ein digitaler Kompass (Magnetometer) integriert.\n\nIm Gerät sind zwei Akkus eingebaut, die zusammen eine Kapazität von 20 Wh erreichen.\nAn der oberen Gehäuseseite sind jeweils ein Taster zum Ein-/Ausschalten des Geräts, Laut- und Leisestellen der beiden integrierten Lautsprecher und zum Starten/Pausieren von Musik- und Videoanwendungen.\nDas PlayBook ist mit zwei HD-Video 1080p Kameras ausgestattet. Die Vorderseite beinhaltet eine 3 Megapixel-Kamera und die Rückseite eine 5 Megapixel-Kamera.\n\nAn der Gehäuseunterseite befinden sich ein Micro-USB-Anschluss für das Ladekabel bzw. USB-Datenkabel, ein Micro-HDMI-Anschluss für die Verbindung mit einem Fernseher oder Bildschirm und ein Anschluss für die optional verfügbare Schnellladestation.\nEine 3,5 mm Kopfhörerbuchse ist auf der Oberseite des Tablets integriert.\n\nDas PlayBook der ersten Generation ist mit einem 1 GHz ARM Cortex-A9 Dual-Core-Prozessor ausgestattet. Dieses Modell wurde mit 16, 32 und 64 GB Massenspeicher angeboten. Das ausgelieferte Betriebssystem des PlayBook war seit Februar 2012 die Version OS 2.0. Über ein Update konnte das Tablet seit dem Oktober 2012 auf die Version 2.1 gebracht werden.\n\nDie zweite Generation wurde mit einem 1,5 GHz TI OMap 4460 Dual-Core-Prozessor ausgeliefert. Die Geräte wurden nur mit einer 32 GB-Speicherversion angeboten. Zusätzlich zum WLAN und Bluetooth enthält das PlayBook 3G+ eine Mobilfunkfunktion, die UMTS/HSPA+ unterstützt. In Kanada und den USA wurde das Gerät als \"PlayBook 4G LTE\" mit einer anderen Mobilfunkkarte angeboten. Eine LTE-Variante für Europa und Lateinamerika war für 2012 geplant, deren Produktion jedoch von RIM verworfen wurde. Für die Mobilfunknutzung ist an der Geräteunterseite eine Öffnung für eine Micro-SIM-Karte vorhanden, die durch eine Plastikabdeckung gegen Verschmutzung geschlossen wird. Das Tablet wurde mit der OS-Version 2.1 ausgeliefert und war ab dem 9. August 2012 weltweit erhältlich. Für den Verkaufsstart arbeitete RIM mit den kanadischen Netzbetreibern Bell, Rogers und TELUS zusammen.\n\nIm PlayBook wird das QNX-basierte Blackberry Tablet OS als Betriebssystem eingesetzt.\nZu den bereits fest im Betriebssystem enthaltenen Programmen können weitere Apps nachträglich aus der sog. Blackberry App World entweder kostenlos oder gegen Gebühr geladen und installiert werden. Das Betriebssystem des PlayBook ist multitaskingfähig, so dass zwischen mehreren gleichzeitig laufenden Programmen gewechselt werden kann.\nDas Gerät unterstützt auch Adobe Flash 10.1 und HTML5, wo es beim HTML5-Test mit 373 Punkten in der Version 2.0 den Tablet-Markt anführte und diesen Vorsprung in der Version 2.1 auf 393 Punkte ausbaute.\n\nMit dem OS 2.0 ist das PlayBook kompatibel zu Android 2.3. Dadurch können diese Apps nach einer Portierung in das Blackberry-Format \".bar\" im Gerät installiert werden. Die portierten Apps werden nach erfolgreicher Zertifizierung durch RIM in der Blackberry App World veröffentlicht.\n\nEnde November 2011 wurde bekannt, dass das Sicherheitssystem des Betriebssystems Playbook OS von Hackern geknackt wurde, wodurch ein Vollzugriff auf das Blackberry Playbook möglich wurde. Jedoch schaffte es RIM, diese Lücke im System ab Version 2.0 erfolgreich zu schließen.\n\nDas Blackberry PlayBook unterstützt verschiedenste Audio- und Videoformate.\n\nFür das Gerät werden verschiedene Taschen in einer schwarzen Leder- oder Kunstlederausführung angeboten. Beim sog. Convertible Case aus Kunstleder wird das PlayBook passgenau eingesetzt und kann so befestigt mit dem im Case integrierten Aufsteller aufrecht gestellt werden.\n\nFür das PlayBook wird eine Schnellladestation angeboten, mit der das Gerät zweimal schneller als mit dem Standard-USB-Ladekabel aufgeladen wird. Die Ladestation hat einen speziellen 90° Anschluss und Fuß, so dass das Gerät beim Ladevorgang wie ein Bilderrahmen steht und ein Arbeiten weiter möglich ist.\n\nIm März 2012 wurde eine Minitastatur speziell für das PlayBook angeboten. Diese konnte mit Stand April 2010 nur über den US-Blackberry-Shop bezogen werden. Die Tastatur hat daher das englische Tastenlayout (QWERTY).\nDie Minitastatur wurde zusammen mit einem sog. Convertible Case ausgeliefert, in dem das PlayBook und die Tastatur zusammen aufbewahrt transportiert werden können.\n\nIm Juni 2011 startete RIM für rund 1.000 Playbooks eine Rückrufaktion, da diese aufgrund eines Betriebssystemfehlers keine Installation neuer Programme zuließen. In vielen Tests wurde bis zum Erscheinen von Playbook OS 2.0 bemängelt, dass das Tablet keinen eigenen Mailclient hatte.\n"}
{"id": "6312797", "url": "https://de.wikipedia.org/wiki?curid=6312797", "title": "Linux Gazette", "text": "Linux Gazette\n\nDie Linux Gazette war ein monatlich erscheinendes Computer-E-Zine, das sich mit Linux befasst. Verfasst werden die Artikel in Englisch, um anschließend inoffiziell in neun weitere Sprachen, darunter Russisch, Französisch und Chinesisch übersetzt zu werden. Seit Juni 2011 ist keine Ausgabe mehr erschienen.\n\nGestartet wurde das kostenlose Projekt 1995 von \"John Fisk\". Das Magazin wurde von der SSC unterstützt und veröffentlicht. Die SSC sponserte damals noch das Linux Journal, bevor es von der \"Belltown Media Inc.\" übernommen wurde.\n\nVerfasst wurden die Artikel in der Regel von Freiwilligen die schließlich von Mitarbeitern der Linux Gazette korrekturgelesen worden sind.\n\nDie Linux Gazette hob sich vor allem durch die \"Answer Gang\" von anderen Magazinen mit ähnlichen Themen ab. Dabei wurden nicht nur ausführliche Tutorien veröffentlicht, sondern auch ein manchmal gestellter Dialog in den Artikel eingefügt, die zum Thema hinführten und zum eigenen Slogan \"Making Linux just a little more fun\" passen sollten. So entstanden in der Regel amüsante und doch informative Beiträge.\n\n"}
{"id": "6313506", "url": "https://de.wikipedia.org/wiki?curid=6313506", "title": "Garland-Heckbert-Algorithmus", "text": "Garland-Heckbert-Algorithmus\n\nDer Garland-Heckbert-Algorithmus ist ein Verfahren der Computergrafik, mit dem der Detailgrad eines als Dreiecksnetz modellierten 3D-Körpers kontrolliert reduziert werden kann, ohne dabei das grundsätzliche Aussehen des Körpers zu verändern. Dies geschieht inkrementell, wobei immer eine Kante des Dreiecksnetzes gelöscht und die beiden adjazenten Knoten zu einem einzelnen Knoten zusammengefasst werden. Es wird immer diejenige Kante gelöscht, deren Entfernen die geringste optische Veränderung des Körpers bewirkt.\n\nDer Algorithmus wurde 1997 in einer Veröffentlichung von Michael Garland und Paul Heckbert vorgestellt.\n\nIn einem Dreiecksnetz wird das Löschen einer Kante und Zusammenfassen der übrig gebliebenen Knoten als Kantenkontraktion oder -kollaps bezeichnet. Der Algorithmus gibt Auskunft darüber, welche Kante gelöscht werden muss, und an welcher Stelle der neu entstandene Knoten platziert wird.\n\nDazu wird eine Fehlerquadrik verwendet, die jedem Knoten und jeder Kante zugeordnet wird. Diese gibt Auskunft darüber, wie groß der entstehende optische Fehler wäre, wenn die entsprechende Kante kontrahiert werden würde. Gleichzeitig kann mit ihr berechnet werden, wo der neu entstehende Knoten platziert werden muss, damit genau dieser Fehler (und kein größerer) entsteht.\n\nBerechne zunächst für jeden Knoten b die zugehörige initale Fehlerquadrik Q. Siehe dazu weiter unten.\n\nDanach iteriere solange, bis der gewünschte Detailgrad erreicht ist:\n\nDen Fehler, der beim Zusammenfassen zweier Knoten v und v zu einem neuen v entsteht, definiert man als: Quadrat der Summe der Abstände, die v zu allen Flächen hat, die durch irgendeins der Dreiecke definiert werden, welche an v oder v grenzen.\n\nUm zunächst den Abstand eines Punktes v zu einer Fläche F zu berechnen, kann folgende Formel verwendet werden:\n\nDabei ist b ein beliebiger Punkt in der Fläche (z. B. einer der Eckpunkte des Dreiecks, das in der Fläche liegt), und n ist der Normalenvektor der Fläche (zum Zeilenvektor transponiert).\n\nBildet man nun wie vorgesehen das Quadrat dieses Abstands, erhält man:\n\nVerwendet man homogene Koordinaten, so ist diese Rechnung gleichbedeutend mit:\n\nDie Matrix formula_4 wird als Fehlerquadrik der Fläche F bezeichnet.\n\nBetrachtet man nun einen Knoten b des Dreiecksnetzes, so kann ihm als Fehlerquadrik Q die Summe der Quadriken seiner angrenzenden Dreiecksflächen F zugewiesen werden.\n\nDie Quadrik Q wird zur Initialisierung des Algorithmus für jeden Knoten des Dreiecksnetzes berechnet.\n\nJede Kante e des Dreiecksnetzes erhält als Quadrik Q die Summe der Quadriken ihrer Endpunkte b und b:\n\nFalls der Kante e vorher noch keine Quadrik zugeordnet war (nur im ersten Iterationsschritt), oder falls sich die Quadrik im Vergleich zum letzten Iterationsschritt verändert hat (weil einer der Endpunkte durch Kantenkontraktion verschoben wurde), muss nun berechnet werden:\nUm den optimalen Punkt v zu bestimmen, muss also der Minimalwert der Fehlerfunktion gefunden werden, d. h. alle partiellen Ableitungen von formula_7 müssen gleich 0 sein.\n\nBerechnet man diese Ableitungen, erhält man folgendes zu lösende Gleichungssystem:\n\nDabei können sich mehrere Fälle ergeben:\n\nNachdem nun v bekannt ist, wird der entstandene Fehler formula_7 berechnet. Dieser Fehler wird in eine Prioritätswarteschlange eingetragen, wobei der niedrigste Fehler das Top-Element der Warteschlange ist.\n\nAus der Warteschlange wird das Top-Element entfernt. Dieses Element entspricht derjenigen Kante, deren Kontraktion den geringsten Fehler verursacht. Die Kante wird nun kontrahiert, und dem dabei neu entstehenden Punkt v wird die Fehlerquadrik der dabei zerstörten Kante zugewiesen. Dies bewirkt, dass der Fehler in den folgenden Iterationsschritten nicht nur von dem jeweils aktuellen Dreiecksnetz abhängt, sondern auch die vorherigen Veränderungen mit einbezogen werden.\n"}
{"id": "6320359", "url": "https://de.wikipedia.org/wiki?curid=6320359", "title": "Cars 2", "text": "Cars 2\n\nCars 2 ist ein US-amerikanischer Animationsfilm, der am 28. Juli 2011 (in Deutschland) erschien und von Pixar produziert wurde. Er stellt die Fortsetzung des 2006 erschien Films Cars dar. Im Film reisen das Rennauto Lightning McQueen (gesprochen von Manou Lubowski) und sein Freund Hook, der Abschleppwagen (gesprochen von Reinhard Brock), nach Japan und Europa, um am World Grand Prix teilzunehmen, jedoch wird Hook vom britischen Geheimdienst mit einem amerikanischen Agenten verwechselt.\n\nJohn Lasseter führte Regie, während Brad Lewis Ko-Regisseur war. Außerdem war Cars 2 seit dem originalen Cars der erste Film, in dem John Lasseter wieder Regie führte.\n\nDer Film wurde von Walt Disney Pictures verlegt und erschien in den Vereinigten Staaten am 24. Juni 2011. Er wurde bereits 2008 – für 2012 – unter anderem zusammen mit Oben angekündigt, und ist bereits der 12. animierte Film aus diesem Studio.\n\nNachdem Lightning McQueen zum vierten Mal den Piston Cup gewonnen hat, kehrt er in die kleine Stadt Radiator Springs zurück. Miles Axelrod, ein ehemaliger Öltycoon, berichtet im Fernsehen von seinem Umbau in ein Elektrofahrzeug und wirbt für umweltfreundliche Energie. Zu diesem Zweck ruft er den ersten „World Grand Prix“ ins Leben, wo die Autos mit dem von ihm entwickelten umweltfreundlichen Allinol-Treibstoff angetrieben werden. Obwohl Lightning McQueen die Teilnahme zunächst ablehnt, sagt er aufgrund der Provokationen des italienischen Formel-1-Rennwagens Francesco Bernoulli doch zu.\n\nWährenddessen bohren unzählige „Gurken“-Autos unter der Leitung von Professor Zündapp und einem unbekannten Anführer im Meer nach Erdöl, nachdem sie auf das größte Ölfeld der Welt gestoßen sind. Zündapps Plan ist es, die mit Allinol betankten Autos des World Grand Prix mithilfe einer als Fernsehkamera getarnten Strahlenkanone zu entzünden, um Allinol als gefährlich darzustellen und sich so die Profite aus dem Ölfeld zu sichern.\n\nDas erste Rennen des World Grand Prix findet in Tokio statt. Der britische Agent Finn McMissile und seine Gehilfin Holley Shiftwell versuchen das Komplott aufzudecken und wollen zu diesem Zweck während des Rennens den amerikanischen Informanten Rod Redline zu einer Übergabe von Beweismitteln treffen. Redline wird jedoch von Zündapps Handlangern gefangen genommen, schafft es jedoch, Hook die Beweismittel unterzuschieben. Finn McMissile und Holley Shiftwell werden so zu Hook geführt, den sie mit Redline verwechseln. Über den Teamfunk von Lightning McQueens Team nehmen sie Kontakt zu ihm auf und lotsen ihn aus der Box weg. McQueen, der während des Rennens von all dem nichts bemerkt, begeht aufgrund des Gesprächs einen Fahrfehler und unterliegt knapp Francesco Bernoulli. Daraufhin, und aufgrund McQueens Beschwerden über Hooks Verhalten während der Willkommensparty am Tag zuvor kommt es zum Zerwürfnis mit Hook, welcher enttäuscht die Heimreise antritt.\n\nDas zweite Rennen des Grand Prix findet in Porto Corsa in Italien statt, wo gleichzeitig ein Treffen der „Gurken“ unter Professor Zündapp stattfindet. Hook wird von McMissile und Shiftwell eingeschleust, um Informationen zu sammeln. Während des Rennens setzen die „Gurken“ ihre Kanone ein und treffen den Großteil der Teilnehmer. Als nun die vermeintliche Gefahr des Allinol-Treibstoffs bekannt wird, erklärt Axelrod während des letzten Rennens in London darauf zu verzichten. Lightning McQueen beschließt jedoch, nachdem er das Rennen gewonnen hat, trotzdem mit Allinol zu fahren und gibt dies in einem Fernsehinterview bekannt. Daraufhin beschließen die „Gurken“, McQueen im letzten Rennen mit der Kanone anzugreifen. Als er dies hört, fliegt Hooks Tarnung auf und wird gemeinsam mit Finn McMissile und Holley Shiftwell gefangen genommen.\n\nHook hat einen Traum, der ihm sein Verhalten aus der Sichtweise anderer zeigt und wacht daraufhin im Big Bentley in London auf, wo McMissile und Shiftwell an die Zahnräder des Uhrwerks gefesselt sind. Er kann sich befreien und macht sich auf, um seine Freunde vor einer Bombe in McQueens Box zu warnen, nichtwissend dass die Gurken die Bombe an seinem Kühler befestigt haben. Während des Rennens versuchen die „Gurken“, McQueen mit der Kanone abzuschießen, welche jedoch keinen Effekt auf ihn zeigt. Daraufhin beschließen sie, McQueen und Hook zu verfolgen und zu töten, was jedoch von McMissile, Shiftwell und McQueens Freunden verhindert wird. Als sie schließlich Professor Zündapp gefangen nehmen können, offenbart dieser, dass nur der Erbauer der Bombe diese durch seine Stimme wieder deaktivieren könne. Hook findet heraus, dass Miles Axelrod der geheime Kopf der Verschwörung ist und konfrontiert ihn damit. Hook erkannte ihn durch ein Foto seiner Motorumbauten, Axelrod bestreitet die Anschuldigungen zunächst, deaktiviert jedoch kurz vor Ablauf des Countdowns die Bombe und gesteht damit die Tat.\n\nAls Dank für die Aufdeckung der Verschwörung wird Hook bald darauf von der Queen zum Ritter geschlagen und kehrt mit seinen Freunden nach Radiator Springs zurück, wo sie den inoffiziellen „Radiator Springs Grand Prix“ veranstalten. Zum Schluss wird aufgeklärt, warum die Strahlenkanone keinen Einfluss auf McQueen hatte: Sein Team hatte das Allinol heimlich gegen richtiges Bio-Benzin ausgetauscht.\n\nLaut \"Rotten Tomatoes\" wurde der Film mit 38 % positiven Kritiken bei einem durchschnittlichen Rating von 5,5 von 10 eher mittelmäßig bis schlecht bewertet.\n\nDie deutsche Synchronisation entstand nach einem Dialogbuch von Benedikt Rabanus unter seiner Dialogregie im Auftrag der Film- & Fernseh-Synchron.\nEine hatte am 16. Juni 2017 Premiere.\n\n\n"}
{"id": "6323414", "url": "https://de.wikipedia.org/wiki?curid=6323414", "title": "Prawez (Computer)", "text": "Prawez (Computer)\n\nPrawez [] (bulgarisch ) war eine Computer-Marke, die in der bulgarischen Stadt Prawez zwischen 1980 und Anfang der 1990er vom KMT-Prawez (Kombinat für Mikroprozessortechnik Prawez ()) hergestellt wurden. Es handelte sich hauptsächlich um Apple- und IBM-Nachbauten. Die Prawez-Serie stellte zeitweise bis zu 40 % aller innerhalb des Rat für gegenseitige Wirtschaftshilfe (RGW) gehandelten Desktop-Computer.\n\nDie Bulgarische Kommunistische Partei (BKP) entschied Anfang der 1980er Jahre, mit der Produktion eigener Mikrocomputerserien zu beginnen. Im Rahmen des RGW wurden diese als eine auszutauschende Geräteklasse bestimmt. Allerdings entwickelte man keine völlig neuen Systeme, sondern spezialisierte sich auf das Klonen bereits existierender Modelle. Bestimmend war dabei auch, dass Bulgarien als Entwicklungsland eingestuft wurde und verschiedene Exportbeschränkungen für moderne Technik nicht im gleichen Umfang wie für andere Länder des RGW galten.\n\nDie ersten Modelle IMKO (individueller Mikrocomputer - ) wurden vom Institut für technische Kybernetik und Robotik entwickelt. 1981 wurden ca. 50 Stück des Modells IMKO hergestellt, das bei Nutzern beliebt war, vor allem wegen der leichten Bedienbarkeit. 1982 begann die Produktion des verbesserten Modells IMKO-2.\n\nDie IMKO-2/Prawez-8-Systeme stellten möglichst perfekte Nachbildungen des Apple II dar. Die Entwicklung der IBM-kompatiblen Serie Prawez 16 begann 1984. Im Zweigwerk in Plowdiw wurde ab 1988 der Homecomputer \"Pyldin-601\" () hergestellt. Quer über alle Modelle wurden ca. 60.000 Computer jährlich hergestellt.\n\n2013 wurde von einer Firma, die sich die Namensrechte gesichert hat, ein \"Pravetz-64M\"-Laptop vorgestellt. Die Entwicklung steht in keiner Beziehung zur originalen Produktion.\n\n1985 wurde in Prawez die erste Chipfabrik Bulgariens in Betrieb genommen. Unter anderem wurden dort die Prozessoren \"CM601\" (ein Motorola-6800-Klon), der \"CM630\" (ein Nachbau des 6502) und die Peripheriebausteine \"CM602\" (PIA MC6821), \"CM604\" (SSDA MC6852), \"CM606\" (Timer MC6840) und \"CM607\" (CRT controller MC6845) hergestellt. Die Bausteine \"CM631\", \"CM632\" und \"CM633\" bildeten einen zum Apple IIe kompatiblen Chipsatz.\n\nMit Ausnahme des Prawez 8D waren alle Modelle der Prawez-8-Serie voll kompatibel mit dem Apple II. Es war möglich, Software der ursprünglichen \"Apple II\" sowie ab 8E des \"Apple IIe\" ohne Änderungen zu verwenden. Zeichengenerator-ROM und Monitor-ROM wurden leicht modifiziert, um das kyrillische Alphabet (Kyrillisch-Großbuchstaben anstelle von Kleinbuchstaben des lateinischen Alphabets) darzustellen. Die Änderungen entsprachen denen des \"Apple II plus\" für Katakana. Außerdem wurde die Startmeldung auf \"IMCO\" bzw. \"IMCO-2M\" (anstelle von \"APPLE][\") geändert.\n\nDer \"Prawez 8M\" war eine speziell für den Militäreinsatz produzierte Version in einem Metallgehäuse mit integriertem Monitor und beweglicher Tastatur. Die Hauptplatine war eine Weiterentwicklung des Prawez 82. Neben einer Z80-CPU zum CP/M-Betrieb waren außerdem 64 kB RAM fest eingebaut. Die Ansteuerung entsprach der Apple II Language Card. Es gab verschiedene Varianten entsprechend dem Einsatzgebiet, z. B. existieren Tastaturvarianten mit eingebautem Joystick für Positionierungsaufgaben. Es wurde auch eine begrenzte Anzahl im späteren Prawez-8A-Gehäuse für den allgemeinen Einsatz, ebenfalls unter der Bezeichnung 8M hergestellt.\n\nDer \"Prawez 8Co\" stellte eine kompakte Version des Prawez 8A dar, ähnlich dem Apple IIc, jedoch weiterhin in einem Pultgehäuse. Diskettencontroller, serielle und parallele Schnittstellen wurden integriert, das RAM war fest mit 128 kB bestückt und nicht erweiterbar. 80-Zeichen-Darstellung war standardmäßig möglich. Das Gerät war als gehobener Heimcomputer gedacht. Der \"Prawez 8C\" war die darauf folgende, parallel produzierte Version mit gleichem Grundaufbau aber vollen Erweiterungsmöglichkeiten für den professionellen Einsatz. Der \"Prawez 8VC\" basierte auf der gleichen Hauptplatine wie der Prawez 8C, jedoch in einem Gehäuse, das sowohl den Monitor bereits enthielt als auch eine abgesetzte Tastatur bot.\n\nIn den späten 1980er Jahren wurde in Taschkent die usbekisch-bulgarische Gemeinschaftsfirma \"Option\" gegründet, um speziell für den Schuleinsatz in Usbekistan angepasste Rechner zu produzieren. Schätzungen zufolge wurden mehr als 50 % der Computerklassen in den Schulen der Republik Usbekistan (ca. 2500 Schulen) mit diesen Rechnern ausgestattet.\n\nDer Prawez 8D ( - dt. Heim/Haus) war als Homecomputer gedacht und ein kompatibler Nachbau des Oric Atmos. Neben dem 6502-Klon CM630 (1 MHz) wurde ein AY-3-8912 Sound-Generator sowie 48 KB RAM und 16 kB ROM verbaut. Das weiße Gehäuse war wesentlich größer als das des Oric und enthielt eine komfortable Tastatur in Standardgröße. Das Netzteil war eingebaut. Dank eingebautem Modulator konnte ein Fernseher anstelle eines speziellen Computer-Monitors verwendet werden. Das ROM enthielt geänderte Grafikroutinen, um neben dem lateinischen auch einen kyrillischen Zeichensatz zu unterstützen. Zu Beginn war nur die Speicherung auf Kassette vorgesehen. Ab 1990 wurde ein Floppycontroller sowie das Betriebssystem DOS-8D angeboten. Der Computer ist nicht weit verbreitet.\n\nDer Prawez 16 (ES1839), zu Beginn als IMKO-4 bezeichnet, stellt einen weitgehenden IBM-XT Clone dar. Es wurden verschiedene Varianten, unter anderem auch mit 8086, produziert. Insbesondere durch die verbauten Laufwerke gelten die Rechner als langsam. Spätere Modelle enthielten auch 286 und 386sx CPUs. Kurz vor Einstellung der Produktion wurde noch ein auf dem Intel 486 basierender Rechner vorgestellt.\n\nDer \"Pyldin-601\" () war Homecomputer mit dem CM601-Nachbau der Motorola-6800-CPU als Prozessor. Er wurde in Plowdiw hergestellt.\n\n"}
{"id": "6327898", "url": "https://de.wikipedia.org/wiki?curid=6327898", "title": "CCcam", "text": "CCcam\n\nCCcam ist ein nachempfundenes Conditional Access System Modul in Software (Softcam). Es wird in frei programmierbaren DVB-Receivern zur Dekodierung von Pay-TV verwendet.\n\n\nDie Emulation einer Smartcard und das Cardsharing ist in vielen europäischen Ländern verboten. In Deutschland ist hierfür unter anderem das Zugangskontrolldiensteschutzgesetz relevant, welches jedoch nur gewerbsmäßiges Handeln unter Strafe stellt. Die Rechtmäßigkeit der Weiterreichung eines Kontrollwortes innerhalb eines Receivers ist wegen diverser Patente der Verschlüsselungsanbieter zumindest umstritten. Die Algorithmen zur Gewinnung der Kontrollwörter aus einer Abo-TV Smartcard sind von den CA-Anbietern nicht offengelegt, sind also durch Reverse Engineering entstanden. Auch diese Praktiken sind in Europa höchst zweifelhaft und können beispielsweise als Computerbetrug oder Ausspähen von Daten angesehen und geahndet werden. Zahlreiche Boards, die sich mit digitaler TV-Empfangstechnik beschäftigen, haben zwischenzeitlich Diskussionen und Support für CCcam und andere Softcams eingestellt. CCcam wird nur in ausführbarer Form und nicht im Quellcode für diverse Prozessorplattformen meist anonym über das Internet verbreitet.\n"}
{"id": "6330192", "url": "https://de.wikipedia.org/wiki?curid=6330192", "title": "Microsoft Windows Server 2008 R2", "text": "Microsoft Windows Server 2008 R2\n\nWindows Server 2008 R2 ist ein Serverbetriebssystem von Microsoft und wurde am 22. Oktober 2009 veröffentlicht. Im Gegensatz zu Windows Server 2003 R2 ist Windows Server 2008 R2 nicht näher mit dem direkten Vorgänger Windows Server 2008 verwandt; Windows Server 2008 basiert auf Windows Vista, Windows Server 2008 R2 hingegen auf Windows 7. Der Windows Server 2008 R2 ist der letzte Windows Server, der die Intel Itanium Architektur unterstützt. Der Nachfolger Windows Server 2012 unterstützt nur noch die x64-Architektur.\n\nAm 22. Februar 2011 erschien das erste Service Pack, gemeinsam für Windows Server 2008 R2 und Windows 7.\n\n\"Windows Small Business Server 2011\", die letzte Version der Windows-Small-Business-Server-Produktreihe, basiert auf Windows Server 2008 R2 und wurde 2011 veröffentlicht.\n\nWindows Server 2008 R2 ist als erstes Microsoft-Betriebssystem nicht mehr für 32-Bit-Prozessoren erhältlich. Es kann ausschließlich auf 64-Bit-x86-Prozessoren sowie Intel-Itanium-Rechnern installiert werden.\n\nWindows Server 2008 R2 ist in folgenden Editionen verfügbar:\n\n\nZusätzlich sind auf Codebasis des Server 2008 R2 die Small Business Server 2011 erschienen:\n\n\nIm Windows Server 2008 R2 gibt es Folgende Neuerungen gegenüber Windows Server 2008:\n\n\n\n\n\n\n\n\n\nFolgende Voraussetzungen müssen für die Installation von Server 2008 R2 gegeben sein:\n"}
{"id": "6333673", "url": "https://de.wikipedia.org/wiki?curid=6333673", "title": "Dracut (initramfs)", "text": "Dracut (initramfs)\n\ndracut ist eine Software, um für Linux-Systeme ein initramfs – ein temporäres Dateisystem – zu erstellen. Dieses wird vom Linux-Kernel während des Bootvorgangs verwendet, bis das finale root-Dateisystem eingehängt wird.\n\nZiel von dracut ist es, eine universelle Schnittstelle zum Erzeugen eines initramfs anzubieten, die von allen Distributionen genutzt werden kann. Denn bisher nutzt jede Distribution einen selbst entwickelten Ablauf zum Generieren dieser initramfs, was Benutzbarkeit und Interoperabilität senkt und die Fehleranfälligkeit erhöht.\n\ndracut ist modular aufgebaut und bietet definierte Schnittstellen, um die Funktionalität relativ einfach erweitern zu können.\n\nAlle Module müssen in der Skriptsprache der Debian Almquist Shell (/bin/dash), einer kompakten Betriebssystem-Shell, programmiert sein.\n\ndracut bietet spezielle Dash-Funktionen an, um\n\nAls Hooks werden Dash-Skripte bezeichnet, die bei bestimmten Ereignissen aufgerufen bzw. ausgeführt werden. Diese sind …\n\nIm Sommer 2009 wurde dracut das erste Mal mit Fedora 12 Bestandteil einer weit verbreiteten Linux-Distribution. Mittlerweile ist das Projekt direkt beim Linux-Kernel-Projekt beheimatet.\n\n"}
{"id": "6337801", "url": "https://de.wikipedia.org/wiki?curid=6337801", "title": "To – A Space Fantasy", "text": "To – A Space Fantasy\n\nTo – A Space Fantasy ist ein Anime-Computeranimationsfilm des japanischen Regisseurs Fumihiko Sori aus dem Jahr 2009. Er basiert auf zwei Folgen der 19-teiligen Manga-Serie \"2001 Ya Monogatari\" von Yukinobu Hoshino. \n\nAuf Grundlage von \"2001 Ya Monogatari\" hatte 1987 bereits Yoshio Takeuchi einen 60-minütigen OVA erstellt. To beschränkt sich auf die beiden Kapitel 12. \"Symbiotic Planet\" (, \"Daen Kidō\") und 14. \"Elliptical Orbit\" (, \"Kyōsei Wakusei\").\n\nDer Film erschien in Japan am 2. Oktober 2009 in zwei Teilen auf DVD in einer Verleihversion und ab 18. Dezember 2009 in Japan auf DVD und Blu-ray-Disc als Kaufversion.\n\nAm 24./25. November 2009 wurden beide Teile über Satellit auf BS-TBS und am 27. November, 4./11./18. Dezember nach Mitternacht (und damit am vorigen Fernsehtag) als Vierteiler terrestrisch auf TBS ausgestrahlt. In Deutschland erschien er am 28. Mai 2010 unter dem Titel \"To – A Space Fantasy\" (FSK 12) ebenfalls auf DVD und Blu-Ray bei Animaze vertrieben durch WVG Medien.\n\n"}
{"id": "6338597", "url": "https://de.wikipedia.org/wiki?curid=6338597", "title": "Thomson TO7", "text": "Thomson TO7\n\nDer Thomson TO7 war ein Heimcomputer aus Frankreich, der in Deutschland nur gering verbreitet war. Er wurde als erster Computer der Firma Thomson im November 1982 vorgestellt. Das Kürzel TO steht für „Télé-Ordinateur“ (dt. Fernseh-Computer).\n\nAls besonderes Merkmal besitzt der TO7 einen Lichtgriffel, der unter einer kleinen Klappe oberhalb der Tastatur verstaut ist. Er wurde vom Betriebssystem und zahlreichen Anwendungen unterstützt – so konnte bereits das Einschaltmenü des Computers mit dem Griffel bedient werden. Diese native Unterstützung des Lichtgriffels war das Markenzeichen auch nachfolgender Computersysteme von Thomson. Der TO7 ist ferner mit einer Folientastatur ausgestattet, mit der allerdings keine hohe Tippgeschwindigkeit erreicht werden kann – auch wird jeder Anschlag durch ein kurzes akustischen Signal (Beep) begleitet. Zur Linken der Tastatur befindet sich – durch eine Klappe geschützt – ein Schacht für Steckmodule. An der Rückseite befinden sich drei Systembus- sowie eine Speicherbus-Schnittstelle. Der TO7 verfügt über kein integriertes BASIC-System. Dieses wurde auf Steckmodul von Microsoft mitgeliefert. Im Juni 1984 wurde der TO7 von seinem Nachfolger TO7-70 abgelöst.\n\n\n"}
{"id": "6343202", "url": "https://de.wikipedia.org/wiki?curid=6343202", "title": "FrameNet", "text": "FrameNet\n\nFrameNet ist ein Projekt, das im International Computer Science Institute (ICSI) in Berkeley beheimatet ist. Es wird ein elektronisches Online-Wörterbuch der englischen Sprache erstellt, welches auf semantischen Frames basiert. Ein semantisches Frame kann als ein Konzept mit einem Skript angesehen werden. Dieses beschreibt ein Objekt, einen Status oder ein Ereignis. Die lexikalische Datenbank des Projekts enthält um die 10.000 lexikalische Einheiten (\"Lexical Units\") (Tupel von einem Wort und einer Bedeutung; polysemische Wörter werden durch verschiedene \"Lexical Units\" dargestellt), 800 semantische \"Frames\" und über 120.000 Beispielsätze.\n\nFrameNet wurde vor allem von Charles J. \"Chuck\" Fillmore konzipiert.\n\nFrames\n\nFrame Elemente\n\nLexical Units\n\nRealisierung\n\nValenzen\n\nBeispielsätze\n\n\n"}
{"id": "6344042", "url": "https://de.wikipedia.org/wiki?curid=6344042", "title": "Sonderverzeichnis", "text": "Sonderverzeichnis\n\nIm Betriebssystem Windows des Anbieters Microsoft werden dem Benutzer konzeptionelle Objekte, wie etwa der Desktop, in Form von Sonderverzeichnissen () als abstrakte Konstrukte über eine Schnittstelle zum Dateisystem statt eines absoluten Verzeichnispfades zur Verfügung gestellt (Virtualisierung). Damit kann eine Anwendung das Betriebssystem unabhängig von dessen Version oder Sprache nach dem richtigen Ort für bestimmte Dateien fragen.\n\nWindows benutzt das Konzept von Sonderverzeichnissen, um den Inhalt von mit dem Computer verbundenen Speichermedien auf eine durchgängige Art und Weise so anzuzeigen, dass der Benutzer sich nicht um absolute Dateipfade kümmern muss, die sich ja einerseits schon zwischen den verschiedenen Versionen des Betriebssystems des Öfteren verändert, als auch bei den einzelnen Installationen verschieden angegeben werden können. Dieses Konzept hat sich so mit der Zeit entwickelt, weshalb jede neue Windows-Version neue Sonderverzeichnisse seit ihrer Einführung in Windows 95 gezeigt hat.\n\nUm das Logo von Microsoft „Designed for Windows“ (Für Windows entworfen) zu erhalten, musste eine Anwendung die Sonderverzeichnisse zur Verortung derjenigen Verzeichnisse benutzen, in welchen sich die Dokumente und Anwendungseinstellungen befinden.\n\nEin Sonderverzeichnis kann gleichwohl entweder eine Bezugnahme auf ein Verzeichnis des Dateisystems sein oder eine Bezugnahme auf ein „virtuelles“ Verzeichnis sein. Im ersten Fall wären sie eine Analogie zu den Umgebungsvariablen – de facto werden viele in einer Computersitzung () bestimmten Umgebungsvariablen gemäß den Vorgaben der Sonderverzeichnisse gesetzt.\n\nVirtuelle Verzeichnisse existieren eigentlich gar nicht im Dateisystem. Sie werden stattdessen über den Windows-Explorer als ein Verzeichnisbaum dargestellt, mit/zu denen der Benutzer navigieren kann. Diesen kennt man auch als den Namensraum der Windows Benutzeroberfläche (englisch \"\"). Bei Windows XP ist die Wurzel dieses Namensraumes der virtuelle Ordner \"Desktop\", von dem aus die virtuellen Verzeichnisse \"Eigene Dokumente\", \"Arbeitsplatz\", \"Netzwerkverbindungen\" (\"Netzwerkumgebung\" unter Windows 95 und 98) und \"Papierkorb\" abzweigen und zugänglich sind. Einige virtuelle Verzeichnisse (wie der Desktop) haben ein zugehöriges Sonderverzeichnis, das einen Bezug zu einem bestimmten Verzeichnis im echten Dateisystem darstellt. Der Windows Explorer bietet auf diese Weise dem Benutzer immer den kombinierten Inhalt eines virtuellen Verzeichnisses und seines zugehörigen Dateisystemverzeichnisses an. Den Explorer sieht man, wenn man in Windows den Arbeitsplatz anklickt oder die Tastenkombination WIN + E bemüht (eine Abbildung davon würde die Rechte von Microsoft tangieren). Im virtuellen Verzeichnis „Desktop“ sieht man auch die virtuellen Standardverzeichnisse. Befindet sich dort der allbekannte „Neuer Ordner“, dann wäre er ein echtes Verzeichnis und würde sich im Desktop-Verzeichnis im Profil des jeweiligen Benutzers befinden.\n\nWichtige interne Sonderverzeichnisse von Windows sind die virtuellen Verzeichnisse „Lokale Einstellungen“ und „Anwendungsdaten“, die sich zu jedem Benutzer finden. Beide Verzeichnisse werden von verschiedenen Anwendungen zu ihrer Ausführung und Verwaltung verwendet. Deshalb finden sich darunter viele weitere Verzeichnisse.\n\nEs ist eine von Programmierern leider oft nicht beachtete Konvention, dass das Sonderverzeichnis „Lokale Einstellungen“ nur für Daten verwendet werden soll, die den Computer betreffen, auf dem sich das Verzeichnis der Anwendung selbst befindet. Wohingegen die „Anwendungsdaten“ jene Informationen beinhalten soll, die mit dem eingeloggten Benutzer und seinen Einstellungen zusammenhängen. Das wird insbesondere dadurch missachtet, dass andere virtuelle Verzeichnisse verwendet und zum Windows Explorer hinzugefügt werden.\n\nDer Hintergrund: In einer Netzwerkdomäne, also einem Netzwerk, das Active Directory verwendet, um Benutzeridentitäten aktiv auf Netzwerkebene statt auf dem jeweiligen Computer aktiv zu verwalten, haben Benutzer häufig „mitwandernde“ Profile (), die immer auf den Computer heruntergeladen werden müssen, an dem sich der dazu berechtigte Benutzer anmeldet. Der ganze „Anwendungsdaten“-Verzeichnisbaum wird dabei nämlich – als Teil des mitwandernden Profils – auf den Computer heruntergeladen; nicht aber die „Lokalen Einstellungen“, die stationär sind.\n\nDie nachfolgenden beiden Tabellen führen die meisten der System- und virtuellen Verzeichnisse auf, die in Windows Vista gelten. Dabei wird auch die Version des Betriebssystems angegeben, unter dem die jeweiligen Verzeichnisse eingeführt wurden (BS Version).\n\nHinweise:\n\n\n"}
{"id": "6358102", "url": "https://de.wikipedia.org/wiki?curid=6358102", "title": "Combit Relationship Manager", "text": "Combit Relationship Manager\n\nDer combit Relationship Manager ist eine Customer-Relationship-Management-(CRM) bzw. Kundenmanagement-Software zum Verwalten von Kundenkontakten. Die Lösung basiert auf einer relationalen Client-Server Datenbank und unterstützt auf SQL-Basis den Microsoft SQL Server und das Open Source-Datenbanksystem PostgreSQL. Die CRM Lösung kann auch auf bereits bestehende SQL Serverdatenbanken aufsetzen und als Datenbank-Frontend verwendet werden.\n\nDie Software ist für analytisches CRM, operatives CRM, kollaboratives CRM und kommunikatives CRM geeignet. Zum Einsatz kommt der combit Relationship Manager vor allem in kleinen und mittelständischen Unternehmen oder projektorientierten Abteilungen großer Unternehmen. Unter anderem in Personal- und Marketingabteilungen, Vertrieb, Einkauf, Callcenter oder Support. Dabei kann er individuell an die jeweiligen Bedingungen, z. B. Branche, Anzahl der Benutzer oder Größe des Unternehmens angepasst werden. Die Oberfläche kann auf Englisch umgeschaltet werden, so kann das CRM-System auch in Filialen im Ausland und sprachlich gemischten Teams eingesetzt werden.\n\nDie erste Version des combit Relationship Managers kam 2004 auf den Markt. Seitdem hat die Fachpresse die Software mehrfach getestet.\nHergestellt und vertrieben wird der combit Relationship Manager von combit GmbH.\n\nVorläufer des combit Relationship Managers ist der address manager der combit GmbH, dessen Windows-Version 1992 auf den Markt kam und sich in 18 Jahren zu einer der bekanntesten Kontaktmanagement-Lösungen entwickelt hat. Da der address manager eine proprietäre Datenbank nutzt, stößt die Software bei sehr großen Datenmengen in Sachen Performance an Grenzen und bietet z. B. auch keine Relationen. Der combit Relationship Manager wurde parallel zum weiterhin angebotenen address manager entwickelt, um die durch die SQL-Datenbank Basis erweiterten Möglichkeiten zu nutzen.\n\nAb der Version 2006 hat die Software auch eine englische Oberfläche, seit Version 5 verarbeitet der Relationship Manager auch Unicode-Daten, z. B. japanische Schriftzeichen. Der combit Relationship Manager ist als Kauf- und seit Mai 2009 auch als Mietlizenz erhältlich. Seit September 2009 gibt es den cRM.WebAccess, mit dem per Internet auf die cRM-Daten zugegriffen werden kann. Aktuell ist die Version 9, die im Juni 2017 auf den Markt kam.\n\nDie Software hat unter anderem ein Kunden- und Kontaktmanagement, Termin- und Aufgabenmanagement, Dokumentenverwaltung, Kampagnenmanagement, Telefonie-Funktionen (CTI), und verschiedene Statistikmöglichkeiten. Enthalten sind außerdem Beispiel-Solutions mit unterschiedlichen Schwerpunkten und Modulen, die als Vorlage für die eigene Lösung verwendet werden können, z. B. Umfragen, Eventmanagement, Kampagnenmanagement, Beschwerdemanagement, Kaufentscheidungsprozesse im Buying Center. Mit dem integrierten Reportgenerator werden Auswertungen wie Datenanalyse, Reports, Kreuztabellen, Diagramme, Etiketten und Briefe ausgegeben, an einen Drucker geschickt oder als Datei gespeichert. Ausgabeformate sind u. a. PDF, RTF, Microsoft Excel, HTML, XHTML, TIFF, JPG, BMP, XML.\n\nDie Oberfläche kann mit frei definierbaren Relationen (Datenmodellierung) auf eigene Wünsche angepasst werden. Die Infozentrale gibt einen Überblick über anstehende Termine, erstellte Angebote und mögliche Verkaufschancen. In den Eingabemasken sind Automatismen eingebaut, wie zum Beispiel Eingaberegeln, Folgeverknüpfungen und Autotexte. Über den integrierten Workflow-Designer, Scripting, OLE Automation Server und E-Mail-Autopilot können Vorgänge im Unternehmen automatisiert werden.\n\nZu den Kommunikationsmöglichkeiten gehören Einzel- und Serien-E-Mails/-Briefe/-Faxe, Groupware-Funktionen, und eine Anbindung an Social Media. Aus- und eingehende E-Mails sind unter Microsoft Outlook, Mozilla Thunderbird und Tobit möglich. Als LDAP Server kann der combit Relationship Manager in anderen Programmen als Adressbuch geladen werden, z. B. in Outlook, Mozilla, Windows Personensuche. Über den cRM.WebAccess greifen die Anwender auch per Internet auf Kundendaten zu.\n\nAnbindungen an andere Softwarelösungen gibt es unter anderem für Warenwirtschaftssysteme und ERP-Systeme auf SQL-Datenbanksystem-Basis. Mit der Anbindung an Active Directory können Benutzerdaten importiert und synchronisiert werden.\n\n\n"}
{"id": "6360558", "url": "https://de.wikipedia.org/wiki?curid=6360558", "title": "Die Schlümpfe (2011)", "text": "Die Schlümpfe (2011)\n\nDie Schlümpfe (Originaltitel: \"The Smurfs\") ist ein US-amerikanischer 3D-Film – eine Mischung aus Real- und Computeranimationsfilm – aus dem Jahr 2011 von Regisseur Raja Gosnell. Die Produktion ist nach \"Die Schlümpfe und die Zauberflöte\" von 1975 der zweite Kinospielfilm um die gleichnamigen Comicfiguren des belgischen Zeichners Peyo.\n\nDie Schlümpfe leben ruhig in ihrem Pilzdorf im magischen Wald und bereiten sich auf das Blaumondfest vor. Währenddessen will Tollpatsch Clumsy für Papa Schlumpf Schlumpfwurzeln besorgen, wagt sich aber aus Versehen zu nah an das Gebiet des bösen Zauberers Gargamel. Der verfolgt ihn und wird von Clumsy unabsichtlich ins Dorf geführt. Auf der Flucht rennt Clumsy auch noch in die falsche Richtung und gerät zusammen mit Papa Schlumpf, Schlaubi, McTapfer, Muffi und Schlumpfine in einen magischen Wasserfall, der sie ins heutige Manhattan transportiert. Auch Gargamel und sein Kater Azrael folgen den Schlümpfen.\n\nIn New York gerät Clumsy in einen Karton des Werbespezialisten Patrick, der ihn mit nach Hause nimmt. Die anderen Schlümpfe folgen ihm und lernen so Patrick und seine schwangere Frau Grace kennen. Sie ist begeistert von den Fabelwesen, aber ihm passt der unangemeldete Besuch gar nicht, denn die blauen Zwerge sorgen nicht nur für viel Unruhe, sondern stören ihn auch bei der Erstellung einer neuen Make-up-Werbekampagne. Durch Clumsys erneute Tollpatschigkeit wird dann auch noch die falsche Werbung – eine mit einem Blaumond – veröffentlicht. Die Schlümpfe wollen so schnell wie möglich wieder heim, aber ihnen fehlt der Blaumond und ein Zauber.\n\nInzwischen hat Gargamel aus einer von Schlumpfines Haarsträhnen ihre blaue Essenz gewonnen und ist den Schlümpfen auf den Fersen. Er jagt sie, versagt aber immer wieder. Bis er in einem Antiquitätenladen, in dem die Schlümpfe nach einem Zauberbuch suchen, Papa Schlumpf schnappt. Der nimmt den anderen noch das Versprechen ab, ihn nicht zu retten, sondern den Zauber zu verwenden und in dieser Nacht beim Blaumond nach Hause zurückzukehren.\n\nPatrick sieht durch seine Frau und die Schlümpfe ein, dass ihm seine Familie wichtiger sein müsste als seine Arbeit und er beschließt Papa Schlumpf zu retten. Die Schlümpfe beteiligen sich trotz ihres Versprechens auch an der Rettung. Während Schlaubi das Portal ins Dorf öffnet und Hilfe holt, stürmen sie Belvedere Castle, wo sich Gargamel eingenistet hat. Der hat von Papa viel mehr Essenz bekommen und ist sehr mächtig geworden. Trotzdem besiegen ihn die Schlümpfe und Clumsy gelingt es das magische Zepter im letzten Moment aufzufangen.\n\nDurch den Zauber hat sich der Mond blau verfärbt, was Patricks Auftraggeberin für einen PR-Gag hält und ihn nicht feuert. Die Schlümpfe kehren nach Hause zurück.\n\nDer Film wurde 2011 unter der Regie von Raja Gosnell von Sony Pictures Animation und Columbia Pictures produziert. Die Musik komponierte Heitor Pereira und für den Schnitt war Sabrina Plisco verantwortlich.\n\nAm 28. Juli 2011 wurde der Film in Argentinien uraufgeführt. Am nächsten Tag folgten die Premieren in den USA und Kanada. Der Deutschlandstart war am 4. August 2011.\n\nDie deutsche Synchronisation des Films übernahm die Berliner Synchron AG in Berlin.\n\nIn der Handlung des Filmes wird die Kontinuität der bisherigen Schlumpfwelt beibehalten. Allerdings wird die Metaebene dadurch durchbrochen, dass Patrick Winslow die Schlümpfe in der Wikipedia recherchiert und findet, dass sie von Peyo geschaffen wurden.\n\n\nAus Anlass der Premiere des Films wurden in Júzcar (Spanien) zu Marketingzwecken alle Fassaden des Dorfes blau gefärbt. Bei einer Abstimmung zum Ende des Jahres 2011 wurden die Bewohner gefragt, ob die Häuser weiterhin blau bleiben oder in den weißen Ursprungszustand zurückversetzt werden sollen. 33 Bewohner stimmten gegen die Beibehaltung, 141 Bewohner für die Beibehaltung. Damit wird Júzcar blau bleiben.\n\n"}
{"id": "6362740", "url": "https://de.wikipedia.org/wiki?curid=6362740", "title": "Tinkerbell – Ein Sommer voller Abenteuer", "text": "Tinkerbell – Ein Sommer voller Abenteuer\n\nTinker Bell – Ein Sommer voller Abenteuer ist ein computeranimierter Direct-to-DVD-Film aus dem Jahr 2010, der von den DisneyToon Studios hauptsächlich in Indien produziert wurde. Der Film ist die zweite Fortsetzung des 2008 veröffentlichten Filmes Tinker Bell und basiert ebenso wie die vorangegangenen Filme auf den Charakteren des Kinderbuches \"Peter Pan\" von J. M. Barrie.\n\nBei einem Ausflug auf das Festland, trifft die Fee Tinker Bell erstmals auf einen Menschen. Während die kleine Fee von dem Mädchen namens Lizzy festgehalten wird, machen sich ihre Freundinnen zu einer abenteuerlichen Rettungsmission auf, doch Tinker Bell freundet sich schnell mit dem vernachlässigten Mädchen an.\n\n"}
{"id": "6364695", "url": "https://de.wikipedia.org/wiki?curid=6364695", "title": "Schlüsselbund (Software)", "text": "Schlüsselbund (Software)\n\nDer Schlüsselbund () ist ein System von Apple zur Verwaltung von Kennwörtern und digitalen Zertifikaten. Es erschien erstmals in Mac OS 8.6 als Teil von Apples Mail-System PowerTalk, und ist seit Mac OS 9 in das System integriert.\n\nZugriff darauf erhält der Nutzer über das Dienstprogramm Schlüsselbundverwaltung (). Außerdem ist unter Mac OS X das Kommandozeilenprogramm security verfügbar.\n\nDer Schlüsselbund ist auch in iOS enthalten.\n\nEin Schlüsselbund ist eine Datei, in der Kennwörter (etwa für Internetseiten oder drahtlose Netzwerke), digitale Zertifikate und sichere Notizen gespeichert werden können. Standardmäßig besitzt jeder Benutzer einen eigenen und das System einen gemeinsam genutzten Schlüsselbund. Über das Programm Schlüsselbundverwaltung können weitere Schlüsselbunde hinzugefügt und verwaltet werden. Standardmäßig sind drei Schlüsselbunde vorhanden:\n\nZudem kann es je nach Konfiguration, etwa in Firmennetzwerken unter /Network/Library/Keychains/, weitere Schlüsselbunde geben.\n\nAlle Schlüsselbunde sind mit einem Passwort gesichert. Der Benutzer-Schlüsselbund wird mit dem Benutzer-Passwort verschlüsselt und beim Login geöffnet, und erst beim Abmelden wieder geschlossen.\n\nWeitere Schlüsselbunde können mit eigenen Passwörtern gesichert werden, und es kann festgelegt werden, dass sich der Schlüsselbund nach einigen Minuten Inaktivität schließt.\n\nStandardmäßig muss man, um den Inhalt von z. B. Passwörtern oder sicheren Notizen anzuzeigen, das Passwort eingeben, selbst wenn der Schlüsselbund geöffnet ist.\n\nDie Schlüsselbundverwaltung bietet eine sehr umfangreiche Verwaltung für digitale Zertifikate. Unter anderem ist folgendes möglich:\n\n\nGenau genommen findet die Erstellung/Signierung von Zertifikaten nicht in der Schlüsselbundverwaltung statt, sondern im Programm \"Zertifikatsassistent\". Die Schlüsselbundverwaltung dient somit lediglich der Anzeige und Verwaltung von Zertifikaten.\n\nBenutzer und Programme können Passwörter in den Benutzerschlüsselbund schreiben. Auf diese Weise sind z. B. das E-Mail-Passwort oder Passwörter für Websites sicher gespeichert, und der Nutzer muss sie nicht jedes Mal neu eingeben.\n\nStandardmäßig ist der Zugriff nur dem Programm erlaubt, das den Eintrag erstellt hat; greifen andere Programme darauf zu, erscheint eine Warnung. Der Benutzer kann dieses Verhalten aber ändern.\n\nDie Schlüsselbundverwaltung bietet weiterhin einen Passwortgenerator für beliebig sichere Kennwörter.\n\nBenutzer können zudem sogenannte \"sichere Notizen\" erstellen und in einen Schlüsselbund speichern. Diese Notizen werden, wie der Rest des Schlüsselbunds, verschlüsselt gespeichert.\n\nDer Schlüsselbund besteht aus zwei Teilen: dem UI (z. B. die Schlüsselbundverwaltung oder das Kommandozeilen-Tool security) und dem dahinter liegenden Framework.\n\nApple hat den Quelltext des Frameworks, libsecurity_keychain, unter der Apple Public Source License veröffentlicht.\n\nFür Entwickler bietet Apple mit Security.framework ein öffentlich dokumentiertes C-API für libsecurity_framework an; mit diesem API können Programme auch den Schlüsselbund lesen und schreiben.\n\nDie Schlüsselbunde selber sind mit Triple DES verschlüsselt; für Root-CAs unter Mac OS X Lion wird Elliptic Curve Cryptography verwendet.\n"}
{"id": "6368477", "url": "https://de.wikipedia.org/wiki?curid=6368477", "title": "Device Mapper", "text": "Device Mapper\n\nDer Device Mapper ist ein Teil des Linux-Kernels (seit 2.6). Er erlaubt die Erzeugung virtueller blockorientierter Geräte, indem er deren Adressbereich auf andere blockorientierte Geräte oder spezielle Funktionen abbildet. Der Device Mapper wird vor allem für den Logical Volume Manager (LVM) und Geräteverschlüsselung genutzt. Der Device Mapper stellt einige Funktionen zur Verfügung, die LVM benötigt (und die in früheren Linux-Versionen integraler Bestandteil von LVM waren): Erzeugung und Verwaltung der blockorientierten Geräte, Snapshots (inklusive Zurückschreiben der Änderungen ins Ursprungsgerät (\"Merge\")) sowie diverse RAID-Funktionen (insbesondere Striping (Level 0) und Mirroring (Level 1)). Dank der Herauslösung aus LVM können diese Funktionen nun auch mit anderen blockorientierten Geräten (z. B. Festplatten(partitionen) und loop devices) genutzt werden. LVM und cryptsetup (LUKS) stellen Funktionen einer höheren Ebene zur Verfügung und schirmen den Benutzer so von den Details ab, die für den unmittelbaren Umgang mit dem Device Mapper (dmsetup) erforderlich sind. Geräte des Device Mappers können im laufenden Betrieb (beschreibbar eingehängtes Dateisystem) blockiert und weitgehend umkonfiguriert werden. Seit der Kernelversion 3.2 unterstützt der Device Mapper auch Thin Provisioning. Ähnlich wie LVM setzt auch die Multipath-Funktion auf dem Device Mapper auf.\n\nGeräte werden mit Hilfe des Device Mappers erzeugt, indem man dem Konsolenprogramm dmsetup neben dem Namen des Geräts folgende Daten übergibt:\n\nDie Definition eines Geräts kann aus einem einzelnen oder mehreren solchen Blöcken bestehen. So kann man mit der folgenden Konfiguration zwei Festplatten (je 100 GiB) zu einem einzigen logischen Laufwerk verbinden:\n\n0 209715200 linear /dev/sdb 0\n209715200 209715200 linear /dev/sdc 0\n\nDie vom Device Mapper erzeugten Geräte erscheinen unter /dev/mapper/ mit dem dmsetup übergebenen Namen und unter /sys/block/ mit den Kernelnamen (dm-0, dm-1, ...).\n\nÜber dmsetup kann das Zusammenspiel der Manipulation von DM-Geräten mit udev gesteuert werden. Über den Daemon dmeventd kann außerdem auf Ereignisse reagiert werden, die DM-Geräte betreffen (etwa zur Neige gehender Speicherplatz bei thin provisioning).\n\nLVM teilt dem Device Mapper mit, welche Blöcke auf einem Gerät in welcher Reihenfolge zu einem logischen Laufwerk gehören. Nach dem Anlegen des Geräts ist nicht mehr erkennbar, dass es sich um ein LVM-Gerät handelt; man könnte diese Zuweisung auch selber vornehmen. Zwei nacheinander per LVM erzeugte Laufwerke stellen sich im Device Mapper beispielsweise so dar:\n8:8 sind major und minor number für /dev/sda8, die zweite Zahl gibt die Größe an, die letzte den Offset zum Startsektor der Partition (nicht 0 wegen der LVM-Metadaten).\n\nDieser Abschnitt bezieht sich auf Snapshots von Volumes, die nicht Teil eines thin-pool Volumes sind, also auf das alte Verfahren. Snapshots werden meist per LVM erzeugt. Die LVM-Programme zeigen dann nur zwei Objekte an: das Ursprungslaufwerk und das Snapshotlaufwerk. Außerdem besteht derzeit die Restriktion, dass LVM nur Snapshotlaufwerke in derselben volume group wie das Ursprungslaufwerk anlegen kann. Dies ist eine Beschränkung des Verwaltungsprogramms (\"lvcreate\"), keine des Device Mappers. Aus dessen Sicht existieren nicht zwei, sondern vier Geräte (Snapshot vom logical volume (LV) \"test\" in der volume group (VG) \"vg0\", Name des Snapshot-LV ist \"test-snap\"):\nDas ursprüngliche Gerät \"vg0-test\" wird vom Zieltyp linear umgeschrieben auf snapshot-origin, \"vg0-test-real\" hat die ursprüngliche Definition von \"vg0-test\", unter \"vg0-test--snap\" wird die Snapshotsicht auf das Ursprungslaufwerk verfügbar gemacht, und \"vg0-test--snap-cow\" ist das Gerät, in dem per Copy-On-Write (COW) die nach Erzeugung des Snapshots am Ursprungsgerät vorgenommenen Änderungen protokolliert werden. Dies sind Snapshots auf Geräte-, nicht auf Dateisystemebene. Werden weitere Snapshots erzeugt, wird aus LVM-Sicht jeweils ein zusätzliches Laufwerk erzeugt, aus Sicht des Device Mappers jeweils zwei (Snapshot und COW).\n\nLUKS-Volumes haben einen Header-Bereich (im folgenden Beispiel zwei MiB), der Rest speichert die verschlüsselten Daten. Die Verwaltungswerkzeuge lesen aus dem Header die nötigen Parameter und legen über den Rest ein mit diesen Parametern konfiguriertes DM-Volume. Ein LUKS-Volume muss kein LVM-Volume sein. Beispielhaft ein 100-MiB-Volume:\nDas von LUKS darin angelegte, verschlüsselte Volume ist etwas kleiner:\nDer Device Mapper sieht das Volume folgendermaßen (Schlüssel gekürzt):\nWie schon bei LVM (Snapshots) gehen bei LUKS die Möglichkeiten des Device Mappers (bzw. von dmsetup) über die der Verwaltungsprogramme hinaus. So ist es über die dmsetup-Funktionen \"load\", \"suspend\" und \"resume\" möglich, die Größe eines eingehängten Volumes zu ändern, was \"cryptsetup\" nicht erlaubt.\n\nMit der Version 3.2 wurden die targets \"thin\" und \"thin-pool\" Bestandteil des Linux-Kernels. Diese targets funktionieren so, dass zunächst ein Volume für Metadaten (in der Größe des maximalen Ausbaus; 4 MiB Metadaten und 16 MiB Blockgröße reichen für etwa 1,3 TiB virtueller Kapazität) und eins für Daten (mindestens in der Größe des minimalen Ausbaus) erzeugt wird. Diese beiden Volumes werden dann über das target \"thin-pool\" verbunden. Der Pool kann mehrere Volumes (und Snapshots von diesen) enthalten. Diese werden über Nachrichten an das pool device erzeugt (dmsetup message). Im Gegensatz zu den sonstigen vom Device Mapper erzeugten Geräten kann das pool device nicht direkt als blockorientiertes Gerät beschrieben werden. Über das target \"thin\" werden dann die als normale blockorientierte Geräte ansprechbaren Objekte erzeugt (deren Größe später erhöht und verringert werden kann). Die Integration der Snapshotfunktion in das pool device reduziert nicht nur Speicherverbrauch auf den jeweils aktuell nötigen Wert (was eine größere Anzahl von Snapshots ermöglicht), sondern verringert durch eine interne Umorganisation der Snapshotverwaltung den Performanceverlust bei verketteten Snapshots. Mehrere Snapshots können sich Blöcke teilen, so dass nur einmal Speicherplatz belegt wird, die Daten aber in mehreren Volumes sichtbar sind.\n\nThin Provisioning unterstützt die primär für SSDs gedachte Funktion TRIM. Der Sinn dieser Funktion liegt allerdings nicht in den Eigenschaften und dem Schutz der darunter liegenden Hardware, sondern im Sparen von Speicherplatz, was wegen dessen Überbelegung von Bedeutung ist.\n\nDer Device Mapper stellt neben den wichtigsten targets \"linear\", \"crypt\" und \"snapshot\"/\"snapshot-origin\" eine Reihe spezieller targets zur Verfügung:\n\nProfessionelle Speichersysteme mit einem hohen Anspruch an Redundanz bieten analog zu RAID (dieselben Daten auf mehreren Geräten; Schutz vor dem Ausfall des eigentlichen Speichermediums) die Möglichkeit, auf unterschiedlichen Wegen auf dasselbe Speichermedium zuzugreifen (Schutz vor Ausfall eines der Geräte, die den Rechner mit dem Speichermedium verbinden). Dies wird vor allem bei Systemen auf Basis von Fibre Channel genutzt. Softwareseitig ist wichtig, dass das Speichermedium über einen festen Namen ansprechbar ist, der unabhängig davon ist, auf welchem Weg auf das Medium zugegriffen wird. Dies wird über das target \"multipath\" erreicht, das über viele Optionen konfiguriert werden und dadurch sogar Geschwindigkeitsunterschiede zwischen alternativen Wegen zum Speichermedium ausgleichen kann. \n\n"}
{"id": "6373718", "url": "https://de.wikipedia.org/wiki?curid=6373718", "title": "WinAVR", "text": "WinAVR\n\nWinAVR ist eine Distribution des Cross-Compilers avr-gcc zum Einsatz unter Windows. Das letzte Release erfolgte am 20. Januar 2010 vor der Einstellung des Projekts. Eine Fortsetzung des Projekts wurde Mitte 2011 angekündigt. Nach der Fortsetzung erfolgte das letzte Release am 13. November 2014.\n\nNeben dem Compiler für AVR-Mikrocontroller beinhaltete die Distribution eine komplette GNU Toolchain mit binutils, AVR-LibC, gdb, Simulator, In-System-Programmer, make und weitere aus der Unix-Welt bekannte Tools und Werkzeuge wie find, grep, awk, sed etc. sowie den auf Scintilla basierenden Programmier-Editor \"Programmer's Notepad\". Je nach Version ist nicht nur ein C- und C++-Compiler enthalten, sondern auch ein Compiler für Objective-C und eine komplette AVR32-Entwicklungsumgebung.\n\n"}
{"id": "6378671", "url": "https://de.wikipedia.org/wiki?curid=6378671", "title": "Lightweight Portable Security", "text": "Lightweight Portable Security\n\nLightweight Portable Security (kurz: LPS) ist eine Linux-Distribution des US-Verteidigungsministeriums, die im Juni 2011 veröffentlicht wurde. Das Live-System wird lediglich von einer CD oder einem USB-Stick gestartet, womit es höhere Sicherheit und Mobilität gewährt. Zudem hinterlässt es auch keinerlei Spuren auf dem Rechner.\n\nVorinstalliert sind ein Texteditor, der Taschenrechner und ein SSH-Client; eine Deluxe-Version enthält zusätzlich das Office-Paket LibreOffice und die Adobe Reader Software. Die Verschlüsselung vertraulicher Daten ist per Drag and Drop möglich. Änderungen am LPS-Stick werden beim nächsten Neustart automatisch rückgängig gemacht.\n\nMinimal vorausgesetzt wird ein x86-Prozessor sowie 1 GB RAM.\n\n"}
{"id": "6380057", "url": "https://de.wikipedia.org/wiki?curid=6380057", "title": "Digitale Bildhauerei", "text": "Digitale Bildhauerei\n\nIn der Digitalen Bildhauerei wird im Gegensatz zur herkömmlichen Bildhauerei die Skulptur nicht von Hand bearbeitet, sondern von einer hauptsächlich automatisch arbeitenden CNC-Bearbeitungsanlage.\nDas hierbei entstehende Bildnis wird entweder Schicht für Schicht im 3D-Druck-Verfahren modelliert, oder von einer CNC-Fräse oder CNC-Drehmaschine aus einem Materialblock durch Materialabtrag spanend herausgearbeitet.\n\nDigitale Bildhauerei ist somit ein Gebiet der Digitalen Kunst.\n\nUm von einer computergesteuerten Maschine hergestellt zu werden, wird für ein derart zu verwirklichendes Objekt zunächst ein digitales dreidimensionales Modell benötigt. Dieses Modell besteht meist im *.obj, *.ply oder *.stl-Format. Hierbei handelt es sich um Punktewolken, von denen jeder Körperpunkt einen Längen-, Breiten-, und Höhenwert hat, wobei jeweils drei oder mehr solcher Punkte zu zweidimensionalen Flächen verbunden sind und diese wiederum zu einem dreidimensionalen Modell vereinheitlicht werden (siehe auch Meshing).\nDie Erstellung solch eines virtuellen 3D-Modells geschieht entweder direkt am Computer durch die Modellierung in entsprechenden 3D-Grafikprogrammen, beziehungsweise auch per CAD.\n\nEs kann auch ein 3D-Scan zur Erstellung einer digitalen 3D-Kopie von bereits real existierenden Personen, Tieren oder Gegenständen durchgeführt werden. Der hierbei eingesetzte 3D-Scanner arbeitet meist berührungslos durch das Abtasten mit einem oder mehreren Laserstrahlen, kann aber auch CNC-gesteuert tastend erfolgen.\nDie dreidimensionale Abtastung erfolgt oft in mehreren Einzelansichten. Beispielsweise kann es sinnvoll sein, beim Einscannen komplexer Körper diese von mehr als einer Seite zu scannen (vorne, hinten, rechts, links, oben, unten und ggf. noch Ansichten dazwischen).\n\nNachdem das 3D-Scannen abgeschlossen ist, werden die Einzelscans am Computer zu einem fertigen 3D-Modell zusammengefügt. Die damit erzeugte Mesh-Datei hat den Vorteil, dass sie mit entsprechenden 3D-Programmen virtuell künstlerisch verändert werden kann. So ist es z. B. möglich, beim Erstellen einer Büste, dem Kopf einer eingescannten Person einen Hut, eine Brille oder beliebig viele andere Variationen vom Original hinzuzufügen.\nDieser Schritt der Computerbearbeitung wird oft als die \"eigentliche digitale Bildhauerei\" bezeichnet.\n\nNach der Fertigstellung des virtuellen 3D-Modells wird dieses zu einem CAM-Programm gesendet. Wenn für die Herstellung der realen Skulptur eine CNC-Maschine vorgesehen ist, übersetzt das CAM-Programm nun die Mesh-Datei in Fräsbahnen, welche von der CNC-Fräse oder CNC-Drehmaschine exakt nach Vorgabe abgefahren werden. Auf diese Weise wird Bahn für Bahn, oder im Falle von 3D-Druck, Schicht für Schicht, das fertige 3D-Objekt hergestellt.\n\n3D-Druck hat den Vorteil, dass sich im Modell auch innere Strukturen darstellen lassen, die ein Fräser nicht erreichen würde. Jedoch ist die Materialwahl beim 3D-Druck eingeschränkt, daher werden meist Kunststoff oder Pulvermaterialien eingesetzt. Beim CNC-Fräsen ist die Materialwahl nahezu uneingeschränkt möglich, da sich mit einem geeigneten Fräser fast jedes Material zerspanen lässt.\nDie gewünschte Oberflächengüte beeinflusst entscheidend die Fräszeit. Je feiner die Oberfläche sein soll, umso kleiner muss der Fräser sein, und umso mehr Bahnen muss er in umso kleineren Abständen zueinander fahren.\n\n"}
{"id": "6382804", "url": "https://de.wikipedia.org/wiki?curid=6382804", "title": "Text Engineering Software Laboratory", "text": "Text Engineering Software Laboratory\n\nTesla (Text Engineering Software Laboratory, deutsch \"Labor zur Verarbeitung von Texten\") ist eine Software, mit der reproduzierbare Experimente auf textuellen Daten durchgeführt werden können. Als textuelle Daten gelten dabei alle Arten von Daten, die sich durch eine Sequenz diskreter Einheiten darstellen lassen.\n\nTesla wird seit 2005 am Institut für Linguistik der Universität zu Köln (Abteilung Sprachliche Informationsverarbeitung) entwickelt und stellt eine Software-Umgebung für Wissenschaftler, die mit Texten arbeiten, zur Verfügung. \n\nDer konzeptuelle Schwerpunkt des Frameworks liegt dabei auf experimenteller Daten- und Verfahrensanalyse; so werden Wissenschaftler dabei unterstützt,\n\n\n\n\nTesla ist als Komponentensystem in Java implementiert, das auf Basis einer Client-Server-Architektur realisiert wurde. Über den Eclipse-basierten Client kann der Nutzer Texte verwalten und Experimente entwerfen. Experimente bestehen aus dem zu analysierenden Ausgangsmaterial (einzelne Texte oder Textsammlungen) und Komponenten, die bestimmte Aufgaben der Textprozessierung (bspw. Tokenisierung, Part-of-speech-Tagging oder Sequenzalignment) übernehmen. Die Komponenten sind miteinander kombinierbar, wenn ihre Schnittstellen aufeinander abgestimmt sind. Schnittstellen der Komponenten sind die von ihnen erzeugten Ergebnisse, die als Annotationen mit den Rohdaten (Texte) verknüpft werden. Im Unterschied zu vergleichbaren Systemen wie UIMA sind die Ein- und Ausgabeschnittstellen von Tesla-Komponenten kaum restringiert, wodurch eine fein granulierte Komponenten-Kapselung ermöglicht wird, und es bspw. auch möglich ist, komplexe Datentypen (wie Graphen oder hochdimensionale Vektoren) als Annotationen zu verwenden.\n\n\n"}
{"id": "6389177", "url": "https://de.wikipedia.org/wiki?curid=6389177", "title": "Transformers: Prime", "text": "Transformers: Prime\n\nTransformers: Prime (auch \"Transformers: Prime – The Animated Series\") ist eine US-amerikanische CGI-Serie, welche auf der Spielzeugreihe der Transformers basiert. Die Serie wird von den Hasbro Studios produziert, während die CGI-Animation im japanischen Studio Polygon Pictures erstellt wird.\n\nDie Serie stammt aus der Feder der beiden Drehbuchautoren Roberto Orci und Alex Kurtzman, welche bereits an den ersten beiden \"Live Action Transformers\"-Filmen mitgewirkt hatten, sowie Jeff Kline und Duane Capizzi. Dem Team wurde die \"Binder of Revelation\", eine 400-seitige Produktionsbibel an der Hasbro seit den Kinofilmen gearbeitet hat, zur Verfügung gestellt. Diese Bibel kombiniert die beliebtesten Transformers-Kontinuitäten, um eine komplett neue Serie zu produzieren. Das Autorenteam Nicole Dubuc, Marsha Griffin, Joseph Kuhr und Steven Melching arbeitete unter Capizzi um der Serie ein sehr cineastischen, spannendes und gefährliches Gefühl zu geben, da die heutige Jugend durch die Medien wesentlich abgestumpfter sind als zuvor.\n\nEs ist schon eine lange Zeit her, seitdem die Decepticon die Erde das letzte Mal angegriffen haben, doch in einem sicheren Moment kehren Megatron und seine Decepticons aus den Tiefen des Weltalls zurück und planen mithilfe des dunklen Energon bereits gefallene cybertronische Krieger wieder zum Leben zu erwecken und die Erde anzugreifen. Doch auf seinem Weg zur Erde wird Megatron von Optimus Prime abgefangen und von diesem in einem Kampf bis zum Tode geschlagen. Dabei zerstört Optimus die einzige Weltraumbrücke zur Erde, wodurch nur eine kleine Gruppe von Autobots auf der Erde die Menschen vor den im dunklen lauernden Decepticons beschützen können.\n\nZur selben Zeit befreunden sich die Autobots Arcee, Bulkhead und Bumblebee mit drei Menschenkindern namens Jack, Miko und Raf und sorgen in der Autobot Basis für Chaos.\n\nNach Megatrons Tod hat Starscream die Führerschaft der Decepticons übernommen und plant mithilfe des übrig geblieben Energon seine eigene Armee von Untoten zu erschaffen. Nach etlichen Gefechten zwischen den Fraktionen kehrt Megatron zurück und bestraft Starscream für seinen Versuch, die Decepticons an seiner Stelle zu führen. Zu den Decepticons stoßen währenddessen immer mehr Verbündete, wie die Wissenschaftlerin Airachnid, der Doktor Knock Out und der Krieger Breakdown, welche es den Autobots umso schwerer machen, die menschliche Rasse zu beschützen. Aber auch unter den Menschen tritt eine Armee mit dem Namen MECH in Erscheinung und versucht unter der Leitung des Terroristen Silas die gefährlichsten Waffen der Erde zu stehlen, darunter auch die Autobots und Decepticons.\n\nIm Finale der Staffel stehen sich Optimus Prime und Megatron erneut gegenüber, doch während ihres Kampfes tritt eine neue, längst totgeglaubte Macht in Erscheinung: Unicron, der Zerstörer, welcher von den 13 ersten Transformern in die unendlichen Weiten des Weltraums geworfen wurde um auf ewig in der Leere des Raums zu schweben. Wie sich herausstellt, ist Unicron der Kern der Erde und die einzige Möglichkeit sein Erwachen aufzuhalten, welches die Erde zerstören würde, ist es die Autobot Matrix der Führerschaft gegen seinen Spark, dem Lebenfunken jedes Transformers, einzusetzen. Mithilfe von Megatron gelingt Optimus dies, doch Optimus verliert dabei sein Gedächtnis und glaubt, er wäre der junge Archivar Orion Pax, welcher einst Seite an Seite mit Megatron auf Cybertron gekämpft hatte. Megatron nutzt seine Chance und kann Optimus davon überzeugen, dass die Autobots ihre eingeschworenen Feinde sind.\nDie Staffel kommt zu einem Ende als Optimus, nun Orion Pax, zusammen mit Megatron die Nemesis, das Kriegsschiff der Decepticons, betritt und den Truppen als verlorener Verbündeter vorgestellt wird.\n\nOrion Pax ist nun Teil der Decepticon Armee und arbeitet für Megatron an einer Entschlüsselung von alten cybertronischen Aufzeichnung welche die Positionen zu versteckten Waffen und Energon-Lagern preisgeben. Zur selben Zeit bereiten sich die Autobots auf die Reise nach Cybertron vor, damit Jack mithilfe eines Schlüssels den Super-Computer Vector Sigma aktivieren kann. Dieser soll Orions Erinnerungen an sein Leben als Optimus Prime wiederherstellen...\nIm Verlauf der Staffel gewinnt Optimus seine Erinnerung zurück und muss sich und die Autobots durch eine wesentlich größere Bedrohung durch MECH, welche die Technologie entwickelt haben, eigene Transformer zu erschaffen, und die Decepticons, welche alte Waffen von Cybertron für ihre Zwecke benutzen, schützen. Im Finale schafft Megatron es, das Omega-Schloss zu aktivieren, welches Cybertron revitalisieren soll. Doch anstelle es dafür zu benutzen, seinen Heimatplaneten zu retten, missbraucht er es um die Erde in ein neues Cybertron zu verwandeln. Die Autobots sehen sich gezwungen, das Omega-Schloss zu zerstören um Megatrons Wahnsinn einhalt zu gebieten, doch selbst nach diesem kleinen Sieg greifen die Decepticons die Autobot-Basis an und scheinen sogar Optimus Prime getötet zu haben...\n\nWährend sich die übriggebliebenen Autobots wieder auf der Erde sammeln, taucht der vermisste Shockwave, ein Wissenschaftler der Decepticons, wieder auf und präsentiert mit dem Predacon Predaking Megatron die optimale Lösung die Autobots auf der Erde zu jagen und endgültig zu vernichten. Zur selben Zeit konnte der Autobot-Scout Smokescreen den schwerbeschädigten Optimus Prime vor den Decepticons retten und muss nun die Entscheidung treffen ob er mithilfe des \"Schmiedehammers von Solus Prime\", einem alten Artefakt von Cybertron, das Omega-Schloss wiederaufbauen oder ob er Optimus neue Kräfte im Kampf gegen die Decepticons verleihen soll...\n\n\n\n\n\nJune Darby:\nJune Darby ist die Mutter von Jack, sie ist alles andere als froh, dass Jack nun sich immer in Gefahr durch die Autobots bringt. June Darby ist zudem Krankenschwester und gerät manchmal mit Ratchet aneinander.\n\n Die deutsche Synchronfassung der Serie wird bei \"SDI Media Germany GmbH\" in Berlin produziert.\nDie deutschen DVDs zur Serie werden von \"EDEL\" unter deren \"EDEL:kids\" Label veröffentlicht welche ebenfalls eine Hörspielreihe basierend auf der Serie produzieren. Die DVDs enthalten deutschen sowie englischen Ton.\n\n"}
{"id": "6393369", "url": "https://de.wikipedia.org/wiki?curid=6393369", "title": "GnuVocabTrain", "text": "GnuVocabTrain\n\ngnuVocabTrain ist ein kostenloser Vokabeltrainer, der verschiedene Abfragemodi und Einstellungsmöglichkeiten in einer mehrsprachigen Benutzeroberfläche bietet. Die Software wurde in Java geschrieben und ist somit auf allen Betriebssystemen lauffähig, für die eine Java-Laufzeitumgebung verfügbar ist. Das Programm hat im Jahr 2011 an Verbreitung gewonnen und wird in vielen öffentlichen Bildungseinrichtungen genutzt.\n\nMit dem Vokabeleditor können Vokabeln eingegeben und in Vokalbellisten zusammengefasst werden. Eingabehilfen für arabische, griechische, hebräische, kyrillische, lateinische Sonderzeichen sowie Lautschrift und selbst definierte Sonderzeichen und Zeichenketten erlauben vielfältiges Erfassen.\n\nDie Vokabeln können schriftlich und mündlich geübt werden; ebenso über die Abfrage von – nach Bedeutungsgruppen sortierbaren – Synonymen.\n\nZum spielerischen Erlernen neuer Vokabeln ist ein Vokabel-Memory integriert (siehe Bild).\nStatistiken zeigen den Lernfortschritt.\n\n"}
{"id": "6395320", "url": "https://de.wikipedia.org/wiki?curid=6395320", "title": "CFosSpeed", "text": "CFosSpeed\n\ncFosSpeed ist eine Software-Lösung für Traffic-Shaping für das Windows-Betriebssystem. Sie verbessert die Internet-Latenz, ohne die Bandbreite dabei nennenswert zu senken.\nDas Programm fügt sich selbst als Treiber in den Windows-Protokollstapel ein und führt dort eine Paket-Inspektion sowie eine Layer-7-Protokoll-Analyse aus.\n\nSie wird daher unter anderem häufig von Online-Spielern und Internet-Telefonie-Nutzern verwendet.\n\nDie Software teilt Datenpakete in verschiedene Klassen ein. Dieses geschieht durch vom Benutzer festlegbare Filter. Der Datenstrom kann daher unter anderem anhand des Programmnamens, des Layer-7-Protokolls (z. B. FTP, SSH, HTTP), des TCP- oder des UDP-Ports oder anhand von DSCP-Flags priorisiert werden.\n\nAusgehende Datenpakete werden nicht direkt versendet. Stattdessen werden die Pakete erst in eine Warteschlange eingeordnet und anschließend anhand ihrer Priorität abgeschickt. Auf diese Weise werden Pakete, die dringend benötigt werden, vor weniger (zeit)kritischen Paketen versandt.\n\nTraffic-Shaping stellt daher sicher, dass auch bei größeren Datenübertragungen interaktive Verbindungen wie SSH, VNC, Internet-Telefonie, Online-Spielen flüssig reagieren und auch andere zeitkritische Pakete schnell verschickt werden. Dazu kommt, dass schnelles Verschicken von (TCP-)ACK-Signalen Downloads bei überlastetem Upload beschleunigen kann. Das liegt daran, dass der Server erst weitere Daten schickt, wenn der Empfang vorhergehender Pakete bestätigt wurde (TCP-Flusssteuerung).\n\nCFosSpeed verhindert außerdem Netzwerküberlastungen bei Downloads, indem es das TCP-Fenster verringert und so verhindert, dass der Server zu viele Daten verschickt.\n\nZusätzlich verfügt cFosSpeed über einen Paketfilter-Firewall, eine Online-Zeit- und Volumenkontrolle, einen designbaren Netzwerkmonitor und vieles andere. So gibt es beispielsweise eine (Computer-)Sprache mit der Experten ihre eigenen Netzwerkklassen schreiben können.\n\nVerschiedene Nutzer berichten, dass cFosSpeed bei ihnen den gegenteiligen Effekt hervorruft. Die Bandbreite Ihres Netzwerkzugangs verringert sich durch die Nutzung von cFosSpeed teilweise dramatisch. Ein Nutzer eines Glasfaseranschlusses erreichte bei der Nutzung von cFosSpeed eine Bandbreite von lediglich 10 MBit/s, nach der Deinstallation der Software stieg die Bandbreite auf über 900 MBit/s an.\n\n\n"}
{"id": "6395365", "url": "https://de.wikipedia.org/wiki?curid=6395365", "title": "ViFlow", "text": "ViFlow\n\nViflow (Eigenschreibweise viflow oder auch ViFlow) ist eine Geschäftsprozessmanagementsoftware zur grafischen Abbildung und Verbesserung von Abläufen in Unternehmen und deren Darstellung im Intranet.\nHersteller der Software ist das Unternehmen \"ViCon\" \"GmbH\" aus Hannover (Deutschland).\n\nViflow verwendet zur grafischen Darstellung Microsoft Visio. Dazu ist Microsoft Visio vollständig in die Software Viflow integriert und erweitert diese um zusätzliche Funktionen zur zentralen Pflege von Inhalten und zur webbasierten Veröffentlichung für die Geschäftsprozessmodellierung.\n\nViflow wird mit 42.000 Lizenzen bei 7.200 Unternehmen in 45 Ländern eingesetzt (Stand 2016).\n\nDie erste Version von Viflow wurde von der ViCon GmbH im September 2000 erstmals als ViFlow 2000 veröffentlicht. Darauf folgten die Versionen ViFlow 2002 (Januar 2002) und ViFlow 2003 (April 2004).\nAb März 2006 verzichtete der Hersteller auf die Jahreszahl in der Versionsbezeichnung und veröffentlichte die Version ViFlow 4. Im Mai 2010 erschien dann die Version ViFlow 4.5 und im Februar 2013 die Version 5.\nAktuell ist die Version viflow 6, die seit 22. Juni 2016 auf dem Markt ist. Mit dieser Version wurde auch die Schreibweise des Programmnamens von \"ViFlow\" auf \"viflow\" geändert.\nIn Viflow werden Unternehmensabläufe als „Prozesse“ bezeichnet. Ein Prozess kann beliebig durch weitere Unterprozesse detaillierter beschrieben werden. Als Prozess kann man zum Beispiel den Ablauf der „Auftragsabwicklung“ bezeichnen. Dieser Prozess wird in Viflow grafisch beschrieben und mit weiteren Informationen (Wer macht was? Was wird dafür benötigt?) versehen.\nStandardeinstellung für die grafische Darstellung ist die Swimlane-Darstellung, durch die die an einem Prozess beteiligten Bereiche (Abteilungen, Personen, Systeme) als waagerechte „Schwimmbahnen“ dargestellt werden und die durchzuführenden Tätigkeiten als Prozesskästchen innerhalb dieser Bahnen platziert werden.\nDie weitergegebenen Informationen (Dokumente, Daten) werden als Pfeilverbindungen zwischen den Prozesskästchen modelliert.\n\nIn der grafischen Gestaltung ist man aber prinzipiell frei und kann nahezu alle Möglichkeiten von Microsoft Visio ausschöpfen. So ist auch die Darstellung der Prozesse nach den Konventionen der EPK-, BPMN-, FlowChart-Methode möglich.\n\nDie mit Viflow erfassten und gesammelten Informationen können als Webdarstellung erzeugt werden, sodass diese in einem firmeninternen Intranet allen Mitarbeitern zur Verfügung gestellt werden können.\n\nDer Hersteller bietet die Software in drei Editionen an: blue, silver und gold. Voraussetzung für den Betrieb ist die Software Microsoft Visio (ab Version 2010). Es wird eine Variante inkl. Microsoft Visio Standard 2016 und eine Variante ohne Visio (falls der Anwender Visio schon besitzt) angeboten.\n\nDie Oberfläche der Software ist in den Sprachen Deutsch, Englisch, Französisch, Ungarisch, Spanisch, Niederländisch und Italienisch verfügbar.\n\nViflow wird u. a. eingesetzt, um Qualitätsmanagementsysteme zu beschreiben und Qualitätsmanagementhandbücher (QM-Handbücher) papierlos zu erstellen. Weiterhin kann es für die Dokumentation von IT-Systemen, Projekten und klinischen Behandlungspfaden eingesetzt werden.\n\nViflow ist eine Software zur Geschäftsprozessmodellierung, mit der der Benutzer dieser Software die Abläufe in seinem Unternehmen grafisch darstellen kann, um sich dieser bewusst zu werden und andere Mitarbeiter darüber zu informieren. Die Software erkennt nicht automatisch eventuelle Schwachpunkte in Prozessen und schlägt auch keine Verbesserungsmaßnahmen vor.\n\nDarüber hinaus handelt es sich auch nicht um ein Workflow-System, das reale Prozesse tatsächlich ablaufen lässt und auch nicht um ein Dokumentenmanagement-System zur Verwaltung von Formularen etc. Es kann aber eine Verknüpfung von in Prozessen verwendete Dokumente auf die tatsächlichen Dokumente erstellt werden.\n\n\n"}
